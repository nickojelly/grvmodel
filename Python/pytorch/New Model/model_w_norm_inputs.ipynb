{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "with torch.profiler.profile() as profiler:\n",
    "        pass\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"DATA/total_list_72_5k.npy\", \"rb\")\n",
    "data = pickle.load(file)\n",
    "# seperate out classes from inputs\n",
    "raceIDs, inputs, classes, prices, margins, betfairSP = zip(*data)\n",
    "# removing nan from inputs and convert to float\n",
    "inputs_df = pd.DataFrame(inputs)\n",
    "inputs_df.fillna(value=-1, inplace=True)\n",
    "inputs = inputs_df.values.tolist()\n",
    "#inputs = [[float(i) for i in j] for j in inputs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluded =  0\n"
     ]
    }
   ],
   "source": [
    "REBUILD_DATA = True\n",
    "\n",
    "\n",
    "class GRV:\n",
    "    # class to store training data\n",
    "\n",
    "    # reading data from pickle\n",
    "    file = open(r\"DATA/total_list_72_5k.npy\", \"rb\")\n",
    "    data = pickle.load(file)\n",
    "    # seperate out classes from inputs\n",
    "    raceIDs, inputs, classes, prices, margins, betfairSP = zip(*data)\n",
    "    # removing nan from inputs and convert to float\n",
    "    inputs_df = pd.DataFrame(inputs)\n",
    "    inputs_df.fillna(value=-1, inplace=True)\n",
    "    inputs = inputs_df.values.tolist()\n",
    "    inputs = [[float(i) for i in j] for j in inputs]\n",
    "\n",
    "    # data\n",
    "    training_data = []\n",
    "\n",
    "    def make_training_data(self):\n",
    "        excluded = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            if len(self.classes[i]) == 8:\n",
    "                self.training_data.append(\n",
    "                    [\n",
    "                        np.array(self.inputs[i]),\n",
    "                        np.array(self.classes[i]),\n",
    "                        np.array(self.prices[i]),\n",
    "                        np.array(self.margins[i]),\n",
    "                        np.array(self.betfairSP[i]),\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                \n",
    "\n",
    "                adjustedList = self.classes[i] + ([8] * (8 - len(self.classes[i])))\n",
    "                #print(adjustedList)\n",
    "                #print(self.inputs[i])\n",
    "                adjustedListP = self.prices[i] + ([0] * (8 - len(self.prices[i])))\n",
    "                adjustedListM = self.margins[i] + ([100] * (8 - len(self.margins[i])))\n",
    "                adjustedListSP = self.betfairSP[i] + ([0] * (8 - len(self.betfairSP[i]))) # USED TO BE MARGINS DONT KNOW WHY\n",
    "                self.training_data.append(\n",
    "                    [\n",
    "                        np.array(self.inputs[i]),\n",
    "                        np.array(adjustedList),\n",
    "                        np.array(adjustedListP),\n",
    "                        np.array(adjustedListM),\n",
    "                        np.array(adjustedListSP)\n",
    "                    ]\n",
    "                )\n",
    "                if len(adjustedList) != 8:\n",
    "                    print(adjustedList)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"excluded = \", excluded)\n",
    "\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    grv = GRV()\n",
    "    grv.make_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\model_w_norm_inputs.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# dataset setup\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m training_data \u001b[39m=\u001b[39m grv\u001b[39m.\u001b[39mtraining_data\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([i[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m training_data])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m Y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(np\u001b[39m.\u001b[39marray([i[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m training_data]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grv' is not defined"
     ]
    }
   ],
   "source": [
    "softmin = nn.Softmin(dim=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# dataset setup\n",
    "training_data = grv.training_data\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data])\n",
    "Y = torch.Tensor(np.array([i[1] for i in training_data]))\n",
    "P = torch.Tensor(np.array([i[2] for i in training_data]))\n",
    "Y_m = softmin(torch.Tensor(np.array([i[3] for i in training_data]))).float()\n",
    "bfSP = torch.Tensor(np.array([i[4] for i in training_data]))\n",
    "len_dataset = len(X)\n",
    "# Generate winner only class\n",
    "Y_w = []\n",
    "for i in Y:\n",
    "    n = np.zeros(8)\n",
    "    index = torch.argmin(i)\n",
    "    n[index] = float(1)\n",
    "    Y_w.append(n)\n",
    "\n",
    "Y_w = torch.tensor([i for i in Y_w])\n",
    "\n",
    "scaler.fit(X)\n",
    "Xn = scaler.transform(X)\n",
    "Xn = torch.tensor(Xn).float()\n",
    "\n",
    "with open(\"normalizer.npy\", \"wb\") as fp:   #Pickling\n",
    "    \n",
    "    pickle.dump(scaler, fp)\n",
    "\n",
    "# Xn = nn.functional.normalize(X, dim = 1)\n",
    "X = Xn.to(device)\n",
    "Y_w = Y_w.to(device)\n",
    "\n",
    "\n",
    "Y_m = Y_m.to(device)\n",
    "P = P.to(device)\n",
    "bfSP = bfSP.to('cuda')\n",
    "bfSP = torch.nan_to_num(bfSP, nan=0)\n",
    "my_dataset = TensorDataset(X, Y_m, P, bfSP)\n",
    "my_dataloader = DataLoader(my_dataset)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1902e-08, 5.4522e-01, 1.6185e-07,  ..., 3.9502e-04, 2.0311e-02,\n",
      "         7.0031e-05],\n",
      "        [1.9163e-06, 9.9489e-01, 4.2758e-07,  ..., 4.1068e-03, 9.8058e-07,\n",
      "         9.0723e-04],\n",
      "        [1.0918e-02, 2.2546e-04, 3.8218e-07,  ..., 6.6391e-04, 2.8960e-08,\n",
      "         2.3285e-01],\n",
      "        ...,\n",
      "        [3.6189e-07, 2.8248e-04, 1.5618e-03,  ..., 3.7835e-44, 3.7835e-44,\n",
      "         3.7835e-44],\n",
      "        [2.9270e-06, 7.3968e-01, 1.1459e-03,  ..., 2.4869e-01, 2.8026e-44,\n",
      "         2.8026e-44],\n",
      "        [3.3685e-08, 7.3622e-01, 6.1377e-08,  ..., 1.2922e-01, 1.4217e-07,\n",
      "         6.5828e-08]], device='cuda:0')\n",
      "tensor([0.4167, 0.4799, 0.0000,  ..., 0.0000, 0.0000, 0.5125], device='cuda:0')\n",
      "tensor([0.4167, 0.4799, 0.0000,  ..., 0.0000, 0.0000, 0.5125])\n"
     ]
    }
   ],
   "source": [
    "print(Y_m)\n",
    "print(X[:, 119])\n",
    "print(Xn[:, 119])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to pass in dataset to get_data (created above)\n",
    "def make_loader(dataset, config, train=True):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(config[\"validation_split\"] * dataset_size))\n",
    "    random_seed = 42\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    if train:\n",
    "        dataset_sampler = SubsetRandomSampler(train_indices)\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "            num_workers=0,\n",
    "            sampler=dataset_sampler\n",
    "        )\n",
    "    else:\n",
    "        dataset_sampler = SubsetRandomSampler(val_indices)\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "            num_workers=0,\n",
    "            sampler=dataset_sampler,\n",
    "        )\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(f1_layer_size, f2_layer_size, dropout, num_layers=2):\n",
    "\n",
    "    if num_layers == 2:\n",
    "        network = nn.Sequential(  # fully-connected, dual hidden layer\n",
    "            nn.Linear(144, f1_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f1_layer_size, f2_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f2_layer_size, 8),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        network = nn.Sequential(  # fully-connected, dual hidden layer\n",
    "            nn.Linear(144, f1_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f1_layer_size, f2_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f2_layer_size, f2_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f2_layer_size, 8),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_MSE(output, target):\n",
    "    sorts = torch.argsort(target)\n",
    "    out = sorts.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    out_first3 = ohe*output\n",
    "    target_ohe = ohe*target\n",
    "    loss = torch.sum((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "    # loss = torch.sum(((out_first3-target_ohe))**2)\n",
    "    return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,2,3,5,6]])\n",
    "y =torch.tensor([[6,2,3,4,5]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_order_MSE(output, target):\n",
    "    sorts = torch.argsort(target)\n",
    "    print(sorts)\n",
    "    out = sorts.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    out_first3 = ohe*output\n",
    "    target_ohe = ohe*target\n",
    "    loss = torch.mean(((abs(out_first3-target_ohe)*10)**2))\n",
    "    # loss = torch.sum(((out_first3-target_ohe))**2)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_customiser(x,y,loss_func=nn.HuberLoss(reduction='none',delta=0.1)):\n",
    "    sorts_t = torch.argsort(y)\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    loss = loss_func(x,y)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_l1(x=None,y=None,beta=0.1):\n",
    "    loss_func=nn.SmoothL1Loss(reduction='none',beta=beta)\n",
    "    sorts_t = torch.argsort(y)\n",
    "    sorts_o = torch.argsort(x)\n",
    "    diff_place = abs(sorts_t-sorts_o)\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    loss = loss_func(x,y)*ohe\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_l1_place(x=None,y=None,beta=0.1):\n",
    "    loss_func=nn.SmoothL1Loss(reduction='none',beta=beta)\n",
    "    sorts_t = torch.argsort(y)\n",
    "    sorts_o = torch.argsort(x)\n",
    "    diff_place = abs(sorts_t-sorts_o)\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    loss = loss_func(x,y)*diff_place\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_l1_place_1(x=None,y=None,beta=0.1):\n",
    "    loss_func=nn.SmoothL1Loss(reduction='none',beta=beta)\n",
    "    sorts_t = torch.argsort(y)\n",
    "    weight_adj = 1/(sorts_t+0.5) # WOOOH MAGIC NUMBER BAD :(\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    loss = loss_func(x,y)*weight_adj\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config, dataset):\n",
    "    # Make the data\n",
    "\n",
    "    train_loader = make_loader(dataset, config, train=True)\n",
    "    test_loader = make_loader(dataset, config, train=False)\n",
    "    # Make the model\n",
    "    # model = Net().to(device)\n",
    "    model = build_network(\n",
    "        config[\"f1_layer_size\"], config[\"f2_layer_size\"], config[\"dropout\"], config[\"num_layers\"]\n",
    "    )\n",
    "\n",
    "    loss_functions = {\n",
    "        \"Huber\":nn.HuberLoss(),\n",
    "        \"Huber_custom\":loss_customiser,\n",
    "        \"l1_custom\":custom_l1_place,\n",
    "        \"l1_custom_1stplace\":custom_l1_place_1,\n",
    "        \"MSE\":nn.MSELoss(),\n",
    "        \"L1\":nn.SmoothL1Loss(reduction='mean', beta=config[\"l1_beta\"]),\n",
    "        \"BCE\":nn.CrossEntropyLoss(),\n",
    "        \"Custom\":custom_MSE,\n",
    "        \"KL\":nn.KLDivLoss(reduction='batchmean'),\n",
    "        \"NLL\":nn.NLLLoss()\n",
    "    }\n",
    "    # Make the loss and optimizer\n",
    "    #  criterion = nn.NLLLoss()\n",
    "    loss_f = loss_functions[config['loss']]\n",
    "    criterion = loss_f\n",
    "    optimizer = config[\"optimizer\"]\n",
    "\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(), lr=config[\"learning_rate\"], momentum=0.9\n",
    "        )\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    print(optimizer)\n",
    "    if optimizer == \"adamW\":\n",
    "        print(\"HERE\")\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    return model, train_loader, test_loader, criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, batch_ct):\n",
    "    model.eval()\n",
    "    classL, predL, maxL, correctL, priceP, priceR, bfPriceR, pred_odds, model_outputs = [], [], [], [], [], [], [], [], []\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total, max_sum, max_w_sum, profit, bfprofit, bfnotavail, bf_available,bf_only_bets, bf_only_profit, test_val,bf_sp_prices = 0, 0, 0, 0, 0,0,0,0,0,0 ,0,0\n",
    "        alt_bet_1, alt_bet_2 = 0,0\n",
    "        value_pick_correct, value_pick_profit = 0, 0\n",
    "        num_bets = 0\n",
    "        for images, labels, prices, bfspPrices in test_loader:\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            #converts prices from tensor to list\n",
    "            prices = prices[0,].tolist()\n",
    "            bfspPrices = bfspPrices[0,].tolist()\n",
    "\n",
    "            #gets the prediction and its confidence and the real class\n",
    "            max, predicted = torch.max(outputs.data, 1)\n",
    "            _, real = torch.max(labels.data, 1)\n",
    "\n",
    "            #converts prediction from tensor to item\n",
    "            prediction = predicted.item()\n",
    "            real_item = real.item()\n",
    "\n",
    "            #appends prediction and likelyhood to lists\n",
    "            predL.append(prediction)\n",
    "            maxL.append(max.item())\n",
    "\n",
    "        \n",
    "            total += labels.size(0)\n",
    "            correct += prediction == real_item\n",
    "\n",
    "            correctL.append(int(prediction == real_item))\n",
    "            classL.append(real_item)\n",
    "\n",
    "            priceR.append(prices[real_item])\n",
    "            priceP.append(prices[prediction])\n",
    "            bfPriceR.append(bfspPrices[real_item])\n",
    "            # print(outputs.data.flatten().tolist())\n",
    "\n",
    "            predicted_odds = [\n",
    "                1 / ((x + 10**-7)) for x in outputs.data.flatten().tolist()\n",
    "            ]\n",
    "\n",
    "            pred_odds.append(predicted_odds)\n",
    "            model_outputs.append(outputs.data.flatten().tolist())\n",
    "\n",
    "            if prices[real_item] > (predicted_odds[real_item]):\n",
    "                value_pick_correct += 1\n",
    "                value_pick_profit += prices[real_item]\n",
    "                \n",
    "\n",
    "            bets = [x > (y) for x, y in zip(prices, predicted_odds)]\n",
    "            num_bets += sum(bets)\n",
    "\n",
    "            value_pick_profit += -sum(bets)\n",
    "\n",
    "            delta_pred = prices[prediction]-predicted_odds[prediction]\n",
    "            alt_bet_1 -= 1+10*delta_pred\n",
    "            alt_bet_2 -= 5\n",
    "\n",
    "\n",
    "            if bfspPrices[prediction]:\n",
    "                bf_only_bets += 1\n",
    "                bf_only_profit -= 1\n",
    "                bf_sp_prices += bfspPrices[prediction]\n",
    "                test_val += 1\n",
    "\n",
    "            if prediction == real_item:\n",
    "                max_sum += max\n",
    "                profit += prices[real_item]\n",
    "                if bfspPrices[real_item]:\n",
    "                    bfprofit += bfspPrices[real_item]\n",
    "                    bf_only_profit += bfspPrices[real_item]\n",
    "                    alt_bet_1 += (1+10*delta_pred)*bfspPrices[real_item]\n",
    "                    alt_bet_2 += 5*bfspPrices[real_item]\n",
    "                    bf_available += 1\n",
    "                    test_val -= 1\n",
    "                else:\n",
    "                    bfprofit += prices[real_item]*1.12\n",
    "                    bfnotavail += 1\n",
    "                    alt_bet_1 += (1+10*delta_pred)*prices[real_item]*1.12\n",
    "                    alt_bet_2 += 5*prices[real_item]*1.12\n",
    "            else:\n",
    "                max_w_sum += max\n",
    "\n",
    "            profit += -1\n",
    "            bfprofit += -1\n",
    "\n",
    "            # print(f\"{correct=}\")\n",
    "\n",
    "        # print(f\"Accuracy of the model on the {total} \" +\n",
    "        #       f\"test images: {100 * correct / total}%\" +\n",
    "        #       f\"profit: {profit}\"+\n",
    "        #       f\"profit: {value_pick_profit}\")\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"test_accuracy\": correct / total,\n",
    "                \"correct_conf\": max_sum / correct,\n",
    "                \"incorrect_conf\": (max_w_sum) / (total - correct),\n",
    "                \"profit\": profit,\n",
    "                \"bfprofit\": bfprofit,\n",
    "                \"bfnotavail\": bfnotavail,\n",
    "                \"value_pick_roi\": value_pick_profit / num_bets,\n",
    "                \"value_pick_correct\": value_pick_correct,\n",
    "                \"num_bets_per\": num_bets / total,\n",
    "                \"bf_avail\": bf_available,\n",
    "                \"bfOnlyProfit\": bf_only_profit,\n",
    "                \"bfOnlyBets\": bf_only_bets,\n",
    "                \"test_val\": test_val,\n",
    "                \"alt_bet_1\":alt_bet_1,\n",
    "                \"alt_bet_2\":alt_bet_2\n",
    "            }\n",
    "        )\n",
    "\n",
    "        logdf = pd.DataFrame(\n",
    "            data={\n",
    "                \"class\": classL,\n",
    "                \"pred\": predL,\n",
    "                \"max\": maxL,\n",
    "                \"correct\": correctL,\n",
    "                \"priceR\": priceR,\n",
    "                \"priceP\": priceP,\n",
    "                \"bets\": sum(bets),\n",
    "                \"pred_odds\": pred_odds,\n",
    "                \"model_outputs\": model_outputs,\n",
    "                \"bfodds\" : bfPriceR\n",
    "            }\n",
    "        )\n",
    "        # table = wandb.Table(dataframe=logdf)\n",
    "        # wandb.log({\"table_key\": table})\n",
    "        classCounts = logdf[\"class\"].value_counts()\n",
    "        predCounts = logdf[\"pred\"].value_counts()\n",
    "        # boxplot = logdf.boxplot(column=['priceR'],by='correct')\n",
    "        print(classCounts, predCounts)\n",
    "        # boxplot\n",
    "        # plt.savefig(\"boxplot.png\")\n",
    "        # wandb.log({\"boxplot\":boxplot})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
    "    #print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_saver(model, optimizer, epoch, loss):\n",
    "    \n",
    "    pathtofolder = \"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model\"\n",
    "    model_name = wandb.run.name\n",
    "    isExist = os.path.exists(\n",
    "        f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "    )\n",
    "    if isExist:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )\n",
    "    else:\n",
    "        print(\"created path\")\n",
    "        os.makedirs(\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "        )\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader,test_loader, criterion, optimizer, config):\n",
    "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Run training and track with wandb\n",
    "    total_batches = len(loader) * config.epochs\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "\n",
    "    raw_inputs = True\n",
    "    if config['loss'] == \"KL\":\n",
    "\n",
    "        for epoch in tqdm(range(config.epochs)):\n",
    "            for _, (images, labels, _ , _) in enumerate(loader):\n",
    "\n",
    "                loss = train_batch_lsftmax(images, labels, model, optimizer, criterion, btch_count=batch_ct, raw_inputs=True)\n",
    "                example_ct +=  len(images)\n",
    "                batch_ct += 1\n",
    "\n",
    "                # Report metrics every 25th batch\n",
    "                if ((batch_ct + 1) % 250) == 0:\n",
    "                    train_log(loss, example_ct, epoch)\n",
    "                    \n",
    "\n",
    "            if epoch %10 ==0:\n",
    "                test(model,test_loader, epoch)\n",
    "                model_saver(model,optimizer,epoch,loss)\n",
    "\n",
    "    else:\n",
    "        for epoch in tqdm(range(config.epochs)):\n",
    "            for _, (images, labels, _ , _) in enumerate(loader):\n",
    "\n",
    "                loss = train_batch(images, labels, model, optimizer, criterion, btch_count=batch_ct, raw_inputs=True)\n",
    "                example_ct +=  len(images)\n",
    "                batch_ct += 1\n",
    "\n",
    "                # Report metrics every 25th batch\n",
    "                if ((batch_ct + 1) % 250) == 0:\n",
    "                    train_log(loss, example_ct, epoch)\n",
    "\n",
    "            if epoch %10 ==0:\n",
    "                test(model,test_loader, epoch)\n",
    "                model_saver(model, optimizer, epoch, loss)\n",
    "\n",
    "def train_batch(images, labels, model, optimizer, criterion, btch_count=0, raw_inputs=True, beta=0.1):\n",
    "    images, labels = images, labels\n",
    "    \n",
    "\n",
    "    # Forward pass ➡\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels.float())\n",
    "    \n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_batch_lsftmax(images, labels, model, optimizer, criterion, btch_count=0, raw_inputs=True):\n",
    "    images, labels = images, labels\n",
    "    \n",
    "\n",
    "    # Forward pass ➡\n",
    "    outputs = model(images)\n",
    "    loss = criterion(F.log_softmax(outputs), labels.float())\n",
    "    \n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(config=None,prev_model=None):\n",
    "    dataset = my_dataset\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"new customs 71.7K\", config=config):\n",
    "      # access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "\n",
    "      # make the model, data, and optimization problem\n",
    "      model, train_loader, test_loader, criterion, optimizer = make(config, dataset)\n",
    "\n",
    "      prev_model = r'C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\good models\\lemon-sweep-1_990.pt'\n",
    "      if prev_model:\n",
    "        checkpoint = torch.load(prev_model, map_location=\"cuda:0\")\n",
    "        print(\"here\")\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "      model = model.to(device)\n",
    "      #optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      train(model, train_loader,test_loader, criterion, optimizer, config)\n",
    "\n",
    "      # and test its final performance\n",
    "      #test(model, test_loader)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'profit'},\n",
      " 'parameters': {'batch_size': {'values': [1000]},\n",
      "                'dropout': {'values': [0.3, 0.4, 0.5]},\n",
      "                'epochs': {'values': [1000]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'l1_beta': {'distribution': 'uniform', 'max': 1, 'min': 0},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.001,\n",
      "                                  'min': 0.0001},\n",
      "                'len_data': {'value': 72546},\n",
      "                'loss': {'values': ['L1']},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adamW'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'metric': {'name': 'profit', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adamW'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3, 0.4, 0.5]},\n",
       "  'len_data': {'value': 72546},\n",
       "  'epochs': {'values': [1000]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'values': ['L1']},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 0.0001, 'max': 0.001},\n",
       "  'l1_beta': {'distribution': 'uniform', 'min': 0, 'max': 1},\n",
       "  'batch_size': {'values': [1000]}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"profit\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3, 0.4, 0.5]},\n",
    "    \"len_data\": {\"value\": len_dataset},\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [1000]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"L1\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.0001,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0,\n",
    "            \"max\": 1,\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [1000]\n",
    "            # \"values\": [32, 64, 128, 360, 720]\n",
    "            # 'values':[4,8,16,32,64,128,360]\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20221012_132429-2zpt6w7t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/new%20customs%2071.7K/runs/2zpt6w7t\" target=\"_blank\">dashing-glade-28</a></strong> to <a href=\"https://wandb.ai/nickojelly/new%20customs%2071.7K\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.3, 'epochs': 100, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.0001, 'loss': 'L1', 'l1_beta': 0.1, 'len_data': 72546, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "100\n",
      "{'batch_size': 64, 'dropout': 0.3, 'epochs': 100, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.0001, 'loss': 'L1', 'l1_beta': 0.1, 'len_data': 72546, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "adamW\n",
      "HERE\n",
      "here\n",
      "Sequential(\n",
      "  (0): Linear(in_features=144, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.3, inplace=False)\n",
      "  (6): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:16<27:54, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 0    3814\n",
      "4     938\n",
      "5     768\n",
      "6     768\n",
      "3     592\n",
      "1     228\n",
      "2     124\n",
      "7      22\n",
      "Name: pred, dtype: int64\n",
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [01:16<13:03,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 6    1516\n",
      "5    1198\n",
      "1    1093\n",
      "2    1011\n",
      "4     909\n",
      "3     727\n",
      "7     488\n",
      "0     312\n",
      "Name: pred, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [02:14<11:23,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 4    1644\n",
      "5    1150\n",
      "1     896\n",
      "6     763\n",
      "3     759\n",
      "2     748\n",
      "7     720\n",
      "0     574\n",
      "Name: pred, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [03:13<09:30,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 5    1902\n",
      "4    1035\n",
      "6    1004\n",
      "3     900\n",
      "1     837\n",
      "2     636\n",
      "0     531\n",
      "7     409\n",
      "Name: pred, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [04:09<08:12,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 4    1451\n",
      "6    1292\n",
      "5    1019\n",
      "2     916\n",
      "3     822\n",
      "7     750\n",
      "1     685\n",
      "0     319\n",
      "Name: pred, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [05:04<06:35,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 5    1363\n",
      "3    1291\n",
      "4    1172\n",
      "6    1047\n",
      "2     757\n",
      "1     566\n",
      "7     562\n",
      "0     496\n",
      "Name: pred, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [06:01<05:25,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 5    1417\n",
      "6    1359\n",
      "4    1126\n",
      "2    1038\n",
      "3     816\n",
      "1     681\n",
      "7     422\n",
      "0     395\n",
      "Name: pred, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [07:00<04:13,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 4    1345\n",
      "6    1242\n",
      "5    1202\n",
      "7     871\n",
      "2     790\n",
      "3     665\n",
      "0     610\n",
      "1     529\n",
      "Name: pred, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [07:57<02:40,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 6    1216\n",
      "2    1202\n",
      "5    1145\n",
      "4    1088\n",
      "7    1044\n",
      "3     740\n",
      "1     589\n",
      "0     230\n",
      "Name: pred, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [08:55<01:17,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1102\n",
      "3    1094\n",
      "4    1056\n",
      "2     948\n",
      "6     898\n",
      "1     847\n",
      "0     756\n",
      "7     553\n",
      "Name: class, dtype: int64 5    1746\n",
      "4    1058\n",
      "2     954\n",
      "3     883\n",
      "6     826\n",
      "1     752\n",
      "7     553\n",
      "0     482\n",
      "Name: pred, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:34<00:00,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8c0b97102442639289f85857954eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>alt_bet_1</td><td>▁▇▆▇███▇▇█</td></tr><tr><td>alt_bet_2</td><td>▁█▅▆█▆█▇▇▇</td></tr><tr><td>bfOnlyBets</td><td>▁▇▆▇▇█▆▆▇▇</td></tr><tr><td>bfOnlyProfit</td><td>▁▇▃▆█▅█▆▇▇</td></tr><tr><td>bf_avail</td><td>▁█▇███████</td></tr><tr><td>bfnotavail</td><td>▁█▇▆▇▇▇█▇▇</td></tr><tr><td>bfprofit</td><td>▁█▅▆█▆█▇▇▇</td></tr><tr><td>correct_conf</td><td>▁████▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>incorrect_conf</td><td>▁████▇▇▇█▇</td></tr><tr><td>loss</td><td>█▃▅▅▃▃▃▃▂▆▃▂▁▃▃▁▃▃▄▃▄▄▂▃▄▂▂▂▄▂▂▃▄▆▂▄▄▁▄▃</td></tr><tr><td>num_bets_per</td><td>█▁▂▂▁▂▂▂▁▂</td></tr><tr><td>profit</td><td>▁█▆▇█▇▇▇▇▇</td></tr><tr><td>test_accuracy</td><td>▁█▇███████</td></tr><tr><td>test_val</td><td>█▁▂▁▁▂▁▁▁▁</td></tr><tr><td>value_pick_correct</td><td>▁█▇██▇█▇██</td></tr><tr><td>value_pick_roi</td><td>▁█▅█▇▄▇▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>alt_bet_1</td><td>93876.62913</td></tr><tr><td>alt_bet_2</td><td>2007.76164</td></tr><tr><td>bfOnlyBets</td><td>6078</td></tr><tr><td>bfOnlyProfit</td><td>543.97153</td></tr><tr><td>bf_avail</td><td>1554</td></tr><tr><td>bfnotavail</td><td>259</td></tr><tr><td>correct_conf</td><td>0.54873</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>incorrect_conf</td><td>0.49854</td></tr><tr><td>num_bets_per</td><td>2.69451</td></tr><tr><td>profit</td><td>-712.36</td></tr><tr><td>test_val</td><td>4524</td></tr><tr><td>value_pick_correct</td><td>1998</td></tr><tr><td>value_pick_roi</td><td>-0.21774</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dashing-glade-28</strong>: <a href=\"https://wandb.ai/nickojelly/new%20customs%2071.7K/runs/2zpt6w7t\" target=\"_blank\">https://wandb.ai/nickojelly/new%20customs%2071.7K/runs/2zpt6w7t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221012_132429-2zpt6w7t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb_config_static = {'batch_size': 64, 'dropout': 0.3, 'epochs': 100, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.0001, 'loss': 'L1', 'l1_beta':0.1, \"len_data\": len_dataset, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
    "model = model_pipeline(config=wandb_config_static)\n",
    "# wandb.init()\n",
    "# model = model_pipeline(config=wandb_config_static, prev_model=r'C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\good models\\vocal-sweep-80_90.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_pipeline(config)\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"grv_priced_sweep_custom_new\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=144, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.3, inplace=False)\n",
       "  (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Dropout(p=0.3, inplace=False)\n",
       "  (6): Linear(in_features=64, out_features=8, bias=True)\n",
       "  (7): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'prediction_inputs.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\model_w_norm_inputs.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39mchdir(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mNick\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mGitHub\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mgrvmodel\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPython\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pred_inputs_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m( \u001b[39m'\u001b[39;49m\u001b[39mprediction_inputs.npy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data\u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(pred_inputs_file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m race_ids,inputs,names \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mdata)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'prediction_inputs.npy'"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\")\n",
    "pred_inputs_file = open( 'prediction_inputs.npy', 'rb')\n",
    "data= pickle.load(pred_inputs_file)\n",
    "race_ids,inputs,names = zip(*data)\n",
    "for (i,j) in zip(race_ids,names):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\model_w_norm_inputs.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Xt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mTensor(np\u001b[39m.\u001b[39;49marray([i \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m inputs]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Xt\u001b[39m.\u001b[39mshape\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/model_w_norm_inputs.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Xn \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(Xt)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "Xt = torch.Tensor(np.array([i for i in inputs]))\n",
    "Xt.shape\n",
    "Xn = scaler.transform(Xt)\n",
    "Xtn = torch.tensor(Xtn).float()\n",
    "Xtn\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    outputs = model(Xtn)\n",
    "    print()\n",
    "    print(torch.argmax(outputs,1).tolist())\n",
    "    outs = torch.argmax(outputs,1).tolist()\n",
    "    for i,j in enumerate(names):\n",
    "        print(j[outs[i]])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43115443075634c02a7c247a87b0dd9d74842892e56d473b9e19f544f3149aff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
