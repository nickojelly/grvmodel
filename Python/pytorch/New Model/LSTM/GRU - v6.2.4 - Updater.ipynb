{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "# from rnn_classes import Dog, DogInput, Race, Races, GRUNet, smallGRUNet, smalll_lin_GRUNet, smalll_prelin_GRUNet\n",
    "import rnn_classes\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n",
    "from model_saver import model_saver, model_saver_wandb\n",
    "import training_testing_gru\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, pad_packed_sequence,pad_sequence, unpack_sequence, unpad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_l2(output, target):\n",
    "    loss = torch.mean(abs(output-target), dim=1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dist_last__1', 'box_last__1', 'speed_avg_1', 'split_speed_v1_1', 'split_margin_avg_1', 'margin_avg_1', 'first_out_avg_1', 'post_change_avg_1', 'races_1', 'wins_1', 'weight_', 'min_time_', 'min_split_time_v1', 'last_start_price']]\n",
      "(1273739, 24)\n",
      "20\n",
      "Latest date = 2023-06-14 00:00:00\n",
      "size after state filter (316570, 26)\n",
      "(316570, 26)\n",
      "Latest date = 2023-06-14 00:00:00\n",
      "num_features_per_dog=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7180 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 7180/7180 [05:56<00:00, 20.14it/s]  \n",
      "  0%|          | 0/11947 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      " 41%|████▏     | 4941/11947 [00:14<00:18, 376.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 7 is out of bounds for dimension 0 with size 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 7523/11947 [00:23<00:23, 186.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 7 is out of bounds for dimension 0 with size 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 9411/11947 [00:27<00:05, 479.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 5 is out of bounds for dimension 0 with size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11947/11947 [00:34<00:00, 347.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 11947, number of unique dogs = 7181\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "hidden_size = 32\n",
    "states = [\"NSW\"]\n",
    "data_file = 'gru_inputs_simple_v6_updated.fth'\n",
    "raceDB = build_dataset(data_file, hidden_size ,state_filter=states, margin_type='boosted_sftmin',v6=True, date_filter=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([300.], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races = raceDB.get_test_input([1,2,3])\n",
    "races[0].race_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([300.], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races[0].race_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 0, Test examples 11947\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7180/7180 [00:00<00:00, 166827.89it/s]\n"
     ]
    }
   ],
   "source": [
    "raceDB.create_dogs_test_split_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7181/7181 [00:01<00:00, 5767.26it/s]\n"
     ]
    }
   ],
   "source": [
    "raceDB.attach_races_to_dog_inputv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dog_input = [list(d.races.values()) for d in raceDB.dogsDict.values() if d.races.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_y = pack_sequence([torch.stack(n,0) for n in [[z.full_input.to('cpu') for z in inner] for inner in all_dog_input]], enforce_sorted=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_y = packed_y.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'curious-durian-408'\n",
    "# model,hidden_state_dict = setup_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date=datetime.date(2019, 12, 1)\n",
      "period=datetime.date(2020, 11, 30)\n",
      "start_date=datetime.date(2020, 11, 30)\n",
      "period=datetime.date(2021, 11, 30)\n",
      "start_date=datetime.date(2021, 11, 30)\n",
      "period=datetime.date(2022, 7, 31)\n",
      "[(datetime.date(2019, 12, 1), datetime.date(2020, 11, 30)), (datetime.date(2020, 11, 30), datetime.date(2021, 11, 30)), (datetime.date(2021, 11, 30), datetime.date(2022, 7, 31))]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime.strptime(\"2019-12-01\", \"%Y-%m-%d\").date()\n",
    "end_date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()-datetime.timedelta(1)\n",
    "period = start_date\n",
    "batches = []\n",
    "while start_date<end_date:\n",
    "   \n",
    "    print(f\"{start_date=}\")\n",
    "    period = min(start_date+datetime.timedelta(365), end_date)\n",
    "    print(f\"{period=}\")\n",
    "    batches.append((start_date,period))\n",
    "    start_date=period\n",
    "    #batches.append((start_date,end_date))\n",
    "# batches.append((period,end_date))\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-30\n",
      "2021-11-30\n",
      "2022-07-31\n",
      "Train examples [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "batch_races_ids = [] # list of race_ids\n",
    "j = 0\n",
    "current_batch = []\n",
    "for i,r in enumerate(raceDB.raceIDs):   \n",
    "    _,end_date = batches[j]\n",
    "    race_date = raceDB.racesDict[r].race_date\n",
    "    if race_date>end_date:\n",
    "        print(end_date)\n",
    "\n",
    "        batch_races_ids.append(current_batch)\n",
    "        current_batch = []\n",
    "        j += 1\n",
    "        if j>len(batches)-1:\n",
    "            break\n",
    "    else:\n",
    "        current_batch.append(r)\n",
    "print(f\"Train examples {[len(x) for x in batch_races_ids]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03dcc081ef14b499c54a33aa6725277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ccfbf7518f42a2bac8641ba7df2f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf1f3d34b464773b5d426254f9b25bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ad7f7a2d574793976efa02a2430075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dogs = []\n",
    "train_dog_input = []\n",
    "for bi, batch in enumerate(tqdm(batch_races_ids)):\n",
    "    # print(bi)\n",
    "    # print(batch)\n",
    "    batch_dogs = []\n",
    "    batch_dog_input = []\n",
    "    for i in tqdm(raceDB.dog_ids):\n",
    "        dog = raceDB.dogsDict[i]\n",
    "        train = [dog.races[x] for x in batch if x in dog.races.keys()]\n",
    "        if train:\n",
    "            batch_dogs.append(dog)\n",
    "            batch_dog_input.append(train)\n",
    "    train_dogs.append(batch_dogs)\n",
    "    train_dog_input.append(batch_dog_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_races = [[raceDB.racesDict[r] for r in inner] for inner in batch_races_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples [0, 0, 0]\n",
      "Train examples [0, 0, 0]\n",
      "Train examples [0, 0, 0]\n",
      "Train examples [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train examples {[len(x) for x in train_dogs]}\")\n",
    "print(f\"Train examples {[len(x) for x in train_dog_input]}\")\n",
    "print(f\"Train examples {[len(x) for x in batch_races]}\")\n",
    "print(f\"Train examples {[len(x) for x in batch_races_ids]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = range(0,len(raceDB.test_dog_ids))\n",
    "packed_x = \"\"#[pack_sequence([torch.stack(n,0) for n in [[z.full_input for z in inner] for inner in x]], enforce_sorted=False).to('cuda:0') for x in train_dog_input]\n",
    "packed_x_basic = \"\"#[pack_sequence([torch.stack(n,0) for n in [[z.stats for z in inner] for inner in x]], enforce_sorted=False).to('cuda:0') for x in train_dog_input]\n",
    "packed_y = \"\"#pack_sequence([torch.stack(n,0) for n in [[z.full_input.to('cuda:0') for z in inner] for inner in [x for x in raceDB.get_dog_test(test_idx)]]], enforce_sorted=False)\n",
    "packed_y_basic = pack_sequence([torch.stack(n,0) for n in [[z.stats.to('cuda:0') for z in inner] for inner in [x for x in raceDB.get_dog_test(test_idx)]]], enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.batches = {'num_batches':len(train_dogs),\n",
    "                  'dogs':train_dogs,\n",
    "                  'train_dog_input':train_dog_input,\n",
    "                  'batch_races':batch_races,\n",
    "                  'batch_races_ids':batch_races_ids,\n",
    "                  'packed_x':packed_x,\n",
    "                  'packed_x_basic':packed_x_basic,\n",
    "                  'packed_y_basic':packed_y_basic,\n",
    "                    'packed_y':packed_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None, prev_model_file=None, prev_model_version='450'):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"NEW GRU - updates\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      wandb.define_metric(\"multibet profit\", summary=\"max\")\n",
    "      \n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "      # input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0] #create fix so messy\n",
    "      print(config.input_type)\n",
    "      if config.input_type == 'full':\n",
    "        print('here1')\n",
    "        input_size = raceDB.batches['packed_x'][0].data[0].shape[0]\n",
    "      elif config.input_type == 'basic':\n",
    "        print('here')\n",
    "        raceDB.batches['packed_x'] = raceDB.batches['packed_x_basic']\n",
    "        raceDB.batches['packed_y'] = raceDB.batches['packed_y_basic']\n",
    "        input_size = raceDB.batches['packed_y'][0].data[0].shape[0]\n",
    "\n",
    "      print(f\"{input_size=}\")\n",
    "\n",
    "      # raceDB.batches['packed_y'][0] = raceDB.batches['packed_y'][0]._replace(data=)\n",
    "\n",
    "      raceDB.reset_hidden(num_layers=config['num_layers'], hidden_size=config['hidden_size'])\n",
    "      model = rnn_classes.GRUNetv3_LN(input_size,config['hidden_size'], num_layers=config['num_layers'],fc0_size=config['f0_layer_size'], fc1_size=config['f1_layer_size'])\n",
    "\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      if prev_model_file!=None:\n",
    "        model_name = prev_model_file\n",
    "        model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{prev_model_version}.pt\"\n",
    "        model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "        model.load_state_dict(model_data['model_state_dict'])\n",
    "        raceDB.fill_hidden_states_dict_v2(model_data['db_train'])\n",
    "        config['parent model'] = prev_model_file\n",
    "\n",
    "      raceDB.to_cuda()\n",
    "\n",
    "      criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "      optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "      model = model.to(device)\n",
    "\n",
    "      print(model)\n",
    "      print(model.forward)\n",
    "\n",
    "      # training_testing_gru.validate_model_v3(model,raceDB, criterion,epoch=0)\n",
    "      # training_testing_gru.train_regular_v3(model, dataset, criterion, optimizer, 'na', config, update=True)\n",
    "      model.eval()\n",
    "      training_testing_gru.validate_model_v3(model,raceDB, criterion,epoch=0)\n",
    "\n",
    "      if sweep:\n",
    "        raceDB.reset_all_lstm_states\n",
    "        raceDB.reset_hidden()\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':128,\n",
    "                       'datafile':data_file,\n",
    "                       'stats':raceDB.stats_cols,\n",
    "                       'input_type':'basic',\n",
    "                       'races':states,\n",
    "                       'latest_date':raceDB.latest_date,\n",
    "                       'num_layers':2,\n",
    "                       'batch_size': 750,\n",
    "                       'dropout': 0.3,\n",
    "                       'epochs': 10_000,\n",
    "                       'learning_rate': 0.0003,\n",
    "                       'optimizer': 'adamW',\n",
    "                       'f0_layer_size':128,\n",
    "                       'f1_layer_size':64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'rnn_classes' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\grvmodel\\\\Python\\\\pytorch\\\\New Model\\\\LSTM\\\\rnn_classes.py'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static)\n",
    "importlib.reload(training_testing_gru)\n",
    "importlib.reload(rnn_classes)\n",
    "# (model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.reset_hidden(num_layers=wandb_config_static['num_layers'], hidden_size=wandb_config_static['hidden_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70db380ca9e142eb8546a280bd0b951e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230615_205426-8clmsrag</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nickojelly/NEW%20GRU%20-%20updates/runs/8clmsrag' target=\"_blank\">exalted-galaxy-283</a></strong> to <a href='https://wandb.ai/nickojelly/NEW%20GRU%20-%20updates' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nickojelly/NEW%20GRU%20-%20updates' target=\"_blank\">https://wandb.ai/nickojelly/NEW%20GRU%20-%20updates</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nickojelly/NEW%20GRU%20-%20updates/runs/8clmsrag' target=\"_blank\">https://wandb.ai/nickojelly/NEW%20GRU%20-%20updates/runs/8clmsrag</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 128, 'datafile': 'gru_inputs_simple_v6_updated.fth', 'stats': \"[['dist_last__1', 'box_last__1', 'speed_avg_1', 'split_speed_v1_1', 'split_margin_avg_1', 'margin_avg_1', 'first_out_avg_1', 'post_change_avg_1', 'races_1', 'wins_1', 'weight_', 'min_time_', 'min_split_time_v1', 'last_start_price']]\", 'input_type': 'basic', 'races': ['NSW'], 'latest_date': '2023-06-14T00:00:00', 'num_layers': 2, 'batch_size': 750, 'dropout': 0.3, 'epochs': 10000, 'learning_rate': 0.0003, 'optimizer': 'adamW', 'f0_layer_size': 128, 'f1_layer_size': 64}\n",
      "10000\n",
      "{'hidden_size': 128, 'datafile': 'gru_inputs_simple_v6_updated.fth', 'stats': \"[['dist_last__1', 'box_last__1', 'speed_avg_1', 'split_speed_v1_1', 'split_margin_avg_1', 'margin_avg_1', 'first_out_avg_1', 'post_change_avg_1', 'races_1', 'wins_1', 'weight_', 'min_time_', 'min_split_time_v1', 'last_start_price']]\", 'input_type': 'basic', 'races': ['NSW'], 'latest_date': '2023-06-14T00:00:00', 'num_layers': 2, 'batch_size': 750, 'dropout': 0.3, 'epochs': 10000, 'learning_rate': 0.0003, 'optimizer': 'adamW', 'f0_layer_size': 128, 'f1_layer_size': 64}\n",
      "basic\n",
      "here\n",
      "input_size=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7181/7181 [00:00<00:00, 478296.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =3845\n",
      "empty  =3336\n",
      "0.5354407464141484null_dog=0\n",
      "GRUNetv3_LN(\n",
      "  (gru): GRU(20, 128, num_layers=2, dropout=0.3)\n",
      "  (relu0): ReLU()\n",
      "  (fc0): Linear(in_features=1094, out_features=1094, bias=True)\n",
      "  (layer_norm): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=1094, out_features=128, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (rl3): ReLU()\n",
      "  (drop3): Dropout(p=0.3, inplace=False)\n",
      "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n",
      "<bound method GRUNetv3_LN.forward of GRUNetv3_LN(\n",
      "  (gru): GRU(20, 128, num_layers=2, dropout=0.3)\n",
      "  (relu0): ReLU()\n",
      "  (fc0): Linear(in_features=1094, out_features=1094, bias=True)\n",
      "  (layer_norm): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=1094, out_features=128, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (rl3): ReLU()\n",
      "  (drop3): Dropout(p=0.3, inplace=False)\n",
      "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ROI < 30</td><td>▁▁</td></tr><tr><td>ROI < 30 2</td><td>▁▁</td></tr><tr><td>accuracy</td><td>▁▁</td></tr><tr><td>accuracy2</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁</td></tr><tr><td>flat_simple</td><td>▁▁</td></tr><tr><td>loss_val</td><td>▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▁</td></tr><tr><td>multibet profit</td><td>▁▁</td></tr><tr><td>multibet profit < 30</td><td>▁▁</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁</td></tr><tr><td>profit_relu</td><td>▁▁</td></tr><tr><td>relu roi</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ROI < 30</td><td>0.06372</td></tr><tr><td>ROI < 30 2</td><td>0.05148</td></tr><tr><td>accuracy</td><td>0.30719</td></tr><tr><td>accuracy2</td><td>0.30719</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>flat_simple</td><td>70.48545</td></tr><tr><td>loss_val</td><td>1.94635</td></tr><tr><td>multibet outlay < 30</td><td>261937.28865</td></tr><tr><td>multibet profit < 30</td><td>16690.58046</td></tr><tr><td>multibet profit < 30 sd</td><td>26.42078</td></tr><tr><td>profit_relu</td><td>73933.69953</td></tr><tr><td>relu roi</td><td>0.23449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-galaxy-283</strong> at: <a href='https://wandb.ai/nickojelly/NEW%20GRU%20-%20updates/runs/8clmsrag' target=\"_blank\">https://wandb.ai/nickojelly/NEW%20GRU%20-%20updates/runs/8clmsrag</a><br/>Synced 6 W&B file(s), 3 media file(s), 3 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230615_205426-8clmsrag\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False, prev_model_file='kind-wood-610', prev_model_version='1300')\n",
    "# (model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False, prev_model_file='youthful-butterfly-730', prev_model_version='700')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.reset_hidden(num_layers=wandb_config_static['num_layers'], hidden_size=wandb_config_static['hidden_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m race \u001b[39m=\u001b[39m raceDB\u001b[39m.\u001b[39;49mbatches[\u001b[39m'\u001b[39;49m\u001b[39mbatch_races\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m2\u001b[39;49m]\n\u001b[0;32m      2\u001b[0m [d \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m race\u001b[39m.\u001b[39mdogs]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "race = raceDB.batches['batch_races'][0][2]\n",
    "[d for d in race.dogs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48ca33c5a1168302a4f8eae355aad1c03b1396f568d40bc174a6e6aabe725d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
