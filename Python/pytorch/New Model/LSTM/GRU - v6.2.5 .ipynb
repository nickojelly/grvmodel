{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "# from rnn_classes import Dog, DogInput, Race, Races, GRUNet, smallGRUNet, smalll_lin_GRUNet, smalll_prelin_GRUNet\n",
    "import rnn_classes\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n",
    "from model_saver import model_saver, model_saver_wandb\n",
    "import training_testing_gru\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, pad_packed_sequence,pad_sequence, unpack_sequence, unpad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_l2(output, target):\n",
    "    loss = torch.mean(abs(output-target), dim=1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.compile(rnn_classes.GRUNetv2(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dist_last__1', 'box_last__1', 'speed_avg_1', 'split_speed_avg_1', 'split_margin_avg_1', 'margin_avg_1', 'run_home_speed_1', 'first_out_avg_1', 'pos_out_avg_1', 'post_change_avg_1', 'wins_1', 'weight_', 'last_start_prob']]\n",
      "(1242144, 23)\n",
      "19\n",
      "Latest date = 2023-05-16 00:00:00\n",
      "size after state filter (130943, 25)\n",
      "(130943, 25)\n",
      "Latest date = 2023-05-14 00:00:00\n",
      "num_features_per_dog=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3604 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 3604/3604 [00:55<00:00, 65.12it/s] \n",
      "  0%|          | 0/17351 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 17351/17351 [00:40<00:00, 432.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 17351, number of unique dogs = 3605\n",
      "0        (Auckland, 318.0)\n",
      "1        (Auckland, 318.0)\n",
      "2        (Auckland, 527.0)\n",
      "3        (Auckland, 318.0)\n",
      "4        (Auckland, 318.0)\n",
      "               ...        \n",
      "17346    (Auckland, 527.0)\n",
      "17347    (Auckland, 318.0)\n",
      "17348    (Auckland, 527.0)\n",
      "17349    (Auckland, 318.0)\n",
      "17350    (Auckland, 318.0)\n",
      "Length: 17351, dtype: object\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "hidden_size = 32\n",
    "states = [\"NZ\"]\n",
    "raceDB = build_dataset('gru_inputs_simple_8.fth', hidden_size ,state_filter=states,margin_type='sftmin',v6=True)\n",
    "raceDB.create_new_weights_v2()\n",
    "#raceDB.adjust_weights({\"Dapto\":10, \"Gunnedah\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 13565, Test examples 3786\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date=datetime.date(2019, 12, 1)\n",
      "period=datetime.date(2020, 5, 29)\n",
      "start_date=datetime.date(2020, 5, 29)\n",
      "period=datetime.date(2020, 11, 25)\n",
      "start_date=datetime.date(2020, 11, 25)\n",
      "period=datetime.date(2021, 5, 24)\n",
      "start_date=datetime.date(2021, 5, 24)\n",
      "period=datetime.date(2021, 11, 20)\n",
      "start_date=datetime.date(2021, 11, 20)\n",
      "period=datetime.date(2022, 5, 19)\n",
      "start_date=datetime.date(2022, 5, 19)\n",
      "period=datetime.date(2022, 7, 31)\n",
      "[(datetime.date(2019, 12, 1), datetime.date(2020, 5, 29)), (datetime.date(2020, 5, 29), datetime.date(2020, 11, 25)), (datetime.date(2020, 11, 25), datetime.date(2021, 5, 24)), (datetime.date(2021, 5, 24), datetime.date(2021, 11, 20)), (datetime.date(2021, 11, 20), datetime.date(2022, 5, 19)), (datetime.date(2022, 5, 19), datetime.date(2022, 7, 31))]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime.strptime(\"2019-12-01\", \"%Y-%m-%d\").date()\n",
    "end_date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()-datetime.timedelta(1)\n",
    "period = start_date\n",
    "batches = []\n",
    "while start_date<end_date:\n",
    "   \n",
    "    print(f\"{start_date=}\")\n",
    "    period = min(start_date+datetime.timedelta(180), end_date)\n",
    "    print(f\"{period=}\")\n",
    "    batches.append((start_date,period))\n",
    "    start_date=period\n",
    "    #batches.append((start_date,end_date))\n",
    "# batches.append((period,end_date))\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29\n",
      "2020-11-25\n",
      "2021-05-24\n",
      "2021-11-20\n",
      "2022-05-19\n",
      "2022-07-31\n",
      "Train examples [2201, 2826, 2680, 2396, 2444, 1001]\n"
     ]
    }
   ],
   "source": [
    "batch_races_ids = [] # list of race_ids\n",
    "j = 0\n",
    "current_batch = []\n",
    "for i,r in enumerate(raceDB.raceIDs):   \n",
    "    _,end_date = batches[j]\n",
    "    race_date = raceDB.racesDict[r].race_date\n",
    "    if race_date>end_date:\n",
    "        print(end_date)\n",
    "\n",
    "        batch_races_ids.append(current_batch)\n",
    "        current_batch = []\n",
    "        j += 1\n",
    "        if j>len(batches)-1:\n",
    "            break\n",
    "    else:\n",
    "        current_batch.append(r)\n",
    "print(f\"Train examples {[len(x) for x in batch_races_ids]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4233f198caf45a1abc8184d1c5e0201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f743ac9c4144778122f734f17b8a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f0297865b64d8595482f44527b69ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e93b5d48b14353be2212d02e950fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e719d615997d46339859c49cfc045e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cc7f3fc9e7421584b7616aa1a8ebb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6703991d4946ea8cdc57b5d199be28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3604 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dogs = []\n",
    "train_dog_input = []\n",
    "for bi, batch in enumerate(tqdm(batch_races_ids)):\n",
    "    # print(bi)\n",
    "    # print(batch)\n",
    "    batch_dogs = []\n",
    "    batch_dog_input = []\n",
    "    for i in tqdm(raceDB.dog_ids):\n",
    "        dog = raceDB.dogsDict[i]\n",
    "        train = [dog.races[x] for x in batch if x in dog.races.keys()]\n",
    "        if train:\n",
    "            batch_dogs.append(dog)\n",
    "            batch_dog_input.append(train)\n",
    "    train_dogs.append(batch_dogs)\n",
    "    train_dog_input.append(batch_dog_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_races = [[raceDB.racesDict[r] for r in inner] for inner in batch_races_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples [1557, 1594, 1489, 1492, 1400, 1111]\n",
      "Train examples [1557, 1594, 1489, 1492, 1400, 1111]\n",
      "Train examples [2201, 2826, 2680, 2396, 2444, 1001]\n",
      "Train examples [2201, 2826, 2680, 2396, 2444, 1001]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train examples {[len(x) for x in train_dogs]}\")\n",
    "print(f\"Train examples {[len(x) for x in train_dog_input]}\")\n",
    "print(f\"Train examples {[len(x) for x in batch_races]}\")\n",
    "print(f\"Train examples {[len(x) for x in batch_races_ids]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3604/3604 [00:00<00:00, 34958.60it/s]\n"
     ]
    }
   ],
   "source": [
    "raceDB.create_dogs_test_split_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3605/3605 [00:01<00:00, 2227.40it/s]\n"
     ]
    }
   ],
   "source": [
    "raceDB.attach_races_to_dog_inputv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = range(0,len(raceDB.test_dog_ids))\n",
    "packed_x = \"\"#[pack_sequence([torch.stack(n,0) for n in [[z.full_input for z in inner] for inner in x]], enforce_sorted=False).to('cuda:0') for x in train_dog_input]\n",
    "packed_x_basic = [pack_sequence([torch.stack(n,0) for n in [[z.stats for z in inner] for inner in x]], enforce_sorted=False).to('cuda:0') for x in train_dog_input]\n",
    "packed_y = \"\"#pack_sequence([torch.stack(n,0) for n in [[z.full_input.to('cuda:0') for z in inner] for inner in [x for x in raceDB.get_dog_test(test_idx)]]], enforce_sorted=False)\n",
    "packed_y_basic = pack_sequence([torch.stack(n,0) for n in [[z.stats.to('cuda:0') for z in inner] for inner in [x for x in raceDB.get_dog_test(test_idx)]]], enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_x_basic = [pad_packed_sequence(x) for x in packed_x_basic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1557, 19])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x_basic[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dog_input_stacked = [[torch.stack(n,0) for n in [[z.full_input.to('cpu') for z in inner] for inner in x]] for x in train_dog_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [sum([len(x) for x in n])/len([len(x) for x in n]) for n in train_dog_input_stacked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.batches = {'num_batches':len(train_dogs),\n",
    "                  'dogs':train_dogs,\n",
    "                  'train_dog_input':train_dog_input,\n",
    "                  'batch_races':batch_races,\n",
    "                  'batch_races_ids':batch_races_ids,\n",
    "                  'packed_x':packed_x,\n",
    "                  'packed_x_basic':packed_x_basic,\n",
    "                  'packed_y_basic':packed_y_basic, \n",
    "                  'packed_y':packed_y}\n",
    "\n",
    "# raceDB.batches = {'num_batches':len(train_dogs),\n",
    "#                     'dogs':train_dogs,\n",
    "#                     'train_dog_input':train_dog_input,\n",
    "#                     'batch_races':batch_races,\n",
    "#                     'batch_races_ids':batch_races_ids,\n",
    "#                     'packed_x':packed_x,\n",
    "#                     'packed_y':packed_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None, prev_model_file=None, prev_model_version='450'):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"NEW GRU\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss_val\", summary=\"min\")\n",
    "      wandb.define_metric(\"accuracy\", summary=\"max\")\n",
    "      wandb.define_metric('ROI < 30', summary=\"max\")\n",
    "      wandb.define_metric(\"multibet profit\", summary=\"max\")\n",
    "      \n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "      # input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0] #create fix so messy\n",
    "      print(config.input_type)\n",
    "      if config.input_type == 'full':\n",
    "        print('here1')\n",
    "        input_size = raceDB.batches['packed_x'][0].data[0].shape[0]\n",
    "      elif config.input_type == 'basic':\n",
    "        print('here')\n",
    "        raceDB.batches['packed_x'] = raceDB.batches['packed_x_basic']\n",
    "        raceDB.batches['packed_y'] = raceDB.batches['packed_y_basic']\n",
    "        input_size = raceDB.batches['packed_x'][0].data[0].shape[0]\n",
    "\n",
    "      print(f\"{input_size=}\")\n",
    "\n",
    "\n",
    "      raceDB.reset_hidden(num_layers=config['num_layers'], hidden_size=config['hidden_size'])\n",
    "      model = rnn_classes.GRUNetv3_LN(input_size,config['hidden_size'], num_layers=config['num_layers'],fc0_size=config['f0_layer_size'], fc1_size=config['f1_layer_size'])\n",
    "\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      if prev_model_file!=None:\n",
    "        model_name = prev_model_file\n",
    "        model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{prev_model_version}.pt\"\n",
    "        model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "        model.load_state_dict(model_data['model_state_dict'])\n",
    "        config['parent model'] = prev_model_file\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "        optimizer.load_state_dict(model_data['optim'])\n",
    "        # optimizer.to(device)\n",
    "      else:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "      raceDB.to_cuda()\n",
    "      criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "\n",
    "      print(optimizer)\n",
    "\n",
    "      model = model.to(device)\n",
    "\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        training_testing_gru.train_regular_v3(model, dataset, criterion, optimizer, 'na', config)\n",
    "      except (KeyboardInterrupt) as error:\n",
    "        print(error)\n",
    "        print(\"finished Early\")\n",
    "        \n",
    "      # dataset.create_hidden_states_dict()\n",
    "      raceDB.create_hidden_states_dict_v2()\n",
    "      \n",
    "      model_saver_wandb(model, optimizer, 450, 0.1, raceDB.hidden_states_dict_gru_v6,raceDB.train_hidden_dict , model_name=\"long nsw new  22000 RUN\")\n",
    "      if sweep:\n",
    "        raceDB.reset_hidden()\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':128,\n",
    "                       'stats':raceDB.stats_cols,\n",
    "                       'races':states,\n",
    "                       'latest_date':raceDB.latest_date,\n",
    "                       'input_type':'basic',\n",
    "                       'num_layers':2,\n",
    "                       'batch_size': 750,\n",
    "                       'dropout': 0.3,\n",
    "                       'epochs': 10_000,\n",
    "                       'learning_rate': 0.0004,\n",
    "                       'optimizer': 'adamW',\n",
    "                       'f0_layer_size':128,\n",
    "                       'f1_layer_size':64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'rnn_classes' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\grvmodel\\\\Python\\\\pytorch\\\\New Model\\\\LSTM\\\\rnn_classes.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(training_testing_gru)\n",
    "importlib.reload(rnn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for race in raceDB.racesDict.values():\n",
    "    for dog in race.dogs:\n",
    "        try:\n",
    "            del dog.stats\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.reset_hidden(num_layers=wandb_config_static['num_layers'], hidden_size=wandb_config_static['hidden_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dd7bdfb89644fdbabae7b1c9f218af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666656966, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230517_140202-0m29j8l9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nickojelly/NEW%20GRU/runs/0m29j8l9' target=\"_blank\">rural-butterfly-608</a></strong> to <a href='https://wandb.ai/nickojelly/NEW%20GRU' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nickojelly/NEW%20GRU' target=\"_blank\">https://wandb.ai/nickojelly/NEW%20GRU</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nickojelly/NEW%20GRU/runs/0m29j8l9' target=\"_blank\">https://wandb.ai/nickojelly/NEW%20GRU/runs/0m29j8l9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 128, 'stats': \"[['dist_last__1', 'box_last__1', 'speed_avg_1', 'split_speed_avg_1', 'split_margin_avg_1', 'margin_avg_1', 'run_home_speed_1', 'first_out_avg_1', 'pos_out_avg_1', 'post_change_avg_1', 'wins_1', 'weight_', 'last_start_prob']]\", 'races': ['SA'], 'latest_date': '2023-05-16T00:00:00', 'input_type': 'basic', 'num_layers': 2, 'batch_size': 750, 'dropout': 0.3, 'epochs': 10000, 'learning_rate': 0.0004, 'optimizer': 'adamW', 'f0_layer_size': 128, 'f1_layer_size': 64}\n",
      "10000\n",
      "{'hidden_size': 128, 'stats': \"[['dist_last__1', 'box_last__1', 'speed_avg_1', 'split_speed_avg_1', 'split_margin_avg_1', 'margin_avg_1', 'run_home_speed_1', 'first_out_avg_1', 'pos_out_avg_1', 'post_change_avg_1', 'wins_1', 'weight_', 'last_start_prob']]\", 'races': ['SA'], 'latest_date': '2023-05-16T00:00:00', 'input_type': 'basic', 'num_layers': 2, 'batch_size': 750, 'dropout': 0.3, 'epochs': 10000, 'learning_rate': 0.0004, 'optimizer': 'adamW', 'f0_layer_size': 128, 'f1_layer_size': 64}\n",
      "basic\n",
      "here\n",
      "input_size=19\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "GRUNetv3_LN(\n",
      "  (gru): GRU(19, 128, num_layers=2, dropout=0.3)\n",
      "  (relu0): ReLU()\n",
      "  (fc0): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (layer_norm): LayerNorm((19,), eps=1e-05, elementwise_affine=True)\n",
      "  (layer_norm2): LayerNorm((1094,), eps=1e-05, elementwise_affine=True)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=1094, out_features=128, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (rl3): ReLU()\n",
      "  (drop3): Dropout(p=0.3, inplace=False)\n",
      "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [16:02:04<00:00,  5.77s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ROI < 30</td><td>▅▆▅▅▆▆▅▄▅▄▄▃▄▄▃▂▁▃▄▅▄▆▆▄▄▅▅▄▅▅▆▇▇█▇▇▇██▇</td></tr><tr><td>ROI < 30 2</td><td>▅▆▅▅▅▅▅▄▄▄▃▂▄▃▃▃▁▃▄▄▄▆▅▄▄▅▄▅▅▅▆▇▇█▇▇▇██▇</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁▁▂▂▂▂▄▆▇█▇█▇█▇███████▇██▇█▇███▇▇▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>flat_simple</td><td>▁▂▂▁▂▂▂▂▂▁▄▃▅▆▄▂▃▄▄▄▄▄▅▄▅▆▃▄▄▄▅▄▆▅▇▅▅▅▆█</td></tr><tr><td>loss_1</td><td>█▇▇▇▇▇▇▇▇▇▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▆▆▆▆▆▆▆▅▅▃▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅</td></tr><tr><td>multibet outlay < 30</td><td>▁▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▂▂▂▂▂▂▃▃▅▄▄▄▄▅▄▅▅▆▅▄▅▄▅▃▅▅▄▅▅▄▅▅▅▆█▆</td></tr><tr><td>multibet profit < 30</td><td>▇▆▆▆▆▆▆▅▅▅▅▃▄▄▄▃▁▃▄▅▅▆▆▃▄▅▅▄▄▅▆▇▇█▇▇▇██▇</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▂▂▂▂▃▂▂▁▁▁▂▁▁▂▂▃▃▄▄▃▄▅▄▄▅▅▅▅▆▅▆▆▆███</td></tr><tr><td>profit_relu</td><td>▄▃▁▁▁▁▂▂▂▃▄▄▆▆▆▆▆▇▇▇▇██▇▇█▇▆▇▇▇▇▇▆▆▆▆▇██</td></tr><tr><td>relu roi</td><td>▁▂▂▃▃▃▃▃▃▃▄▃▅▄▅▄▅▆▆▇▆██▆▆█▅▄▆▅▆▆▆▄▄▄▄▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ROI < 30 2</td><td>-0.01338</td></tr><tr><td>epoch</td><td>9999</td></tr><tr><td>flat_simple</td><td>37.3961</td></tr><tr><td>loss_1</td><td>1.22294</td></tr><tr><td>multibet outlay < 30</td><td>88967.38037</td></tr><tr><td>multibet profit < 30</td><td>-4617.09152</td></tr><tr><td>multibet profit < 30 sd</td><td>25.71636</td></tr><tr><td>profit_relu</td><td>-892.75347</td></tr><tr><td>relu roi</td><td>-0.02828</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rural-butterfly-608</strong> at: <a href='https://wandb.ai/nickojelly/NEW%20GRU/runs/0m29j8l9' target=\"_blank\">https://wandb.ai/nickojelly/NEW%20GRU/runs/0m29j8l9</a><br/>Synced 6 W&B file(s), 1000 media file(s), 1000 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230517_140202-0m29j8l9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"ROI < 30\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f0_layer_size\": {\"values\": [1024]},\n",
    "    \"f1_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"input_type\": {\"values\": ['full','basic']},\n",
    "    \"num_layers\": {\"values\": [2]},\n",
    "    'hidden_size':{'values':[128]},\n",
    "    \"len_data\": {\"value\": len(raceDB.raceIDs)},\n",
    "    \"stats\":{\"value\": raceDB.stats_cols},\n",
    "    \"races\":{\"value\": states},\n",
    "    # \"hidden_size\": {\"value\":hidden_size}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [1500]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"CEL\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        # \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00008,\n",
    "            \"max\": 0.0015,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [7]\n",
    "        },\n",
    "        \"batch_before_backwards\": {\n",
    "            'values': [7]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"NEW GRU-sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48ca33c5a1168302a4f8eae355aad1c03b1396f568d40bc174a6e6aabe725d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
