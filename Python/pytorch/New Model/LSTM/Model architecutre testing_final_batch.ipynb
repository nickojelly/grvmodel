{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "with torch.profiler.profile() as profiler:\n",
    "        pass\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(f1_layer_size, f2_layer_size, dropout, num_layers=2):\n",
    "\n",
    "\n",
    "    network = nn.Sequential(  # fully-connected, dual hidden layer\n",
    "        nn.Linear(128, f1_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(f1_layer_size, f2_layer_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(f2_layer_size, 8),\n",
    "        nn.Softmax(dim=1),\n",
    "    )\n",
    "\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogInput:\n",
    "    def __init__(self, dogid, raceid,stats, dog,dog_box, lstmCellh,lstmCellc) -> None:\n",
    "        self.dogid= dogid\n",
    "        self.raceid = raceid\n",
    "        self.stats = stats.to('cuda:0')\n",
    "        self.dog = dog\n",
    "        self.lstmCellh = lstmCellh.float().to('cuda:0')\n",
    "        self.lstmCellc = lstmCellc.float().to('cuda:0')\n",
    "        self.visited = 0\n",
    "        \n",
    "        \n",
    "    def lstm_i(self, lstmInput):\n",
    "        (self.lstmCellh,self.lstmCellc) = lstmInput\n",
    "        # self.lstmCellh=self.lstmCellh.to(device)\n",
    "        # self.lstmCellc=self.lstmCellc.to(device)\n",
    "        self.visited = self.visited + 1\n",
    "        # if self.visited>1:\n",
    "        #     print(\"FOUND LEAK\")\n",
    "        #     sasdfasd\n",
    "\n",
    "    def nextrace(self, raceid):\n",
    "        self.nextrace_id = raceid\n",
    "\n",
    "    def prevrace(self, raceid):\n",
    "        self.prevrace_id = raceid\n",
    "\n",
    "    def lstm_o(self, lstm_o):\n",
    "        # print(lstm_o[0]._version)\n",
    "        (lh,lc) = lstm_o\n",
    "        if self.nextrace_id==-1:\n",
    "            pass\n",
    "        else:\n",
    "            self.dog.races[self.nextrace_id].lstm_i((lh.detach(), lc.detach())) #DETACH\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    def __init__(self, dogid, hidden_size, layers) -> None:\n",
    "        self.dogid = dogid\n",
    "        # self.raceids = raceids #possible dictionary of race id keys dog stat outs\n",
    "        self.lstmcell = 0\n",
    "        self.layers = layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l_debug = None\n",
    "        self.races = {}\n",
    "\n",
    "    def add_races(self, raceid, racedate, stats,nextraceid, prevraceid, box):\n",
    "        self.races[raceid] = DogInput(self.dogid, raceid, stats, self, box, torch.randn(self.hidden_size).clone(),torch.randn(self.hidden_size).clone()) #this is the change\n",
    "        self.races[raceid].nextrace(nextraceid)\n",
    "        self.races[raceid].prevrace(prevraceid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Race:\n",
    "    def __init__(self, raceid,trackOHE, dist, classes):\n",
    "        self.raceid = raceid\n",
    "        self.race_dist = dist.to('cuda:0')\n",
    "        self.race_track = trackOHE.to('cuda:0')\n",
    "        self.classes =  classes.to('cuda:0')\n",
    "\n",
    "    def add_dogs(self, dogs_list:DogInput):\n",
    "        self.dog1 = dogs_list[0]\n",
    "        self.dog2 = dogs_list[1]\n",
    "        self.dog3 = dogs_list[2]\n",
    "        self.dog4 = dogs_list[3]\n",
    "        self.dog5 = dogs_list[4]\n",
    "        self.dog6 = dogs_list[5]\n",
    "        self.dog7 = dogs_list[6]\n",
    "        self.dog8 = dogs_list[7]\n",
    "        self.dogs = dogs_list\n",
    "\n",
    "    def nn_input(self):\n",
    "        input = torch.cat([x.stats for x in self.dogs], dim = 0)\n",
    "        full_input = torch.cat((self.race_dist,self.race_track, input), dim=0).to(device='cuda:0')\n",
    "        self.full_input = full_input\n",
    "        return full_input\n",
    "\n",
    "    def lstm_input(self):\n",
    "        \n",
    "        l_input = [(x.lstmCellh,x.lstmCellc) for x in self.dogs]\n",
    "        return l_input\n",
    "\n",
    "    def list_dogs(self):\n",
    "        dogs_l = [x for x in self.dogs]\n",
    "        return dogs_l\n",
    "\n",
    "    def pass_lstm_output(self, lstm_h, lstm_c):\n",
    "        for i,dog in enumerate(self.dogs):\n",
    "            \n",
    "            lh = lstm_h[i]\n",
    "            lc = lstm_c[i]\n",
    "            lh,lc = lh.detach(), lc.clone()\n",
    "            dog.lstm_o((lh,lc))\n",
    "            dog.dog.l_debug = (lh,lc)\n",
    "        # zipped_lstm = zip(self.dogs,lstms)\n",
    "        # [x.lstm_o(y) for x,y in zipped_lstm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Races:\n",
    "    def __init__(self, hidden_size, layers, batch_size = 100) -> None:\n",
    "        self.racesDict = {}\n",
    "        self.dogsDict = {}\n",
    "        self.raceIDs = []\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.getter = operator.itemgetter(*range(batch_size))\n",
    "\n",
    "    def add_race(self,raceid:str, trackOHE, dist, classes):\n",
    "        self.racesDict[raceid] = Race(raceid, trackOHE, dist, classes)\n",
    "        self.raceIDs.append(raceid)\n",
    "\n",
    "    def add_dog(self,dogid):\n",
    "        if dogid not in self.dogsDict.keys():\n",
    "            self.dogsDict[dogid] = Dog(dogid, self.hidden_size, self.layers)\n",
    "        else:\n",
    "            self.dogsDict[dogid] = self.dogsDict[dogid]\n",
    "\n",
    "    def get_race_input(self, idx) -> Race:\n",
    "        raceidx = operator.itemgetter(*idx)\n",
    "        #raceidx  = self.getter(idx)\n",
    "        race_batch_id = raceidx(self.raceIDs)\n",
    "\n",
    "        #race_getter = operator.itemgetter(*raceidx)\n",
    "\n",
    "        races = [self.racesDict[x] for x in race_batch_id] #Returns list of class Race\n",
    "        \n",
    "\n",
    "        # raceidx = self.raceIDs[idx]\n",
    "        #input = torch.cat([x.stats for x in races.dogs.values()], dim = 0)\n",
    "        #full_input = torch.cat((self.racesDict[raceidx].race_dist,self.racesDict[raceidx].race_track, input), dim=0 )\n",
    "        # dogs = [x for x in self.racesDict[raceidx].dogs]\n",
    "        \n",
    "        return races #self.racesDict[raceidx]\n",
    "\n",
    "    def get_race_classes(self, idx):\n",
    "        raceidx = self.raceIDs[idx]\n",
    "        classes = [x for x in self.raceDict[raceidx].classes]\n",
    "        return classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm2 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm3 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm4 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm5 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm6 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm7 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm8 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size * 8, 64)\n",
    "        self.fc3 = nn.Linear(64, 8)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, race: Race):\n",
    "        #x = race.nn_input().float().to('cuda:0')\n",
    "        x = torch.stack([r.full_input.float() for r in race])\n",
    "\n",
    "        #creates list of LSTM data \n",
    "        lstm_ins = [list(i) for i in zip(*[r.lstm_input() for r in race])]\n",
    "\n",
    "        # creates list of tensors for lstm Cells\n",
    "        hCell = [torch.stack([x[0] for x in y]) for y in lstm_ins]\n",
    "        cCell = [torch.stack([x[1] for x in y]) for y in lstm_ins]\n",
    "\n",
    "        (h1, c1) = self.lstm1(x, (hCell[0], cCell[0]))\n",
    "        (h2, c2) = self.lstm2(x, (hCell[1], cCell[1]))\n",
    "        (h3, c3) = self.lstm3(x, (hCell[2], cCell[2]))\n",
    "        (h4, c4) = self.lstm4(x, (hCell[3], cCell[3]))\n",
    "        (h5, c5) = self.lstm5(x, (hCell[4], cCell[4]))\n",
    "        (h6, c6) = self.lstm6(x, (hCell[5], cCell[5]))\n",
    "        (h7, c7) = self.lstm7(x, (hCell[6], cCell[6]))\n",
    "        (h8, c8) = self.lstm8(x, (hCell[7], cCell[7]))\n",
    "\n",
    "        lstm_list = [\n",
    "            (h1, c1),\n",
    "            (h2, c2),\n",
    "            (h3, c3),\n",
    "            (h4, c4),\n",
    "            (h5, c5),\n",
    "            (h6, c6),\n",
    "            (h7, c7),\n",
    "            (h8, c8)\n",
    "        ]\n",
    "\n",
    "        hCello = [i for i in zip(*[x[0] for x in lstm_list])]\n",
    "        cCello = [i for i in zip(*[x[1] for x in lstm_list])]\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            r.pass_lstm_output(hCello[i],cCello[i])\n",
    "        xhh = torch.cat((h1.clone(),h2.clone(), h3.clone(), h4.clone(), h5.clone(), h6.clone(), h7.clone(), h8.clone()), dim=1).clone()\n",
    "        xh = self.fc2(xhh)\n",
    "        xf = self.fc3(xh)\n",
    "\n",
    "        output = F.softmax(xf, dim=0)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data, hidden_size):\n",
    "\n",
    "    #Load in pickeled dataframe\n",
    "    resultsdf = pickle.load(data)\n",
    "    dog_stats_df = pd.DataFrame(resultsdf)\n",
    "    dog_stats_df = dog_stats_df.fillna(-1).drop_duplicates(subset=['dogid', 'raceid'])\n",
    "    dog_stats_df['stats_cuda'] = dog_stats_df.apply(lambda x: torch.tensor(x['stats']), axis =1)\n",
    "    dog_stats_df['box'] = dog_stats_df['stats'].apply(lambda x: x[0])\n",
    "\n",
    "    #Created RaceDB\n",
    "    raceDB = Races(hidden_size, 1)\n",
    "\n",
    "    #Fill in dog portion:\n",
    "\n",
    "    dog_stats_group = dog_stats_df.sort_values(['date']).groupby([\"dogid\"])\n",
    "\n",
    "    for i,j in tqdm(dog_stats_group):\n",
    "        j[\"next_race\"] = j[\"raceid\"].shift(-1).fillna(-1)\n",
    "        j[\"prev_race\"] = j[\"raceid\"].shift(1).fillna(-1)\n",
    "        raceDB.add_dog(i)\n",
    "        j.apply(lambda x: raceDB.dogsDict[i].add_races(x['raceid'], x['date'], torch.Tensor(x['stats']),x['next_race'], x['prev_race'], x['box']), axis=1)\n",
    "\n",
    "    #Fill in races portion\n",
    "    softmin = nn.Softmin()\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "\n",
    "    null_dog = Dog(\"nullDog\", raceDB.hidden_size, raceDB.layers)\n",
    "    null_dog_i = DogInput(\"nullDog\", \"-1\", torch.zeros(16), null_dog,0, torch.zeros(raceDB.hidden_size), torch.zeros(raceDB.hidden_size))\n",
    "    null_dog_i.nextrace(-1)\n",
    "    null_dog_i.prevrace(-1)\n",
    "\n",
    "    null_dog_list = [null_dog] * 8\n",
    "    #TO FIX LATER PROPER BOX PLACEMENT #FIXED\n",
    "\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "    for i,j in tqdm(races_group):\n",
    "    #Track info tensors\n",
    "        dist = torch.tensor([j.dist.iloc[0]]) \n",
    "        trackOHE = torch.tensor(j.trackOHE.iloc[0])\n",
    "        #margins\n",
    "        empty_dog_list = [null_dog_i]*8\n",
    "        empty_margin_list = [100]*8\n",
    "        boxes_list = [x for x in j['box']]\n",
    "        margin_list = [x for x in j[\"place\"]]\n",
    "        dog_list = [raceDB.dogsDict[x].races[i] for x in j[\"dogid\"]]\n",
    "\n",
    "        #adjustedMargin = [margin_list[x-1] for x in boxes_list]\n",
    "        for n,x in enumerate(boxes_list):\n",
    "            empty_margin_list[x-1] = margin_list[n]\n",
    "            empty_dog_list[x-1] = dog_list[n]\n",
    "        adjustedMargin = softmin(torch.tensor(empty_margin_list)).to('cuda:0')\n",
    "        #adjusted_dog_list = [dog_list[x-1] for x in boxes_list]\n",
    "        \n",
    "        raceDB.add_race(i,trackOHE,dist, adjustedMargin)\n",
    "        \n",
    "        \n",
    "        # List of Dog Input??\n",
    "        raceDB.racesDict[i].add_dogs(empty_dog_list)\n",
    "        raceDB.racesDict[i].nn_input()\n",
    "\n",
    "\n",
    "    return raceDB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25187/25187 [03:30<00:00, 119.41it/s]\n",
      "  0%|          | 0/72073 [00:00<?, ?it/s]C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_15288\\1524283141.py:51: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
      "  adjustedMargin = softmin(torch.tensor(empty_margin_list)).to('cuda:0')\n",
      "100%|██████████| 72073/72073 [00:57<00:00, 1255.59it/s]\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( 'dog_stats_df.npy', 'rb')\n",
    "raceDB = build_dataset(dog_stats_file, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Net.forward of Net(\n",
       "  (lstm1): LSTMCell(144, 5)\n",
       "  (lstm2): LSTMCell(144, 5)\n",
       "  (lstm3): LSTMCell(144, 5)\n",
       "  (lstm4): LSTMCell(144, 5)\n",
       "  (lstm5): LSTMCell(144, 5)\n",
       "  (lstm6): LSTMCell(144, 5)\n",
       "  (lstm7): LSTMCell(144, 5)\n",
       "  (lstm8): LSTMCell(144, 5)\n",
       "  (fc2): Linear(in_features=40, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnet = Net(144,5)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(newnet.parameters(), lr=0.001)\n",
    "newnet = newnet.to('cuda:0')\n",
    "newnet.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def validate_model(model, batch_size):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in trange(60000,70000,batch_size):   \n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "            race = raceDB.get_race_input(races_idx)\n",
    "            X = race\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            output = model(X)\n",
    "            #print(y)\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            #print(predicted)\n",
    "            #print(actual)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "            total +=10\n",
    "\n",
    "\n",
    "\n",
    "            #loss = loss_function(output, y)\n",
    "            #optimizer.zero_grad()\n",
    "            #newnet.zero_grad()\n",
    "            #loss.backward(retain_graph=True)  \n",
    "            #optimizer.step()\n",
    "            #if i %5000 == 0:\n",
    "            #    print(loss)\n",
    "        # optimizer.step() \n",
    "        #print(loss)\n",
    "    print(f\"accuray: {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [05:34<00:00,  1.79it/s]\n",
      "  2%|▏         | 30/1250 [00:00<00:04, 299.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0551, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:03<00:00, 374.28it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.18696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [05:32<00:00,  1.80it/s]\n",
      "  4%|▍         | 54/1250 [00:00<00:04, 272.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0551, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:03<00:00, 373.83it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.18512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [05:34<00:00,  1.79it/s]\n",
      "  6%|▌         | 73/1250 [00:00<00:03, 362.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0553, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:03<00:00, 381.13it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.19072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [05:34<00:00,  1.79it/s]\n",
      "  3%|▎         | 35/1250 [00:00<00:03, 343.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:03<00:00, 380.90it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.18416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [05:32<00:00,  1.80it/s]\n",
      "  5%|▍         | 60/1250 [00:00<00:03, 299.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0551, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:03<00:00, 372.83it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.18912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [05:34<00:00,  1.79it/s]\n",
      "  2%|▏         | 30/1250 [00:00<00:04, 294.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0551, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:03<00:00, 372.61it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [05:32<00:00,  1.80it/s]\n",
      "  5%|▌         | 63/1250 [00:00<00:03, 309.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:03<00:00, 371.61it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.19104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [05:42<00:00,  1.75it/s]\n",
      "  2%|▏         | 23/1250 [00:00<00:05, 221.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:03<00:00, 367.13it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray: 0.18936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 128/600 [01:14<04:27,  1.76it/s]"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "list_t = [] \n",
    "last = 0\n",
    "batch_size = 100\n",
    "for epoch in range(200): \n",
    "    for i in trange(0,60000,batch_size):   \n",
    "        races_idx = range(last,last+batch_size)\n",
    "        last = i\n",
    "        race = raceDB.get_race_input(races_idx)\n",
    "        X = race\n",
    "        # print(X)\n",
    "        #y = race.classes.to(device)\n",
    "        y = torch.stack([x.classes for x in race])\n",
    "        #print(y)\n",
    "        output = newnet(X)\n",
    "        # print(y)\n",
    "        # print(output)\n",
    "        #\n",
    "        #print(output) \n",
    "        #print([x.dogid for x in X.dogs])\n",
    "        loss = loss_function(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        #newnet.zero_grad()\n",
    "        loss.backward(retain_graph=True)  \n",
    "        optimizer.step()\n",
    "        # if i %5000 == 0:\n",
    "        #     #print(loss)\n",
    "    # optimizer.step() \n",
    "    print(loss)\n",
    "    validate_model(newnet, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YYY\n"
     ]
    }
   ],
   "source": [
    "print(\"YYY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([-0.8675, -0.8717, -1.5944, -0.5800, -0.0219], device='cuda:0'),\n",
      "  tensor([-0.5273,  0.3271,  0.7316,  0.4938,  1.6515], device='cuda:0')),\n",
      " (tensor([ 1.8622,  0.6056, -0.5197, -0.5091,  0.7088], device='cuda:0'),\n",
      "  tensor([-1.1639, -0.4896,  0.9631, -0.3343, -0.7571], device='cuda:0')),\n",
      " (tensor([ 1.0674, -2.0852, -1.0210, -0.0981, -0.2083], device='cuda:0'),\n",
      "  tensor([-1.3528,  1.0761,  1.2515,  0.3496,  0.6863], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "dlstm = [list(i) for i in zip(*[x.lstm_input() for x in test_data])]\n",
    "pprint.pprint(dlstm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cCell = [torch.stack([x[0] for x in y]) for y in dlstm]\n",
    "hCell = [torch.stack([x[1] for x in y]) for y in dlstm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cCell[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.5273,  0.3271,  0.7316,  0.4938,  1.6515],\n",
       "         [-1.1639, -0.4896,  0.9631, -0.3343, -0.7571],\n",
       "         [-1.3528,  1.0761,  1.2515,  0.3496,  0.6863]], device='cuda:0'),\n",
       " tensor([[-0.1061, -0.2952,  1.9279,  0.9492, -0.2213],\n",
       "         [ 0.7067, -1.4521, -0.4989, -0.0936,  0.2086],\n",
       "         [-1.3173, -0.1100, -0.9247, -0.7827, -0.1964]], device='cuda:0'),\n",
       " tensor([[-0.6996, -0.1256, -0.8835, -0.0646, -2.0322],\n",
       "         [ 1.0575, -0.2605, -0.1528, -0.4997,  0.4953],\n",
       "         [ 0.8972,  0.1420,  1.7114,  0.2030,  0.3664]], device='cuda:0'),\n",
       " tensor([[ 0.9384, -1.7895, -0.1702,  0.8365, -0.3397],\n",
       "         [ 0.9431,  0.7915, -0.1227, -0.3582, -1.5961],\n",
       "         [-0.5381,  1.8346,  1.1186, -0.0132, -1.0070]], device='cuda:0'),\n",
       " tensor([[-1.3374,  0.7250,  0.9002,  1.6969, -0.3953],\n",
       "         [-0.1624, -1.7428,  0.5430, -1.1477,  1.3154],\n",
       "         [-2.4506, -0.3516, -0.2425, -1.9107, -1.3467]], device='cuda:0'),\n",
       " tensor([[-0.0748, -1.1441, -0.9800, -0.3879,  1.4227],\n",
       "         [-0.9902, -0.5500, -0.8701,  2.1527,  0.8719],\n",
       "         [-0.1297, -0.2071, -0.6797, -0.4930, -0.1676]], device='cuda:0'),\n",
       " tensor([[ 1.0561,  0.7028, -0.9943,  0.8695,  0.5319],\n",
       "         [-2.6373, -0.7280, -0.0351, -0.9051, -0.8489],\n",
       "         [ 0.6732,  1.8240,  0.1028, -0.4300,  0.9132]], device='cuda:0'),\n",
       " tensor([[-0.1616,  0.2579,  0.8063,  0.3895,  0.9010],\n",
       "         [ 1.7293, -1.1653,  0.1046, -0.2537, -0.4013],\n",
       "         [ 0.8751,  0.6250,  0.6417, -1.6019,  0.5123]], device='cuda:0')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hCell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43115443075634c02a7c247a87b0dd9d74842892e56d473b9e19f544f3149aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
