{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "# from rnn_classes import Dog, DogInput, Race, Races, GRUNet, smallGRUNet, smalll_lin_GRUNet, smalll_prelin_GRUNet\n",
    "import rnn_classes\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n",
    "from model_saver import model_saver, model_saver_wandb\n",
    "import training_testing_gru\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, pad_packed_sequence,pad_sequence, unpack_sequence, unpad_sequence\n",
    "import training_testing_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_l2(output, target):\n",
    "    loss = torch.mean(abs(output-target), dim=1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.compile(rnn_classes.GRUNetv2(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dist_last__1', 'box_last__1', 'speed_avg_1', 'split_speed_v1_1', 'split_margin_avg_1', 'margin_avg_1', 'first_out_avg_1', 'post_change_avg_1', 'races_1', 'wins_1', 'weight_', 'min_time_', 'min_split_time_v1', 'last_start_price']]\n",
      "(1246719, 23)\n",
      "20\n",
      "Latest date = 2023-05-20 00:00:00\n",
      "size after state filter (131306, 25)\n",
      "(131306, 25)\n",
      "Latest date = 2023-05-18 00:00:00\n",
      "num_features_per_dog=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3609 [00:00<?, ?it/s]c:\\ProgramData\\Anaconda3\\envs\\torch2\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 3609/3609 [00:50<00:00, 71.51it/s] \n",
      "  0%|          | 0/17400 [00:00<?, ?it/s]c:\\ProgramData\\Anaconda3\\envs\\torch2\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 17400/17400 [00:38<00:00, 451.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 17400, number of unique dogs = 3610\n",
      "0        (Auckland, 318.0)\n",
      "1        (Auckland, 318.0)\n",
      "2        (Auckland, 527.0)\n",
      "3        (Auckland, 318.0)\n",
      "4        (Auckland, 318.0)\n",
      "               ...        \n",
      "17395     (Waikato, 318.0)\n",
      "17396     (Waikato, 318.0)\n",
      "17397     (Waikato, 527.0)\n",
      "17398     (Waikato, 318.0)\n",
      "17399     (Waikato, 318.0)\n",
      "Length: 17400, dtype: object\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "hidden_size = 32\n",
    "states = [\"NZ\"]\n",
    "raceDB = build_dataset('gru_inputs_simple_v6_test.fth', hidden_size ,state_filter=states,margin_type='sftmin',v6=True)\n",
    "raceDB.create_new_weights_v2()\n",
    "#raceDB.adjust_weights({\"Dapto\":10, \"Gunnedah\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 13565, Test examples 3835\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date=datetime.date(2019, 12, 1)\n",
      "period=datetime.date(2020, 5, 29)\n",
      "start_date=datetime.date(2020, 5, 29)\n",
      "period=datetime.date(2020, 11, 25)\n",
      "start_date=datetime.date(2020, 11, 25)\n",
      "period=datetime.date(2021, 5, 24)\n",
      "start_date=datetime.date(2021, 5, 24)\n",
      "period=datetime.date(2021, 11, 20)\n",
      "start_date=datetime.date(2021, 11, 20)\n",
      "period=datetime.date(2022, 5, 19)\n",
      "start_date=datetime.date(2022, 5, 19)\n",
      "period=datetime.date(2022, 7, 31)\n",
      "[(datetime.date(2019, 12, 1), datetime.date(2020, 5, 29)), (datetime.date(2020, 5, 29), datetime.date(2020, 11, 25)), (datetime.date(2020, 11, 25), datetime.date(2021, 5, 24)), (datetime.date(2021, 5, 24), datetime.date(2021, 11, 20)), (datetime.date(2021, 11, 20), datetime.date(2022, 5, 19)), (datetime.date(2022, 5, 19), datetime.date(2022, 7, 31))]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime.strptime(\"2019-12-01\", \"%Y-%m-%d\").date()\n",
    "end_date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()-datetime.timedelta(1)\n",
    "period = start_date\n",
    "batches = []\n",
    "while start_date<end_date:\n",
    "   \n",
    "    print(f\"{start_date=}\")\n",
    "    period = min(start_date+datetime.timedelta(180), end_date)\n",
    "    print(f\"{period=}\")\n",
    "    batches.append((start_date,period))\n",
    "    start_date=period\n",
    "    #batches.append((start_date,end_date))\n",
    "# batches.append((period,end_date))\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-29\n",
      "2020-11-25\n",
      "2021-05-24\n",
      "2021-11-20\n",
      "2022-05-19\n",
      "2022-07-31\n",
      "Train examples [2201, 2826, 2680, 2396, 2444, 1001]\n"
     ]
    }
   ],
   "source": [
    "batch_races_ids = [] # list of race_ids\n",
    "j = 0\n",
    "current_batch = []\n",
    "for i,r in enumerate(raceDB.raceIDs):   \n",
    "    _,end_date = batches[j]\n",
    "    race_date = raceDB.racesDict[r].race_date\n",
    "    if race_date>end_date:\n",
    "        print(end_date)\n",
    "\n",
    "        batch_races_ids.append(current_batch)\n",
    "        current_batch = []\n",
    "        j += 1\n",
    "        if j>len(batches)-1:\n",
    "            break\n",
    "    else:\n",
    "        current_batch.append(r)\n",
    "print(f\"Train examples {[len(x) for x in batch_races_ids]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a460d37ec3994bf6a292e1fe746b6f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc9e958574c4b92a2677f9edc07de97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3609 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923f2bc901604a07aa57129885e65c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3609 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ccddbf59234a9eb795a81af342f37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3609 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5b5fc639724dac8a1b8489d69b3d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3609 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6e3997d18748c9ac0069e2635abeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3609 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5053b27da845788e44087152fa35a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3609 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dogs = []\n",
    "train_dog_input = []\n",
    "for bi, batch in enumerate(tqdm(batch_races_ids)):\n",
    "    # print(bi)\n",
    "    # print(batch)\n",
    "    batch_dogs = []\n",
    "    batch_dog_input = []\n",
    "    for i in tqdm(raceDB.dog_ids):\n",
    "        dog = raceDB.dogsDict[i]\n",
    "        train = [dog.races[x] for x in batch if x in dog.races.keys()]\n",
    "        if train:\n",
    "            batch_dogs.append(dog)\n",
    "            batch_dog_input.append(train)\n",
    "    train_dogs.append(batch_dogs)\n",
    "    train_dog_input.append(batch_dog_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_races = [[raceDB.racesDict[r] for r in inner] for inner in batch_races_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples [1557, 1594, 1489, 1492, 1400, 1111]\n",
      "Train examples [1557, 1594, 1489, 1492, 1400, 1111]\n",
      "Train examples [2201, 2826, 2680, 2396, 2444, 1001]\n",
      "Train examples [2201, 2826, 2680, 2396, 2444, 1001]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train examples {[len(x) for x in train_dogs]}\")\n",
    "print(f\"Train examples {[len(x) for x in train_dog_input]}\")\n",
    "print(f\"Train examples {[len(x) for x in batch_races]}\")\n",
    "print(f\"Train examples {[len(x) for x in batch_races_ids]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3609/3609 [00:00<00:00, 33386.36it/s]\n"
     ]
    }
   ],
   "source": [
    "raceDB.create_dogs_test_split_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3610/3610 [00:01<00:00, 1941.18it/s]\n"
     ]
    }
   ],
   "source": [
    "raceDB.attach_races_to_dog_inputv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = range(0,len(raceDB.test_dog_ids))\n",
    "packed_x = \"\"#[pack_sequence([torch.stack(n,0) for n in [[z.full_input for z in inner] for inner in x]], enforce_sorted=False).to('cuda:0') for x in train_dog_input]\n",
    "packed_x_basic = [pad_packed_sequence(pack_sequence([torch.stack(n,0) for n in [[z.stats.to('cuda:0') for z in inner] for inner in x]], enforce_sorted=False))for x in train_dog_input]\n",
    "packed_y = \"\"#pack_sequence([torch.stack(n,0) for n in [[z.full_input.to('cuda:0') for z in inner] for inner in [x for x in raceDB.get_dog_test(test_idx)]]], enforce_sorted=False)\n",
    "packed_y_basic = pad_packed_sequence(pack_sequence([torch.stack(n,0) for n in [[z.stats.to('cuda:0') for z in inner] for inner in [x for x in raceDB.get_dog_test(test_idx)]]], enforce_sorted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_x_basic = [pad_packed_sequence(x) for x in packed_x_basic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1557, 20])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x_basic[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked = unpack_sequence(packed_x_basic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1557"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_312\\1324076212.py:1: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
      "  nested = torch.nested.nested_tensor(unpacked)\n"
     ]
    }
   ],
   "source": [
    "nested = torch.nested.nested_tensor(unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer  = nn.TransformerEncoderLayer(d_model=20,nhead=4).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1557, 20])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x_basic[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoder_layer(padded_x_basic[0][0].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1557, 20])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_x_basic[0][0].float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1708,  0.5108,  2.1908,  ...,  0.2228, -1.0999, -0.9056],\n",
       "        [-1.4513,  0.7152,  2.1147,  ..., -0.0393, -1.0783, -0.7099],\n",
       "        [-1.1686,  0.7340,  0.0943,  ...,  0.0453, -0.2615, -0.5735],\n",
       "        ...,\n",
       "        [ 0.9456, -0.4808,  0.0664,  ..., -0.5273, -0.5002, -0.9016],\n",
       "        [ 0.8274, -0.4897, -0.1180,  ..., -0.2977, -0.3392, -1.2762],\n",
       "        [-0.4448,  0.1323, -0.0369,  ..., -0.7002, -0.0393, -0.8480]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-1.1708, -1.4513, -1.1686, -0.2120,  0.6496,  0.3790, -1.1653, -1.0864,\n",
       "         -0.7685, -0.2735, -1.0294, -1.1291, -1.1102,  0.1459], device='cuda:0',\n",
       "        grad_fn=<IndexBackward0>),\n",
       " tensor([0.5108, 0.7152, 0.7340, 0.7785, 0.5425, 0.5794, 0.5450, 0.3639, 0.9087,\n",
       "         0.2044], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([2.1908, 2.1147, 0.0943, 1.9416, 0.9474, 1.7561, 2.1187, 2.1312, 2.1985,\n",
       "         0.6009], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([-0.4003, -0.4126,  0.1401, -0.7992], device='cuda:0',\n",
       "        grad_fn=<IndexBackward0>),\n",
       " tensor([0.9204, 0.1915, 0.9526, 2.2515, 2.9153, 2.0073, 1.0532, 1.3416, 1.5354,\n",
       "         3.8105, 0.6398, 2.2670, 0.8582, 1.0711, 0.3113, 0.4485, 0.7538, 0.3519],\n",
       "        device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([-0.0934, -0.1772,  0.1373], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([-1.1421, -1.2737, -1.6256, -1.2465, -0.7016, -0.8933, -0.9594, -0.9663,\n",
       "         -1.6277, -0.6409, -1.1947, -0.8697, -1.3943, -1.3076], device='cuda:0',\n",
       "        grad_fn=<IndexBackward0>),\n",
       " tensor([-0.5545, -0.3838, -0.7384, -0.5425, -0.0824, -0.6873, -0.5040, -0.4555,\n",
       "         -0.6195, -0.9344, -0.4120, -0.3836, -0.4880, -0.2389, -0.4725, -0.0490],\n",
       "        device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([-0.4887, -0.6966, -0.3260, -0.9714, -0.9383, -0.4630, -0.5036, -0.3971,\n",
       "         -0.8029, -0.1732, -0.6673, -0.2663, -0.5284, -1.3592, -0.1525],\n",
       "        device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([ 0.0450,  0.0517,  0.2850, -0.0450, -0.0478, -0.1103, -0.2430, -0.2029,\n",
       "         -0.0228, -0.2053, -0.0832, -0.0677, -0.1792], device='cuda:0',\n",
       "        grad_fn=<IndexBackward0>),\n",
       " tensor([-1.2749, -1.1043, -1.7463, -1.0245, -0.1238, -1.0005, -0.9148, -1.0369,\n",
       "         -1.3569, -0.4649, -1.1462], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([-0.4629,  0.0915, -0.8590, -0.5759, -0.1748, -0.8278, -0.4331, -0.6932,\n",
       "         -0.2979, -0.4685, -0.2917, -0.5956, -0.4202,  0.2487, -0.4829, -0.5260,\n",
       "          0.1610, -0.3103, -0.0482], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([-0.8780, -0.8395, -0.6818, -0.1073,  0.5607, -0.8561, -0.6243, -0.5191,\n",
       "         -0.7026, -0.3896, -0.7146, -0.4940, -0.8392,  1.1219, -0.9429, -0.8029,\n",
       "         -0.7245, -0.7337,  0.7574, -0.6745, -0.3570, -0.8103], device='cuda:0',\n",
       "        grad_fn=<IndexBackward0>),\n",
       " tensor([1.2264, 1.2021, 1.1114, 1.1030, 0.4562, 1.1163, 1.1259, 1.2240, 1.1035,\n",
       "         0.3090], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([ 0.8435,  1.0639,  1.1014,  0.6174,  0.3564,  0.9869,  1.0201,  0.7074,\n",
       "          1.2654,  0.7280,  1.0911,  0.9116,  1.2802, -1.2771,  1.0977,  1.3095,\n",
       "          1.2105,  1.2566, -0.9086,  1.0375,  0.6004,  0.8842,  0.7003,  0.5101],\n",
       "        device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([ 0.6898,  0.8709,  0.9988,  1.0125, -0.2601,  0.6832,  1.0064,  0.8709,\n",
       "          0.9740,  0.2326,  0.9793,  0.2651,  1.0317,  1.3217,  0.8607],\n",
       "        device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([ 1.8216,  1.8650,  2.3807,  0.4821, -1.4557,  1.3459,  1.8191,  1.9145,\n",
       "         -0.0934,  0.2953,  2.0142,  1.5702,  0.2516, -0.8212,  1.8155,  2.1593,\n",
       "          0.0046,  2.1035, -0.8033,  1.5947,  0.0223], device='cuda:0',\n",
       "        grad_fn=<IndexBackward0>),\n",
       " tensor([ 0.2228, -0.0393,  0.0453, -1.0634, -1.3556, -0.3598,  0.0545, -0.2260,\n",
       "         -0.1863, -0.3984, -0.1268, -0.2163, -0.0506, -1.3760, -0.1167],\n",
       "        device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([-1.0999, -1.0783], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       " tensor([-0.9056, -0.7099, -0.5735, -1.0873, -1.3840, -1.0880], device='cuda:0',\n",
       "        grad_fn=<IndexBackward0>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpad_sequence(encoded[0], padded_x_basic[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dog_input_stacked = [[torch.stack(n,0) for n in [[z.full_input.to('cpu') for z in inner] for inner in x]] for x in train_dog_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [sum([len(x) for x in n])/len([len(x) for x in n]) for n in train_dog_input_stacked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.batches = {'num_batches':len(train_dogs),\n",
    "                  'dogs':train_dogs,\n",
    "                  'train_dog_input':train_dog_input,\n",
    "                  'batch_races':batch_races,\n",
    "                  'batch_races_ids':batch_races_ids,\n",
    "                  'packed_x':packed_x,\n",
    "                  'packed_x_basic':packed_x_basic,\n",
    "                  'packed_y_basic':packed_y_basic, \n",
    "                  'packed_y':packed_y}\n",
    "\n",
    "# raceDB.batches = {'num_batches':len(train_dogs),\n",
    "#                     'dogs':train_dogs,\n",
    "#                     'train_dog_input':train_dog_input,\n",
    "#                     'batch_races':batch_races,\n",
    "#                     'batch_races_ids':batch_races_ids,\n",
    "#                     'packed_x':packed_x,\n",
    "#                     'packed_y':packed_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None, prev_model_file=None, prev_model_version='450'):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"NEW attn\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss_val\", summary=\"min\")\n",
    "      wandb.define_metric(\"accuracy\", summary=\"max\")\n",
    "      wandb.define_metric('ROI < 30', summary=\"max\")\n",
    "      wandb.define_metric(\"multibet profit\", summary=\"max\")\n",
    "      \n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "      # input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0] #create fix so messy\n",
    "      print(config.input_type)\n",
    "      if config.input_type == 'full':\n",
    "        print('here1')\n",
    "        input_size = raceDB.batches['packed_x'][0].data[0].shape[0]\n",
    "      elif config.input_type == 'basic':\n",
    "        print('here')\n",
    "        raceDB.batches['packed_x'] = raceDB.batches['packed_x_basic']\n",
    "        raceDB.batches['packed_y'] = raceDB.batches['packed_y_basic']\n",
    "        input_size = 20\n",
    "\n",
    "      print(f\"{input_size=}\")\n",
    "\n",
    "\n",
    "      raceDB.reset_hidden(num_layers=config['num_layers'], hidden_size=config['hidden_size'])\n",
    "      model = rnn_classes.AttnNetv1(input_size,config['hidden_size'], num_layers=config['num_layers'],fc0_size=config['f0_layer_size'], fc1_size=config['f1_layer_size'])\n",
    "\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      if prev_model_file!=None:\n",
    "        model_name = prev_model_file\n",
    "        model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{prev_model_version}.pt\"\n",
    "        model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "        model.load_state_dict(model_data['model_state_dict'])\n",
    "        config['parent model'] = prev_model_file\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "        optimizer.load_state_dict(model_data['optim'])\n",
    "        # optimizer.to(device)\n",
    "      else:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "      raceDB.to_cuda()\n",
    "      criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "\n",
    "      print(optimizer)\n",
    "\n",
    "      model = model.to(device)\n",
    "\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        training_testing_attn.train_regular_v3(model, dataset, criterion, optimizer, 'na', config)\n",
    "      except (KeyboardInterrupt) as error:\n",
    "        print(error)\n",
    "        print(\"finished Early\")\n",
    "        \n",
    "      # dataset.create_hidden_states_dict()\n",
    "      raceDB.create_hidden_states_dict_v2()\n",
    "      \n",
    "      model_saver_wandb(model, optimizer, 450, 0.1, raceDB.hidden_states_dict_gru_v6,raceDB.train_hidden_dict , model_name=\"long nsw new  22000 RUN\")\n",
    "      if sweep:\n",
    "        raceDB.reset_hidden()\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':20,\n",
    "                       'stats':raceDB.stats_cols,\n",
    "                       'races':states,\n",
    "                       'latest_date':raceDB.latest_date,\n",
    "                       'input_type':'basic',\n",
    "                       'num_layers':1,\n",
    "                       'batch_size': 750,\n",
    "                       'dropout': 0.3,\n",
    "                       'epochs': 10_000,\n",
    "                       'learning_rate': 0.0004,\n",
    "                       'optimizer': 'adamW',\n",
    "                       'f0_layer_size':128,\n",
    "                       'f1_layer_size':64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'rnn_classes' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\grvmodel\\\\Python\\\\pytorch\\\\New Model\\\\LSTM\\\\rnn_classes.py'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(training_testing_attn)\n",
    "importlib.reload(rnn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for race in raceDB.racesDict.values():\n",
    "    for dog in race.dogs:\n",
    "        try:\n",
    "            del dog.stats\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.reset_hidden(num_layers=wandb_config_static['num_layers'], hidden_size=wandb_config_static['hidden_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9f6a4502cf446bb6324706816414e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230602_184934-shl1jfca</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nickojelly/NEW%20GRU/runs/shl1jfca' target=\"_blank\">still-shadow-704</a></strong> to <a href='https://wandb.ai/nickojelly/NEW%20GRU' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nickojelly/NEW%20GRU' target=\"_blank\">https://wandb.ai/nickojelly/NEW%20GRU</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nickojelly/NEW%20GRU/runs/shl1jfca' target=\"_blank\">https://wandb.ai/nickojelly/NEW%20GRU/runs/shl1jfca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 20, 'stats': \"[['dist_last__1', 'box_last__1', 'speed_avg_1', 'split_speed_v1_1', 'split_margin_avg_1', 'margin_avg_1', 'first_out_avg_1', 'post_change_avg_1', 'races_1', 'wins_1', 'weight_', 'min_time_', 'min_split_time_v1', 'last_start_price']]\", 'races': ['NZ'], 'latest_date': '2023-05-18T00:00:00', 'input_type': 'basic', 'num_layers': 1, 'batch_size': 750, 'dropout': 0.3, 'epochs': 10000, 'learning_rate': 0.0004, 'optimizer': 'adamW', 'f0_layer_size': 128, 'f1_layer_size': 64}\n",
      "10000\n",
      "{'hidden_size': 20, 'stats': \"[['dist_last__1', 'box_last__1', 'speed_avg_1', 'split_speed_v1_1', 'split_margin_avg_1', 'margin_avg_1', 'first_out_avg_1', 'post_change_avg_1', 'races_1', 'wins_1', 'weight_', 'min_time_', 'min_split_time_v1', 'last_start_price']]\", 'races': ['NZ'], 'latest_date': '2023-05-18T00:00:00', 'input_type': 'basic', 'num_layers': 1, 'batch_size': 750, 'dropout': 0.3, 'epochs': 10000, 'learning_rate': 0.0004, 'optimizer': 'adamW', 'f0_layer_size': 128, 'f1_layer_size': 64}\n",
      "basic\n",
      "here\n",
      "input_size=20\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0004\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "AttnNetv1(\n",
      "  (encoder): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=20, out_features=20, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=20, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=20, bias=True)\n",
      "    (norm1): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (relu0): ReLU()\n",
      "  (fc0): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=230, out_features=128, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (rl3): ReLU()\n",
      "  (drop3): Dropout(p=0.3, inplace=False)\n",
      "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371c1b59a0f445f0a10c1cceadb2c7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">still-shadow-704</strong> at: <a href='https://wandb.ai/nickojelly/NEW%20GRU/runs/shl1jfca' target=\"_blank\">https://wandb.ai/nickojelly/NEW%20GRU/runs/shl1jfca</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230602_184934-shl1jfca\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (model,dataset, optimizer) \u001b[39m=\u001b[39m model_pipeline(raceDB,config\u001b[39m=\u001b[39;49mwandb_config_static,sweep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[48], line 68\u001b[0m, in \u001b[0;36mmodel_pipeline\u001b[1;34m(my_dataset, config, prev_model, sweep, model_state_dict, prev_model_file, prev_model_version)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m# and use them to train the model\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m   training_testing_attn\u001b[39m.\u001b[39;49mtrain_regular_v3(model, dataset, criterion, optimizer, \u001b[39m'\u001b[39;49m\u001b[39mna\u001b[39;49m\u001b[39m'\u001b[39;49m, config)\n\u001b[0;32m     69\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m     70\u001b[0m   \u001b[39mprint\u001b[39m(error)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\training_testing_attn.py:74\u001b[0m, in \u001b[0;36mtrain_regular_v3\u001b[1;34m(model, raceDB, criterion, optimizer, scheduler, config, update)\u001b[0m\n\u001b[0;32m     71\u001b[0m batch_races_ids \u001b[39m=\u001b[39m raceDB\u001b[39m.\u001b[39mbatches[\u001b[39m'\u001b[39m\u001b[39mbatch_races_ids\u001b[39m\u001b[39m'\u001b[39m][i]\n\u001b[0;32m     72\u001b[0m X \u001b[39m=\u001b[39m raceDB\u001b[39m.\u001b[39mbatches[\u001b[39m'\u001b[39m\u001b[39mpacked_x\u001b[39m\u001b[39m'\u001b[39m][i]\n\u001b[1;32m---> 74\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39;49mshape\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m example_ct\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(batch_races)\n\u001b[0;32m     78\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"ROI < 30\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f0_layer_size\": {\"values\": [1024]},\n",
    "    \"f1_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"input_type\": {\"values\": ['full','basic']},\n",
    "    \"num_layers\": {\"values\": [2]},\n",
    "    'hidden_size':{'values':[128]},\n",
    "    \"len_data\": {\"value\": len(raceDB.raceIDs)},\n",
    "    \"stats\":{\"value\": raceDB.stats_cols},\n",
    "    \"races\":{\"value\": states},\n",
    "    # \"hidden_size\": {\"value\":hidden_size}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [1500]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"CEL\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        # \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00008,\n",
    "            \"max\": 0.0015,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [7]\n",
    "        },\n",
    "        \"batch_before_backwards\": {\n",
    "            'values': [7]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"NEW GRU-sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48ca33c5a1168302a4f8eae355aad1c03b1396f568d40bc174a6e6aabe725d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
