{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "from rnn_classes import Dog, DogInput, Race, Races, GRUNet, smallGRUNet, smalll_lin_GRUNet\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n",
    "from training_testing import validate_model, train_regular, train_log, train_super_batch, train_super_batch_KL, train_super_batch_L1, train_regular_L1,train_regular_one_hot\n",
    "from model_saver import model_saver, model_saver_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_to_bf(model:GRUNet,raceDB:Races,example_ct):\n",
    "    with torch.no_grad():\n",
    "        sft_max = nn.Softmax(dim=-1)\n",
    "        l_sftmax = nn.LogSoftmax(dim=-1)\n",
    "        nnl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        full_test_races = raceDB.get_test_input(range(0,len(raceDB.test_race_ids)))\n",
    "        full_test_races_w_prices = []\n",
    "        excluded, included = 0,0\n",
    "        for r in full_test_races:\n",
    "            if 0 in r.prices or -1 in r.prices:\n",
    "                excluded+=1\n",
    "            else:\n",
    "                full_test_races_w_prices.append(r)\n",
    "                included+=1\n",
    "        print(included,excluded)\n",
    "\n",
    "        output = l_sftmax(model(full_test_races_w_prices))\n",
    "        bf_prices = torch.log(torch.tensor([x.implied_prob for x in full_test_races_w_prices ]).to('cuda:0'))\n",
    "        full_classes = torch.stack([x.classes for x in full_test_races_w_prices ])\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(f\"our loss = {nnl_loss(output,full_classes)}\")\n",
    "        print(f\"their loss = {nnl_loss(bf_prices ,full_classes)}\")\n",
    "        wandb.log({\"our loss\":nnl_loss(output,full_classes), \"their loss\":nnl_loss(bf_prices ,full_classes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168053, 19)\n",
      "(1168053, 19)\n",
      "(288467, 22)\n",
      "Latest date = 2023-03-06 00:00:00\n",
      "num_features_per_dog=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14655 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 14655/14655 [01:26<00:00, 170.31it/s]\n",
      "  0%|          | 0/40482 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 40482/40482 [01:17<00:00, 523.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 40482, number of unique dogs = 14655\n",
      "0          (Dubbo, 400.0)\n",
      "1          (Dubbo, 318.0)\n",
      "2          (Dubbo, 318.0)\n",
      "3        (Grafton, 305.0)\n",
      "4        (Grafton, 305.0)\n",
      "               ...       \n",
      "40477    (Gosford, 388.0)\n",
      "40478    (Gosford, 515.0)\n",
      "40479    (Gosford, 388.0)\n",
      "40480    (Gosford, 388.0)\n",
      "40481    (Gosford, 388.0)\n",
      "Length: 40482, dtype: object\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "#dog_stats_file = open( 'new gru input 2023-01.npy', 'rb')\n",
    "hidden_size = 64\n",
    "raceDB = build_dataset('new_windows_gru_REAL.npy', hidden_size ,state_filter=[\"NSW\"], margin_type='neg_raw')\n",
    "raceDB.create_new_weights_v2()\n",
    "# raceDB.adjust_weights({\"Dapto\":10, \"Gunnedah\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 32452, Test examples 8030\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None, prev_model_file=\"rich-sweep-2\"):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"GRU - FastTrack - AUS Testing - L1\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      wandb.define_metric(\"multibet profit\", summary=\"max\")\n",
    "      \n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "      input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0] #create fix so messy\n",
    "\n",
    "      model = smalll_lin_GRUNet(input_size,config['hidden_size'])\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      if prev_model_file!=None:\n",
    "        model_name = prev_model_file\n",
    "        model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_450.pt\"\n",
    "        model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "        raceDB.fill_hidden_states_from_dict(hidden_dict=model_data['db'])\n",
    "        model.load_state_dict(model_data['model_state_dict'])\n",
    "        config['parent model'] = prev_model_file\n",
    "\n",
    "\n",
    "      raceDB.to_cuda()\n",
    "\n",
    "      # criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "      criterion = nn.SmoothL1Loss(reduction='none', beta=10)\n",
    "      optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.Adadelta(model.parameters())\n",
    "      # optimizer = optim.RMSprop(model.parameters(), lr=config['learning_rate'])\\\n",
    "      # optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
    "\n",
    "      print(criterion, optimizer)\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',threshold=0.0001, patience=10000, verbose=True, factor=0.5)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        train_regular_L1(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      except KeyboardInterrupt:\n",
    "        print(\"finished Early\")\n",
    "      dataset.create_hidden_states_dict()\n",
    "      model_saver_wandb(model, optimizer, 450, 0.1, dataset.hidden_states_dict_gru, model_name=\"long nsw new  22000 RUN\")\n",
    "      if sweep:\n",
    "        raceDB.reset_all_lstm_states\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes',\n",
      " 'metric': {'goal': 'maximize', 'name': 'ROI < 30'},\n",
      " 'parameters': {'batch_before_backwards': {'values': [5, 10, 20]},\n",
      "                'batch_size': {'values': [100, 250, 500, 1000]},\n",
      "                'dropout': {'values': [0.3]},\n",
      "                'epochs': {'values': [50]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'hidden_size': {'value': 64},\n",
      "                'l1_beta': {'value': 0.1},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.001,\n",
      "                                  'min': 1e-05},\n",
      "                'len_data': {'value': 40482},\n",
      "                'loss': {'values': ['CEL']},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adamW'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'bayes',\n",
       " 'metric': {'name': 'ROI < 30', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adamW'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3]},\n",
       "  'len_data': {'value': 40482},\n",
       "  'hidden_size': {'value': 64},\n",
       "  'epochs': {'values': [50]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'values': ['CEL']},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 1e-05, 'max': 0.001},\n",
       "  'l1_beta': {'value': 0.1},\n",
       "  'batch_size': {'values': [100, 250, 500, 1000]},\n",
       "  'batch_before_backwards': {'values': [5, 10, 20]}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sweep_config = {\"method\": \"bayes\"}\n",
    "\n",
    "metric = {\"name\": \"ROI < 30\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": len(raceDB.raceIDs)},\n",
    "    \"hidden_size\": {\"value\":64}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [50]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"CEL\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\":{\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00001,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [100,250,500,1000]\n",
    "        },\n",
    "        \"batch_before_backwards\": {\n",
    "            'values': [5,10,20]\n",
    "        },\n",
    "\n",
    "        # \"batch_before_backwards\": {\n",
    "        #     # a flat distribution between 0 and 0.1\n",
    "        #     \"distribution\": \"uniform\",\n",
    "        #     \"min\": 3,\n",
    "        #     \"max\": 50,\n",
    "        # },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 5000, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.00095, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1,'batch_before_backwards':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230306_191118-2m7n4f6b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing%20-%20L1/runs/2m7n4f6b\" target=\"_blank\">stoic-sun-4</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing%20-%20L1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.00095, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 10}\n",
      "1000\n",
      "{'hidden_size': 64, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.00095, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40482/40482 [00:15<00:00, 2546.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =273645\n",
      "empty  =50211\n",
      "0.8449588706091596null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00095\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [02:00<00:00, 20.09s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.82it/s]84s/it]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.30it/s]31s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.23it/s]23s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.08it/s]04s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.15it/s]64s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.23it/s]12s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.98it/s]17s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.76it/s]63s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.03it/s]51s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.64it/s].09s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.78it/s].62s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.10it/s].58s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.93it/s].54s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.92it/s].49s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.08it/s].41s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.55it/s].61s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.69it/s].02s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.71it/s].22s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.26it/s].11s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.22it/s].50s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.60it/s].46s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.25it/s].79s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.11it/s].25s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.31it/s].30s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.61it/s].26s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.30it/s]49s/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.15it/s].70s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.44it/s].30s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.27it/s]87s/it] \n",
      "100%|██████████| 6/6 [00:02<00:00,  2.85it/s]78s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.63it/s].54s/it]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.38it/s]06.32s/it]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.33it/s]08.17s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.51it/s]13.27s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.30it/s]12.74s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.24it/s]08.03s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.08it/s]03.73s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.22it/s]04.92s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.34it/s]00.26s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.33it/s]9.54s/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.45it/s]13.60s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.46it/s]11.83s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.07it/s]07.85s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.15it/s]04.31s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.53it/s]01.70s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.35it/s]7.66s/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.18it/s]00.81s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.15it/s]03.65s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.34it/s]9.45s/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.39it/s]6.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Nick\\\\AppData\\\\Local\\\\Temp\\\\tmpvp78cu3awandb-media\\\\cjnt5g2x.table.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.34it/s]5.94s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.50it/s]6.11s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.41it/s]6.35s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.55it/s]6.78s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.59it/s]5.57s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.62it/s]2.87s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.67it/s]6.36s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.69it/s]9.52s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.39it/s]7.84s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.48it/s]6.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Nick\\\\AppData\\\\Local\\\\Temp\\\\tmpvp78cu3awandb-media\\\\15nytxzk.table.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.06it/s]7.78s/it]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.45it/s]6.79s/it]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.42it/s]00.39s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.53it/s]04.24s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.04it/s]04.84s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.34it/s]02.18s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.66it/s]02.14s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.97it/s]06.66s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.92it/s]06.75s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.14it/s]03.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Nick\\\\AppData\\\\Local\\\\Temp\\\\tmpvp78cu3awandb-media\\\\1p1s21hu.table.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.29it/s]02.34s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.59it/s]00.50s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.58it/s]7.97s/it] \n",
      "100%|██████████| 6/6 [00:03<00:00,  1.56it/s]02.01s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.53it/s]04.46s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.17it/s]01.37s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.58it/s]7.89s/it] \n",
      "100%|██████████| 6/6 [00:03<00:00,  1.56it/s]8.75s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.59it/s]01.19s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.24it/s]00.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Nick\\\\AppData\\\\Local\\\\Temp\\\\tmpvp78cu3awandb-media\\\\3jz86i5n.table.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.93it/s]9.65s/it] \n",
      "100%|██████████| 6/6 [00:02<00:00,  2.91it/s]00.43s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.02it/s]8.63s/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.26it/s]00.02s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.90it/s]04.44s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.09it/s]01.78s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.26it/s]8.00s/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.06it/s]9.12s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.31it/s]00.37s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.14it/s]01.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Nick\\\\AppData\\\\Local\\\\Temp\\\\tmpvp78cu3awandb-media\\\\3baiv9fn.table.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.64it/s]02.30s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.02it/s]02.57s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.12it/s]00.36s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.99it/s]00.15s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.18it/s]04.23s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.48it/s]8.81s/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.03it/s]8.37s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]00.98s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.41it/s]7.92s/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.50it/s]94.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Nick\\\\AppData\\\\Local\\\\Temp\\\\tmpvp78cu3awandb-media\\\\9d11wdbi.table.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.41it/s]93.99s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]93.87s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.73it/s]91.92s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.06it/s]92.96s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.01it/s]99.01s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.62it/s]99.52s/it]\n"
     ]
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False,prev_model_file=\"pious-waterfall-236\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: hg9kz1xn\n",
      "Sweep URL: https://wandb.ai/nickojelly/GRU_sweeps/sweeps/hg9kz1xn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ndwtrweu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00021092187045869445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230228_101624-ndwtrweu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/ndwtrweu\" target=\"_blank\">sleek-sweep-1</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/hg9kz1xn\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/hg9kz1xn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00021092187045869445, 'len_data': 40228, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00021092187045869445, 'len_data': 40228, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40228/40228 [00:13<00:00, 2923.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =272093\n",
      "empty  =49731\n",
      "0.8454714378045143null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00021092187045869445\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:34<00:00,  1.84it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.46it/s]t]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.37it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.46it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]] \n",
      "100%|██████████| 64/64 [00:26<00:00,  2.45it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.56it/s]]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.29it/s]]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.72it/s]]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.53it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.00it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.29it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.05it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.97it/s]it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"GRU_sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48ca33c5a1168302a4f8eae355aad1c03b1396f568d40bc174a6e6aabe725d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
