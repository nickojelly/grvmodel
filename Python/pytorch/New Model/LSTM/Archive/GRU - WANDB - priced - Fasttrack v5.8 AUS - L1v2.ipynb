{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "from rnn_classes import Dog, DogInput, Race, Races, GRUNet, smallGRUNet, smalll_lin_GRUNet\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n",
    "from training_testing import validate_model, train_regular, train_log, train_super_batch, train_super_batch_KL, train_super_batch_L1, train_regular_L1,train_regular_one_hot\n",
    "from model_saver import model_saver, model_saver_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_to_bf(model:GRUNet,raceDB:Races,example_ct):\n",
    "    with torch.no_grad():\n",
    "        sft_max = nn.Softmax(dim=-1)\n",
    "        l_sftmax = nn.LogSoftmax(dim=-1)\n",
    "        nnl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        full_test_races = raceDB.get_test_input(range(0,len(raceDB.test_race_ids)))\n",
    "        full_test_races_w_prices = []\n",
    "        excluded, included = 0,0\n",
    "        for r in full_test_races:\n",
    "            if 0 in r.prices or -1 in r.prices:\n",
    "                excluded+=1\n",
    "            else:\n",
    "                full_test_races_w_prices.append(r)\n",
    "                included+=1\n",
    "        print(included,excluded)\n",
    "\n",
    "        output = l_sftmax(model(full_test_races_w_prices))\n",
    "        bf_prices = torch.log(torch.tensor([x.implied_prob for x in full_test_races_w_prices ]).to('cuda:0'))\n",
    "        full_classes = torch.stack([x.classes for x in full_test_races_w_prices ])\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(f\"our loss = {nnl_loss(output,full_classes)}\")\n",
    "        print(f\"their loss = {nnl_loss(bf_prices ,full_classes)}\")\n",
    "        wandb.log({\"our loss\":nnl_loss(output,full_classes), \"their loss\":nnl_loss(bf_prices ,full_classes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1164832, 18)\n",
      "(1164832, 18)\n",
      "(123805, 21)\n",
      "Latest date = 2023-03-02 00:00:00\n",
      "num_features_per_dog=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3489 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 3489/3489 [00:26<00:00, 130.40it/s]\n",
      "  0%|          | 0/16386 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 16386/16386 [00:32<00:00, 498.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 16386, number of unique dogs = 3489\n",
      "0        (Palmerston North, 410.0)\n",
      "1        (Palmerston North, 410.0)\n",
      "2        (Palmerston North, 410.0)\n",
      "3        (Palmerston North, 410.0)\n",
      "4        (Palmerston North, 410.0)\n",
      "                   ...            \n",
      "16381        (Christchurch, 295.0)\n",
      "16382        (Christchurch, 520.0)\n",
      "16383        (Christchurch, 295.0)\n",
      "16384        (Christchurch, 295.0)\n",
      "16385        (Christchurch, 295.0)\n",
      "Length: 16386, dtype: object\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "#dog_stats_file = open( 'new gru input 2023-01.npy', 'rb')\n",
    "hidden_size = 64\n",
    "raceDB = build_dataset('new_windows_gru_REAL.npy', hidden_size ,state_filter=\"NZ\", margin_type='neg_raw')\n",
    "raceDB.create_new_weights_v2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 13565, Test examples 2821\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None, prev_model_file=\"rich-sweep-2\"):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"GRU - FastTrack - AUS Testing - L1\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      wandb.define_metric(\"multibet profit\", summary=\"max\")\n",
    "      \n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "      input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0] #create fix so messy\n",
    "\n",
    "      model = smalll_lin_GRUNet(input_size,config['hidden_size'])\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      if prev_model_file!=None:\n",
    "        model_name = prev_model_file\n",
    "        model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_450.pt\"\n",
    "        model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "        raceDB.fill_hidden_states_from_dict(hidden_dict=model_data['db'])\n",
    "        model.load_state_dict(model_data['model_state_dict'])\n",
    "        config['parent model'] = prev_model_file\n",
    "\n",
    "\n",
    "      raceDB.to_cuda()\n",
    "\n",
    "      # criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "      criterion = nn.SmoothL1Loss(reduction='none', beta=10)\n",
    "      optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.Adadelta(model.parameters())\n",
    "      # optimizer = optim.RMSprop(model.parameters(), lr=config['learning_rate'])\\\n",
    "      # optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
    "\n",
    "      print(criterion, optimizer)\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',threshold=0.0001, patience=10000, verbose=True, factor=0.5)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        train_regular_L1(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      except KeyboardInterrupt:\n",
    "        print(\"finished Early\")\n",
    "      dataset.create_hidden_states_dict()\n",
    "      model_saver_wandb(model, optimizer, 450, 0.1, dataset.hidden_states_dict_gru, model_name=\"long nsw new  22000 RUN\")\n",
    "      if sweep:\n",
    "        raceDB.reset_all_lstm_states\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes',\n",
      " 'metric': {'goal': 'maximize', 'name': 'ROI < 30'},\n",
      " 'parameters': {'batch_before_backwards': {'values': [5, 10, 20]},\n",
      "                'batch_size': {'values': [100, 250, 500, 1000]},\n",
      "                'dropout': {'values': [0.3]},\n",
      "                'epochs': {'values': [50]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'hidden_size': {'value': 64},\n",
      "                'l1_beta': {'value': 0.1},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.001,\n",
      "                                  'min': 1e-05},\n",
      "                'len_data': {'value': 16386},\n",
      "                'loss': {'values': ['CEL']},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adamW'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'bayes',\n",
       " 'metric': {'name': 'ROI < 30', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adamW'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3]},\n",
       "  'len_data': {'value': 16386},\n",
       "  'hidden_size': {'value': 64},\n",
       "  'epochs': {'values': [50]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'values': ['CEL']},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 1e-05, 'max': 0.001},\n",
       "  'l1_beta': {'value': 0.1},\n",
       "  'batch_size': {'values': [100, 250, 500, 1000]},\n",
       "  'batch_before_backwards': {'values': [5, 10, 20]}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sweep_config = {\"method\": \"bayes\"}\n",
    "\n",
    "metric = {\"name\": \"ROI < 30\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": len(raceDB.raceIDs)},\n",
    "    \"hidden_size\": {\"value\":64}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [50]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"CEL\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\":{\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00001,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [100,250,500,1000]\n",
    "        },\n",
    "        \"batch_before_backwards\": {\n",
    "            'values': [5,10,20]\n",
    "        },\n",
    "\n",
    "        # \"batch_before_backwards\": {\n",
    "        #     # a flat distribution between 0 and 0.1\n",
    "        #     \"distribution\": \"uniform\",\n",
    "        #     \"min\": 3,\n",
    "        #     \"max\": 50,\n",
    "        # },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 50, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.00095, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1,'batch_before_backwards':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230303_110900-2q05kji8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/2q05kji8\" target=\"_blank\">skilled-butterfly-263</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'batch_size': 50, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.00095, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 7}\n",
      "1000\n",
      "{'hidden_size': 64, 'batch_size': 50, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.00095, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16386/16386 [00:00<00:00, 18752.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =131088\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00095\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 271/271 [00:46<00:00,  5.89it/s]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.11it/s]t]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.64it/s]t]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.34it/s]t]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.37it/s]t]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.65it/s]t]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.55it/s]t]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.18it/s]t]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.20it/s]t]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.30it/s]t]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.46it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.49it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.36it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.55it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.49it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.39it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.30it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.53it/s]it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.77it/s]it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.63it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.48it/s]it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.17it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.35it/s]it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.19it/s]it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.69it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.38it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.37it/s]it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.21it/s]it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.10it/s]it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.26it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.61it/s]it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.22it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.36it/s]it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.23it/s]it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.06it/s]it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.03it/s]it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.95it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.33it/s]it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.70it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.60it/s]it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.74it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.44it/s]it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.71it/s]it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.76it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.57it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.59it/s]it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.27it/s]it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.37it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.49it/s]it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.28it/s]it]\n",
      "100%|██████████| 271/271 [00:39<00:00,  6.80it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.45it/s]it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.75it/s]it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.50it/s]s/it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.60it/s]s/it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.63it/s]s/it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.63it/s]s/it]\n",
      "100%|██████████| 271/271 [00:39<00:00,  6.81it/s]s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.44it/s]s/it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.71it/s]s/it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.47it/s]s/it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.69it/s]s/it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.56it/s]s/it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.63it/s]s/it]\n",
      "100%|██████████| 271/271 [00:40<00:00,  6.64it/s]s/it]\n",
      "100%|██████████| 271/271 [00:39<00:00,  6.88it/s]s/it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.55it/s]s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.32it/s]s/it]\n",
      "100%|██████████| 271/271 [00:48<00:00,  5.63it/s]s/it]\n",
      "100%|██████████| 271/271 [00:48<00:00,  5.56it/s]s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.85it/s]s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.74it/s]s/it]\n",
      "100%|██████████| 271/271 [00:50<00:00,  5.40it/s]s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.06it/s]s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.98it/s]s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.80it/s]s/it]\n",
      "100%|██████████| 271/271 [00:48<00:00,  5.62it/s]s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.81it/s]s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.12it/s]s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.18it/s]s/it]\n",
      "100%|██████████| 271/271 [00:49<00:00,  5.48it/s]s/it]\n",
      "100%|██████████| 271/271 [00:51<00:00,  5.31it/s]s/it]\n",
      "100%|██████████| 271/271 [00:51<00:00,  5.28it/s]s/it]\n",
      "100%|██████████| 271/271 [00:49<00:00,  5.53it/s]s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.78it/s]s/it]\n",
      "100%|██████████| 271/271 [00:50<00:00,  5.41it/s]s/it]\n",
      "100%|██████████| 271/271 [00:50<00:00,  5.40it/s]s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.07it/s]s/it]\n",
      "100%|██████████| 271/271 [01:00<00:00,  4.47it/s]s/it]\n",
      "100%|██████████| 271/271 [00:57<00:00,  4.73it/s]s/it]\n",
      "100%|██████████| 271/271 [00:50<00:00,  5.32it/s]s/it]\n",
      "100%|██████████| 271/271 [00:53<00:00,  5.05it/s]s/it]\n",
      "100%|██████████| 271/271 [00:55<00:00,  4.91it/s]s/it]\n",
      "100%|██████████| 271/271 [00:48<00:00,  5.53it/s]s/it]\n",
      "100%|██████████| 271/271 [00:52<00:00,  5.13it/s]s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.74it/s]s/it]\n",
      "100%|██████████| 271/271 [00:48<00:00,  5.62it/s]s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.18it/s]s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.83it/s]s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.80it/s]s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.23it/s]7s/it]\n",
      "100%|██████████| 271/271 [00:49<00:00,  5.42it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:50<00:00,  5.40it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.09it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.86it/s]7s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.87it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.11it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.77it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.84it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:53<00:00,  5.02it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:51<00:00,  5.26it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.72it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:49<00:00,  5.45it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.84it/s]3s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.70it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.71it/s]3s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.08it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.94it/s]1s/it]\n",
      "100%|██████████| 271/271 [00:49<00:00,  5.51it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:49<00:00,  5.50it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:53<00:00,  5.10it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.79it/s]9s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.06it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.79it/s]3s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.17it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:48<00:00,  5.63it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.38it/s]1s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.68it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.65it/s]8s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.21it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.96it/s]3s/it]\n",
      "100%|██████████| 271/271 [00:51<00:00,  5.26it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.91it/s]1s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.66it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.99it/s]8s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.16it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:48<00:00,  5.54it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.33it/s]8s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.10it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.25it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.42it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.82it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.36it/s]8s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.23it/s]5s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.98it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:41<00:00,  6.49it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.12it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.21it/s]7s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.20it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.88it/s]7s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.38it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.35it/s]8s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.83it/s]5s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.33it/s]1s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.25it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.25it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.15it/s]3s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.75it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.98it/s]9s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.76it/s]5s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.75it/s]7s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  6.01it/s]9s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.86it/s]9s/it]\n",
      "100%|██████████| 271/271 [00:47<00:00,  5.68it/s]9s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.25it/s]5s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.95it/s]5s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.20it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.25it/s]3s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.81it/s]5s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.34it/s]4s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.12it/s]8s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.12it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.13it/s]7s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.79it/s]8s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.43it/s]7s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.18it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:44<00:00,  6.02it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.33it/s]0s/it]\n",
      "100%|██████████| 271/271 [00:46<00:00,  5.84it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:43<00:00,  6.27it/s]5s/it]\n",
      "100%|██████████| 271/271 [00:42<00:00,  6.35it/s]6s/it]\n",
      "100%|██████████| 271/271 [00:45<00:00,  5.93it/s]2s/it]\n",
      "100%|██████████| 271/271 [00:50<00:00,  5.40it/s]7s/it]\n",
      " 18%|█▊        | 182/1000 [3:40:26<16:30:46, 72.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Early\n",
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2e1d38b7bf45e18ee9fa8569852b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='255.460 MB of 255.460 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▂▃▄▃▃▄▃▄▄▆▅▅▃▃▂▄▄▃▃▄▂▁▇▆▇▇▇█▅▃▅█▇▇▆▆▆▆▅▄</td></tr><tr><td>FK ROI < 30</td><td>▁▄▆▄▃▅█▄▅▇▄▅▄▄▂▅▆▅▄▅▂▂▇▇▆▆▅▆▅▃▄▇▆▅▆▅▅▆▅▅</td></tr><tr><td>ROI</td><td>▂▃▃▃▂▄▂▄▄▅▅▅▃▂▂▄▄▃▃▃▂▁▇▆▇▇▇█▅▃▅█▆▇▆▆▆▆▅▄</td></tr><tr><td>ROI < 30</td><td>▁▄▆▄▃▅█▄▄▇▄▅▄▄▃▅▇▅▅▅▂▂▇▇▆▆▅▆▅▄▄▇▆▅▆▅▅▆▅▅</td></tr><tr><td>accuracy</td><td>▄▃▄▄▃▅▃▃▄▅▇▄▁▃▃▁▂▃▄▄▄▅▇▇▆▇▅▇▅▅▇█▇▆▇▇▇▇▆▅</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▆▆▄▄▃▃▅▃▄▃▂▃▃▄▃▃▂▂▂▂▃▂▂▂▁▂▂▂▃▂▂▁▁▂▂▂▂▂▂</td></tr><tr><td>correct</td><td>▄▃▄▄▃▅▃▃▄▅▇▄▁▃▃▁▂▃▄▄▄▅▇▇▆▇▅▇▅▅▇█▇▆▇▇▇▇▆▅</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▄▃▃▃▃▃▃▂▃▂▂▂▂▂▁▂▂▁▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>███▆▆▄▂▂▁▁▂▂▄▁▂▁▁▁▁▂▃▅▄▂▂▂▃▃▃▃▂▃▂▂▂▂▃▃▃▂</td></tr><tr><td>multibet outlay < 30</td><td>▇▇█▅▅▄▁▁▁▁▂▃▄▁▂▂▁▁▂▂▄█▆▄▄▅▆▅▅▅▅▆▄▄▅▅▆▅▅▄</td></tr><tr><td>multibet profit</td><td>▁▃▃▃▂▄▂▄▄▅▅▅▃▃▂▄▄▃▃▃▂▁▇▆▇▇▇█▅▄▅█▇▇▆▆▆▆▅▄</td></tr><tr><td>multibet profit < 30</td><td>▁▄▆▄▄▅█▅▅▇▅▅▅▅▃▅▇▅▅▅▃▂▇▇▆▆▅▆▅▄▅▇▆▅▆▅▅▆▆▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▄▆█▅▄▄▃▁▁▂▁▂▄▂▂▁▂▂▁▁▂▄▅▃▂▂▄▃▃▃▂▄▃▃▃▃▃▃▃▂</td></tr><tr><td>multibet profit sd</td><td>▆▆▇▄▄▅▁▅▄▅▅▃▄▃▄▅▃▃▃▃▄▂█▅▆▇▇█▄▄▇▇▅▇▆▆▅▅▆▅</td></tr><tr><td>profit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.04097</td></tr><tr><td>FK ROI < 30</td><td>-0.05372</td></tr><tr><td>ROI</td><td>-0.03859</td></tr><tr><td>ROI < 30</td><td>-0.05389</td></tr><tr><td>accuracy</td><td>0.19273</td></tr><tr><td>batch_before_backwards</td><td>7</td></tr><tr><td>batch_loss</td><td>12.52422</td></tr><tr><td>correct</td><td>530</td></tr><tr><td>epoch</td><td>182</td></tr><tr><td>epoch_loss</td><td>13.28694</td></tr><tr><td>loss_val</td><td>1.44355</td></tr><tr><td>multibet outlay</td><td>84105.69748</td></tr><tr><td>multibet outlay < 30</td><td>56286.50392</td></tr><tr><td>multibet profit < 30</td><td>-3033.48496</td></tr><tr><td>multibet profit < 30 sd</td><td>25.8822</td></tr><tr><td>multibet profit sd</td><td>56.26791</td></tr><tr><td>profit</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">skilled-butterfly-263</strong>: <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/2q05kji8\" target=\"_blank\">https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/2q05kji8</a><br/>Synced 5 W&B file(s), 278 media file(s), 278 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230303_110900-2q05kji8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: fkf5o4gd\n",
      "Sweep URL: https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zp6bcv9v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003921465953934761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_004346-zp6bcv9v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/zp6bcv9v\" target=\"_blank\">lucky-sweep-1</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003921465953934761, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003921465953934761, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 21746.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0003921465953934761\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:08<00:00,  1.46it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.33it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.51it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.10it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  1.97it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.51it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.36it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.49it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.05it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.22it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.45it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.34it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.10it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.09it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.41it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.54it/s]\n",
      "100%|██████████| 13/13 [00:09<00:00,  1.42it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.09it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.03it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.47it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.09it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.38it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.07it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.48it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n",
      "100%|██████████| 13/13 [00:09<00:00,  1.40it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:09<00:00,  1.39it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.20it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.07it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.03it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n",
      "100%|██████████| 50/50 [28:45<00:00, 34.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cff2aaa618b483584b73f31a60c9898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.403 MB of 67.403 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>█▇▆▆▅▄▂▁▃▂▁▁▂▃▃▄▄▃▃▃▄▄▃▂▃▄▄▄▅▅▄▅▄▄▅▅▆▆▄▅</td></tr><tr><td>FK ROI < 30</td><td>▁▁▂▄▄▄▅▅▆▆▅▅▄▄▄▄▄▄▄▄▅▅▄▄▅▅▅▆▆▆▆▆▆▇▇▇█▇▆▇</td></tr><tr><td>ROI</td><td>█▇▆▆▅▄▂▁▃▂▁▁▂▃▃▄▄▃▃▃▄▃▃▂▃▄▄▄▅▄▄▅▄▄▄▅▅▅▄▅</td></tr><tr><td>ROI < 30</td><td>▁▁▂▃▄▄▄▅▆▆▅▅▄▄▄▄▄▄▄▄▅▅▄▄▅▅▆▆▆▆▆▆▆▇▇▇█▇▇▇</td></tr><tr><td>accuracy</td><td>▄▄▅▆▃▃▁▁▃▂▅▅▅▅▅▆▅▅▅▅▅▅▅▄▅▅▆▆▅▆▆▆▆▇▇▆█▇▇▆</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▂▇▄▂▇▄▂▆▄▆▄▂▆▄▁▆▄▁▆▁▆▃▁▆▃▁▆▃▁▃▁▆▃▁▆▃▁▅▃</td></tr><tr><td>correct</td><td>▄▄▅▆▃▃▁▁▃▂▅▅▅▅▅▆▅▅▅▅▅▅▅▄▅▅▆▆▅▆▆▆▆▇▇▆█▇▇▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▆▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>██▇▆▄▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▁▁▁▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>██▇▇▅▃▂▁▁▁▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂</td></tr><tr><td>multibet profit</td><td>█▇▆▆▅▃▂▁▃▂▁▁▂▃▃▄▄▃▃▃▄▃▃▂▃▄▄▄▅▄▄▅▄▄▄▅▅▅▄▅</td></tr><tr><td>multibet profit < 30</td><td>▁▁▂▃▄▅▅▅▇▇▆▅▅▅▅▅▅▄▄▅▆▅▅▅▅▆▆▆▇▆▆▆▆▇▇▇█▇▇▇</td></tr><tr><td>multibet profit < 30 sd</td><td>█▇▆▅▃▂▁▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▂▂▂▃▃▃▄▄▄▄</td></tr><tr><td>multibet profit sd</td><td>██▇▆▄▃▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>profit</td><td>▆▅▄▅▅▄▅▂▂▁▃▃▁▄▆▇▇▇▆▆█▆▅▅▆▆▇▇▆▇▇█▇▇▇▇█▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.0441</td></tr><tr><td>FK ROI < 30</td><td>-0.05782</td></tr><tr><td>ROI</td><td>-0.04302</td></tr><tr><td>ROI < 30</td><td>-0.0606</td></tr><tr><td>accuracy</td><td>0.18545</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>17.47592</td></tr><tr><td>correct</td><td>510</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>17.47592</td></tr><tr><td>loss_val</td><td>4.49386</td></tr><tr><td>multibet outlay</td><td>91203.90747</td></tr><tr><td>multibet outlay < 30</td><td>60214.72665</td></tr><tr><td>multibet profit < 30</td><td>-3649.13496</td></tr><tr><td>multibet profit < 30 sd</td><td>30.71119</td></tr><tr><td>multibet profit sd</td><td>68.57149</td></tr><tr><td>profit</td><td>1886.40675</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lucky-sweep-1</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/zp6bcv9v\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/zp6bcv9v</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_004346-zp6bcv9v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ohx15mpl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00012066292095517836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_011302-ohx15mpl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/ohx15mpl\" target=\"_blank\">serene-sweep-2</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00012066292095517836, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00012066292095517836, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 26781.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00012066292095517836\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  1.98it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.49it/s]\n",
      "100%|██████████| 13/13 [00:12<00:00,  1.01it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.00it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.33it/s]\n",
      "100%|██████████| 13/13 [00:12<00:00,  1.01it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  1.98it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.47it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
      "100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.46it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.41it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.36it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n",
      "100%|██████████| 13/13 [00:12<00:00,  1.01it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.03it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.46it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n",
      "100%|██████████| 13/13 [00:07<00:00,  1.63it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.36it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.00it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
      "100%|██████████| 13/13 [00:15<00:00,  1.18s/it]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.03it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.18it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  1.99it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n",
      "100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  1.99it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.31it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  1.98it/s]\n",
      "100%|██████████| 50/50 [28:41<00:00, 34.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c808b7bd1454dd4baca9586a3e6b21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.240 MB of 67.240 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▇▆▇████████▇▇▇▇▇▇▇▇▆▆▆▆▆▄▄▄▄▄▄▃▃▂▂▂▁▂▂▂▁</td></tr><tr><td>FK ROI < 30</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇▇█████████████████▇▇▇</td></tr><tr><td>ROI</td><td>▇▇▇██████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▁▂▂▂▁</td></tr><tr><td>ROI < 30</td><td>▁▁▂▂▃▃▃▄▄▄▄▅▅▆▆▆▇▇▇▇▇████████████████▇▇▇</td></tr><tr><td>accuracy</td><td>██▅█▅▆▆▆▇▇▇▆▆▇▆▅▅▄▄▄▃▃▄▄▃▄▄▄▃▃▂▁▃▂▂▁▂▁▁▁</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▁▁▇▆▁▁▆▆▁▁▆▁▁▆▆▁▁▆▆▁▁▆▆▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>██▅█▅▆▆▆▇▇▇▆▆▇▆▅▅▄▄▄▃▃▄▄▃▄▄▄▃▃▂▁▃▂▂▁▂▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▅▅▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>█▇▇▇▆▆▆▅▅▅▅▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>█▇▇▆▆▆▅▅▅▅▅▅▄▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet profit</td><td>▇▇▇██████▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▁▂▂▂▁</td></tr><tr><td>multibet profit < 30</td><td>▁▁▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇███████████████████</td></tr><tr><td>multibet profit < 30 sd</td><td>██▇▇▆▆▆▅▅▅▅▄▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>multibet profit sd</td><td>█████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▁▂▁▂▂▂▃▃▄▆▅▅▄▄▃▅▅▅▅▅▅▅▇████▇▆▄▃▃▃▃▃▃▆▇▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.05742</td></tr><tr><td>FK ROI < 30</td><td>-0.08332</td></tr><tr><td>ROI</td><td>-0.05636</td></tr><tr><td>ROI < 30</td><td>-0.08831</td></tr><tr><td>accuracy</td><td>0.17964</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>18.91152</td></tr><tr><td>correct</td><td>494</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>18.91152</td></tr><tr><td>loss_val</td><td>4.96776</td></tr><tr><td>multibet outlay</td><td>91537.64377</td></tr><tr><td>multibet outlay < 30</td><td>59545.32247</td></tr><tr><td>multibet profit < 30</td><td>-5258.19967</td></tr><tr><td>multibet profit < 30 sd</td><td>28.85681</td></tr><tr><td>multibet profit sd</td><td>70.45472</td></tr><tr><td>profit</td><td>1841.70156</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">serene-sweep-2</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/ohx15mpl\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/ohx15mpl</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_011302-ohx15mpl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ue32hp97 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007069882482912235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_014216-ue32hp97</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/ue32hp97\" target=\"_blank\">colorful-sweep-3</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007069882482912235, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007069882482912235, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 27003.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007069882482912235\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:21<00:00,  6.25it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.30it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.88it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.31it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.23it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.28it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.94it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.25it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.24it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.29it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.05it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.26it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.17it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.23it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.25it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.53it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.26it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.23it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.30it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.57it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.27it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.09it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.30it/s]\n",
      "100%|██████████| 135/135 [00:23<00:00,  5.69it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.29it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.18it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.06it/s]\n",
      "100%|██████████| 135/135 [00:23<00:00,  5.83it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.27it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.15it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.34it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.15it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.23it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.20it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.98it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.34it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.25it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.27it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.13it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.32it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.26it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.21it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.44it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.28it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.22it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.29it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.43it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.28it/s]\n",
      "100%|██████████| 135/135 [00:20<00:00,  6.56it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.24it/s]\n",
      "100%|██████████| 50/50 [39:49<00:00, 47.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4bacfd577c4e4d9c139d5725dc6540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.385 MB of 67.385 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▃▄▂▁▁▅▄▃▃▆▅▄▂▄▃▂▄▄▃▃▅▃▂▄▃▂▄▄▄▄▃▄▆▇▆█▇▇▅▅</td></tr><tr><td>FK ROI < 30</td><td>▃▃▂▁▁▄▃▃▄▆█▇▆█▆▅█▇▅▆▇▆▅▇▆▄▄▆▄▆▃▅▆█▆█▆▆▇▆</td></tr><tr><td>ROI</td><td>▂▄▂▁▁▅▄▃▂▅▅▄▁▄▂▂▃▃▃▃▄▂▂▃▃▂▄▄▄▄▃▄▆█▆█▇▇▅▅</td></tr><tr><td>ROI < 30</td><td>▂▃▂▁▁▃▃▃▄▆▇▇▅▇▆▄▇▇▅▆▇▅▄▆▆▄▄▆▄▆▃▅▇█▆█▆▆▇▆</td></tr><tr><td>accuracy</td><td>▃▃▂▁▄▃▄▆▃▃▅▄▄▅▅▄▅▄▄▆▅▅▄▆▆▅▄▆▆█▆▆▅▆▅▅▅▆▆▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▄▅▅▂▄▅▂▄▃█▄▃█▃▄█▃▄▄▂▄▄▂▃▂▁▃▂▆▂▂▆▂▃▃▂▃▃▁▃</td></tr><tr><td>correct</td><td>▃▃▂▁▄▃▄▆▃▃▅▄▄▅▅▄▅▄▄▆▅▅▄▆▆▅▄▆▆█▆▆▅▆▅▅▅▆▆▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▅▄▄▄▄▄▃▂▃▃▂▂▃▁▂▁▁▂▁▁▁</td></tr><tr><td>loss_val</td><td>██▇▇▇▆▆▆▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▇▇▇▆▇▆▆▇▆▇▇▇▆▇▇▇▇▇█▇▆▇▆▅▅▅▄▄▃▃▂▃▂▂▁▂▁▁▂▁</td></tr><tr><td>multibet outlay < 30</td><td>▄▅▅▄▄▄▅▅▄▅▆▅▅▆▇▆▆▇█▇▇▇▆▆▅▅▅▅▄▃▃▃▂▂▂▂▁▁▂▁</td></tr><tr><td>multibet profit</td><td>▂▄▂▁▁▅▄▃▂▅▅▄▁▄▂▂▃▃▃▃▄▂▂▃▃▂▄▄▄▄▃▄▇█▆█▇▇▆▆</td></tr><tr><td>multibet profit < 30</td><td>▂▃▂▁▁▃▃▃▄▆▇▇▅▇▆▄▇▇▅▆▇▅▄▆▆▄▄▆▄▆▃▅▇█▆█▆▆▇▆</td></tr><tr><td>multibet profit < 30 sd</td><td>▂▃▂▁▃▄▄▅▃▅▇▇▅▇▇▆▇▇██▇█▅▆▆▃▄▆▄▆▄▆▄▅▂▄▂▃▄▃</td></tr><tr><td>multibet profit sd</td><td>█▆▇▅▅█▇▇▅▇▆▄▁▄▃▃▄▄▆▃▄▂▂▁▂▁▃▂▂▁▂▂▂▃▃▃▄▄▁▂</td></tr><tr><td>profit</td><td>█▆█▂▁▇▃▇▃▆█▅▅▆▄▆▆▆▅▆▅▅▂▄▅▄▅▆▃▅▆▄▇▇▃▇▇█▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.03263</td></tr><tr><td>FK ROI < 30</td><td>-0.01909</td></tr><tr><td>ROI</td><td>-0.03141</td></tr><tr><td>ROI < 30</td><td>-0.01565</td></tr><tr><td>accuracy</td><td>0.19745</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>17.34825</td></tr><tr><td>correct</td><td>543</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>17.34825</td></tr><tr><td>loss_val</td><td>2.7388</td></tr><tr><td>multibet outlay</td><td>84983.80517</td></tr><tr><td>multibet outlay < 30</td><td>56800.21703</td></tr><tr><td>multibet profit < 30</td><td>-888.88722</td></tr><tr><td>multibet profit < 30 sd</td><td>29.69615</td></tr><tr><td>multibet profit sd</td><td>52.76897</td></tr><tr><td>profit</td><td>1789.47742</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">colorful-sweep-3</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/ue32hp97\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/ue32hp97</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_014216-ue32hp97\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: blpeo95o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006068160421309081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_022236-blpeo95o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/blpeo95o\" target=\"_blank\">logical-sweep-4</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006068160421309081, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006068160421309081, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 27504.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0006068160421309081\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:17<00:00,  7.73it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.55it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.29it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.68it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.82it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.59it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.73it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.65it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.62it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.48it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.86it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.29it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.68it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.02it/s]\n",
      "100%|██████████| 135/135 [00:14<00:00,  9.17it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.79it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.56it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.71it/s]\n",
      "100%|██████████| 135/135 [00:16<00:00,  7.99it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.75it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.67it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.30it/s]\n",
      "100%|██████████| 135/135 [00:17<00:00,  7.59it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.78it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.67it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.75it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.57it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.77it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.64it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.69it/s]\n",
      "100%|██████████| 135/135 [00:20<00:00,  6.56it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.34it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.68it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.69it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  6.86it/s]\n",
      "100%|██████████| 135/135 [00:14<00:00,  9.27it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.43it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.70it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.69it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.58it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.74it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.60it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.74it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.59it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.75it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.62it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.67it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.60it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.73it/s]\n",
      "100%|██████████| 135/135 [00:23<00:00,  5.71it/s]\n",
      "100%|██████████| 50/50 [36:49<00:00, 44.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1a5563b3e241c49014d005da80e75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.365 MB of 67.365 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▅▂▂▃▃▃▃▃▃▂▃▃▃▂▃▁▃▂▂▁▂▂▂▂▄▃▂▃▄▄▄▄▄▅▄▅▆▆▇█</td></tr><tr><td>FK ROI < 30</td><td>▂▃▄▃▂▂▁▁▁▂▃▄▄▃▄▂▅▄▄▃▄▄▄▄▅▅▄▅▇▆▆▅▅▇▆▆▆▆▇█</td></tr><tr><td>ROI</td><td>▄▂▂▃▃▃▃▃▃▂▃▃▃▂▃▁▃▂▁▁▂▂▂▂▄▃▂▃▄▄▄▄▄▅▄▅▆▆▇█</td></tr><tr><td>ROI < 30</td><td>▂▃▄▃▂▂▂▁▁▂▃▃▄▃▄▂▅▄▃▃▄▄▄▄▅▅▅▅▇▆▇▅▅▇▆▆▆▆▇█</td></tr><tr><td>accuracy</td><td>▂▃▁▄▅▅▅▅▅▆▇▅▅▇▆▆▆▆▆▅▆▇▇█▇▇█▇▆▅▆▅▆▇▆▅▆█▆▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▅▆▆▃▄▅▃▃▂█▃▂▇▃▄▇▃▄▄▂▄▄▂▃▁▂▂▁▇▃▁▆▂▃▄▂▃▃▂▃</td></tr><tr><td>correct</td><td>▂▃▁▄▅▅▅▅▅▆▇▅▅▇▆▆▆▆▆▅▆▇▇█▇▇█▇▆▅▆▅▆▇▆▅▆█▆▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▆▆▆▆▆▅▅▅▄▅▄▄▄▄▃▃▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>loss_val</td><td>██▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>multibet outlay</td><td>█▇▆▅▅▅▄▄▃▃▃▃▃▃▃▃▄▄▃▃▃▃▃▃▃▃▄▃▃▃▃▃▃▃▃▃▂▂▂▁</td></tr><tr><td>multibet outlay < 30</td><td>█▇▅▂▄▄▂▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▄▃▄▄▄▄▅▄▄▄▄▃▄▃</td></tr><tr><td>multibet profit</td><td>▄▂▂▃▃▂▃▃▃▂▃▃▃▂▃▁▃▂▁▁▂▂▂▂▄▃▂▃▄▄▄▄▄▅▄▅▆▆▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▂▄▃▁▂▂▁▁▂▃▃▄▃▄▂▅▄▃▃▄▄▄▄▅▅▅▅▇▆▇▅▅▇▆▆▆▆▇█</td></tr><tr><td>multibet profit < 30 sd</td><td>▄▅▆▄▃▃▁▁▂▁▂▂▄▃▃▃▅▄▃▃▄▃▄▄▅▅▅▆█▆▇▅▆▇▇▆▆▆▇▆</td></tr><tr><td>multibet profit sd</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▂▁▁▂▂▁▂▂▂▂▂▃▂▃▃</td></tr><tr><td>profit</td><td>▃▂▄▄▃▃▁▂▃▄▆▄▁▂▄▃▃▃▄▁▂▄▄▃▅▅▄▃▃▃▃▃▄▄▄█▅▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>0.02095</td></tr><tr><td>FK ROI < 30</td><td>-0.01391</td></tr><tr><td>ROI</td><td>0.03325</td></tr><tr><td>ROI < 30</td><td>-0.00547</td></tr><tr><td>accuracy</td><td>0.18764</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>50.63058</td></tr><tr><td>correct</td><td>516</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>50.63058</td></tr><tr><td>loss_val</td><td>3.66397</td></tr><tr><td>multibet outlay</td><td>89421.25776</td></tr><tr><td>multibet outlay < 30</td><td>61346.58793</td></tr><tr><td>multibet profit < 30</td><td>-335.69971</td></tr><tr><td>multibet profit < 30 sd</td><td>32.52939</td></tr><tr><td>multibet profit sd</td><td>65.81291</td></tr><tr><td>profit</td><td>1911.6695</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">logical-sweep-4</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/blpeo95o\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/blpeo95o</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_022236-blpeo95o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u80vbbtm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005980970763987507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_025957-u80vbbtm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/u80vbbtm\" target=\"_blank\">true-sweep-5</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005980970763987507, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005980970763987507, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 27597.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0005980970763987507\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:15<00:00,  8.50it/s]\n",
      "100%|██████████| 135/135 [00:17<00:00,  7.59it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.59it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.35it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.70it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.67it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.70it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.62it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.76it/s]\n",
      "100%|██████████| 135/135 [00:16<00:00,  8.36it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.51it/s]\n",
      "100%|██████████| 135/135 [00:17<00:00,  7.74it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.79it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.64it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.73it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.60it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.72it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.70it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.71it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  6.85it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.82it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.55it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.67it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  6.84it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.84it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.71it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.60it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.74it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.39it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.72it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.74it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.62it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.09it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.70it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.27it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.74it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.15it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.82it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.31it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.62it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.31it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.68it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.05it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.72it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.30it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.76it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.97it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.76it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.22it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.68it/s]\n",
      "100%|██████████| 50/50 [36:43<00:00, 44.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901e52fd606f46578f65eea49cf2a4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.354 MB of 67.354 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▃▂▂▂▃▃▃▃▃▃▂▁▃▂▂▂▂▂▂▂▁▁▂▁▃▂▄▄▄▄▆▅▅▇█▇▇▅▇▆</td></tr><tr><td>FK ROI < 30</td><td>▂▂▃▃▃▃▂▂▃▃▂▁▂▁▁▂▃▃▃▃▃▃▄▄▅▅▅▆▆▆█▆▆▆█████▇</td></tr><tr><td>ROI</td><td>▃▂▂▂▂▃▃▃▃▂▂▁▃▂▂▂▂▁▁▁▁▁▂▁▃▂▄▄▃▄▅▅▅▇█▇▆▅▇▆</td></tr><tr><td>ROI < 30</td><td>▂▂▃▃▃▃▂▂▃▂▂▁▂▁▁▂▃▃▃▃▃▃▃▄▅▅▅▆▆▅▇▆▆▆█████▇</td></tr><tr><td>accuracy</td><td>▂▂▁▄▄▄▅▄▆▅▅▅▄▅▃▄▅▅▅▅▅▄▃▄▅▅▄▅▅▄▆▄▃▅▆▆▆▆██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▅▆▆▃▄▅▃▃▂█▃▂█▃▄▇▃▄▄▂▄▄▂▃▁▂▂▁▇▂▁▆▂▃▃▂▃▃▁▃</td></tr><tr><td>correct</td><td>▂▂▁▄▄▄▅▄▆▅▅▅▄▅▃▄▅▅▅▅▅▄▃▄▅▅▄▅▅▄▆▄▃▅▆▆▆▆██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▆▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▁▂▁</td></tr><tr><td>loss_val</td><td>██▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁</td></tr><tr><td>multibet outlay</td><td>█▆▆▄▄▃▂▂▂▂▂▃▂▂▂▂▃▂▂▁▁▁▁▃▃▂▂▃▃▃▃▂▂▂▂▁▂▂▂▁</td></tr><tr><td>multibet outlay < 30</td><td>█▇▄▃▄▃▂▂▂▁▂▂▁▂▂▂▃▂▂▂▁▁▂▃▃▃▄▄▄▄▄▃▄▄▄▄▅▆▆▅</td></tr><tr><td>multibet profit</td><td>▃▂▂▂▂▃▃▃▃▂▂▁▃▂▂▂▂▁▁▁▁▁▂▁▃▂▄▄▃▄▆▅▅▇█▇▆▅▇▆</td></tr><tr><td>multibet profit < 30</td><td>▂▂▃▃▂▃▂▂▃▂▂▁▂▁▁▂▃▃▃▃▃▃▃▄▅▅▄▆▆▅▇▆▆▆█████▇</td></tr><tr><td>multibet profit < 30 sd</td><td>▄▄▄▃▂▂▁▁▂▂▂▂▂▂▁▁▃▂▂▁▁▂▂▄▆▅▆▇▇▇█▆▅▆█▇▇▇█▇</td></tr><tr><td>multibet profit sd</td><td>█▃▂▂▂▂▂▃▃▂▂▂▂▃▃▂▂▂▂▂▁▂▁▁▂▂▃▃▂▂▂▃▃▃▃▃▂▂▃▃</td></tr><tr><td>profit</td><td>▂▂▄▃▄▆▄▄▆▄▁▂▃▄▄▄▂▄▂▂▂▂▁▁▄▂▃▄▄▅▅▄▄▇▆▆▆▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>0.0321</td></tr><tr><td>FK ROI < 30</td><td>-0.01066</td></tr><tr><td>ROI</td><td>0.04561</td></tr><tr><td>ROI < 30</td><td>-0.00212</td></tr><tr><td>accuracy</td><td>0.19418</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>49.64127</td></tr><tr><td>correct</td><td>534</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>49.64127</td></tr><tr><td>loss_val</td><td>3.50225</td></tr><tr><td>multibet outlay</td><td>91168.7959</td></tr><tr><td>multibet outlay < 30</td><td>62742.32107</td></tr><tr><td>multibet profit < 30</td><td>-133.29053</td></tr><tr><td>multibet profit < 30 sd</td><td>34.53833</td></tr><tr><td>multibet profit sd</td><td>67.5509</td></tr><tr><td>profit</td><td>1922.61875</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-5</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/u80vbbtm\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/u80vbbtm</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_025957-u80vbbtm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pt751nco with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004723857813859652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_033718-pt751nco</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/pt751nco\" target=\"_blank\">neat-sweep-6</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004723857813859652, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004723857813859652, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 27597.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004723857813859652\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:30<00:00,  4.49it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.95it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.58it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.38it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.03it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.45it/s]\n",
      "100%|██████████| 135/135 [00:31<00:00,  4.28it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.55it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.95it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  5.00it/s]\n",
      "100%|██████████| 135/135 [00:32<00:00,  4.16it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.93it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.49it/s]\n",
      "100%|██████████| 135/135 [00:32<00:00,  4.17it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.01it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.94it/s]\n",
      "100%|██████████| 135/135 [00:32<00:00,  4.17it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.52it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.97it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.53it/s]\n",
      "100%|██████████| 135/135 [00:31<00:00,  4.27it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.47it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.99it/s]\n",
      "100%|██████████| 135/135 [00:34<00:00,  3.93it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.53it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.91it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.47it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.01it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.63it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.51it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.90it/s]\n",
      "100%|██████████| 135/135 [00:35<00:00,  3.78it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.99it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.87it/s]\n",
      "100%|██████████| 135/135 [00:33<00:00,  4.02it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.02it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.94it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.50it/s]\n",
      "100%|██████████| 135/135 [00:31<00:00,  4.35it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.53it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.90it/s]\n",
      "100%|██████████| 135/135 [00:37<00:00,  3.57it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.00it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.93it/s]\n",
      "100%|██████████| 135/135 [00:31<00:00,  4.29it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.04it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  5.00it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.45it/s]\n",
      "100%|██████████| 135/135 [00:33<00:00,  4.01it/s]\n",
      "100%|██████████| 135/135 [00:29<00:00,  4.55it/s]\n",
      "100%|██████████| 50/50 [45:07<00:00, 54.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715d542097c44c2493d34d8411d636aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.489 MB of 67.489 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▄▇▄▂▄▁▅▄▁▄▆▆▅▄▆▄▃▃▅▇▆█▆▅▄▅▄▄▂▂▃▂█▇█▆▆▇▅▇</td></tr><tr><td>FK ROI < 30</td><td>▄▃▂▂▂▁▃▂▂▄▆▅▆▄▆▆▅▅▆█▆▇▇▅▄▄▄▅▄▅▃▃▆▅▄▄▄▆▅▅</td></tr><tr><td>ROI</td><td>▄▇▅▂▅▂▆▅▁▄▆▆▅▄▆▄▃▃▅▇▆▇▆▅▄▅▅▅▂▂▃▂█▇█▆▅▇▅▇</td></tr><tr><td>ROI < 30</td><td>▄▃▃▂▂▁▃▂▂▄▆▆▆▅▆▆▅▅▆█▇▇▇▅▅▄▄▅▄▅▂▃▆▅▄▄▄▆▅▅</td></tr><tr><td>accuracy</td><td>▁▃▁▂▃▂▃▄▅▄▅▅▅▅▅▆▆▆▇▇▆▇▇▅▄▆▆▃▆▃▆▅▅▄▆▇█▇▆▅</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▅▆▇▂▅▆▂▅▅█▅▅█▄▅█▄▅▅▁▅▅▁▄▄▁▄▄▆▃▄▅▃▄▄▃▄▄▁▄</td></tr><tr><td>correct</td><td>▁▃▁▂▃▂▃▄▅▄▅▅▅▅▅▆▆▆▇▇▆▇▇▅▄▆▆▃▆▃▆▅▅▄▆▇█▇▆▅</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇█▇▇▆▆▅▅▅▅▅▆▄▅▅▅▄▃▄▃▃▃▃▂▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>██▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▇▆▇▇▇█▇█▆█▇▇▇▇▇▇▆▆▅▅▅▅▄▅▄▃▂▃▃▃▃▂▂▃▃▂▁▂▂▁</td></tr><tr><td>multibet outlay < 30</td><td>▄▅▄▅▅▇▆▆▄▇▆▇▇██▇▆▆▆▅▅▆▄▅▃▂▁▃▃▂▂▁▁▂▃▁▁▂▂▁</td></tr><tr><td>multibet profit</td><td>▄▇▅▂▄▁▆▄▁▄▆▆▅▄▆▄▃▃▅▇▆▇▆▅▄▅▅▅▃▃▄▃█▇█▆▆▇▅▇</td></tr><tr><td>multibet profit < 30</td><td>▄▃▃▂▂▁▃▂▂▄▆▆▆▅▆▆▅▅▆█▇▇▇▅▅▄▅▅▅▅▃▃▆▅▄▄▄▆▅▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▄▄▄▃▃▄▅▅▂▆▇▇▆▇█▆▅▄▅▆▆▆▆▅▄▄▂▃▄▂▂▁▄▄▃▂▂▃▂▃</td></tr><tr><td>multibet profit sd</td><td>▅█▆▅▆▅▆▆▄▅▄▄▄▃▄▂▂▂▂▂▃▂▂▂▂▃▂▂▂▁▃▂▃▄▄▂▃▂▂▃</td></tr><tr><td>profit</td><td>▄█▂▄▄▆▃▅▂▄▅▅▃▃▄▄▃▃▃▄▄▆▆▄▅▆▆▃▅▂▄▁▃▃▄▂▆▅▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.02945</td></tr><tr><td>FK ROI < 30</td><td>-0.04401</td></tr><tr><td>ROI</td><td>-0.02785</td></tr><tr><td>ROI < 30</td><td>-0.04571</td></tr><tr><td>accuracy</td><td>0.18691</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>4.95803</td></tr><tr><td>correct</td><td>514</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>4.95803</td></tr><tr><td>loss_val</td><td>2.52819</td></tr><tr><td>multibet outlay</td><td>84565.60696</td></tr><tr><td>multibet outlay < 30</td><td>56567.10525</td></tr><tr><td>multibet profit < 30</td><td>-2585.56927</td></tr><tr><td>multibet profit < 30 sd</td><td>29.07885</td></tr><tr><td>multibet profit sd</td><td>55.07152</td></tr><tr><td>profit</td><td>1699.49442</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">neat-sweep-6</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/pt751nco\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/pt751nco</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_033718-pt751nco\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 649fnzi5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004808376045847639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_042308-649fnzi5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/649fnzi5\" target=\"_blank\">true-sweep-7</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004808376045847639, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004808376045847639, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 26054.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004808376045847639\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:18<00:00,  7.28it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  6.99it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.32it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.71it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.32it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.59it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.71it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.21it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.63it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.32it/s]\n",
      "100%|██████████| 135/135 [00:14<00:00,  9.13it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.55it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.16it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.83it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.21it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.42it/s]\n",
      "100%|██████████| 135/135 [00:17<00:00,  7.62it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.71it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.61it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.26it/s]\n",
      "100%|██████████| 135/135 [00:20<00:00,  6.66it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.55it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.26it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.69it/s]\n",
      "100%|██████████| 135/135 [00:25<00:00,  5.32it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.65it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.60it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.27it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.58it/s]\n",
      "100%|██████████| 135/135 [00:14<00:00,  9.58it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.23it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.60it/s]\n",
      "100%|██████████| 135/135 [00:27<00:00,  4.97it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.69it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.60it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.20it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.37it/s]\n",
      "100%|██████████| 135/135 [00:17<00:00,  7.67it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.69it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.56it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.25it/s]\n",
      "100%|██████████| 135/135 [00:14<00:00,  9.03it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.32it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.56it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.76it/s]\n",
      "100%|██████████| 135/135 [00:25<00:00,  5.33it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.66it/s]\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.62it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.19it/s]\n",
      "100%|██████████| 135/135 [00:24<00:00,  5.59it/s]\n",
      "100%|██████████| 50/50 [37:02<00:00, 44.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a872b97960c1471c98aa9c661830615e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.350 MB of 67.350 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>█▅▃▂▄▄▄▂▆▇▅▅▆▅▇▅▅▅▃▁▂▂▃▄▄▄▃▃▄▄▃▄▆▆▆▅▇▇▇▄</td></tr><tr><td>FK ROI < 30</td><td>▁▂▃▂▂▂▁▁▂▄▃▃▂▃▄▄▄▃▂▂▁▂▂▃▅▄▃▃▃▄▅▆▇▅▇▆██▇▂</td></tr><tr><td>ROI</td><td>█▄▃▂▄▄▄▃▆▇▅▅▆▅▇▅▄▄▃▁▂▂▃▃▄▄▃▂▄▄▃▃▅▆▆▅▇▇▆▄</td></tr><tr><td>ROI < 30</td><td>▁▂▂▂▂▂▁▁▂▄▄▃▂▃▄▄▃▃▂▂▁▂▂▃▄▃▃▃▃▄▅▆▇▅▇▅██▆▂</td></tr><tr><td>accuracy</td><td>▁▁▁▂▄▄▅▄▅▅▅▅▆▇▅▅▅▆▆▆▅▆▆▅▇█▇▇▅▆▇▆▇▇██▆▆▅▆</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▅▆▅▃▄▅▃▃▂█▃▂█▃▄█▃▄▄▂▄▄▂▃▁▂▂▁▇▃▁▇▃▄▄▂▃▄▂▃</td></tr><tr><td>correct</td><td>▁▁▁▂▄▄▅▄▅▅▅▅▆▇▅▅▅▆▆▆▅▆▆▅▇█▇▇▅▆▇▆▇▇██▆▆▅▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁</td></tr><tr><td>loss_val</td><td>██▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>█▅▅▄▃▃▃▂▂▃▃▂▂▂▂▂▂▂▃▃▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▁▃▂▂▁</td></tr><tr><td>multibet outlay < 30</td><td>█▆▄▂▃▃▂▂▁▂▂▂▂▂▂▂▂▂▃▂▁▁▁▂▁▁▂▂▂▃▃▃▃▂▃▂▄▄▄▃</td></tr><tr><td>multibet profit</td><td>█▄▃▂▄▄▄▃▆▇▅▅▆▆▇▅▄▄▃▁▂▂▃▄▄▄▃▃▄▄▃▃▆▆▆▅▇▇▆▄</td></tr><tr><td>multibet profit < 30</td><td>▁▂▃▃▃▂▂▂▃▄▄▄▃▃▄▄▄▃▃▂▂▃▂▃▅▄▃▃▃▄▅▆▇▅▇▆██▆▂</td></tr><tr><td>multibet profit < 30 sd</td><td>▅▃▃▃▂▂▂▁▂▄▄▃▂▃▄▄▄▃▄▃▁▂▂▃▄▂▃▃▃▄▅▆▇▅▇▄██▇▃</td></tr><tr><td>multibet profit sd</td><td>█▃▁▁▁▂▂▁▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▁▂▂▁▁▂▂▂▂▂▂▂▁</td></tr><tr><td>profit</td><td>▃▁▁▂▂▇▇▅▇▆▁▂▇█▅▄▄▆▅▄▆▂▂▁▆█▆▇▆▆▇▃▅▄▄▇▄▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.06324</td></tr><tr><td>FK ROI < 30</td><td>-0.0836</td></tr><tr><td>ROI</td><td>-0.06389</td></tr><tr><td>ROI < 30</td><td>-0.08995</td></tr><tr><td>accuracy</td><td>0.18764</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>54.18754</td></tr><tr><td>correct</td><td>516</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>54.18754</td></tr><tr><td>loss_val</td><td>3.99895</td></tr><tr><td>multibet outlay</td><td>91266.03269</td></tr><tr><td>multibet outlay < 30</td><td>61732.7601</td></tr><tr><td>multibet profit < 30</td><td>-5552.93971</td></tr><tr><td>multibet profit < 30 sd</td><td>30.27379</td></tr><tr><td>multibet profit sd</td><td>60.9635</td></tr><tr><td>profit</td><td>1699.4952</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-7</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/649fnzi5\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/649fnzi5</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_042308-649fnzi5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 887er3i2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007796847016044851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_050045-887er3i2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/887er3i2\" target=\"_blank\">genial-sweep-8</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007796847016044851, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007796847016044851, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 27093.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007796847016044851\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:05<00:00,  2.31it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.00it/s]\n",
      "100%|██████████| 13/13 [00:09<00:00,  1.37it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.10it/s]\n",
      "100%|██████████| 13/13 [00:07<00:00,  1.79it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.36it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.03it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.05it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.35it/s]\n",
      "100%|██████████| 13/13 [00:09<00:00,  1.40it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.05it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.07it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.05it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.10it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.10it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.10it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  1.97it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.09it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.38it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.07it/s]\n",
      "100%|██████████| 13/13 [00:09<00:00,  1.37it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.02it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.05it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.09it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.28it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.11it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.37it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.05it/s]\n",
      "100%|██████████| 13/13 [00:09<00:00,  1.33it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.09it/s]\n",
      "100%|██████████| 13/13 [00:11<00:00,  1.10it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.03it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.06it/s]\n",
      "100%|██████████| 13/13 [00:07<00:00,  1.83it/s]\n",
      "100%|██████████| 13/13 [00:07<00:00,  1.84it/s]\n",
      "100%|██████████| 50/50 [28:45<00:00, 34.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27fc8f4f16d4e5ab952593adb58df18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.382 MB of 67.382 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>█▆▅▄▁▁▃▄▄▄▅▆▄▄▄▅▅▄▄▄▃▃▂▂▃▄▄▄▄▄▅▆▆▅▅▅▆▆▆▅</td></tr><tr><td>FK ROI < 30</td><td>▂▁▁▁▃▃▄▃▁▁▂▂▂▂▃▃▂▂▁▂▂▂▂▂▃▃▂▃▄▃▃▄▅▅▅▆██▇▇</td></tr><tr><td>ROI</td><td>█▆▅▄▁▂▃▄▄▄▅▆▅▄▄▅▅▄▄▄▃▃▂▃▃▄▄▄▄▄▅▅▅▅▄▄▅▅▆▄</td></tr><tr><td>ROI < 30</td><td>▂▁▁▁▃▃▄▃▁▁▂▂▂▂▃▃▂▂▂▂▂▂▂▂▃▃▂▃▄▃▃▄▅▅▅▅███▇</td></tr><tr><td>accuracy</td><td>▃▃▄▃▁▁▁▄▄▄▅▄▅▆▅▅▄▄▄▅▄▄▅▆▅▅▄▅▆▅▆▆▇▆▆▆▇▇▇█</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▂▇▄▂▇▄▂▇▄▇▄▂▆▄▂▆▄▂▆▁▆▄▁▆▃▁▆▃▁▃▁▅▃▁▅▃▁▅▃</td></tr><tr><td>correct</td><td>▃▃▄▃▁▁▁▄▄▄▅▄▅▆▅▅▄▄▄▅▄▄▅▆▅▅▄▅▆▅▆▆▇▆▆▆▇▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>█▇▆▆▅▅▅▄▃▄▄▃▃▃▃▂▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>multibet outlay < 30</td><td>██▇▆▃▂▃▂▂▃▃▃▁▁▁▁▂▂▁▁▁▂▂▂▃▂▂▂▂▂▁▂▂▂▂▂▃▂▂▁</td></tr><tr><td>multibet profit</td><td>█▆▅▄▁▂▃▄▄▄▅▆▅▄▄▅▅▄▄▅▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▄</td></tr><tr><td>multibet profit < 30</td><td>▂▁▁▁▃▃▄▄▂▁▂▂▃▃▃▃▃▂▂▂▂▃▃▃▃▃▃▃▄▃▄▄▅▅▅▆███▇</td></tr><tr><td>multibet profit < 30 sd</td><td>▆▅▃▃▄▄▄▃▁▁▂▂▂▂▂▂▃▂▂▂▂▂▃▃▃▃▃▃▃▂▁▃▄▃▃▄█▇▇▄</td></tr><tr><td>multibet profit sd</td><td>█▇▄▃▁▁▁▁▃▃▃▃▂▂▂▂▂▃▃▃▂▂▂▂▂▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>profit</td><td>▆▅▄▇▁▄▁▅▇▇▅█▆█▄▃█▆▇▇▃▂▃▇█▇▆▇▃▃▄▅▅▄▄▄▆▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.05946</td></tr><tr><td>FK ROI < 30</td><td>-0.01704</td></tr><tr><td>ROI</td><td>-0.06375</td></tr><tr><td>ROI < 30</td><td>-0.01547</td></tr><tr><td>accuracy</td><td>0.19782</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>16.85309</td></tr><tr><td>correct</td><td>544</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>16.85309</td></tr><tr><td>loss_val</td><td>4.15569</td></tr><tr><td>multibet outlay</td><td>89774.26809</td></tr><tr><td>multibet outlay < 30</td><td>60027.11335</td></tr><tr><td>multibet profit < 30</td><td>-928.45244</td></tr><tr><td>multibet profit < 30 sd</td><td>31.11066</td></tr><tr><td>multibet profit sd</td><td>57.02276</td></tr><tr><td>profit</td><td>1783.50834</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">genial-sweep-8</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/887er3i2\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/887er3i2</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_050045-887er3i2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xz5zns7m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00048201439333189376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_053008-xz5zns7m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/xz5zns7m\" target=\"_blank\">earnest-sweep-9</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00048201439333189376, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00048201439333189376, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 27458.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00048201439333189376\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:16<00:00,  3.19it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.96it/s]\n",
      "100%|██████████| 54/54 [00:23<00:00,  2.26it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  4.05it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.20it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.22it/s]\n",
      "100%|██████████| 54/54 [00:19<00:00,  2.83it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.20it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.97it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.18it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  4.02it/s]\n",
      "100%|██████████| 54/54 [00:17<00:00,  3.16it/s]\n",
      "100%|██████████| 54/54 [00:20<00:00,  2.59it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.23it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.95it/s]\n",
      "100%|██████████| 54/54 [00:17<00:00,  3.17it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  4.02it/s]\n",
      "100%|██████████| 54/54 [00:19<00:00,  2.72it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  4.03it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.21it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.26it/s]\n",
      "100%|██████████| 54/54 [00:20<00:00,  2.60it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.23it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.94it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.21it/s]\n",
      "100%|██████████| 54/54 [00:17<00:00,  3.09it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.19it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  4.00it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.19it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.97it/s]\n",
      "100%|██████████| 54/54 [00:22<00:00,  2.35it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.19it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.97it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.21it/s]\n",
      "100%|██████████| 54/54 [00:20<00:00,  2.61it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.23it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.98it/s]\n",
      "100%|██████████| 54/54 [00:17<00:00,  3.17it/s]\n",
      "100%|██████████| 54/54 [00:14<00:00,  3.64it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.25it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.22it/s]\n",
      "100%|██████████| 54/54 [00:17<00:00,  3.14it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.99it/s]\n",
      "100%|██████████| 54/54 [00:21<00:00,  2.51it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.98it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.19it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  3.97it/s]\n",
      "100%|██████████| 54/54 [00:21<00:00,  2.52it/s]\n",
      "100%|██████████| 54/54 [00:13<00:00,  4.01it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.22it/s]\n",
      "100%|██████████| 50/50 [35:17<00:00, 42.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16f5643d7ef4f8cb483767faa316ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.425 MB of 67.425 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▄▃▄▅▆▅▆▅▆▆▄▄▃▁▃▃▄▆▆▄▄▄▆▄▂▁▄▅▃▄▇▅▇▅▇▆▆▅██</td></tr><tr><td>FK ROI < 30</td><td>▁▃▃▃▄▄▅▄▅▄▃▄▃▃▅▄█▆▆▄▅▆▇▆▂▃▄▄▄▆▇▆▅▆▇▇▆▇██</td></tr><tr><td>ROI</td><td>▄▃▄▅▆▅▆▅▆▇▄▄▃▁▃▃▄▆▅▄▄▄▆▄▂▁▄▅▃▄▇▅█▆▇▆▆▅██</td></tr><tr><td>ROI < 30</td><td>▁▄▄▃▄▅▆▄▆▄▄▄▃▃▄▄▇▆▆▄▅▆▇▆▂▄▅▄▄▇▇▆▅▆▇▇▇▇██</td></tr><tr><td>accuracy</td><td>▂▁▂▃▃▃▃▃▄▃▃▂▃▅▃▃▃▄▃▄▄▅▇▅▄▆▄▅▇▇▇▇▆▇▇▇██▇█</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▅█▄▃▂▃▄▇▃▃▂▃▁▄▂▄▂▃▃▃▆▃▂▁▂▁▃▂▂▂▃▁▃▆▃▂▁▂▃▅</td></tr><tr><td>correct</td><td>▂▁▂▃▃▃▃▃▄▃▃▂▃▅▃▃▃▄▃▄▄▅▇▅▄▆▄▅▇▇▇▇▆▇▇▇██▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▁▂▁▁</td></tr><tr><td>loss_val</td><td>██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁</td></tr><tr><td>multibet outlay</td><td>██▆▆▆▆▅▅▅▄▅▅▄▄▄▃▄▃▃▄▃▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>multibet outlay < 30</td><td>█▆▃▃▄▃▃▃▁▁▂▃▂▂▁▁▂▁▁▃▂▂▃▁▃▂▂▂▁▂▁▂▂▂▂▂▃▃▃▂</td></tr><tr><td>multibet profit</td><td>▄▂▄▅▆▅▆▅▆▇▄▄▃▁▃▃▄▆▅▄▄▄▆▄▂▁▄▅▄▅▇▅█▆▇▆▆▅██</td></tr><tr><td>multibet profit < 30</td><td>▁▄▄▃▅▅▆▅▆▄▄▅▄▃▅▄▇▆▆▄▅▆▇▆▃▄▅▅▄▇▇▆▅▆▇▇▇▇██</td></tr><tr><td>multibet profit < 30 sd</td><td>▂▆▅▄▅▅▆▄▆▂▃▅▁▂▃▁█▆▃▃▅▇█▅▃▃▄▄▁█▆▄▅▇▇▆█▆▇▅</td></tr><tr><td>multibet profit sd</td><td>█▃▃▃▄▃▃▄▄▄▃▃▄▂▂▂▂▃▂▂▂▂▃▂▂▁▂▂▂▂▂▂▃▃▂▂▂▁▂▂</td></tr><tr><td>profit</td><td>▄▃▄▅█▄▆▅▇▇▆▆▆▃▂▂▃▄▄▄▂▂▃▂▁▂▂▂▃▄▄▃▅▆▃▃▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.00756</td></tr><tr><td>FK ROI < 30</td><td>-0.0074</td></tr><tr><td>ROI</td><td>-0.00529</td></tr><tr><td>ROI < 30</td><td>-0.00523</td></tr><tr><td>accuracy</td><td>0.20145</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>18.32696</td></tr><tr><td>correct</td><td>554</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>18.32696</td></tr><tr><td>loss_val</td><td>3.53717</td></tr><tr><td>multibet outlay</td><td>86986.25218</td></tr><tr><td>multibet outlay < 30</td><td>59570.71158</td></tr><tr><td>multibet profit < 30</td><td>-311.69072</td></tr><tr><td>multibet profit < 30 sd</td><td>31.40311</td></tr><tr><td>multibet profit sd</td><td>57.08579</td></tr><tr><td>profit</td><td>1661.79527</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">earnest-sweep-9</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/xz5zns7m\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/xz5zns7m</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_053008-xz5zns7m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xgulchw7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005796136324016931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_060557-xgulchw7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/xgulchw7\" target=\"_blank\">dashing-sweep-10</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005796136324016931, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005796136324016931, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 25930.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0005796136324016931\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:22<00:00,  6.10it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  5.91it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.07it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  7.10it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.05it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.12it/s]\n",
      "100%|██████████| 135/135 [00:25<00:00,  5.35it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.11it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.01it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.16it/s]\n",
      "100%|██████████| 135/135 [00:28<00:00,  4.81it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  5.97it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  7.06it/s]\n",
      "100%|██████████| 135/135 [00:23<00:00,  5.78it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.03it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.15it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  5.93it/s]\n",
      "100%|██████████| 135/135 [00:23<00:00,  5.81it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.14it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.07it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  5.95it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.03it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.05it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  5.97it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  7.09it/s]\n",
      "100%|██████████| 135/135 [00:30<00:00,  4.44it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.09it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.04it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.03it/s]\n",
      "100%|██████████| 135/135 [00:31<00:00,  4.33it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.07it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  5.92it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.08it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.14it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.10it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.00it/s]\n",
      "100%|██████████| 135/135 [00:18<00:00,  7.13it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.09it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.07it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  7.05it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.07it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  5.93it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  7.04it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  5.96it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  5.99it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.09it/s]\n",
      "100%|██████████| 135/135 [00:26<00:00,  5.03it/s]\n",
      "100%|██████████| 135/135 [00:22<00:00,  6.11it/s]\n",
      "100%|██████████| 135/135 [00:19<00:00,  7.05it/s]\n",
      "100%|██████████| 135/135 [00:21<00:00,  6.18it/s]\n",
      "100%|██████████| 50/50 [39:45<00:00, 47.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d662324a554d8e9879f6e864d496c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='67.408 MB of 67.408 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▃▁▃▂▁▃▃▃▂▂▂▃▃▃▄▃▂▃▂▄▄▆▄▃▄▆▅▅▆▆▆▄▅▅▆▇▆▇█▅</td></tr><tr><td>FK ROI < 30</td><td>▄▂▃▁▁▃▄▃▂▂▂▂▅▆▇▅▄▄▅▆▆█▇▄▅▇▇▆▆▆▅▆▆▇▅█▅▆█▆</td></tr><tr><td>ROI</td><td>▂▁▃▂▁▃▃▃▂▂▂▃▃▃▄▃▃▃▂▃▄▆▄▃▄▆▅▅▆▆▆▅▅▅▆▇▆▇█▅</td></tr><tr><td>ROI < 30</td><td>▃▂▃▁▁▃▄▃▂▂▂▂▄▆▇▅▄▄▅▆▆▇▇▄▆▇▇▆▅▆▆▆▇▇▅█▅▆█▆</td></tr><tr><td>accuracy</td><td>▂▁▂▂▃▃▄▄▃▅▃▂▃▄▅▂▃▃▃▅▂▅▅▃▃▄▃▄▆▅▄▃▃▃█▃▆▄▆▅</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▄▅▅▂▄▅▂▄▃█▄▃█▃▄▇▃▄▄▂▄▄▂▃▂▁▃▂▆▂▂▆▂▃▃▂▃▃▁▃</td></tr><tr><td>correct</td><td>▂▁▂▂▃▃▄▄▃▅▃▂▃▄▅▂▃▃▃▅▂▅▅▃▃▄▃▄▆▅▄▃▃▃█▃▆▄▆▅</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▆▆▅▅▅▅▅▅▅▄▅▅▄▄▄▄▄▄▃▄▃▃▃▂▂▂▁▂▂▁▁▂▁▁</td></tr><tr><td>loss_val</td><td>██▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▆█▅▅▅▄▄▅▅▄▄▄▄▄▄▄▃▄▅▄▂▃▄▃▃▃▃▃▃▂▃▁▂▂▂▂▁▂▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▅█▄▄▃▂▂▄▄▃▂▃▂▂▂▂▁▃▄▄▁▄▄▃▄▄▄▄▄▄▄▂▄▄▃▄▃▄▄▄</td></tr><tr><td>multibet profit</td><td>▃▁▃▂▂▃▄▃▃▃▂▃▃▃▄▃▃▃▂▄▄▆▅▄▄▆▅▅▆▆▆▅▆▅▆▇▆▇█▅</td></tr><tr><td>multibet profit < 30</td><td>▃▁▃▁▁▃▄▃▂▂▂▂▅▆▇▅▄▄▄▆▆▇▇▄▆▇▇▆▅▆▆▆▇▇▅█▅▆█▆</td></tr><tr><td>multibet profit < 30 sd</td><td>▂▅▂▁▁▂▃▃▃▂▂▂▄▄▅▄▃▆▅▅▂▅▆▃▅▇▇▄▄▅▆▄▇▇▄█▃▅▆▅</td></tr><tr><td>multibet profit sd</td><td>█▂▄▄▄▄▄▅▄▄▃▅▅▂▃▂▂▃▁▃▂▅▃▂▂▃▃▃▄▄▆▂▃▂▄▃▃▄▆▃</td></tr><tr><td>profit</td><td>▂▃▃▅▃▃▃▄▂▄▁▂▃▃▃▂▁▃▂▃▃▃▂▂▃▄▂▂▅▃▄▂▃▃▄▃▄▄█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.02234</td></tr><tr><td>FK ROI < 30</td><td>-0.04927</td></tr><tr><td>ROI</td><td>-0.01447</td></tr><tr><td>ROI < 30</td><td>-0.04477</td></tr><tr><td>accuracy</td><td>0.18618</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>18.06277</td></tr><tr><td>correct</td><td>512</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>18.06277</td></tr><tr><td>loss_val</td><td>2.92242</td></tr><tr><td>multibet outlay</td><td>88003.99928</td></tr><tr><td>multibet outlay < 30</td><td>61216.55364</td></tr><tr><td>multibet profit < 30</td><td>-2740.62397</td></tr><tr><td>multibet profit < 30 sd</td><td>31.87661</td></tr><tr><td>multibet profit sd</td><td>58.7133</td></tr><tr><td>profit</td><td>1784.16205</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dashing-sweep-10</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/xgulchw7\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/xgulchw7</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230301_060557-xgulchw7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jgmtjbqe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009348872323541364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 16325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230301_064611-jgmtjbqe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/jgmtjbqe\" target=\"_blank\">graceful-sweep-11</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/fkf5o4gd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009348872323541364, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009348872323541364, 'len_data': 16325, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16325/16325 [00:00<00:00, 28218.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =0\n",
      "empty  =130600\n",
      "0.0null_dog=0\n",
      "SmoothL1Loss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0009348872323541364\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:08<00:00,  3.34it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.39it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.43it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 27/27 [00:14<00:00,  1.84it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.49it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 27/27 [00:14<00:00,  1.83it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.40it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.42it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 27/27 [00:14<00:00,  1.83it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.43it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 27/27 [00:14<00:00,  1.83it/s]\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.96it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.41it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 27/27 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 27/27 [00:14<00:00,  1.84it/s]\n",
      "100%|██████████| 27/27 [00:08<00:00,  3.32it/s]\n",
      "100%|██████████| 27/27 [00:06<00:00,  4.33it/s]\n",
      "100%|██████████| 27/27 [00:06<00:00,  4.00it/s]\n",
      "100%|██████████| 27/27 [00:06<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"GRU_sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48ca33c5a1168302a4f8eae355aad1c03b1396f568d40bc174a6e6aabe725d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
