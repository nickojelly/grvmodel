{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "from rnn_classes import Dog, DogInput, Race, Races, GRUNet, smallGRUNet, smalll_lin_GRUNet\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n",
    "from training_testing import validate_model, train_regular, train_log, train_super_batch, train_super_batch_KL, train_super_batch_L1, train_regular_L1,train_regular_one_hot\n",
    "from model_saver import model_saver, model_saver_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_to_bf(model:GRUNet,raceDB:Races,example_ct):\n",
    "    with torch.no_grad():\n",
    "        sft_max = nn.Softmax(dim=-1)\n",
    "        l_sftmax = nn.LogSoftmax(dim=-1)\n",
    "        nnl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        full_test_races = raceDB.get_test_input(range(0,len(raceDB.test_race_ids)))\n",
    "        full_test_races_w_prices = []\n",
    "        excluded, included = 0,0\n",
    "        for r in full_test_races:\n",
    "            if 0 in r.prices or -1 in r.prices:\n",
    "                excluded+=1\n",
    "            else:\n",
    "                full_test_races_w_prices.append(r)\n",
    "                included+=1\n",
    "        print(included,excluded)\n",
    "\n",
    "        output = l_sftmax(model(full_test_races_w_prices))\n",
    "        bf_prices = torch.log(torch.tensor([x.implied_prob for x in full_test_races_w_prices ]).to('cuda:0'))\n",
    "        full_classes = torch.stack([x.classes for x in full_test_races_w_prices ])\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(f\"our loss = {nnl_loss(output,full_classes)}\")\n",
    "        print(f\"their loss = {nnl_loss(bf_prices ,full_classes)}\")\n",
    "        wandb.log({\"our loss\":nnl_loss(output,full_classes), \"their loss\":nnl_loss(bf_prices ,full_classes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159571, 17)\n",
      "(1159571, 17)\n",
      "(286515, 20)\n",
      "Latest date = 2023-02-25 00:00:00\n",
      "num_features_per_dog=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14572 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 14572/14572 [02:00<00:00, 121.10it/s]\n",
      "  0%|          | 0/40206 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 40206/40206 [01:39<00:00, 404.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 40206, number of unique dogs = 14572\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "#dog_stats_file = open( 'new gru input 2023-01.npy', 'rb')\n",
    "hidden_size = 64\n",
    "raceDB = build_dataset('new_windows_gru_REAL.npy', hidden_size ,state_filter=\"NSW\", margin_type='boosted_sftmin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           (Dubbo, 400.0)\n",
      "1           (Dubbo, 318.0)\n",
      "2           (Dubbo, 318.0)\n",
      "3         (Grafton, 305.0)\n",
      "4         (Grafton, 305.0)\n",
      "               ...        \n",
      "40201    (Richmond, 520.0)\n",
      "40202    (Richmond, 520.0)\n",
      "40203    (Richmond, 520.0)\n",
      "40204    (Richmond, 401.0)\n",
      "40205    (Richmond, 320.0)\n",
      "Length: 40206, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40206/40206 [00:00<00:00, 363192.71it/s]\n"
     ]
    }
   ],
   "source": [
    "raceDB.create_new_weights_v2()\n",
    "raceDB.adjust_weights({\"Dapto\":10, \"Gunnedah\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 32452, Test examples 7754\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def predict_model(model,predDB):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        races_idx = range(0,len(predDB.raceIDs)-1)\n",
    "        race = predDB.get_race_input(races_idx)\n",
    "        X = race\n",
    "        # for i,r in enumerate(race):\n",
    "        #     print(r.raceid, r.track_name)\n",
    "        #     #print(i,r.lstm_input())\n",
    "\n",
    "        output = model(X)\n",
    "        \n",
    "        print(output)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            print(r.raceid, r.track_name, r.dogs[predicted[i].item()])\n",
    "\n",
    "        print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None, prev_model_file=\"super-firebrand-217\"):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"GRU - FastTrack - AUS Testing\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      wandb.define_metric(\"multibet profit\", summary=\"max\")\n",
    "      \n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "      input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0] #create fix so messy\n",
    "\n",
    "      model = smalll_lin_GRUNet(input_size,config['hidden_size'])\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      if prev_model_file!=None:\n",
    "        model_name = prev_model_file\n",
    "        model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_450.pt\"\n",
    "        model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "        raceDB.fill_hidden_states_from_dict(hidden_dict=model_data['db'])\n",
    "        model.load_state_dict(model_data['model_state_dict'])\n",
    "        config['parent model'] = prev_model_file\n",
    "\n",
    "\n",
    "      raceDB.to_cuda()\n",
    "\n",
    "      criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "      #criterion = nn.SmoothL1Loss(reduction='none', beta=0.1)\n",
    "      # optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.Adadelta(model.parameters())\n",
    "      optimizer = optim.RMSprop(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
    "\n",
    "      print(criterion, optimizer)\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',threshold=0.0001, patience=10000, verbose=True, factor=0.5)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        train_regular_one_hot(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      except KeyboardInterrupt:\n",
    "        print(\"finished Early\")\n",
    "      dataset.create_hidden_states_dict()\n",
    "      model_saver_wandb(model, optimizer, 450, 0.1, dataset.hidden_states_dict_gru, model_name=\"long nsw new  22000 RUN\")\n",
    "      if sweep:\n",
    "        raceDB.reset_all_lstm_states\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 200, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.000087, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1,'batch_before_backwards':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230227_090816-33jatlqg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/33jatlqg\" target=\"_blank\">stoic-sponge-226</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'batch_size': 200, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 8.7e-05, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 10}\n",
      "200\n",
      "{'hidden_size': 64, 'batch_size': 200, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 8.7e-05, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40206/40206 [00:18<00:00, 2177.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =271943\n",
      "empty  =49705\n",
      "0.8454677162612545null_dog=0\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 8.7e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:32<00:00,  5.06it/s]\n",
      "100%|██████████| 162/162 [01:18<00:00,  2.07it/s]it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.22it/s]it]\n",
      "100%|██████████| 162/162 [01:13<00:00,  2.20it/s]it]\n",
      "100%|██████████| 162/162 [01:23<00:00,  1.94it/s]it]\n",
      "100%|██████████| 162/162 [01:18<00:00,  2.06it/s]it]\n",
      "100%|██████████| 162/162 [01:16<00:00,  2.12it/s]it]\n",
      "100%|██████████| 162/162 [01:15<00:00,  2.15it/s]it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.45it/s]it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.24it/s]it]\n",
      "100%|██████████| 162/162 [01:11<00:00,  2.27it/s]/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.36it/s]/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.35it/s]/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.69it/s]/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.57it/s]/it]\n",
      "100%|██████████| 162/162 [00:54<00:00,  2.98it/s]/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.70it/s]/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.49it/s]/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.48it/s]/it]\n",
      "100%|██████████| 162/162 [00:58<00:00,  2.75it/s]/it]\n",
      "100%|██████████| 162/162 [00:55<00:00,  2.89it/s]/it]\n",
      "100%|██████████| 162/162 [01:18<00:00,  2.07it/s]/it]\n",
      "100%|██████████| 162/162 [01:31<00:00,  1.76it/s]/it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.22it/s]/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.51it/s]/it]\n",
      "100%|██████████| 162/162 [01:17<00:00,  2.08it/s]7s/it]\n",
      "100%|██████████| 162/162 [01:26<00:00,  1.87it/s]4s/it]\n",
      "100%|██████████| 162/162 [01:15<00:00,  2.14it/s]4s/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.43it/s]0s/it]\n",
      "100%|██████████| 162/162 [01:16<00:00,  2.13it/s]7s/it]\n",
      "100%|██████████| 162/162 [01:10<00:00,  2.31it/s]1s/it]\n",
      "100%|██████████| 162/162 [01:15<00:00,  2.13it/s]6s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.72it/s]7s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.61it/s]1s/it]\n",
      "100%|██████████| 162/162 [01:11<00:00,  2.26it/s]0s/it]\n",
      "100%|██████████| 162/162 [01:14<00:00,  2.18it/s]1s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.51it/s]0s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.40it/s]6s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.70it/s]6s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.58it/s]7s/it]\n",
      "100%|██████████| 162/162 [01:18<00:00,  2.05it/s]9s/it]\n",
      "100%|██████████| 162/162 [01:19<00:00,  2.04it/s]4s/it]\n",
      "100%|██████████| 162/162 [01:18<00:00,  2.07it/s]5s/it]\n",
      "100%|██████████| 162/162 [00:58<00:00,  2.77it/s]9s/it]\n",
      "100%|██████████| 162/162 [01:10<00:00,  2.31it/s]0s/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.49it/s]5s/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.43it/s]7s/it]\n",
      "100%|██████████| 162/162 [01:13<00:00,  2.20it/s]9s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.74it/s]2s/it]\n",
      "100%|██████████| 162/162 [00:58<00:00,  2.76it/s]6s/it]\n",
      "100%|██████████| 162/162 [01:14<00:00,  2.17it/s]9s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.52it/s]1s/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.49it/s]5s/it]\n",
      "100%|██████████| 162/162 [01:13<00:00,  2.19it/s]5s/it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.25it/s]9s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.74it/s]1s/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.42it/s]0s/it]\n",
      "100%|██████████| 162/162 [01:17<00:00,  2.08it/s]2s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.58it/s]6s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.59it/s]7s/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.47it/s]5s/it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.24it/s]8s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.40it/s]1s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.55it/s]9s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.73it/s]0s/it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.25it/s]3s/it]\n",
      "100%|██████████| 162/162 [01:09<00:00,  2.34it/s]0s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.41it/s]1s/it]\n",
      "100%|██████████| 162/162 [01:15<00:00,  2.15it/s]6s/it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.22it/s]7s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.42it/s]8s/it]\n",
      "100%|██████████| 162/162 [01:15<00:00,  2.15it/s]8s/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.49it/s]5s/it]\n",
      "100%|██████████| 162/162 [01:21<00:00,  1.98it/s]2s/it]\n",
      "100%|██████████| 162/162 [01:18<00:00,  2.07it/s]2s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.39it/s]6s/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.48it/s]1s/it]\n",
      "100%|██████████| 162/162 [01:14<00:00,  2.17it/s]9s/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.62it/s]3s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.68it/s]0s/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.43it/s]5s/it]\n",
      "100%|██████████| 162/162 [01:10<00:00,  2.29it/s]4s/it]\n",
      "100%|██████████| 162/162 [01:09<00:00,  2.32it/s]8s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.55it/s]5s/it]\n",
      "100%|██████████| 162/162 [00:58<00:00,  2.75it/s]1s/it]\n",
      "100%|██████████| 162/162 [01:14<00:00,  2.17it/s]8s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.41it/s]7s/it]\n",
      "  4%|▍         | 86/2000 [3:30:30<78:05:03, 146.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Early\n",
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d5cc9fdf5c4fe69740780987118381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='290.610 MB of 290.610 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>FK ROI < 30</td><td>▁▂▄▅▆▇▇▇████████████████████████████████</td></tr><tr><td>ROI</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ROI < 30</td><td>▅▁▃▄▆▆▇▇▇███████████████████████████████</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>correct</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>multibet outlay</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>multibet outlay < 30</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>multibet profit</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet profit < 30</td><td>▁▃▄▆▆▇▇▇████████████████████████████████</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>multibet profit sd</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>profit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.01442</td></tr><tr><td>FK ROI < 30</td><td>-0.00353</td></tr><tr><td>ROI</td><td>-0.00953</td></tr><tr><td>ROI < 30</td><td>0.00613</td></tr><tr><td>accuracy</td><td>0.18723</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>2e-05</td></tr><tr><td>correct</td><td>1451</td></tr><tr><td>epoch</td><td>86</td></tr><tr><td>epoch_loss</td><td>1e-05</td></tr><tr><td>loss_val</td><td>17.20124</td></tr><tr><td>multibet outlay</td><td>495840.83476</td></tr><tr><td>multibet outlay < 30</td><td>396263.59479</td></tr><tr><td>multibet profit < 30</td><td>2429.50921</td></tr><tr><td>multibet profit < 30 sd</td><td>78.98677</td></tr><tr><td>multibet profit sd</td><td>129.89541</td></tr><tr><td>profit</td><td>5128.52072</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stoic-sponge-226</strong>: <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/33jatlqg\" target=\"_blank\">https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/33jatlqg</a><br/>Synced 5 W&B file(s), 131 media file(s), 131 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230227_090816-33jatlqg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes',\n",
      " 'metric': {'goal': 'maximize', 'name': 'ROI < 30'},\n",
      " 'parameters': {'batch_before_backwards': {'values': [5, 10, 20]},\n",
      "                'batch_size': {'values': [100, 250, 500, 1000]},\n",
      "                'dropout': {'values': [0.3]},\n",
      "                'epochs': {'values': [50]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'hidden_size': {'value': 64},\n",
      "                'l1_beta': {'value': 0.1},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.001,\n",
      "                                  'min': 1e-05},\n",
      "                'len_data': {'value': 40206},\n",
      "                'loss': {'values': ['CEL']},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adamW'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'bayes',\n",
       " 'metric': {'name': 'ROI < 30', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adamW'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3]},\n",
       "  'len_data': {'value': 40206},\n",
       "  'hidden_size': {'value': 64},\n",
       "  'epochs': {'values': [50]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'values': ['CEL']},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 1e-05, 'max': 0.001},\n",
       "  'l1_beta': {'value': 0.1},\n",
       "  'batch_size': {'values': [100, 250, 500, 1000]},\n",
       "  'batch_before_backwards': {'values': [5, 10, 20]}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"bayes\"}\n",
    "\n",
    "metric = {\"name\": \"ROI < 30\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": len(raceDB.raceIDs)},\n",
    "    \"hidden_size\": {\"value\":64}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [50]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"CEL\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\":{\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00001,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [100,250,500,1000]\n",
    "        },\n",
    "        \"batch_before_backwards\": {\n",
    "            'values': [5,10,20]\n",
    "        },\n",
    "\n",
    "        # \"batch_before_backwards\": {\n",
    "        #     # a flat distribution between 0 and 0.1\n",
    "        #     \"distribution\": \"uniform\",\n",
    "        #     \"min\": 3,\n",
    "        #     \"max\": 50,\n",
    "        # },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 4q91hs4m\n",
      "Sweep URL: https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jxy9cw8r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000733923176744659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230226_221644-jxy9cw8r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/jxy9cw8r\" target=\"_blank\">polished-sweep-1</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000733923176744659, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000733923176744659, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40206/40206 [00:19<00:00, 2013.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =271943\n",
      "empty  =49705\n",
      "0.8454677162612545null_dog=0\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.000733923176744659\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:34<00:00,  3.74it/s]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.95it/s]\n",
      "100%|██████████| 129/129 [01:01<00:00,  2.08it/s]\n",
      "100%|██████████| 129/129 [01:03<00:00,  2.03it/s]\n",
      "100%|██████████| 129/129 [01:03<00:00,  2.02it/s]\n",
      "100%|██████████| 129/129 [01:02<00:00,  2.05it/s]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.01it/s]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.02it/s]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.12it/s]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.12it/s]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.16it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.00it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.00it/s]]\n",
      "100%|██████████| 129/129 [01:05<00:00,  1.96it/s]]\n",
      "100%|██████████| 129/129 [01:10<00:00,  1.82it/s]]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.88it/s]]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.95it/s]]\n",
      "100%|██████████| 129/129 [01:03<00:00,  2.04it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.01it/s]]\n",
      "100%|██████████| 129/129 [01:01<00:00,  2.10it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.14it/s]]\n",
      "100%|██████████| 129/129 [01:12<00:00,  1.77it/s]]\n",
      "100%|██████████| 129/129 [01:13<00:00,  1.76it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.00it/s]]\n",
      "100%|██████████| 129/129 [01:15<00:00,  1.71it/s]]\n",
      "100%|██████████| 129/129 [01:18<00:00,  1.64it/s]]\n",
      "100%|██████████| 129/129 [01:05<00:00,  1.98it/s]]\n",
      "100%|██████████| 129/129 [01:13<00:00,  1.76it/s]]\n",
      "100%|██████████| 129/129 [01:12<00:00,  1.77it/s]]\n",
      "100%|██████████| 129/129 [01:13<00:00,  1.75it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.01it/s]]\n",
      "100%|██████████| 129/129 [01:10<00:00,  1.83it/s]]\n",
      "100%|██████████| 129/129 [01:05<00:00,  1.96it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.91it/s]]\n",
      "100%|██████████| 129/129 [01:10<00:00,  1.83it/s]]\n",
      "100%|██████████| 129/129 [01:02<00:00,  2.05it/s]]\n",
      "100%|██████████| 129/129 [01:03<00:00,  2.04it/s]]\n",
      "100%|██████████| 129/129 [01:03<00:00,  2.03it/s]]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.94it/s]]\n",
      "100%|██████████| 129/129 [01:01<00:00,  2.08it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.00it/s]]\n",
      "100%|██████████| 129/129 [01:03<00:00,  2.03it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.01it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.00it/s]]\n",
      "100%|██████████| 129/129 [01:05<00:00,  1.97it/s]]\n",
      "100%|██████████| 129/129 [01:01<00:00,  2.11it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.00it/s]]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.89it/s]]\n",
      "100%|██████████| 129/129 [01:03<00:00,  2.03it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  1.99it/s]]\n",
      "100%|██████████| 50/50 [1:57:27<00:00, 140.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9bef5512aa48e6be529958da8df196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='175.995 MB of 175.995 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▆▆▅▄▃▂▄▄▄▂▂▄█▇▄█▄▃▅▃▁▃▆▃▃▅▅▄▄▄▅▁▄▅▃▃▂▃▆▃</td></tr><tr><td>FK ROI < 30</td><td>▇▇▇▇▆▆█▆▆▆▅█▇▇▅▇▅▅▅▂▃▄▅▂▃▃▅▃▃▃▃▁▃▄▂▂▂▃▄▃</td></tr><tr><td>ROI</td><td>▇▇▆▄▄▂▅▄▄▃▂▄█▇▄█▄▃▅▃▁▃▆▃▃▅▆▄▅▅▅▁▄▅▃▃▃▄▆▄</td></tr><tr><td>ROI < 30</td><td>▆▇▇▇▇▆█▆▆▆▅█▇▇▅▇▅▄▅▂▂▃▅▂▃▃▅▃▃▃▃▁▃▄▂▂▃▄▄▄</td></tr><tr><td>accuracy</td><td>▁▁▂▃▄▄▅▅▆▆▅▆▆▆▆▆▇▇▆▆▆▇▇▆▇▇▇▇▇▇▇██▇▇█▇███</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▆▇▇▅▆▇█▇▅▇▄▅▄▄▄▃▂▃▃▃▃▂▂▂▄▄▃▂▄▂▂▂▂▂▁▁▁▂</td></tr><tr><td>correct</td><td>▁▁▂▃▄▄▅▅▆▆▅▆▆▆▆▆▇▇▆▆▆▇▇▆▇▇▇▇▇▇▇██▇▇█▇███</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇█▇▇▆▆▅▆▄▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▂▂▂▁▂▁▂▂▂▃▂▂▂</td></tr><tr><td>multibet outlay</td><td>▆█▇▇▇▄▅▃▃▃▂▃▂▃▁▂▂▁▁▁▂▂▁▁▂▂▂▂▂▁▂▂▁▂▂▁▂▂▂▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▃▃▃▄▄▄▅▄▅▅▅▆▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>multibet profit</td><td>▆▆▅▄▃▂▄▄▄▂▁▃█▇▄█▄▃▅▃▁▃▆▃▃▅▆▄▅▅▅▁▄▅▃▃▃▄▆▄</td></tr><tr><td>multibet profit < 30</td><td>▅▆▆▇▆▅█▆▆▆▅█▇▇▅█▆▄▅▂▂▃▅▂▃▃▅▃▃▃▄▁▃▄▂▂▃▄▅▄</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▃▃▄▄▄▄▄▅▅▆▅▆▆▅▅▅▆▆▆▅▆▆▆▆▆▇▇▆▆▇▆▇▇██▇</td></tr><tr><td>multibet profit sd</td><td>█▇▇▅▅▄▄▄▄▂▂▂▆▄▂▄▂▂▃▃▂▂▂▂▃▄▃▂▃▂▂▁▂▁▁▂▁▁▂▂</td></tr><tr><td>profit</td><td>██▃▅█▃▇▃▄▂▂▂▄▄▄▃▄▄▂▃▁▃▃▆▃▄▂▃▃▃▂▃▄▂▂▅▄▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.09581</td></tr><tr><td>FK ROI < 30</td><td>0.03279</td></tr><tr><td>ROI</td><td>-0.10608</td></tr><tr><td>ROI < 30</td><td>0.04747</td></tr><tr><td>accuracy</td><td>0.23471</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>12.55838</td></tr><tr><td>correct</td><td>1819</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>12.55838</td></tr><tr><td>loss_val</td><td>1.93364</td></tr><tr><td>multibet outlay</td><td>231667.68805</td></tr><tr><td>multibet outlay < 30</td><td>128836.42226</td></tr><tr><td>multibet profit < 30</td><td>6115.85167</td></tr><tr><td>multibet profit < 30 sd</td><td>22.22049</td></tr><tr><td>multibet profit sd</td><td>42.07244</td></tr><tr><td>profit</td><td>4864.54582</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">polished-sweep-1</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/jxy9cw8r\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/jxy9cw8r</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230226_221644-jxy9cw8r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zffmaybn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.0079945781949924e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230227_001513-zffmaybn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/zffmaybn\" target=\"_blank\">good-sweep-2</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 1.0079945781949924e-05, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 1.0079945781949924e-05, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40206/40206 [00:14<00:00, 2827.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =271943\n",
      "empty  =49705\n",
      "0.8454677162612545null_dog=0\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 1.0079945781949924e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:37<00:00,  1.69it/s]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.77it/s]t]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.96it/s]t]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.86it/s]t]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.66it/s]t]\n",
      "100%|██████████| 64/64 [00:50<00:00,  1.26it/s]t]\n",
      "100%|██████████| 64/64 [00:57<00:00,  1.11it/s]t]\n",
      "100%|██████████| 64/64 [00:51<00:00,  1.23it/s]t]\n",
      "100%|██████████| 64/64 [00:48<00:00,  1.33it/s]t]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.96it/s]t]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.99it/s]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.65it/s]it]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.54it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.95it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.07it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.84it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.72it/s]it]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.46it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.87it/s]]  \n",
      "100%|██████████| 64/64 [00:32<00:00,  1.98it/s]]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.97it/s]]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.95it/s]]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.69it/s]]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.87it/s]]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.90it/s]]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.06it/s]]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.72it/s]]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.62it/s]]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.81it/s]]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.97it/s]]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.86it/s]]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.00it/s]]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.96it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.73it/s]it]\n",
      "100%|██████████| 64/64 [00:42<00:00,  1.52it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.05it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.94it/s]it]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.54it/s]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.68it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.87it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.02it/s]it]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.89it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.87it/s]it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.78it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.62it/s]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.65it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  2.00it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.85it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.72it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.78it/s]it]\n",
      "100%|██████████| 50/50 [1:34:03<00:00, 112.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f082e1a342d24e67b6913fff4fd4d400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='168.668 MB of 168.668 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>██▇▇▅▅▄▅▄▃▄▃▃▃▄▃▃▃▃▃▂▂▂▂▂▃▃▂▂▂▂▂▁▂▂▂▂▁▁▂</td></tr><tr><td>FK ROI < 30</td><td>███▄▁▄▂▅▃▃▄▃▃▅▅▄▅▄▅▄▁▂▂▂▃▄▅▄▃▃▁▂▁▂▅▅▃▂▂▃</td></tr><tr><td>ROI</td><td>██▇▇▅▅▅▅▄▃▄▃▃▃▄▃▃▃▃▃▂▃▃▂▂▃▃▂▂▂▂▂▂▂▃▂▂▁▁▂</td></tr><tr><td>ROI < 30</td><td>█▇▇▄▃▄▃▄▃▃▃▂▂▃▄▃▄▃▄▄▂▂▂▃▃▃▄▃▃▂▂▂▁▂▄▄▂▂▁▂</td></tr><tr><td>accuracy</td><td>▁▄▂▂▃▂▂▄▅▅▆▅▅▄▆▄▅▅▅▆▅▅▅▅▇▇▆█▆▆▆█▆▅▇▆▆▅▅▅</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▁▆▇▁▆█▇▆█▇██▇▇█▇▁█▇▁▆█▁▆█▇██▇██▇▇█▇▁█</td></tr><tr><td>correct</td><td>▁▄▂▂▃▂▂▄▅▅▆▅▅▄▆▄▅▅▅▆▅▅▅▅▇▇▆█▆▆▆█▆▅▇▆▆▅▅▅</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>▆▆█▅▅▅▄▅▅▅▅▁▄▃▅▄▅▅▄▃▄▃▄▄▄▃▃▃▃▄▄▄▂▂▄▃▄▄▃▄</td></tr><tr><td>loss_val</td><td>█▆▆▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>█▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>█▇▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet profit</td><td>██▇▇▅▅▄▅▄▃▄▃▃▃▄▃▃▃▃▃▂▃▃▂▂▃▃▂▃▂▂▂▂▂▃▂▂▁▁▂</td></tr><tr><td>multibet profit < 30</td><td>█▇▆▅▃▄▃▄▃▃▃▂▂▃▃▃▃▃▃▃▂▂▂▂▂▃▃▂▂▂▁▁▁▂▃▃▁▁▁▁</td></tr><tr><td>multibet profit < 30 sd</td><td>█▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet profit sd</td><td>█▇▇▇▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▃▃▂▃▃▃▂▂▂▂▂▂▂▂▁▁▁▂</td></tr><tr><td>profit</td><td>▇█▄▅▄▄▄▆▅▄▅▄▅▃▆▃▄▅▅▅▅▃▃▃▅▃▃▄▁▂▂▃▂▂▃▁▃▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.0565</td></tr><tr><td>FK ROI < 30</td><td>0.07499</td></tr><tr><td>ROI</td><td>-0.0703</td></tr><tr><td>ROI < 30</td><td>0.08592</td></tr><tr><td>accuracy</td><td>0.25703</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>14.77034</td></tr><tr><td>correct</td><td>1992</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>14.77034</td></tr><tr><td>loss_val</td><td>1.89579</td></tr><tr><td>multibet outlay</td><td>218174.07222</td></tr><tr><td>multibet outlay < 30</td><td>122803.52607</td></tr><tr><td>multibet profit < 30</td><td>10551.26681</td></tr><tr><td>multibet profit < 30 sd</td><td>22.42296</td></tr><tr><td>multibet profit sd</td><td>39.86794</td></tr><tr><td>profit</td><td>5155.92349</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">good-sweep-2</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/zffmaybn\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/zffmaybn</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230227_001513-zffmaybn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fjo03dim with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002691808312771231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230227_015014-fjo03dim</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/fjo03dim\" target=\"_blank\">zesty-sweep-3</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0002691808312771231, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0002691808312771231, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40206/40206 [00:14<00:00, 2823.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =271943\n",
      "empty  =49705\n",
      "0.8454677162612545null_dog=0\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0002691808312771231\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:51<00:00,  1.25it/s]\n",
      "100%|██████████| 64/64 [00:48<00:00,  1.33it/s]t]\n",
      "100%|██████████| 64/64 [00:45<00:00,  1.40it/s]t]\n",
      "100%|██████████| 64/64 [00:51<00:00,  1.24it/s]t]\n",
      "100%|██████████| 64/64 [00:42<00:00,  1.49it/s]t]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.56it/s]t]\n",
      "100%|██████████| 64/64 [00:42<00:00,  1.51it/s]t]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.53it/s]t]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.48it/s]t]\n",
      "100%|██████████| 64/64 [00:44<00:00,  1.45it/s]t]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.48it/s]it]\n",
      "100%|██████████| 64/64 [00:47<00:00,  1.34it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.58it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.63it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.62it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.58it/s]it]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.56it/s]it]\n",
      "100%|██████████| 64/64 [00:48<00:00,  1.32it/s]it]\n",
      "100%|██████████| 64/64 [00:45<00:00,  1.40it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.58it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.61it/s]]  \n",
      "100%|██████████| 64/64 [00:40<00:00,  1.57it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.63it/s]]  \n",
      "100%|██████████| 64/64 [00:44<00:00,  1.44it/s]]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.46it/s]]\n",
      "100%|██████████| 64/64 [00:58<00:00,  1.09it/s]]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.48it/s]]\n",
      "100%|██████████| 64/64 [00:50<00:00,  1.28it/s]]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.62it/s]]\n",
      "100%|██████████| 64/64 [00:42<00:00,  1.49it/s]]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.61it/s]]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.53it/s]it]\n",
      "100%|██████████| 64/64 [00:45<00:00,  1.39it/s]it]\n",
      "100%|██████████| 64/64 [00:45<00:00,  1.42it/s]it]\n",
      "100%|██████████| 64/64 [00:49<00:00,  1.30it/s]it]\n",
      "100%|██████████| 64/64 [00:49<00:00,  1.28it/s]it]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.48it/s]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.65it/s]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.66it/s]it]\n",
      "100%|██████████| 64/64 [00:49<00:00,  1.30it/s]it]\n",
      "100%|██████████| 64/64 [00:48<00:00,  1.33it/s]it]\n",
      "100%|██████████| 64/64 [00:47<00:00,  1.35it/s]it]\n",
      "100%|██████████| 64/64 [00:48<00:00,  1.32it/s]it]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.54it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.60it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.62it/s]it]\n",
      "100%|██████████| 64/64 [00:46<00:00,  1.39it/s]it]\n",
      "100%|██████████| 64/64 [00:52<00:00,  1.23it/s]it]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.53it/s]it]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.47it/s]it]\n",
      "100%|██████████| 50/50 [1:39:31<00:00, 119.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebeb45e6ea2a4e4fae4685c31a9f00bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='168.634 MB of 168.634 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▄▂▄▇▄▃▅▃█▅▆▅▄▅▅▃▅▁▄▅▅▄▅▃▄▄▄▅▄▅▆▃▅▅▄▄▄▂▃▃</td></tr><tr><td>FK ROI < 30</td><td>▇▄▄█▄▅▆▄▆▅▅▆▅▅▅▄▄▁▂▄▃▄▅▃▄▅▄▅▅▆▇▃▃▃▄▄▄▂▃▃</td></tr><tr><td>ROI</td><td>▄▃▄▇▄▃▅▃█▅▆▅▄▅▄▃▅▁▄▅▅▄▅▄▄▄▄▅▄▅▆▄▅▅▄▅▄▂▃▃</td></tr><tr><td>ROI < 30</td><td>▇▄▅█▄▅▆▅▇▅▅▅▄▅▄▅▄▁▂▄▄▅▆▄▅▅▅▆▆▆▇▄▄▄▅▅▄▃▃▅</td></tr><tr><td>accuracy</td><td>▁▂▃▆▇▆▆▆▆▆▆▆▆▆▇▆▆▆▇█▇▇███▇▆▇▇▆█▇▆▇▇▇▇▇██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▃▇▇▆█▆▆▆▆▅▄▅▄▂▅▆▄▆▄▁▅▅▄▆▅▄▅▄▄▄▄▄▁▄▅▃▅▄</td></tr><tr><td>correct</td><td>▁▂▃▆▇▆▆▆▆▆▆▆▆▆▇▆▆▆▇█▇▇███▇▆▇▇▆█▇▆▇▇▇▇▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▄▃▃▂▃▃▂▂▂▂▂▁▂▂▂▁▁▁▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▅▃▂▃▃▂▃▂▂▂▂▂▁▂▃▂▃▁▂▁▂▁▂▂▃▂▂▃▂▂▂▂▃▃▂▂▃▂</td></tr><tr><td>multibet outlay</td><td>██▆▅▃▄▃▃▃▃▃▃▂▂▂▂▃▂▃▁▂▂▂▁▁▂▃▂▁▂▁▁▂▂▂▂▁▁▂▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▃▄▄▄▅▄▅▅▅▅▅▆▆▅▆▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇█▇▇▇▇</td></tr><tr><td>multibet profit</td><td>▄▂▄▆▄▃▅▃█▅▆▅▄▅▄▃▅▁▄▅▅▄▅▄▄▄▄▅▄▅▆▄▅▅▄▅▄▂▄▃</td></tr><tr><td>multibet profit < 30</td><td>▇▄▄█▄▅▆▅▇▅▅▆▅▅▅▅▄▁▃▄▅▅▆▄▅▆▆▇▆▇█▅▄▅▆▆▅▃▄▆</td></tr><tr><td>multibet profit < 30 sd</td><td>▂▁▃▃▃▄▅▄▆▄▅▅▄▅▄▅▅▄▅▃▅▅▆▅▅▅▆▆▆▇▆▆▆▆▇█▆▆▆▆</td></tr><tr><td>multibet profit sd</td><td>█▇▇█▅▅▅▃█▆▅▅▄▄▄▃▅▂▆▄▄▄▄▃▃▄▃▃▃▃▅▁▃▃▂▂▂▂▂▁</td></tr><tr><td>profit</td><td>▇▆▅█▇▅▅▅█▅▅▁▄▄▄▃▂▄▄▂▄▂▆▄▄▄▄▄▂▄▄▅▂▄▃▅▂▁▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.0794</td></tr><tr><td>FK ROI < 30</td><td>0.04525</td></tr><tr><td>ROI</td><td>-0.0901</td></tr><tr><td>ROI < 30</td><td>0.06151</td></tr><tr><td>accuracy</td><td>0.25394</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>13.6179</td></tr><tr><td>correct</td><td>1968</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>13.6179</td></tr><tr><td>loss_val</td><td>1.90919</td></tr><tr><td>multibet outlay</td><td>220858.61869</td></tr><tr><td>multibet outlay < 30</td><td>128625.40764</td></tr><tr><td>multibet profit < 30</td><td>7912.2269</td></tr><tr><td>multibet profit < 30 sd</td><td>22.71259</td></tr><tr><td>multibet profit sd</td><td>38.75756</td></tr><tr><td>profit</td><td>4990.06105</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">zesty-sweep-3</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/fjo03dim\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/fjo03dim</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230227_015014-fjo03dim\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i1nvitx2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007843910820807531\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230227_033042-i1nvitx2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/i1nvitx2\" target=\"_blank\">deft-sweep-4</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007843910820807531, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007843910820807531, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40206/40206 [00:14<00:00, 2815.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =271943\n",
      "empty  =49705\n",
      "0.8454677162612545null_dog=0\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007843910820807531\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:51<00:00,  2.52it/s]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.80it/s]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.29it/s]\n",
      "100%|██████████| 129/129 [00:54<00:00,  2.35it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.12it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.28it/s]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.55it/s]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.43it/s]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.32it/s]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.63it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.96it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.16it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.35it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.22it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.89it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.62it/s]]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.74it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.17it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.67it/s]]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.96it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.00it/s] \n",
      "100%|██████████| 129/129 [00:38<00:00,  3.33it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.94it/s] \n",
      "100%|██████████| 129/129 [00:41<00:00,  3.08it/s]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.19it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.25it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.97it/s]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.67it/s]\n",
      "100%|██████████| 129/129 [00:51<00:00,  2.53it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.05it/s]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.47it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.63it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.47it/s]]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.84it/s]]\n",
      "100%|██████████| 129/129 [00:51<00:00,  2.53it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.61it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.01it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.23it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.21it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.32it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.42it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.51it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.49it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.49it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.23it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.47it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.47it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.62it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.29it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.15it/s]]\n",
      "100%|██████████| 50/50 [1:38:30<00:00, 118.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e452db69b35e4e9098fa845273af1290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='175.997 MB of 175.997 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▄▃▄▅▇█▆▇▆█▇▆██▇▄▆▄▅▅▇▅▄▅▅▆▄▆▄▃▃▅▂▃▆▅▁▃▅▅</td></tr><tr><td>FK ROI < 30</td><td>▄▄▄▇▇▇▇▇▆▇▇▆▇▅▆▅▆▄▆▄█▅▆▅▅▅▃▅▄▁▃▃▄▃▃▃▁▂▃▃</td></tr><tr><td>ROI</td><td>▄▃▄▅▇█▆▇▆▇▇▆█▇▇▄▅▄▅▅▇▅▄▅▄▆▃▆▄▃▃▅▂▃▆▄▁▃▄▄</td></tr><tr><td>ROI < 30</td><td>▃▃▃▆▆▇▆▆▆▆▆▆▇▅▆▅▆▃▅▄█▅▆▅▅▄▃▄▃▁▃▂▄▃▃▃▁▂▃▂</td></tr><tr><td>accuracy</td><td>▁▂▃▂▄▄▅▅▅▆▅▅▅▅▆▅▇▆▅▆▇▇▇▇▇▇▆▇▇▇▇▇▇██▇████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▇▃▆▇▂▆▆▆▆▆▆▆▆▆▆▆▆▂▆▅▂▅▅▂▄▅▅▅▅▄▅▅▅▄▅▅▁▄</td></tr><tr><td>correct</td><td>▁▂▃▂▄▄▅▅▅▆▅▅▅▅▆▅▇▆▅▆▇▇▇▇▇▇▆▇▇▇▇▇▇██▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>████▇▇▆▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▄▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▁▂</td></tr><tr><td>multibet outlay</td><td>▁▅▇█▇▆▆▅▅▅▆▇▆▄▄▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▃▁▂▁▁▁▂▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▃▄▄▄▄▄▄▄▅▅▆▅▆▅▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇██████</td></tr><tr><td>multibet profit</td><td>▄▃▃▅▇█▆▇▅▇▇▆█▇▇▄▅▄▅▅▇▅▄▅▄▆▃▆▄▃▃▅▂▃▆▄▁▃▄▄</td></tr><tr><td>multibet profit < 30</td><td>▂▂▂▅▅▆▅▆▅▆▅▅▇▅▆▄▅▃▅▄█▆▆▅▅▅▃▅▃▁▃▃▅▃▃▃▁▂▃▃</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▃▃▄▅▅▅▅▅▄▆▆▆▅▆▆▇▇▇█▇▇█▇▇▇▇▆▇▇█▇██▇██▇</td></tr><tr><td>multibet profit sd</td><td>▆▆▇▇█▆▆▆▅▆▆▆▆█▅▅▄▅▅▄▄▃▂▄▂▄▃▄▃▄▂▄▂▂▃▃▁▂▂▃</td></tr><tr><td>profit</td><td>▅▆▅█▆█▇▇▆█▅▇▆▄▅▄▅▅▄▂▆▄▅▃▃▄▄▆▂▂▂▄▃▅▅▁▃▂▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.08948</td></tr><tr><td>FK ROI < 30</td><td>0.04179</td></tr><tr><td>ROI</td><td>-0.09999</td></tr><tr><td>ROI < 30</td><td>0.05426</td></tr><tr><td>accuracy</td><td>0.23471</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>26.28606</td></tr><tr><td>correct</td><td>1819</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>26.28606</td></tr><tr><td>loss_val</td><td>1.93408</td></tr><tr><td>multibet outlay</td><td>231839.19591</td></tr><tr><td>multibet outlay < 30</td><td>124004.0942</td></tr><tr><td>multibet profit < 30</td><td>6728.92802</td></tr><tr><td>multibet profit < 30 sd</td><td>21.80505</td></tr><tr><td>multibet profit sd</td><td>43.98849</td></tr><tr><td>profit</td><td>5076.51896</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">deft-sweep-4</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/i1nvitx2\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/i1nvitx2</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230227_033042-i1nvitx2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0yni2dyk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.556195533100934e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230227_051002-0yni2dyk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/0yni2dyk\" target=\"_blank\">resilient-sweep-5</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 9.556195533100934e-05, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 9.556195533100934e-05, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40206/40206 [00:13<00:00, 2947.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =271943\n",
      "empty  =49705\n",
      "0.8454677162612545null_dog=0\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 9.556195533100934e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:32<00:00,  1.03s/it]\n",
      "100%|██████████| 32/32 [00:31<00:00,  1.03it/s]t]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.14it/s]t]\n",
      "100%|██████████| 32/32 [00:37<00:00,  1.17s/it]t]\n",
      "100%|██████████| 32/32 [00:31<00:00,  1.02it/s]t]\n",
      "100%|██████████| 32/32 [00:39<00:00,  1.22s/it]t]\n",
      "100%|██████████| 32/32 [00:32<00:00,  1.02s/it]t]\n",
      "100%|██████████| 32/32 [00:40<00:00,  1.27s/it]t]\n",
      "100%|██████████| 32/32 [00:30<00:00,  1.04it/s]t]\n",
      "100%|██████████| 32/32 [00:35<00:00,  1.12s/it]t]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.09it/s]it]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.17it/s]it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.20it/s]it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.22it/s]it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]it]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.31it/s]   \n",
      "100%|██████████| 32/32 [00:25<00:00,  1.28it/s]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.32it/s]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.25it/s]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s] \n",
      "100%|██████████| 32/32 [00:24<00:00,  1.32it/s]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.31it/s]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.14it/s]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n",
      "100%|██████████| 32/32 [00:32<00:00,  1.03s/it]\n",
      "100%|██████████| 32/32 [00:33<00:00,  1.03s/it]\n",
      "100%|██████████| 32/32 [00:33<00:00,  1.05s/it]\n",
      "100%|██████████| 32/32 [00:36<00:00,  1.14s/it]]\n",
      "100%|██████████| 32/32 [00:40<00:00,  1.27s/it]]\n",
      "100%|██████████| 32/32 [00:41<00:00,  1.31s/it]]\n",
      "100%|██████████| 32/32 [00:40<00:00,  1.26s/it]]\n",
      "100%|██████████| 32/32 [00:37<00:00,  1.17s/it]]\n",
      "100%|██████████| 32/32 [00:36<00:00,  1.15s/it]it]\n",
      "100%|██████████| 32/32 [00:30<00:00,  1.06it/s]it]\n",
      "100%|██████████| 32/32 [00:31<00:00,  1.03it/s]it]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.12it/s]t] \n",
      "100%|██████████| 32/32 [00:27<00:00,  1.17it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.31it/s]it]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.31it/s]it]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.31it/s]t] \n",
      "100%|██████████| 32/32 [00:24<00:00,  1.32it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.29it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.28it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.28it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.32it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.33it/s]t]\n",
      "100%|██████████| 50/50 [1:23:00<00:00, 99.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53de9e58283f49119bb8b4c94d323243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='164.950 MB of 164.950 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>█▆▆▅▄▅▆▅▃▅▄▅▄▄▃▄▆▇▅▄▄▃▆▄▂▂▁▄▄▂▂▃▃▄▄▃▄▆▅▃</td></tr><tr><td>FK ROI < 30</td><td>█▇▅▅▃▅▆▄▃▂▄▄▄▃▃▄▆▆▄▅▃▃▄▄▃▂▁▃▄▂▂▂▁▃▂▂▄▅▄▅</td></tr><tr><td>ROI</td><td>█▅▆▆▃▅▅▅▃▆▄▅▄▃▃▄▆▇▅▃▄▃▅▅▂▂▁▅▃▂▂▃▃▃▃▃▄▅▄▂</td></tr><tr><td>ROI < 30</td><td>█▇▅▅▃▅▆▄▃▂▄▅▄▂▂▄▇▆▅▅▃▃▅▄▃▂▁▄▄▁▃▂▁▂▃▂▄▆▅▄</td></tr><tr><td>accuracy</td><td>▁▂▂▄▂▄▃▂▁▃▄▃▂▃▃▄▅▅▄▅▅▅▃▅▄▅▆▄▅▆▅▆▅▇▆▇▇▆█▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▇▂▃▇▂▃▇▅▃▇▅▆▆▅▆▆▆▁▆▆▁▃▆▁▂▆▅▆▆▅▆▆▆▆▆▆▁▆</td></tr><tr><td>correct</td><td>▁▂▂▄▂▄▃▂▁▃▄▃▂▃▃▄▅▅▄▅▅▅▃▅▄▅▆▄▅▆▅▆▅▇▆▇▇▆█▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▇▆▆▆▄▅▅▅▄▄▄▄▄▂▃▄▄▃▃▃▃▃▃▃▃▄▃▂▃▁▃▁▁▂▁▁▂</td></tr><tr><td>loss_val</td><td>█▆▆▅▅▄▃▃▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁</td></tr><tr><td>multibet outlay</td><td>█▆▅▅▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▄▃▃▃▄▄▄▅▄▄▅▅▅▅▅▆▅▆▆▅▆▆▆▆▇▆▆▆▆▆▇▆▆▇█▇</td></tr><tr><td>multibet profit</td><td>█▅▆▆▃▆▆▅▃▆▄▅▄▃▃▄▇▇▅▄▄▃▆▅▂▂▁▅▄▂▂▃▄▃▄▃▅▆▅▃</td></tr><tr><td>multibet profit < 30</td><td>█▇▅▅▃▅▆▄▃▂▄▅▄▂▂▄▇▇▅▆▄▃▅▄▄▂▁▄▄▂▃▂▁▃▃▃▅▆▆▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▆▄▂▂▂▄▄▃▄▂▃▄▃▁▂▄▅▅▅▅▄▄▅▄▅▃▃▅▅▂▄▂▃▃▄▄▅▇█▆</td></tr><tr><td>multibet profit sd</td><td>█▆▆▆▄▅▄▄▄▄▃▃▄▃▃▃▃▃▃▂▂▂▂▃▁▂▁▂▂▁▁▂▃▂▂▁▂▂▂▁</td></tr><tr><td>profit</td><td>█▅▆▅▃▅▆▃▂▃▄▂▁▁▂▂▃▄▃▄▂▅▃▃▂▄▃▁▃▂▃▃▂▄▂▂▄▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.06447</td></tr><tr><td>FK ROI < 30</td><td>0.06547</td></tr><tr><td>ROI</td><td>-0.08001</td></tr><tr><td>ROI < 30</td><td>0.07517</td></tr><tr><td>accuracy</td><td>0.25987</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>9.49965</td></tr><tr><td>correct</td><td>2001</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>9.49965</td></tr><tr><td>loss_val</td><td>1.88762</td></tr><tr><td>multibet outlay</td><td>216040.72924</td></tr><tr><td>multibet outlay < 30</td><td>124801.31754</td></tr><tr><td>multibet profit < 30</td><td>9381.69644</td></tr><tr><td>multibet profit < 30 sd</td><td>22.20737</td></tr><tr><td>multibet profit sd</td><td>37.74068</td></tr><tr><td>profit</td><td>4990.46015</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">resilient-sweep-5</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/0yni2dyk\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/0yni2dyk</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230227_051002-0yni2dyk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 89wkscbo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.189393370248573e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230227_063352-89wkscbo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/89wkscbo\" target=\"_blank\">light-sweep-6</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/4q91hs4m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 6.189393370248573e-05, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 6.189393370248573e-05, 'len_data': 40206, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40206/40206 [00:13<00:00, 2999.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =271943\n",
      "empty  =49705\n",
      "0.8454677162612545null_dog=0\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 6.189393370248573e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_lin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc0): Linear(in_features=510, out_features=510, bias=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.93it/s]t]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]t]\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.85it/s]] \n",
      "100%|██████████| 32/32 [00:13<00:00,  2.46it/s]]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s]]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s]]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.89it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.39it/s]]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s] \n",
      "100%|██████████| 32/32 [00:25<00:00,  1.23it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]  \n",
      "100%|██████████| 32/32 [00:23<00:00,  1.37it/s]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.18it/s]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]]\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.40it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.43it/s] \n",
      "100%|██████████| 32/32 [00:16<00:00,  1.91it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.33it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.33it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.39it/s] \n",
      "100%|██████████| 32/32 [00:13<00:00,  2.35it/s]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.16it/s]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"GRU_sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48ca33c5a1168302a4f8eae355aad1c03b1396f568d40bc174a6e6aabe725d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
