{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "with torch.profiler.profile() as profiler:\n",
    "        pass\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogInput:\n",
    "    def __init__(self, dogid, raceid,stats, dog,dog_box, lstmCellh,lstmCellc) -> None:\n",
    "        self.dogid= dogid\n",
    "        self.raceid = raceid\n",
    "        self.stats = stats.to('cuda:0')\n",
    "        self.dog = dog\n",
    "        self.lstmCellh = lstmCellh.float().to('cuda:0')\n",
    "        self.lstmCellc = lstmCellc.float().to('cuda:0')\n",
    "        self.visited = 0\n",
    "        \n",
    "        \n",
    "    def lstm_i(self, lstmInput):\n",
    "        (self.lstmCellh,self.lstmCellc) = lstmInput\n",
    "        # self.lstmCellh=self.lstmCellh.to(device)\n",
    "        # self.lstmCellc=self.lstmCellc.to(device)\n",
    "        self.visited = self.visited + 1\n",
    "        # if self.visited>1:\n",
    "        #     print(\"FOUND LEAK\")\n",
    "        #     sasdfasd\n",
    "\n",
    "    def nextrace(self, raceid):\n",
    "        self.nextrace_id = raceid\n",
    "\n",
    "    def prevrace(self, raceid):\n",
    "        self.prevrace_id = raceid\n",
    "\n",
    "    def lstm_o(self, lstm_o):\n",
    "        # print(lstm_o[0]._version)\n",
    "        (lh,lc) = lstm_o\n",
    "        if self.nextrace_id==-1:\n",
    "            pass\n",
    "        else:\n",
    "            # self.dog.races[self.nextrace_id].lstm_i((lh.detach(), lc.detach()))  #DETACH\n",
    "            self.dog.races[self.nextrace_id].lstm_i((lh.detach(),lc.clone()))  #  .detach()))\n",
    "\n",
    "    def detach_state(self):\n",
    "        self.lstmCellh = self.lstmCellh.detach()\n",
    "        self.lstmCellc = self.lstmCellc.detach()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    def __init__(self, dogid, hidden_size, layers) -> None:\n",
    "        self.dogid = dogid\n",
    "        # self.raceids = raceids #possible dictionary of race id keys dog stat outs\n",
    "        self.lstmcell = 0\n",
    "        self.layers = layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l_debug = None\n",
    "        self.races = {}\n",
    "\n",
    "    def add_races(self, raceid, racedate, stats,nextraceid, prevraceid, box):\n",
    "        self.races[raceid] = DogInput(self.dogid, raceid, stats, self, box, torch.randn(self.hidden_size),torch.randn(self.hidden_size)) #this is the change\n",
    "        self.races[raceid].nextrace(nextraceid)\n",
    "        self.races[raceid].prevrace(prevraceid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Race:\n",
    "    def __init__(self, raceid,trackOHE, dist, classes):\n",
    "        self.raceid = raceid\n",
    "        self.race_dist = dist.to('cuda:0')\n",
    "        self.race_track = trackOHE.to('cuda:0')\n",
    "        self.classes =  classes.to('cuda:0')\n",
    "\n",
    "    def add_dogs(self, dogs_list:DogInput):\n",
    "        self.dog1 = dogs_list[0]\n",
    "        self.dog2 = dogs_list[1]\n",
    "        self.dog3 = dogs_list[2]\n",
    "        self.dog4 = dogs_list[3]\n",
    "        self.dog5 = dogs_list[4]\n",
    "        self.dog6 = dogs_list[5]\n",
    "        self.dog7 = dogs_list[6]\n",
    "        self.dog8 = dogs_list[7]\n",
    "        self.dogs = dogs_list\n",
    "\n",
    "    def nn_input(self):\n",
    "        input = torch.cat([x.stats for x in self.dogs], dim = 0)\n",
    "        full_input = torch.cat((self.race_dist,self.race_track, input), dim=0).to(device='cuda:0')\n",
    "        self.full_input = full_input\n",
    "        return full_input\n",
    "\n",
    "    def lstm_input(self):\n",
    "        l_input = [(x.lstmCellh,x.lstmCellc) for x in self.dogs]\n",
    "        return l_input\n",
    "\n",
    "    def lstm_detach(self):\n",
    "        [x.detach_state for x in self.dogs]\n",
    "\n",
    "    def list_dogs(self):\n",
    "        dogs_l = [x for x in self.dogs]\n",
    "        return dogs_l\n",
    "\n",
    "    def pass_lstm_output(self, lstm_h, lstm_c):\n",
    "        for i,dog in enumerate(self.dogs):\n",
    "            \n",
    "            lh = lstm_h[i]\n",
    "            lc = lstm_c[i]\n",
    "            # lh,lc = lh.detach(), lc.detach()\n",
    "            lh,lc = lh.detach(), lc.clone()# lc.detach()\n",
    "            dog.lstm_o((lh,lc))\n",
    "            dog.dog.l_debug = (lh,lc)\n",
    "        # zipped_lstm = zip(self.dogs,lstms)\n",
    "        # [x.lstm_o(y) for x,y in zipped_lstm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Races:\n",
    "    def __init__(self, hidden_size, layers, batch_size = 100) -> None:\n",
    "        self.racesDict = {}\n",
    "        self.dogsDict = {}\n",
    "        self.raceIDs = []\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.getter = operator.itemgetter(*range(batch_size))\n",
    "\n",
    "    def add_race(self,raceid:str, trackOHE, dist, classes):\n",
    "        self.racesDict[raceid] = Race(raceid, trackOHE, dist, classes)\n",
    "        self.raceIDs.append(raceid)\n",
    "\n",
    "    def add_dog(self,dogid):\n",
    "        if dogid not in self.dogsDict.keys():\n",
    "            self.dogsDict[dogid] = Dog(dogid, self.hidden_size, self.layers)\n",
    "        else:\n",
    "            self.dogsDict[dogid] = self.dogsDict[dogid]\n",
    "\n",
    "    def get_race_input(self, idx) -> Race:\n",
    "        raceidx = operator.itemgetter(*idx)\n",
    "        #raceidx  = self.getter(idx)\n",
    "        race_batch_id = raceidx(self.raceIDs)\n",
    "\n",
    "        #race_getter = operator.itemgetter(*raceidx)\n",
    "\n",
    "        races = [self.racesDict[x] for x in race_batch_id] #Returns list of class Race\n",
    "        \n",
    "\n",
    "        # raceidx = self.raceIDs[idx]\n",
    "        #input = torch.cat([x.stats for x in races.dogs.values()], dim = 0)\n",
    "        #full_input = torch.cat((self.racesDict[raceidx].race_dist,self.racesDict[raceidx].race_track, input), dim=0 )\n",
    "        # dogs = [x for x in self.racesDict[raceidx].dogs]\n",
    "        \n",
    "        return races #self.racesDict[raceidx]\n",
    "\n",
    "    def get_race_classes(self, idx):\n",
    "        raceidx = self.raceIDs[idx]\n",
    "        classes = [x for x in self.raceDict[raceidx].classes]\n",
    "        return classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm2 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm3 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm4 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm5 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm6 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm7 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.lstm8 = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size * 8, 64)\n",
    "        self.fc3 = nn.Linear(64, 8)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, race: Race):\n",
    "        #x = race.nn_input().float().to('cuda:0')\n",
    "        x = torch.stack([r.full_input.float() for r in race])\n",
    "\n",
    "        #creates list of LSTM data \n",
    "        lstm_ins = [list(i) for i in zip(*[r.lstm_input() for r in race])]\n",
    "\n",
    "        # creates list of tensors for lstm Cells\n",
    "        hCell = [torch.stack([x[0] for x in y]) for y in lstm_ins]\n",
    "        cCell = [torch.stack([x[1] for x in y]) for y in lstm_ins]\n",
    "\n",
    "        (h1, c1) = self.lstm1(x, (hCell[0], cCell[0]))\n",
    "        (h2, c2) = self.lstm2(x, (hCell[1], cCell[1]))\n",
    "        (h3, c3) = self.lstm3(x, (hCell[2], cCell[2]))\n",
    "        (h4, c4) = self.lstm4(x, (hCell[3], cCell[3]))\n",
    "        (h5, c5) = self.lstm5(x, (hCell[4], cCell[4]))\n",
    "        (h6, c6) = self.lstm6(x, (hCell[5], cCell[5]))\n",
    "        (h7, c7) = self.lstm7(x, (hCell[6], cCell[6]))\n",
    "        (h8, c8) = self.lstm8(x, (hCell[7], cCell[7]))\n",
    "\n",
    "        lstm_list = [\n",
    "            (h1, c1),\n",
    "            (h2, c2),\n",
    "            (h3, c3),\n",
    "            (h4, c4),\n",
    "            (h5, c5),\n",
    "            (h6, c6),\n",
    "            (h7, c7),\n",
    "            (h8, c8)\n",
    "        ]\n",
    "\n",
    "        hCello = [i for i in zip(*[x[0] for x in lstm_list])]\n",
    "        cCello = [i for i in zip(*[x[1] for x in lstm_list])]\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            r.pass_lstm_output(hCello[i],cCello[i])\n",
    "            #r.lstm_detach()\n",
    "        xhh = torch.cat((h1,h2, h3, h4, h5, h6, h7, h8), dim=1)\n",
    "        xh = self.fc2(xhh)\n",
    "        xf = self.fc3(xh)\n",
    "\n",
    "        output = F.softmax(xf, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data, hidden_size):\n",
    "\n",
    "    #Load in pickeled dataframe\n",
    "    resultsdf = pickle.load(data)\n",
    "    dog_stats_df = pd.DataFrame(resultsdf)\n",
    "    dog_stats_df = dog_stats_df.fillna(-1).drop_duplicates(subset=['dogid', 'raceid'])\n",
    "    dog_stats_df['stats_cuda'] = dog_stats_df.apply(lambda x: torch.tensor(x['stats']), axis =1)\n",
    "    dog_stats_df['box'] = dog_stats_df['stats'].apply(lambda x: x[0])\n",
    "\n",
    "    #Created RaceDB\n",
    "    raceDB = Races(hidden_size, 1)\n",
    "\n",
    "    #Fill in dog portion:\n",
    "\n",
    "    dog_stats_group = dog_stats_df.sort_values(['date']).groupby([\"dogid\"])\n",
    "\n",
    "    for i,j in tqdm(dog_stats_group):\n",
    "        j[\"next_race\"] = j[\"raceid\"].shift(-1).fillna(-1)\n",
    "        j[\"prev_race\"] = j[\"raceid\"].shift(1).fillna(-1)\n",
    "        raceDB.add_dog(i)\n",
    "        j.apply(lambda x: raceDB.dogsDict[i].add_races(x['raceid'], x['date'], torch.Tensor(x['stats']),x['next_race'], x['prev_race'], x['box']), axis=1)\n",
    "\n",
    "    #Fill in races portion\n",
    "    softmin = nn.Softmin()\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "\n",
    "    null_dog = Dog(\"nullDog\", raceDB.hidden_size, raceDB.layers)\n",
    "    null_dog_i = DogInput(\"nullDog\", \"-1\", torch.zeros(16), null_dog,0, torch.zeros(raceDB.hidden_size), torch.zeros(raceDB.hidden_size))\n",
    "    null_dog_i.nextrace(-1)\n",
    "    null_dog_i.prevrace(-1)\n",
    "\n",
    "    null_dog_list = [null_dog] * 8\n",
    "    #TO FIX LATER PROPER BOX PLACEMENT #FIXED\n",
    "\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "    for i,j in tqdm(races_group):\n",
    "    #Track info tensors\n",
    "        dist = torch.tensor([j.dist.iloc[0]]) \n",
    "        trackOHE = torch.tensor(j.trackOHE.iloc[0])\n",
    "        #margins\n",
    "        empty_dog_list = [null_dog_i]*8\n",
    "        empty_margin_list = [100]*8\n",
    "        boxes_list = [x for x in j['box']]\n",
    "        margin_list = [x for x in j[\"place\"]]\n",
    "        dog_list = [raceDB.dogsDict[x].races[i] for x in j[\"dogid\"]]\n",
    "\n",
    "        #adjustedMargin = [margin_list[x-1] for x in boxes_list]\n",
    "        for n,x in enumerate(boxes_list):\n",
    "            empty_margin_list[x-1] = margin_list[n]\n",
    "            empty_dog_list[x-1] = dog_list[n]\n",
    "        adjustedMargin = softmin(torch.tensor(empty_margin_list)).to('cuda:0')\n",
    "        #adjusted_dog_list = [dog_list[x-1] for x in boxes_list]\n",
    "        \n",
    "        raceDB.add_race(i,trackOHE,dist, adjustedMargin)\n",
    "        \n",
    "        \n",
    "        # List of Dog Input??\n",
    "        raceDB.racesDict[i].add_dogs(empty_dog_list)\n",
    "        raceDB.racesDict[i].nn_input()\n",
    "\n",
    "\n",
    "    return raceDB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def validate_model(model,raceDB,criterion, batch_size, example_ct):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in trange(60000,70000,batch_size):   \n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "            race = raceDB.get_race_input(races_idx)\n",
    "            X = race\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            output = model(X)\n",
    "            #print(y)\n",
    "\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            #print(predicted)\n",
    "            #print(actual)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "            total +=10\n",
    "\n",
    "\n",
    "\n",
    "            loss = criterion(output, y)\n",
    "            #optimizer.zero_grad()\n",
    "            #newnet.zero_grad()\n",
    "            #loss.backward(retain_graph=True)  \n",
    "            #optimizer.step()\n",
    "            #if i %5000 == 0:\n",
    "            #    print(loss)\n",
    "        # optimizer.step() \n",
    "        #print(loss)\n",
    "    print(f\"accuray: {correct/total}\")\n",
    "    #wandb.log({\"accuracy\": correct/total, \"loss\": loss}, step=example_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, raceDB, criterion, optimizer, config=None):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    last = 0\n",
    "    batch_size = 1000\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    excep_ct = 0\n",
    "    last_race = None\n",
    "    for epoch in range(100): \n",
    "        for i in trange(batch_size,60000,batch_size):\n",
    "            batch_ct += 1   \n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "\n",
    "            race = raceDB.get_race_input(races_idx)\n",
    "            X = race\n",
    "\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            output = model(X)\n",
    "            example_ct +=  batch_size\n",
    "            batch_ct += 1\n",
    "            # print(\"new batch \\n\\n\")\n",
    "            # for r in race:\n",
    "            #     print(f\"{r.raceid=}\")\n",
    "            #     for d in r.dogs:\n",
    "            #         print(f\"{d.dogid=}\\nlstmc = {d.lstmCellc}\\nlstmh = {d.lstmCellh}\")\n",
    "            if last_race:\n",
    "                [r.lstm_detach for r in last_race]\n",
    "            loss = criterion(output, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            last_race = race\n",
    "            # try:\n",
    "            #     loss.backward(retain_graph=True)  \n",
    "            # except Exception as e:\n",
    "            #     print(\"broke\")\n",
    "\n",
    "                        \n",
    "            #     excep_ct +=1\n",
    "            #     break\n",
    "            # #loss.backward()\n",
    "            optimizer.step()\n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                pass\n",
    "                #train_log(loss, example_ct, epoch)\n",
    "\n",
    "            \n",
    "\n",
    "        print(loss)\n",
    "        validate_model(model,raceDB,criterion, 8, example_ct)\n",
    "    #print(excep_ct)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(my_dataset,config=None,prev_model=None):\n",
    "    dataset = my_dataset\n",
    "    # tell wandb to get started\n",
    "    #config = wandb.config\n",
    "    #pprint.pprint(config)\n",
    "    #pprint.pprint(config.epochs)\n",
    "    print(config)\n",
    "\n",
    "    model = Net(144,config[\"hidden_size\"])\n",
    "    criterion = nn.HuberLoss()\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "    #criterion = nn.NLLLoss()\n",
    "    optimizer = optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    # make the model, data, and optimization problem\n",
    "    #model, train_loader, test_loader, criterion, optimizer = make(config, dataset)\n",
    "\n",
    "\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    model = model.to(device)\n",
    "    #optimizer = optimizer.to(device)\n",
    "    print(model)\n",
    "\n",
    "    # and use them to train the model\n",
    "    train(model, dataset, criterion, optimizer, config)\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25187/25187 [11:07<00:00, 37.72it/s] \n",
      "  0%|          | 0/72073 [00:00<?, ?it/s]C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_430020\\1524283141.py:51: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
      "  adjustedMargin = softmin(torch.tensor(empty_margin_list)).to('cuda:0')\n",
      "100%|██████████| 72073/72073 [01:12<00:00, 995.17it/s] \n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( 'dog_stats_df.npy', 'rb')\n",
    "hidden_size = 3\n",
    "raceDB = build_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 360, 'dropout': 0.3, 'epochs': 100, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.00001, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4,5])\n",
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 3, 'batch_size': 360, 'dropout': 0.3, 'epochs': 100, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 1e-05, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "Net(\n",
      "  (lstm1): LSTMCell(144, 3)\n",
      "  (lstm2): LSTMCell(144, 3)\n",
      "  (lstm3): LSTMCell(144, 3)\n",
      "  (lstm4): LSTMCell(144, 3)\n",
      "  (lstm5): LSTMCell(144, 3)\n",
      "  (lstm6): LSTMCell(144, 3)\n",
      "  (lstm7): LSTMCell(144, 3)\n",
      "  (lstm8): LSTMCell(144, 3)\n",
      "  (fc2): Linear(in_features=24, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/59 [00:12<11:47, 12.20s/it]c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: Error detected in ThnnFusedLstmCellBackward0. Traceback of forward call that caused the error:\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\traitlets\\config\\application.py\", line 972, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 504, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 493, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 724, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_430020\\1436148755.py\", line 1, in <cell line: 1>\n",
      "    model = model_pipeline(raceDB,config=wandb_config_static)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_430020\\967579108.py\", line 25, in model_pipeline\n",
      "    train(model, dataset, criterion, optimizer, config)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_430020\\1655750160.py\", line 20, in train\n",
      "    output = model(X)\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_430020\\2924945152.py\", line 35, in forward\n",
      "    (h8, c8) = self.lstm8(x, (hCell[7], cCell[7]))\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 1189, in forward\n",
      "    ret = _VF.lstm_cell(\n",
      " (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  2%|▏         | 1/59 [00:25<25:05, 25.95s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [12]] is at version 3; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\LSTM - noWANDB.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m model_pipeline(raceDB,config\u001b[39m=\u001b[39;49mwandb_config_static)\n",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\LSTM - noWANDB.ipynb Cell 18\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[1;34m(my_dataset, config, prev_model)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# and use them to train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m train(model, dataset, criterion, optimizer, config)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# and test its final performance\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#test(model, test_loader)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\LSTM - noWANDB.ipynb Cell 18\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, raceDB, criterion, optimizer, config)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m last_race \u001b[39m=\u001b[39m race\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# try:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#     loss.backward(retain_graph=True)  \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# except Exception as e:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m#     break\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/LSTM%20-%20noWANDB.ipynb#X23sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# #loss.backward()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [12]] is at version 3; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "model = model_pipeline(raceDB,config=wandb_config_static)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43115443075634c02a7c247a87b0dd9d74842892e56d473b9e19f544f3149aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
