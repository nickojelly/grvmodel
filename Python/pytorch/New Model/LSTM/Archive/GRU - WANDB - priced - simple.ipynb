{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "with torch.profiler.profile() as profiler:\n",
    "        pass\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogInput:\n",
    "    def __init__(self, dogid, raceid,stats, dog,dog_box, hidden_state, bfsp, sp) -> None:\n",
    "        self.dogid= dogid\n",
    "        self.raceid = raceid\n",
    "        self.stats = stats.to('cuda:0')\n",
    "        self.dog = dog\n",
    "        self.gru_cell = hidden_state.float().to('cuda:0')\n",
    "        self.visited = 0\n",
    "        self.bfsp = bfsp\n",
    "        self.gru_cell_out = None\n",
    "\n",
    "        \n",
    "        \n",
    "    def lstm_i(self, hidden_state):\n",
    "        self.gru_cell = hidden_state\n",
    "        # self.lstmCellh=self.lstmCellh.to(device)\n",
    "        # self.lstmCellc=self.lstmCellc.to(device)\n",
    "        self.visited = self.visited + 1\n",
    "        # if self.visited>1:\n",
    "        #     print(\"FOUND LEAK\")\n",
    "        #     sasdfasd\n",
    "\n",
    "    def nextrace(self, raceid):\n",
    "        self.nextrace_id = raceid\n",
    "\n",
    "    def prevrace(self, raceid):\n",
    "        self.prevrace_id = raceid\n",
    "\n",
    "    def lstm_o(self, lstm_o):\n",
    "        # print(lstm_o[0]._version)\n",
    "        hidden_state = lstm_o\n",
    "        self.gru_cell_out = lstm_o\n",
    "        if self.nextrace_id==-1:\n",
    "            pass\n",
    "        else:\n",
    "            self.dog.races[self.nextrace_id].lstm_i(hidden_state) #((lh.detach(), lc.detach())) #DETACH\n",
    "\n",
    "    def detach_state(self):\n",
    "        self.gru_cell = self.gru_cell.detach()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    def __init__(self, dogid,dog_name, hidden_size, layers) -> None:\n",
    "        self.dogid = dogid\n",
    "        self.dog_name = dog_name\n",
    "        # self.raceids = raceids #possible dictionary of race id keys dog stat outs\n",
    "        self.lstmcell = 0\n",
    "        self.layers = layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l_debug = None\n",
    "        self.races = {}\n",
    "\n",
    "    def add_races(self, raceid, racedate, stats,nextraceid, prevraceid, box, bfsp=None, sp=None):\n",
    "        self.races[raceid] = DogInput(self.dogid, raceid, stats, self, box, torch.randn(self.hidden_size), bfsp, sp) #this is the change\n",
    "        self.races[raceid].nextrace(nextraceid)\n",
    "        self.races[raceid].prevrace(prevraceid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Race:\n",
    "    def __init__(self, raceid,trackOHE, dist, classes=None):\n",
    "        self.raceid = raceid\n",
    "        self.race_dist = dist.to('cuda:0')\n",
    "        self.race_track = trackOHE.to('cuda:0')\n",
    "        self.track_name = None\n",
    "        if classes!=None:\n",
    "            self.classes =  classes.to('cuda:0')\n",
    "\n",
    "    def add_dogs(self, dogs_list:DogInput):\n",
    "        self.dog1 = dogs_list[0]\n",
    "        self.dog2 = dogs_list[1]\n",
    "        self.dog3 = dogs_list[2]\n",
    "        self.dog4 = dogs_list[3]\n",
    "        self.dog5 = dogs_list[4]\n",
    "        self.dog6 = dogs_list[5]\n",
    "        self.dog7 = dogs_list[6]\n",
    "        self.dog8 = dogs_list[7]\n",
    "        self.dogs = dogs_list\n",
    "\n",
    "    def add_track_name(self, track_name):\n",
    "        self.track_name = track_name\n",
    "\n",
    "\n",
    "    def nn_input(self):\n",
    "        input = torch.cat([x.stats for x in self.dogs], dim = 0)\n",
    "        full_input = torch.cat((self.race_dist,self.race_track, input), dim=0).to(device='cuda:0')\n",
    "        self.full_input = full_input\n",
    "        return full_input\n",
    "\n",
    "    def lstm_input(self, pred=False):\n",
    "        if pred:\n",
    "            print('pred')\n",
    "        else:\n",
    "            l_input = [x.gru_cell for x in self.dogs]\n",
    "        return l_input\n",
    "\n",
    "    def lstm_detach(self):\n",
    "        [x.detach_state for x in self.dogs]\n",
    "\n",
    "    def list_dogs(self):\n",
    "        dogs_l = [x for x in self.dogs]\n",
    "        return dogs_l\n",
    "\n",
    "    def pass_gru_output(self, hidden_states):\n",
    "        for i,dog in enumerate(self.dogs):\n",
    "            hs = hidden_states[i]\n",
    "            hs = hs.detach()\n",
    "            dog.lstm_o(hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Races:\n",
    "    def __init__(self, hidden_size, layers, batch_size = 100) -> None:\n",
    "        self.racesDict = {}\n",
    "        self.dogsDict = {}\n",
    "        self.raceIDs = []\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.getter = operator.itemgetter(*range(batch_size))\n",
    "\n",
    "    def add_race(self,raceid:str, trackOHE, dist, classes=None):\n",
    "        self.racesDict[raceid] = Race(raceid, trackOHE, dist, classes)\n",
    "        self.raceIDs.append(raceid)\n",
    "\n",
    "    def add_dog(self,dogid, dog_name):\n",
    "        if dogid not in self.dogsDict.keys():\n",
    "            self.dogsDict[dogid] = Dog(dogid,dog_name, self.hidden_size, self.layers)\n",
    "        # else:\n",
    "        #     self.dogsDict[dogid] = self.dogsDict[dogid]\n",
    "\n",
    "    def get_race_input(self, idx) -> Race:\n",
    "        raceidx = operator.itemgetter(*idx)\n",
    "        race_batch_id = raceidx(self.raceIDs)\n",
    "        races = [self.racesDict[x] for x in race_batch_id] #Returns list of class Race\n",
    "        \n",
    "        return races #self.racesDict[raceidx]\n",
    "\n",
    "    def get_race_classes(self, idx):\n",
    "        raceidx = self.raceIDs[idx]\n",
    "        classes = [x for x in self.raceDict[raceidx].classes]\n",
    "        return classes\n",
    "\n",
    "    def reset_all_lstm_states(self):\n",
    "        for race in self.racesDict.values:\n",
    "            for dog in race.dogs:\n",
    "                dog.lstmCellc = torch.rand(self.hidden_size)\n",
    "                dog.lstmCellh = torch.rand(self.hidden_size)\n",
    "                dog.gru_cell = torch.rand(self.hidden_size)\n",
    "\n",
    "    def create_hidden_states_dict(self):\n",
    "        self.hidden_states_dict = {}\n",
    "        for race in self.racesDict.values():\n",
    "            race_id = race.raceid\n",
    "            for dog in race.dogs:\n",
    "                dog_id = dog.dogid\n",
    "                key = race_id+'_'+dog_id\n",
    "                val = dog.gru_cell_out\n",
    "                self.hidden_states_dict[key] = val\n",
    "\n",
    "    def fill_hidden_states_from_dict(self, hidden_dict):\n",
    "        for race in self.racesDict.values():\n",
    "            race_id = race.raceid\n",
    "            for dog in race.dogs:\n",
    "                dog_id = dog.dogid\n",
    "                dog_prev_race_id = dog.prevrace_id\n",
    "                key = str(dog_prev_race_id)+'_'+dog_id\n",
    "                try:\n",
    "                    val = hidden_dict[key]\n",
    "                    if val != None:\n",
    "                        dog.gru_cell = val\n",
    "                    else:\n",
    "                        dog.gru_cell = torch.rand(self.hidden_size)\n",
    "                except KeyError as e:\n",
    "                    print(f'Key error {e}')\n",
    "                    val = torch.rand(self.hidden_size)\n",
    "                    dog.gru_cell = val\n",
    "                    print(f\"race in = {dog.gru_cell}\")\n",
    "                print(key,val)\n",
    "\n",
    "    def to_cuda(self):\n",
    "        for race in self.racesDict.values():\n",
    "            race_id = race.raceid\n",
    "            for dog in race.dogs:\n",
    "                dog.gru_cell = dog.gru_cell.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.gru1 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru2 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru3 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru4 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru5 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru6 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru7 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru8 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.rl1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size * 8, 64)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.rl2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 8)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, race: Race):\n",
    "        x = torch.stack([r.full_input.float() for r in race])\n",
    "\n",
    "        # creates list of LSTM data\n",
    "        hidden_state_in = [list(i) for i in zip(*[r.lstm_input() for r in race])]\n",
    "\n",
    "        # creates list of tensors for lstm Cells\n",
    "        hCell = [torch.stack([x for x in y]) for y in hidden_state_in]\n",
    "\n",
    "        h1 = self.gru1(x, hCell[0])\n",
    "        h2 = self.gru2(x, hCell[1])\n",
    "        h3 = self.gru3(x, hCell[2])\n",
    "        h4 = self.gru4(x, hCell[3])\n",
    "        h5 = self.gru5(x, hCell[4])\n",
    "        h6 = self.gru6(x, hCell[5])\n",
    "        h7 = self.gru7(x, hCell[6])\n",
    "        h8 = self.gru8(x, hCell[7])\n",
    "\n",
    "        lstm_list = [\n",
    "            h1,\n",
    "            h2,\n",
    "            h3,\n",
    "            h4,\n",
    "            h5,\n",
    "            h6,\n",
    "            h7,\n",
    "            h8,\n",
    "        ]\n",
    "\n",
    "        hCello = [i for i in zip(*[x for x in lstm_list])]\n",
    "        # cCello = [i for i in zip(*[x[1] for x in lstm_list])]\n",
    "\n",
    "        for i, r in enumerate(race):\n",
    "            r.pass_gru_output(hCello[i])\n",
    "            # r.lstm_detach()\n",
    "        xhh = torch.cat((h1, h2, h3, h4, h5, h6, h7, h8), dim=1)\n",
    "        xr1 = self.rl1(xhh)\n",
    "        xd1 = self.drop1(xr1)\n",
    "        xh = self.fc2(xd1)\n",
    "        xd2 = self.drop2(xh)\n",
    "        xr2 = self.rl2(xd2)\n",
    "        xf = self.fc3(xr2)\n",
    "\n",
    "        #output = F.softmax(xf, dim=1)\n",
    "        #output = nn.LogSoftmax(xf)\n",
    "        output = xf\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pred_dataset(data, hidden_size):\n",
    "\n",
    "    #Load in pickeled dataframe\n",
    "    resultsdf = pickle.load(data)\n",
    "    dog_stats_df = pd.DataFrame(resultsdf)\n",
    "    dog_stats_df = dog_stats_df.fillna(-1).drop_duplicates(subset=['dogid', 'raceid'])\n",
    "    dog_stats_df['stats_cuda'] = dog_stats_df.apply(lambda x: torch.tensor(x['stats']), axis =1)\n",
    "    dog_stats_df['box'] = dog_stats_df['stats'].apply(lambda x: x[0])\n",
    "\n",
    "    #Created RaceDB\n",
    "    raceDB = Races(hidden_size, 1)\n",
    "\n",
    "    #Fill in dog portion:\n",
    "\n",
    "    dog_stats_group = dog_stats_df.sort_values(['date']).groupby([\"dogid\"])\n",
    "\n",
    "    for i,j in tqdm(dog_stats_group):\n",
    "        raceDB.add_dog(i, j.dog_name.iloc[0])\n",
    "        j.apply(lambda x: raceDB.dogsDict[i].add_races(x['raceid'], x['date'], torch.Tensor(x['stats']),-1, x['prev_race'], x['box']), axis=1)\n",
    "\n",
    "    #Fill in races portion\n",
    "    softmin = nn.Softmin(dim=0)\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "\n",
    "    null_dog = Dog(\"nullDog\", \"no_name\", raceDB.hidden_size, raceDB.layers)\n",
    "    null_dog_i = DogInput(\"nullDog\", \"-1\", torch.zeros(16), null_dog,0, torch.zeros(raceDB.hidden_size),0,0)\n",
    "    null_dog_i.nextrace(-1)\n",
    "    null_dog_i.prevrace(-1)\n",
    "\n",
    "    null_dog_list = [null_dog] * 8\n",
    "    #TO FIX LATER PROPER BOX PLACEMENT #FIXED\n",
    "\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "    for i,j in tqdm(races_group):\n",
    "    #Track info tensors\n",
    "        dist = torch.tensor([j.dist.iloc[0]]) \n",
    "        trackOHE = torch.tensor(j.trackOHE.iloc[0])\n",
    "\n",
    "        empty_dog_list = [null_dog_i]*8\n",
    "        boxes_list = [x for x in j['box']]      \n",
    "        dog_list = [raceDB.dogsDict[x].races[i] for x in j[\"dogid\"]]\n",
    "\n",
    "        for n,x in enumerate(boxes_list):\n",
    "            empty_dog_list[x-1] = dog_list[n]\n",
    "        \n",
    "        raceDB.add_race(i,trackOHE,dist)\n",
    "        \n",
    "        # List of Dog Input??\n",
    "        raceDB.racesDict[i].add_dogs(empty_dog_list)\n",
    "        raceDB.racesDict[i].nn_input()\n",
    "        raceDB.racesDict[i].add_track_name(j.track_name.iloc[0])\n",
    "        raceDB.racesDict[i].track_name = j.track_name.iloc[0]\n",
    "        raceDB.racesDict[i].grade = j.race_grade.iloc[0]\n",
    "\n",
    "    print(f\"number of races = {len(raceDB.racesDict)}, number of unique dogs = {len(raceDB.dogsDict)}\")\n",
    "    return raceDB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data, hidden_size):\n",
    "\n",
    "    #Load in pickeled dataframe\n",
    "    resultsdf = pickle.load(data)\n",
    "    dog_stats_df = pd.DataFrame(resultsdf)\n",
    "    dog_stats_df = dog_stats_df.fillna(-1).drop_duplicates(subset=['dogid', 'raceid'])\n",
    "    dog_stats_df['stats_cuda'] = dog_stats_df.apply(lambda x: torch.tensor(x['stats']), axis =1)\n",
    "    dog_stats_df['box'] = dog_stats_df['stats'].apply(lambda x: x[0])\n",
    "\n",
    "    #Created RaceDB\n",
    "    raceDB = Races(hidden_size, 1)\n",
    "\n",
    "    #Fill in dog portion:\n",
    "\n",
    "    dog_stats_group = dog_stats_df.sort_values(['date']).groupby([\"dogid\"])\n",
    "\n",
    "    for i,j in tqdm(dog_stats_group):\n",
    "        j[\"next_race\"] = j[\"raceid\"].shift(-1).fillna(-1)\n",
    "        j[\"prev_race\"] = j[\"raceid\"].shift(1).fillna(-1)\n",
    "        raceDB.add_dog(i, j.dog_name.iloc[0])\n",
    "        j.apply(lambda x: raceDB.dogsDict[i].add_races(x['raceid'], x['date'], torch.Tensor(x['stats']),x['next_race'], x['prev_race'], x['box'], x['bfSP'], x['startprice']), axis=1)\n",
    "\n",
    "    #Fill in races portion\n",
    "    softmin = nn.Softmin(dim=0)\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "\n",
    "    null_dog = Dog(\"nullDog\", \"no_name\", raceDB.hidden_size, raceDB.layers)\n",
    "    null_dog_i = DogInput(\"nullDog\", \"-1\", torch.zeros(12), null_dog,0, torch.zeros(raceDB.hidden_size),0,0)\n",
    "    null_dog_i.nextrace(-1)\n",
    "    null_dog_i.prevrace(-1)\n",
    "\n",
    "    null_dog_list = [null_dog] * 8\n",
    "    #TO FIX LATER PROPER BOX PLACEMENT #FIXED\n",
    "\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "    for i,j in tqdm(races_group):\n",
    "    #Track info tensors\n",
    "        dist = torch.tensor([j.dist.iloc[0]]) \n",
    "        trackOHE = torch.tensor(j.trackOHE.iloc[0])\n",
    "        #margins\n",
    "        empty_dog_list = [null_dog_i]*8\n",
    "        empty_margin_list = [20]*8\n",
    "        empty_place_list = [8]*8\n",
    "\n",
    "        places_list = [x for x in j[\"place\"]]\n",
    "        boxes_list = [x for x in j['box']]\n",
    "        margin_list = [x for x in j[\"margin\"]]\n",
    "        \n",
    "        dog_list = [raceDB.dogsDict[x].races[i] for x in j[\"dogid\"]]\n",
    "\n",
    "        #adjustedMargin = [margin_list[x-1] for x in boxes_list]\n",
    "        for n,x in enumerate(boxes_list):\n",
    "            empty_margin_list[x-1] = margin_list[n]\n",
    "            empty_dog_list[x-1] = dog_list[n]\n",
    "            empty_place_list[x-1] = places_list[n]\n",
    "        # adjustedMargin = softmin(torch.tensor(empty_margin_list)).to('cuda:0')\n",
    "        adjustedMargin = softmin(torch.tensor(empty_place_list)).to('cuda:0')\n",
    "        #adjusted_dog_list = [dog_list[x-1] for x in boxes_list]\n",
    "        \n",
    "        raceDB.add_race(i,trackOHE,dist, adjustedMargin)\n",
    "        \n",
    "        \n",
    "        # List of Dog Input??\n",
    "        raceDB.racesDict[i].add_dogs(empty_dog_list)\n",
    "        raceDB.racesDict[i].nn_input()\n",
    "        raceDB.racesDict[i].track_name = j.track_name.iloc[0]\n",
    "        raceDB.racesDict[i].grade = j.race_grade.iloc[0]\n",
    "\n",
    "    print(f\"number of races = {len(raceDB.racesDict)}, number of unique dogs = {len(raceDB.dogsDict)}\")\n",
    "    return raceDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_saver(model, optimizer, epoch, loss, hidden_state_dict):\n",
    "    \n",
    "    pathtofolder = \"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model\"\n",
    "    model_name = wandb.run.name\n",
    "    isExist = os.path.exists(\n",
    "        f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "    )\n",
    "    if isExist:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"db\":hidden_state_dict,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )\n",
    "    else:\n",
    "        print(\"created path\")\n",
    "        os.makedirs(\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "        )\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"db\":hidden_state_dict,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def validate_model(model,raceDB,criterion, batch_size, example_ct, epoch_loss, batch_ct):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    preds = []\n",
    "    grades = []\n",
    "    tracks = []\n",
    "    pred_confs = []\n",
    "    bfsps = []\n",
    "    start_prices = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(20_000,30_000,batch_size):   \n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "            race = raceDB.get_race_input(races_idx)\n",
    "            #tracks.extend([r.track for r in race])\n",
    "            X = race\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            output = model(X)\n",
    "            #print(y)\n",
    "\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            conf, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "            \n",
    "            total += batch_size\n",
    "            actuals.extend(actual.tolist())\n",
    "            preds.extend(predicted.tolist())\n",
    "            pred_confs.extend(conf.tolist())\n",
    "            tracks.extend([r.track_name for r in race])\n",
    "            grades.extend([r.grade for r in race])\n",
    "            for i,dog_idx in enumerate(actual.tolist()):\n",
    "                bfsps.append(race[i].dogs[dog_idx].bfsp)\n",
    "                #start_prices.append(race[i].dogs[dog_idx].sp)\n",
    "\n",
    "            \n",
    "            loss = criterion(output, y)\n",
    "            loss_val += loss\n",
    "\n",
    "    logdf = pd.DataFrame(data = {\"actuals\":actuals, \"preds\":preds,\"conf\":pred_confs, \"grade\":grades, \"track\":tracks, \"bfsps\":bfsps})#, \"sp\":start_prices })\n",
    "\n",
    "    table = wandb.Table(dataframe=logdf)\n",
    "    try:\n",
    "        wandb.log({\"table_key\": table})\n",
    "    except Exception as e:\n",
    "        print(\"e\")\n",
    "    #print(f\"accuray: {correct/total}\")\n",
    "    wandb.log({\"accuracy\": correct/total, \"loss_val\": loss_val/(50_000/batch_size), \"correct\": correct,\"epoch_loss\": epoch_loss/batch_ct}, step=example_ct)\n",
    "\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, raceDB, criterion, optimizer,scheduler, config=None):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    last = 0\n",
    "    batch_size = config.batch_size\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    m = nn.LogSoftmax(dim=1)\n",
    "    for epoch in trange(config.epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        for i in range(batch_size,73590-batch_size,batch_size):\n",
    "            #print(i)\n",
    "            if 20_000-1<i<30_000+1:\n",
    "                continue\n",
    "\n",
    "            batch_ct += 1   \n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "            race = raceDB.get_race_input(races_idx)\n",
    "            X = race\n",
    "            \n",
    "\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            output = model(X)\n",
    "            #print(output,y)\n",
    "            example_ct +=  batch_size\n",
    "            batch_ct += 1\n",
    "\n",
    "            loss = criterion(output, y)\n",
    "            #oss = criterion(m(output), torch.flatten(actual))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)  \n",
    "            #loss.backward()\n",
    "            optimizer.step()\n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                    \n",
    "                    train_log(loss, example_ct, epoch)\n",
    "\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "            output = model(X)\n",
    "\n",
    "            #[r.lstm_detach for r in race]\n",
    "        #wandb.log({\"epoch_loss\": epoch_loss/batch_ct}, step = example_ct)\n",
    "        #print(f'{epoch_loss/batch_ct=}')\n",
    "\n",
    "        #print(loss)\n",
    "        acc = validate_model(model,raceDB,criterion, 8, example_ct, epoch_loss, batch_ct)\n",
    "        scheduler.step(acc)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25734/25734 [02:57<00:00, 145.21it/s]\n",
      "100%|██████████| 73590/73590 [01:15<00:00, 978.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 73590, number of unique dogs = 25734\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( 'dog_stats_df_simple.npy', 'rb')\n",
    "hidden_size = 16\n",
    "raceDB = build_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 782.78it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 1370.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 48, number of unique dogs = 363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( r'C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\forms\\prediction_inputs_gru.npy', 'rb')\n",
    "hidden_size = 16\n",
    "predDB = build_pred_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raceDB.create_hidden_states_dict()\n",
    "# predDB.fill_hidden_states_from_dict(hidden_dict=dataset.hidden_states_dict)\n",
    "# len(raceDB.hidden_states_dict)\n",
    "# predDB.to_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def predict_model(model,predDB):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        races_idx = range(0,len(predDB.raceIDs)-1)\n",
    "        race = predDB.get_race_input(races_idx)\n",
    "        X = race\n",
    "        # for i,r in enumerate(race):\n",
    "        #     print(r.raceid, r.track_name)\n",
    "        #     #print(i,r.lstm_input())\n",
    "\n",
    "        output = model(X)\n",
    "        \n",
    "        print(output)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            print(r.raceid, r.track_name, r.dogs[predicted[i].item()])\n",
    "\n",
    "        print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Race at 0x28da7702970>,\n",
       " <__main__.Race at 0x28da7702b80>,\n",
       " <__main__.Race at 0x28da77026a0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predDB.get_race_input([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_model(model,predDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dogid</th>\n",
       "      <th>dog_name</th>\n",
       "      <th>raceid</th>\n",
       "      <th>race_grade</th>\n",
       "      <th>date</th>\n",
       "      <th>trackOHE</th>\n",
       "      <th>track_name</th>\n",
       "      <th>dist</th>\n",
       "      <th>stats</th>\n",
       "      <th>place</th>\n",
       "      <th>startprice</th>\n",
       "      <th>margin</th>\n",
       "      <th>bfSP</th>\n",
       "      <th>box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115367782</td>\n",
       "      <td>SWIFT GEM</td>\n",
       "      <td>12539914</td>\n",
       "      <td>Maiden Final</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>Traralgon</td>\n",
       "      <td>525.0</td>\n",
       "      <td>[8, 0.05848506493506494, 0.0008907936012381001...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145856635</td>\n",
       "      <td>CELESTIAL JEWEL</td>\n",
       "      <td>12539914</td>\n",
       "      <td>Maiden Final</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>Traralgon</td>\n",
       "      <td>525.0</td>\n",
       "      <td>[2, 0.05945284327323162, 0.0007404203490765129...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.51</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2131520028</td>\n",
       "      <td>KIOMARA</td>\n",
       "      <td>12539914</td>\n",
       "      <td>Maiden Final</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>Traralgon</td>\n",
       "      <td>525.0</td>\n",
       "      <td>[3, 0.05918524613560071, 0.0009662708972431771...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>8.96</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159734832</td>\n",
       "      <td>RAPPA FLASH</td>\n",
       "      <td>12539914</td>\n",
       "      <td>Maiden Final</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>Traralgon</td>\n",
       "      <td>525.0</td>\n",
       "      <td>[7, 0.05796197139049795, 0.0010752646024627035...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167542442</td>\n",
       "      <td>I'M THE POPPET</td>\n",
       "      <td>12539914</td>\n",
       "      <td>Maiden Final</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>Traralgon</td>\n",
       "      <td>525.0</td>\n",
       "      <td>[4, 0.05878095238095238, -1, 0.058780952380952...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538111</th>\n",
       "      <td>612981526</td>\n",
       "      <td>ASTON MEAD</td>\n",
       "      <td>839820812</td>\n",
       "      <td>Grade 7</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>460.0</td>\n",
       "      <td>[8, 0.05788795586564722, 0.000977071454869381,...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538112</th>\n",
       "      <td>578790270</td>\n",
       "      <td>FORGOTTEN BOY</td>\n",
       "      <td>839820812</td>\n",
       "      <td>Grade 7</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>460.0</td>\n",
       "      <td>[2, 0.058005804548986364, 0.000658205284423107...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>10.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538113</th>\n",
       "      <td>653489376</td>\n",
       "      <td>MISS DAISY LEE</td>\n",
       "      <td>839820812</td>\n",
       "      <td>Grade 7</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>460.0</td>\n",
       "      <td>[6, 0.058630664346592615, 0.000897251431724337...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538114</th>\n",
       "      <td>640219891</td>\n",
       "      <td>ENSEMBLE</td>\n",
       "      <td>839820812</td>\n",
       "      <td>Grade 7</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>460.0</td>\n",
       "      <td>[3, 0.058095571658615126, 0.000524703858161521...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538115</th>\n",
       "      <td>653134666</td>\n",
       "      <td>SCARLETT WINGS</td>\n",
       "      <td>839820812</td>\n",
       "      <td>Grade 7</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>460.0</td>\n",
       "      <td>[5, 0.05751395206243033, 0.000671305873384918,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538116 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dogid         dog_name     raceid    race_grade       date  \\\n",
       "0        115367782        SWIFT GEM   12539914  Maiden Final 2018-06-22   \n",
       "1        145856635  CELESTIAL JEWEL   12539914  Maiden Final 2018-06-22   \n",
       "2       2131520028          KIOMARA   12539914  Maiden Final 2018-06-22   \n",
       "3        159734832      RAPPA FLASH   12539914  Maiden Final 2018-06-22   \n",
       "4        167542442   I'M THE POPPET   12539914  Maiden Final 2018-06-22   \n",
       "...            ...              ...        ...           ...        ...   \n",
       "538111   612981526       ASTON MEAD  839820812       Grade 7 2022-11-02   \n",
       "538112   578790270    FORGOTTEN BOY  839820812       Grade 7 2022-11-02   \n",
       "538113   653489376   MISS DAISY LEE  839820812       Grade 7 2022-11-02   \n",
       "538114   640219891         ENSEMBLE  839820812       Grade 7 2022-11-02   \n",
       "538115   653134666   SCARLETT WINGS  839820812       Grade 7 2022-11-02   \n",
       "\n",
       "                                             trackOHE track_name   dist  \\\n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  Traralgon  525.0   \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  Traralgon  525.0   \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  Traralgon  525.0   \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  Traralgon  525.0   \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  Traralgon  525.0   \n",
       "...                                               ...        ...    ...   \n",
       "538111  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    Geelong  460.0   \n",
       "538112  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    Geelong  460.0   \n",
       "538113  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    Geelong  460.0   \n",
       "538114  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    Geelong  460.0   \n",
       "538115  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    Geelong  460.0   \n",
       "\n",
       "                                                    stats  place  startprice  \\\n",
       "0       [8, 0.05848506493506494, 0.0008907936012381001...    1.0        11.0   \n",
       "1       [2, 0.05945284327323162, 0.0007404203490765129...    4.0         4.8   \n",
       "2       [3, 0.05918524613560071, 0.0009662708972431771...    6.0        41.6   \n",
       "3       [7, 0.05796197139049795, 0.0010752646024627035...    5.0         2.8   \n",
       "4       [4, 0.05878095238095238, -1, 0.058780952380952...    3.0         3.3   \n",
       "...                                                   ...    ...         ...   \n",
       "538111  [8, 0.05788795586564722, 0.000977071454869381,...    4.0        11.0   \n",
       "538112  [2, 0.058005804548986364, 0.000658205284423107...    8.0        15.1   \n",
       "538113  [6, 0.058630664346592615, 0.000897251431724337...    1.0        12.5   \n",
       "538114  [3, 0.058095571658615126, 0.000524703858161521...    2.0        37.6   \n",
       "538115  [5, 0.05751395206243033, 0.000671305873384918,...    3.0         3.6   \n",
       "\n",
       "        margin  bfSP  box  \n",
       "0         0.00  12.0    8  \n",
       "1         6.51   5.8    2  \n",
       "2         8.96  50.0    3  \n",
       "3         7.23   3.0    7  \n",
       "4         3.29   NaN    4  \n",
       "...        ...   ...  ...  \n",
       "538111    4.67   NaN    8  \n",
       "538112   10.10   NaN    2  \n",
       "538113    0.00   NaN    6  \n",
       "538114    1.09   NaN    3  \n",
       "538115    3.89   NaN    5  \n",
       "\n",
       "[538116 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\dog_stats_df.npy\", 'rb')\n",
    "resultsdf = pickle.load(dog_stats_file)\n",
    "dog_stats_df = pd.DataFrame(resultsdf)\n",
    "dog_stats_df['box'] = dog_stats_df['stats'].apply(lambda x: x[0])\n",
    "dog_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8289, 0.8543, 0.8846, 0.8804, 0.9043, 0.8930, 0.8867, 0.8679],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = (1-(dog_stats_df[dog_stats_df['place']==1]['box'].value_counts(sort=False)/len(dog_stats_df[dog_stats_df['place']==1]))).tolist()\n",
    "weights = torch.tensor(weights).to(device)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"new LSTM\", config=config):\n",
    "      # access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "\n",
    "      model = GRUNet(112,config.hidden_size)\n",
    "      # criterion = nn.HuberLoss()\n",
    "      # criterion = nn.BCEWithLogitsLoss()\n",
    "      #optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "      #criterion = nn.NLLLoss()\n",
    "      criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "      #criterion = nn.SmoothL1Loss(reduction='mean', beta=0.1)\n",
    "      # optimizer = optim.RMSprop(model.parameters())\n",
    "      # optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "      optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',threshold=0.001, patience=100, verbose=True, factor=0.5)\n",
    "      # optimizer = optim.LBFGS(model.parameters(), lr=0.001)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      train(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      dataset.create_hidden_states_dict()\n",
    "      # if sweep:\n",
    "      #   raceDB.reset_all_lstm_states\n",
    "      \n",
    "\n",
    "\n",
    "      # and test its final performance\n",
    "      #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_race = raceDB.get_race_input([100,101])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73590"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raceDB.raceIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.0005, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'profit'},\n",
      " 'parameters': {'batch_size': {'values': [500, 1000, 5000]},\n",
      "                'dropout': {'values': [0.3]},\n",
      "                'epochs': {'values': [250]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'hidden_size': {'value': 16},\n",
      "                'l1_beta': {'value': 0.1},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.001,\n",
      "                                  'min': 0.00011},\n",
      "                'len_data': {'value': 70000},\n",
      "                'loss': {'values': ['L1']},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adamW'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'metric': {'name': 'profit', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adamW'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3]},\n",
       "  'len_data': {'value': 70000},\n",
       "  'hidden_size': {'value': 16},\n",
       "  'epochs': {'values': [250]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'values': ['L1']},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 0.00011, 'max': 0.001},\n",
       "  'l1_beta': {'value': 0.1},\n",
       "  'batch_size': {'values': [500, 1000, 5000]}}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"profit\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": 70000},\n",
    "    \"hidden_size\": {\"value\":16}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [250]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"L1\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00011,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [500,1000,5000]\n",
    "            # \"values\": [32, 64, 128, 360, 720]\n",
    "            # 'values':[4,8,16,32,64,128,360]\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_config_static['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\GRU - WANDB - priced - simple.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (model,dataset) \u001b[39m=\u001b[39m model_pipeline(raceDB,config\u001b[39m=\u001b[39mwandb_config_static)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "(model,dataset) = model_pipeline(raceDB,config=wandb_config_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pause\n",
    "dataset.create_hidden_states_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDB.fill_hidden_states_from_dict(hidden_dict=dataset.hidden_states_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"LSTM_sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43115443075634c02a7c247a87b0dd9d74842892e56d473b9e19f544f3149aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
