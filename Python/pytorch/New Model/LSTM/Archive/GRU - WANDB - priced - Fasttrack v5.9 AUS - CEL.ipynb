{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "from rnn_classes import Dog, DogInput, Race, Races, GRUNet, smallGRUNet, smalll_lin_GRUNet\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n",
    "from training_testing import validate_model, train_regular, train_log, train_super_batch, train_super_batch_KL, train_super_batch_L1, train_regular_L1,train_regular_one_hot\n",
    "from model_saver import model_saver, model_saver_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_to_bf(model:GRUNet,raceDB:Races,example_ct):\n",
    "    with torch.no_grad():\n",
    "        sft_max = nn.Softmax(dim=-1)\n",
    "        l_sftmax = nn.LogSoftmax(dim=-1)\n",
    "        nnl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        full_test_races = raceDB.get_test_input(range(0,len(raceDB.test_race_ids)))\n",
    "        full_test_races_w_prices = []\n",
    "        excluded, included = 0,0\n",
    "        for r in full_test_races:\n",
    "            if 0 in r.prices or -1 in r.prices:\n",
    "                excluded+=1\n",
    "            else:\n",
    "                full_test_races_w_prices.append(r)\n",
    "                included+=1\n",
    "        print(included,excluded)\n",
    "\n",
    "        output = l_sftmax(model(full_test_races_w_prices))\n",
    "        bf_prices = torch.log(torch.tensor([x.implied_prob for x in full_test_races_w_prices ]).to('cuda:0'))\n",
    "        full_classes = torch.stack([x.classes for x in full_test_races_w_prices ])\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(f\"our loss = {nnl_loss(output,full_classes)}\")\n",
    "        print(f\"their loss = {nnl_loss(bf_prices ,full_classes)}\")\n",
    "        wandb.log({\"our loss\":nnl_loss(output,full_classes), \"their loss\":nnl_loss(bf_prices ,full_classes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159571, 17)\n",
      "(1159571, 17)\n",
      "(286515, 20)\n",
      "Latest date = 2023-02-25 00:00:00\n",
      "num_features_per_dog=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14572 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 14572/14572 [01:32<00:00, 157.20it/s]\n",
      "  0%|          | 0/40206 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 40206/40206 [01:15<00:00, 532.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 40206, number of unique dogs = 14572\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "#dog_stats_file = open( 'new gru input 2023-01.npy', 'rb')\n",
    "hidden_size = 64\n",
    "raceDB = build_dataset('new_windows_gru_REAL.npy', hidden_size ,state_filter=\"NSW\", margin_type='boosted_sftmin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           (Dubbo, 400.0)\n",
      "1           (Dubbo, 318.0)\n",
      "2           (Dubbo, 318.0)\n",
      "3         (Grafton, 305.0)\n",
      "4         (Grafton, 305.0)\n",
      "               ...        \n",
      "40201    (Richmond, 520.0)\n",
      "40202    (Richmond, 520.0)\n",
      "40203    (Richmond, 520.0)\n",
      "40204    (Richmond, 401.0)\n",
      "40205    (Richmond, 320.0)\n",
      "Length: 40206, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40206/40206 [00:00<00:00, 423114.74it/s]\n"
     ]
    }
   ],
   "source": [
    "raceDB.create_new_weights_v2()\n",
    "raceDB.adjust_weights({\"Dapto\":10, \"Gunnedah\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 32452, Test examples 7754\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def predict_model(model,predDB):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        races_idx = range(0,len(predDB.raceIDs)-1)\n",
    "        race = predDB.get_race_input(races_idx)\n",
    "        X = race\n",
    "        # for i,r in enumerate(race):\n",
    "        #     print(r.raceid, r.track_name)\n",
    "        #     #print(i,r.lstm_input())\n",
    "\n",
    "        output = model(X)\n",
    "        \n",
    "        print(output)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            print(r.raceid, r.track_name, r.dogs[predicted[i].item()])\n",
    "\n",
    "        print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None, prev_model_file=None):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"GRU - FastTrack - AUS Testing\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      wandb.define_metric(\"multibet profit\", summary=\"max\")\n",
    "      \n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "      input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0] #create fix so messy\n",
    "\n",
    "      model = smallGRUNet(input_size,config['hidden_size'])\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      if prev_model_file!=None:\n",
    "        model_name = prev_model_file\n",
    "        model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_450.pt\"\n",
    "        model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "        raceDB.fill_hidden_states_from_dict(hidden_dict=model_data['db'])\n",
    "        model.load_state_dict(model_data['model_state_dict'])\n",
    "        config['parent model'] = prev_model_file\n",
    "\n",
    "\n",
    "      raceDB.to_cuda()\n",
    "\n",
    "      criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "      #criterion = nn.SmoothL1Loss(reduction='none', beta=0.1)\n",
    "      # optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.Adadelta(model.parameters())\n",
    "      optimizer = optim.RMSprop(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
    "\n",
    "      print(criterion, optimizer)\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',threshold=0.0001, patience=10000, verbose=True, factor=0.5)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        train_regular(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      except KeyboardInterrupt:\n",
    "        print(\"finished Early\")\n",
    "      dataset.create_hidden_states_dict()\n",
    "      model_saver_wandb(model, optimizer, 450, 0.1, dataset.hidden_states_dict_gru, model_name=\"long nsw new  22000 RUN\")\n",
    "      if sweep:\n",
    "        raceDB.reset_all_lstm_states\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 200, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.000087, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1,'batch_before_backwards':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230226_211151-2qfqhxgn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/2qfqhxgn\" target=\"_blank\">twilight-capybara-225</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'batch_size': 200, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 8.7e-05, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 10}\n",
      "200\n",
      "{'hidden_size': 64, 'batch_size': 200, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 8.7e-05, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 10}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 8.7e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smallGRUNet(\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (fc1): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (fc5): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (fc6): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (fc7): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (fc8): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:27<00:00,  5.88it/s]\n",
      "100%|██████████| 162/162 [00:56<00:00,  2.86it/s]]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.72it/s]]\n",
      "100%|██████████| 162/162 [00:48<00:00,  3.36it/s]]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.69it/s]]\n",
      "100%|██████████| 162/162 [00:56<00:00,  2.85it/s]]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.67it/s]]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.63it/s]]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.59it/s]]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.72it/s]]\n",
      "100%|██████████| 162/162 [00:54<00:00,  2.99it/s]t]\n",
      "100%|██████████| 162/162 [00:58<00:00,  2.78it/s]t]\n",
      "100%|██████████| 162/162 [00:57<00:00,  2.82it/s]t]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.72it/s]t]\n",
      "100%|██████████| 162/162 [00:56<00:00,  2.85it/s]t]\n",
      "100%|██████████| 162/162 [00:56<00:00,  2.87it/s]t]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.70it/s]t]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.64it/s]t]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.50it/s]t]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.71it/s]t]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.66it/s]t]\n",
      "100%|██████████| 162/162 [00:54<00:00,  2.99it/s]t]\n",
      "100%|██████████| 162/162 [00:54<00:00,  2.95it/s]t]\n",
      "100%|██████████| 162/162 [00:52<00:00,  3.07it/s]t]\n",
      "100%|██████████| 162/162 [00:50<00:00,  3.22it/s]t]\n",
      "100%|██████████| 162/162 [00:54<00:00,  2.95it/s]t]\n",
      "100%|██████████| 162/162 [00:56<00:00,  2.86it/s]t]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.69it/s]t]\n",
      "100%|██████████| 162/162 [01:13<00:00,  2.21it/s]t]\n",
      "100%|██████████| 162/162 [01:10<00:00,  2.30it/s]/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.47it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.74it/s]/it]\n",
      "100%|██████████| 162/162 [00:57<00:00,  2.82it/s]/it]\n",
      "100%|██████████| 162/162 [00:57<00:00,  2.80it/s]/it]\n",
      "100%|██████████| 162/162 [00:56<00:00,  2.85it/s]/it]\n",
      "100%|██████████| 162/162 [00:54<00:00,  2.96it/s]/it]\n",
      "100%|██████████| 162/162 [00:56<00:00,  2.88it/s]/it]\n",
      "100%|██████████| 162/162 [00:55<00:00,  2.94it/s]/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.64it/s]/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.55it/s]/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.45it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.71it/s]/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.35it/s]/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.43it/s]/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.45it/s]/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.37it/s]/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.64it/s]/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.60it/s]/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.67it/s]/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.40it/s]/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.68it/s]/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.57it/s]/it]\n",
      "100%|██████████| 162/162 [01:13<00:00,  2.22it/s]/it]\n",
      "100%|██████████| 162/162 [01:10<00:00,  2.31it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.70it/s]/it]\n",
      "100%|██████████| 162/162 [01:14<00:00,  2.17it/s]/it]\n",
      "100%|██████████| 162/162 [01:15<00:00,  2.15it/s]/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.64it/s]/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.44it/s]/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.57it/s]/it]\n",
      "100%|██████████| 162/162 [01:09<00:00,  2.34it/s]/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.64it/s]/it]\n",
      "100%|██████████| 162/162 [01:11<00:00,  2.26it/s]/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.50it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.74it/s]/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.45it/s]/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.44it/s]/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.49it/s]/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.64it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.73it/s]/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.36it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.74it/s]/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.51it/s]/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.49it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.75it/s]/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.65it/s]/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.52it/s]/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.54it/s]/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.50it/s]/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.63it/s]/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.45it/s]/it]\n",
      "100%|██████████| 162/162 [00:58<00:00,  2.76it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.72it/s]/it]\n",
      "100%|██████████| 162/162 [01:13<00:00,  2.19it/s]/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.52it/s]/it]\n",
      "100%|██████████| 162/162 [00:58<00:00,  2.76it/s]/it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.24it/s]/it]\n",
      "100%|██████████| 162/162 [01:20<00:00,  2.01it/s]/it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.22it/s]/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.51it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.72it/s]/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.45it/s]/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.39it/s]/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.54it/s]/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.69it/s]/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.46it/s]/it]\n",
      "100%|██████████| 162/162 [01:10<00:00,  2.31it/s]/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.53it/s]/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.69it/s]/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.72it/s]/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.47it/s]s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.57it/s]s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.74it/s]s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.59it/s]s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.51it/s]s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.53it/s]s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.70it/s]s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.70it/s]s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.68it/s]s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.57it/s]s/it]\n",
      "100%|██████████| 162/162 [01:12<00:00,  2.24it/s]s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.61it/s]s/it]\n",
      "100%|██████████| 162/162 [01:10<00:00,  2.30it/s]s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.54it/s]s/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.43it/s]s/it]\n",
      "100%|██████████| 162/162 [00:57<00:00,  2.82it/s]s/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.64it/s]s/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.63it/s]s/it]\n",
      "100%|██████████| 162/162 [01:09<00:00,  2.34it/s]s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.55it/s]s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.68it/s]s/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.43it/s]s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.49it/s]s/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.37it/s]s/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.46it/s]s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.50it/s]s/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.35it/s]s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.59it/s]s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.57it/s]s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.74it/s]s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.57it/s]s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.59it/s]s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.51it/s]s/it]\n",
      "100%|██████████| 162/162 [01:09<00:00,  2.32it/s]s/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.65it/s]s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.59it/s]s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.68it/s]s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.71it/s]s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.39it/s]s/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.48it/s]s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.73it/s]s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.71it/s]s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.66it/s]s/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.64it/s]s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.52it/s]s/it]\n",
      "100%|██████████| 162/162 [01:15<00:00,  2.16it/s]s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.50it/s]s/it]\n",
      "100%|██████████| 162/162 [01:09<00:00,  2.34it/s]s/it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.60it/s]s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.69it/s]s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.69it/s]s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.50it/s]s/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.45it/s]s/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.37it/s]s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.40it/s]s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.70it/s]s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.70it/s]s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.40it/s]s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.41it/s]s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.53it/s]s/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.36it/s]s/it]\n",
      "100%|██████████| 162/162 [00:59<00:00,  2.72it/s]s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.66it/s]s/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.49it/s]s/it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.44it/s]s/it]\n",
      "100%|██████████| 162/162 [01:00<00:00,  2.66it/s]s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.55it/s]s/it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.50it/s]s/it]\n",
      "100%|██████████| 162/162 [01:09<00:00,  2.33it/s]s/it]\n",
      "100%|██████████| 162/162 [01:13<00:00,  2.22it/s]s/it]\n",
      "100%|██████████| 162/162 [01:18<00:00,  2.06it/s]s/it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.49it/s]s/it]\n",
      "100%|██████████| 162/162 [01:07<00:00,  2.40it/s]s/it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.63it/s]s/it]\n",
      "100%|██████████| 162/162 [01:03<00:00,  2.56it/s]s/it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.37it/s]it]  \n",
      "100%|██████████| 162/162 [01:04<00:00,  2.53it/s]it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.63it/s]it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.50it/s]it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.44it/s]it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.46it/s]it]\n",
      "100%|██████████| 162/162 [01:14<00:00,  2.18it/s]it]\n",
      "100%|██████████| 162/162 [01:10<00:00,  2.31it/s]it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.59it/s]it]\n",
      "100%|██████████| 162/162 [01:09<00:00,  2.34it/s]it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.37it/s]it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.35it/s]it]\n",
      "100%|██████████| 162/162 [01:05<00:00,  2.48it/s]it]\n",
      "100%|██████████| 162/162 [01:01<00:00,  2.65it/s]it]\n",
      "100%|██████████| 162/162 [00:58<00:00,  2.79it/s]it]\n",
      "100%|██████████| 162/162 [01:04<00:00,  2.50it/s]it]\n",
      "100%|██████████| 162/162 [01:19<00:00,  2.04it/s]it]\n",
      "100%|██████████| 162/162 [01:08<00:00,  2.37it/s]it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.44it/s]it]\n",
      "100%|██████████| 162/162 [01:10<00:00,  2.28it/s]it]\n",
      "100%|██████████| 162/162 [01:14<00:00,  2.16it/s]it]\n",
      "100%|██████████| 162/162 [01:16<00:00,  2.13it/s]it]\n",
      "100%|██████████| 162/162 [01:06<00:00,  2.42it/s]it]\n",
      "100%|██████████| 162/162 [01:02<00:00,  2.60it/s]it]\n",
      "100%|██████████| 162/162 [00:58<00:00,  2.75it/s]it]\n",
      "100%|██████████| 200/200 [7:36:33<00:00, 136.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdb94f32d1d43cb86dc2425a388319d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='703.173 MB of 703.173 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█████████</td></tr><tr><td>FK ROI < 30</td><td>▁▄▃▄▆▅▅▅▇▇███▇▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▆▆▆▆▅▄▄▃▂▃▃</td></tr><tr><td>ROI</td><td>▁▂▃▃▄▄▄▄▄▅▅▅▅▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>ROI < 30</td><td>▁▄▄▄▅▅▅▆▇▇▇▇▇▆▆▇▇▇▇████▇█▇▇▇▆▇▇█▇▆▆▅▅▅▆▆</td></tr><tr><td>accuracy</td><td>▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▆█▇▆▂▇▇▅▆▆▆▆▆▇▆▆▆▆▇▅▇▆▅▁▆▆▅▆▅▅▅▅▆▅▅▅▅▅</td></tr><tr><td>correct</td><td>▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▃▅▇█████▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▃▃▄▄▄▄▄▄▅▅▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>multibet profit < 30</td><td>▁▃▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇█▇▇▆▆▆▅▇▆</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>multibet profit sd</td><td>▁▃▂▂▃▃▃▃▃▃▃▃▂▃▃▃▄▄▅▅▅▅▆▆▆▇▇▇▆▇▆▇▇███████</td></tr><tr><td>profit</td><td>▁▃▃▃▄▅▆█▇█▇▆▅▄▃▃▄▄▃▄▄▄▃▆▃▅▆▆▃▄▃████▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.03162</td></tr><tr><td>FK ROI < 30</td><td>0.03167</td></tr><tr><td>ROI</td><td>-0.03072</td></tr><tr><td>ROI < 30</td><td>0.04913</td></tr><tr><td>accuracy</td><td>0.21987</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>11.76333</td></tr><tr><td>correct</td><td>1704</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>epoch_loss</td><td>11.76333</td></tr><tr><td>loss_val</td><td>1.97272</td></tr><tr><td>multibet outlay</td><td>244531.53359</td></tr><tr><td>multibet outlay < 30</td><td>143197.25813</td></tr><tr><td>multibet profit < 30</td><td>7034.80868</td></tr><tr><td>multibet profit < 30 sd</td><td>26.25114</td></tr><tr><td>multibet profit sd</td><td>64.00353</td></tr><tr><td>profit</td><td>5495.58644</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">twilight-capybara-225</strong>: <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/2qfqhxgn\" target=\"_blank\">https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/2qfqhxgn</a><br/>Synced 5 W&B file(s), 300 media file(s), 300 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230226_211151-2qfqhxgn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes',\n",
      " 'metric': {'goal': 'maximize', 'name': 'ROI < 30'},\n",
      " 'parameters': {'batch_before_backwards': {'values': [5, 10, 20]},\n",
      "                'batch_size': {'values': [100, 250, 500]},\n",
      "                'dropout': {'values': [0.3]},\n",
      "                'epochs': {'values': [50]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'hidden_size': {'value': 64},\n",
      "                'l1_beta': {'value': 0.1},\n",
      "                'len_data': {'value': 40206},\n",
      "                'loss': {'values': ['CEL']},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adamW'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'bayes',\n",
       " 'metric': {'name': 'ROI < 30', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adamW'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3]},\n",
       "  'len_data': {'value': 40206},\n",
       "  'hidden_size': {'value': 64},\n",
       "  'epochs': {'values': [50]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'values': ['CEL']},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'l1_beta': {'value': 0.1},\n",
       "  'batch_size': {'values': [100, 250, 500]},\n",
       "  'batch_before_backwards': {'values': [5, 10, 20]}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"bayes\"}\n",
    "\n",
    "metric = {\"name\": \"ROI < 30\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": len(raceDB.raceIDs)},\n",
    "    \"hidden_size\": {\"value\":64}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [50]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"CEL\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        # \"learning_rate\":{\n",
    "        #     # a flat distribution between 0 and 0.1\n",
    "        #     \"distribution\": \"uniform\",\n",
    "        #     \"min\": 0.00001,\n",
    "        #     \"max\": 0.001,\n",
    "        # },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [100,250,500]\n",
    "        },\n",
    "        \"batch_before_backwards\": {\n",
    "            'values': [5,10,20]\n",
    "        },\n",
    "\n",
    "        # \"batch_before_backwards\": {\n",
    "        #     # a flat distribution between 0 and 0.1\n",
    "        #     \"distribution\": \"uniform\",\n",
    "        #     \"min\": 3,\n",
    "        #     \"max\": 50,\n",
    "        # },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep_config, project=\"GRU_sweeps\")\n",
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "# wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48ca33c5a1168302a4f8eae355aad1c03b1396f568d40bc174a6e6aabe725d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
