{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "from rnn_classes import Dog, DogInput, Race, Races, GRUNet, smallGRUNet, smalll_lin_GRUNet, smalll_prelin_GRUNet\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n",
    "from training_testing import validate_model, train_regular, train_log, train_super_batch, train_super_batch_KL, train_super_batch_L1, train_regular_L1,train_regular_one_hot, train_double_loss_regular\n",
    "from model_saver import model_saver, model_saver_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_l2(output, target):\n",
    "    loss = torch.mean(abs(output-target), dim=1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_to_bf(model:GRUNet,raceDB:Races,example_ct):\n",
    "    with torch.no_grad():\n",
    "        sft_max = nn.Softmax(dim=-1)\n",
    "        l_sftmax = nn.LogSoftmax(dim=-1)\n",
    "        nnl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        full_test_races = raceDB.get_test_input(range(0,len(raceDB.test_race_ids)))\n",
    "        full_test_races_w_prices = []\n",
    "        excluded, included = 0,0\n",
    "        for r in full_test_races:\n",
    "            if 0 in r.prices or -1 in r.prices:\n",
    "                excluded+=1\n",
    "            else:\n",
    "                full_test_races_w_prices.append(r)\n",
    "                included+=1\n",
    "        print(included,excluded)\n",
    "\n",
    "        output = l_sftmax(model(full_test_races_w_prices))\n",
    "        bf_prices = torch.log(torch.tensor([x.implied_prob for x in full_test_races_w_prices ]).to('cuda:0'))\n",
    "        full_classes = torch.stack([x.classes for x in full_test_races_w_prices ])\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(f\"our loss = {nnl_loss(output,full_classes)}\")\n",
    "        print(f\"their loss = {nnl_loss(bf_prices ,full_classes)}\")\n",
    "        wandb.log({\"our loss\":nnl_loss(output,full_classes), \"their loss\":nnl_loss(bf_prices ,full_classes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168053, 19)\n",
      "(1168053, 19)\n",
      "(799329, 22)\n",
      "Latest date = 2023-03-06 00:00:00\n",
      "num_features_per_dog=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31481 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 31481/31481 [04:03<00:00, 129.06it/s]\n",
      "  0%|          | 0/111168 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 111168/111168 [03:49<00:00, 483.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 111168, number of unique dogs = 31481\n",
      "0         (Healesville, 350.0)\n",
      "1             (Horsham, 410.0)\n",
      "2               (Dubbo, 400.0)\n",
      "3               (Dubbo, 318.0)\n",
      "4               (Dubbo, 318.0)\n",
      "                  ...         \n",
      "111163       (Ballarat, 390.0)\n",
      "111164       (Ballarat, 390.0)\n",
      "111165       (Ballarat, 450.0)\n",
      "111166       (Ballarat, 450.0)\n",
      "111167       (Ballarat, 545.0)\n",
      "Length: 111168, dtype: object\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "#dog_stats_file = open( 'new gru input 2023-01.npy', 'rb')\n",
    "hidden_size = 64\n",
    "raceDB = build_dataset('new_windows_gru_REAL_new.npy', hidden_size ,state_filter=[\"NSW\",\"QLD\", \"VIC\"], margin_type='boosted_sftmin')\n",
    "raceDB.create_new_weights_v2()\n",
    "#raceDB.adjust_weights({\"Dapto\":10, \"Gunnedah\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 89794, Test examples 21374\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def predict_model(model,predDB):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        races_idx = range(0,len(predDB.raceIDs)-1)\n",
    "        race = predDB.get_race_input(races_idx)\n",
    "        X = race\n",
    "        # for i,r in enumerate(race):\n",
    "        #     print(r.raceid, r.track_name)\n",
    "        #     #print(i,r.lstm_input())\n",
    "\n",
    "        output = model(X)\n",
    "        \n",
    "        print(output)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            print(r.raceid, r.track_name, r.dogs[predicted[i].item()])\n",
    "\n",
    "        print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None, prev_model_file=None):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"GRU - FastTrack - AUS Testing\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      wandb.define_metric(\"multibet profit\", summary=\"max\")\n",
    "      \n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "      input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0] #create fix so messy\n",
    "\n",
    "      model = smalll_prelin_GRUNet(input_size,config['hidden_size'])\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      if prev_model_file!=None:\n",
    "        model_name = prev_model_file\n",
    "        model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_450.pt\"\n",
    "        model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "        raceDB.fill_hidden_states_from_dict(hidden_dict=model_data['db'])\n",
    "        model.load_state_dict(model_data['model_state_dict'])\n",
    "        config['parent model'] = prev_model_file\n",
    "\n",
    "      raceDB.to_cuda()\n",
    "\n",
    "      criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "      #criterion = nn.SmoothL1Loss(reduction='none', beta=0.1)\n",
    "      optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.Adadelta(model.parameters())\n",
    "      # optimizer = optim.RMSprop(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.ASGD(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',threshold=0.0001, patience=10000, verbose=True, factor=0.5)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        # train_double_loss_regular(model, dataset, criterion, optimizer, scheduler, config, crit2=custom_l2)\n",
    "        train_regular(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      except KeyboardInterrupt:\n",
    "        print(\"finished Early\")\n",
    "      dataset.create_hidden_states_dict()\n",
    "      model_saver_wandb(model, optimizer, 450, 0.1, dataset.hidden_states_dict_gru, model_name=\"long nsw new  22000 RUN\")\n",
    "      if sweep:\n",
    "        raceDB.reset_all_lstm_states()\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.000087, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1,'batch_before_backwards':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.reset_all_lstm_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_111857-fv7tkten</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/fv7tkten\" target=\"_blank\">crisp-forest-285</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 8.7e-05, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 7}\n",
      "1000\n",
      "{'hidden_size': 64, 'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 8.7e-05, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 7}\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [02:04<00:00,  1.44it/s]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]/it]\n",
      "100%|██████████| 179/179 [02:49<00:00,  1.06it/s]/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]/it]\n",
      "100%|██████████| 179/179 [02:46<00:00,  1.07it/s]/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.05it/s]/it]\n",
      "100%|██████████| 179/179 [02:49<00:00,  1.06it/s]/it]\n",
      "100%|██████████| 179/179 [02:47<00:00,  1.07it/s]/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s]09s/it]\n",
      "100%|██████████| 179/179 [02:50<00:00,  1.05it/s]83s/it]\n",
      "100%|██████████| 179/179 [02:56<00:00,  1.01it/s]74s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]30s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]80s/it]\n",
      "100%|██████████| 179/179 [02:55<00:00,  1.02it/s]38s/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s]75s/it]\n",
      "100%|██████████| 179/179 [02:58<00:00,  1.00it/s]28s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]18s/it]\n",
      "100%|██████████| 179/179 [02:59<00:00,  1.00s/it]65s/it]\n",
      "100%|██████████| 179/179 [02:50<00:00,  1.05it/s]72s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]98s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.05it/s]21s/it]\n",
      "100%|██████████| 179/179 [03:00<00:00,  1.01s/it]93s/it]\n",
      "100%|██████████| 179/179 [03:03<00:00,  1.02s/it]51s/it]\n",
      "100%|██████████| 179/179 [02:55<00:00,  1.02it/s]85s/it]\n",
      "100%|██████████| 179/179 [03:02<00:00,  1.02s/it]74s/it]\n",
      "100%|██████████| 179/179 [02:54<00:00,  1.03it/s]71s/it]\n",
      "100%|██████████| 179/179 [02:58<00:00,  1.00it/s]49s/it]\n",
      "100%|██████████| 179/179 [02:49<00:00,  1.05it/s]28s/it]\n",
      "100%|██████████| 179/179 [02:49<00:00,  1.05it/s]88s/it]\n",
      "100%|██████████| 179/179 [02:48<00:00,  1.06it/s]51s/it]\n",
      "100%|██████████| 179/179 [02:48<00:00,  1.06it/s]07s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]47s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]61s/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s]27s/it]\n",
      "100%|██████████| 179/179 [02:49<00:00,  1.05it/s]27s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.05it/s]03s/it]\n",
      "100%|██████████| 179/179 [02:50<00:00,  1.05it/s]69s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]2s/it] \n",
      "100%|██████████| 179/179 [02:51<00:00,  1.05it/s]23s/it]\n",
      "100%|██████████| 179/179 [03:04<00:00,  1.03s/it]01s/it]\n",
      "100%|██████████| 179/179 [03:00<00:00,  1.01s/it]16s/it]\n",
      "100%|██████████| 179/179 [02:58<00:00,  1.00it/s]10s/it]\n",
      "100%|██████████| 179/179 [02:56<00:00,  1.02it/s]98s/it]\n",
      "100%|██████████| 179/179 [02:59<00:00,  1.00s/it]87s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]54s/it]\n",
      "100%|██████████| 179/179 [02:56<00:00,  1.01it/s]07s/it]\n",
      "100%|██████████| 179/179 [02:52<00:00,  1.04it/s]25s/it]\n",
      "100%|██████████| 179/179 [02:59<00:00,  1.00s/it]61s/it]\n",
      "100%|██████████| 179/179 [02:54<00:00,  1.02it/s]94s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]07s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]73s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]06s/it]\n",
      "100%|██████████| 179/179 [02:55<00:00,  1.02it/s]97s/it]\n",
      "100%|██████████| 179/179 [02:58<00:00,  1.00it/s]95s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.05it/s]41s/it]\n",
      "100%|██████████| 179/179 [02:52<00:00,  1.04it/s]58s/it]\n",
      "100%|██████████| 179/179 [02:58<00:00,  1.00it/s]2s/it] \n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s]1s/it]\n",
      "100%|██████████| 179/179 [02:54<00:00,  1.03it/s]9s/it]\n",
      "100%|██████████| 179/179 [02:47<00:00,  1.07it/s]07s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]08s/it]\n",
      "100%|██████████| 179/179 [02:50<00:00,  1.05it/s]29s/it]\n",
      "100%|██████████| 179/179 [02:50<00:00,  1.05it/s]3s/it] \n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]2s/it]\n",
      "100%|██████████| 179/179 [02:52<00:00,  1.04it/s]4s/it]\n",
      "100%|██████████| 179/179 [02:48<00:00,  1.06it/s]8s/it]\n",
      "100%|██████████| 179/179 [02:44<00:00,  1.09it/s]6s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]9s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]7s/it]\n",
      "100%|██████████| 179/179 [02:46<00:00,  1.08it/s]94s/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s]3s/it] \n",
      "100%|██████████| 179/179 [02:50<00:00,  1.05it/s]9s/it]\n",
      "100%|██████████| 179/179 [02:46<00:00,  1.08it/s]8s/it]\n",
      "100%|██████████| 179/179 [02:46<00:00,  1.07it/s]6s/it]\n",
      "100%|██████████| 179/179 [02:43<00:00,  1.10it/s]8s/it]\n",
      "100%|██████████| 179/179 [03:01<00:00,  1.01s/it]6s/it]\n",
      "100%|██████████| 179/179 [02:55<00:00,  1.02it/s]9s/it]\n",
      "100%|██████████| 179/179 [02:55<00:00,  1.02it/s]5s/it]\n",
      "100%|██████████| 179/179 [03:02<00:00,  1.02s/it]1s/it]\n",
      "100%|██████████| 179/179 [02:52<00:00,  1.04it/s]34s/it]\n",
      "100%|██████████| 179/179 [02:55<00:00,  1.02it/s]92s/it]\n",
      "100%|██████████| 179/179 [02:55<00:00,  1.02it/s]87s/it]\n",
      "100%|██████████| 179/179 [02:52<00:00,  1.04it/s]3s/it] \n",
      "100%|██████████| 179/179 [02:59<00:00,  1.00s/it]3s/it]\n",
      "100%|██████████| 179/179 [02:58<00:00,  1.00it/s]9s/it]\n",
      "100%|██████████| 179/179 [02:55<00:00,  1.02it/s]0s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.05it/s]6s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.05it/s]4s/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s]3s/it]\n",
      "100%|██████████| 179/179 [03:00<00:00,  1.01s/it]15s/it]\n",
      "100%|██████████| 179/179 [03:07<00:00,  1.05s/it]45s/it]\n",
      "100%|██████████| 179/179 [02:47<00:00,  1.07it/s]0s/it] \n",
      "100%|██████████| 179/179 [03:00<00:00,  1.01s/it]91s/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s]60s/it]\n",
      "100%|██████████| 179/179 [02:44<00:00,  1.09it/s]63s/it]\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]73s/it]\n",
      "100%|██████████| 179/179 [03:33<00:00,  1.19s/it]01s/it]\n",
      "100%|██████████| 179/179 [03:15<00:00,  1.09s/it]17s/it]\n",
      "100%|██████████| 179/179 [02:54<00:00,  1.02it/s].49s/it]\n",
      "100%|██████████| 179/179 [02:49<00:00,  1.06it/s]9.00s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]3.67s/it]\n",
      "100%|██████████| 179/179 [02:50<00:00,  1.05it/s].79s/it] \n",
      "100%|██████████| 179/179 [02:45<00:00,  1.08it/s].94s/it]\n",
      "100%|██████████| 179/179 [02:47<00:00,  1.07it/s].03s/it]\n",
      "100%|██████████| 179/179 [02:48<00:00,  1.06it/s].61s/it]\n",
      "100%|██████████| 179/179 [02:52<00:00,  1.04it/s].19s/it]\n",
      "100%|██████████| 179/179 [03:02<00:00,  1.02s/it].78s/it]\n",
      "100%|██████████| 179/179 [02:55<00:00,  1.02it/s].96s/it]\n",
      "100%|██████████| 179/179 [04:07<00:00,  1.38s/it].26s/it]\n",
      "100%|██████████| 179/179 [04:05<00:00,  1.37s/it]1.03s/it]\n",
      "100%|██████████| 179/179 [06:05<00:00,  2.04s/it]3.84s/it]\n",
      "100%|██████████| 179/179 [04:36<00:00,  1.55s/it]0.53s/it]\n",
      "100%|██████████| 179/179 [04:27<00:00,  1.50s/it]9.96s/it]\n",
      "100%|██████████| 179/179 [10:13<00:00,  3.43s/it]7.74s/it]\n",
      "100%|██████████| 179/179 [07:56<00:00,  2.66s/it]9.75s/it]\n",
      "100%|██████████| 179/179 [08:07<00:00,  2.72s/it]0.07s/it]\n",
      "100%|██████████| 179/179 [05:29<00:00,  1.84s/it]7.52s/it]\n",
      "100%|██████████| 179/179 [06:06<00:00,  2.05s/it]2.20s/it]\n",
      "100%|██████████| 179/179 [06:22<00:00,  2.14s/it]9.07s/it]\n",
      "100%|██████████| 179/179 [08:16<00:00,  2.78s/it]5.63s/it]\n",
      "100%|██████████| 179/179 [06:09<00:00,  2.06s/it]4.66s/it]\n",
      "100%|██████████| 179/179 [07:51<00:00,  2.63s/it]9.80s/it]\n",
      "100%|██████████| 179/179 [04:11<00:00,  1.41s/it]3.40s/it]\n",
      "100%|██████████| 179/179 [08:17<00:00,  2.78s/it]6.45s/it]\n",
      "100%|██████████| 179/179 [06:12<00:00,  2.08s/it]0.13s/it]\n",
      "100%|██████████| 179/179 [04:08<00:00,  1.39s/it]7.35s/it]\n",
      "100%|██████████| 179/179 [03:38<00:00,  1.22s/it]9.62s/it]\n",
      "100%|██████████| 179/179 [04:55<00:00,  1.65s/it]7.09s/it]\n",
      "100%|██████████| 179/179 [02:57<00:00,  1.01it/s]0.52s/it]\n",
      "100%|██████████| 179/179 [05:12<00:00,  1.75s/it]5.63s/it]\n",
      "100%|██████████| 179/179 [04:31<00:00,  1.52s/it]1.03s/it]\n",
      "100%|██████████| 179/179 [05:43<00:00,  1.92s/it]2.35s/it]\n",
      "100%|██████████| 179/179 [06:41<00:00,  2.24s/it]8.09s/it]\n",
      "100%|██████████| 179/179 [05:04<00:00,  1.70s/it]6.66s/it]\n",
      "100%|██████████| 179/179 [09:46<00:00,  3.28s/it]7.27s/it]\n",
      "100%|██████████| 179/179 [08:50<00:00,  2.96s/it]6.50s/it]\n",
      "100%|██████████| 179/179 [07:49<00:00,  2.62s/it]4.76s/it]\n",
      "100%|██████████| 179/179 [08:33<00:00,  2.87s/it]3.71s/it]\n",
      "100%|██████████| 179/179 [11:20<00:00,  3.80s/it]9.88s/it]\n",
      "100%|██████████| 179/179 [08:07<00:00,  2.72s/it]4.18s/it]\n",
      "100%|██████████| 179/179 [10:00<00:00,  3.36s/it]8.69s/it]\n",
      "100%|██████████| 179/179 [07:09<00:00,  2.40s/it]6.03s/it]\n",
      "100%|██████████| 179/179 [06:21<00:00,  2.13s/it]6.48s/it]\n",
      "100%|██████████| 179/179 [08:20<00:00,  2.79s/it]7.27s/it]\n",
      "100%|██████████| 179/179 [07:58<00:00,  2.67s/it]1.92s/it]\n",
      "100%|██████████| 179/179 [07:12<00:00,  2.42s/it]9.13s/it]\n",
      "100%|██████████| 179/179 [08:53<00:00,  2.98s/it]3.08s/it]\n",
      "100%|██████████| 179/179 [06:58<00:00,  2.34s/it]6.23s/it]\n",
      "100%|██████████| 179/179 [09:21<00:00,  3.14s/it]0.50s/it]\n",
      "100%|██████████| 179/179 [10:22<00:00,  3.48s/it]1.61s/it]\n",
      "100%|██████████| 179/179 [07:53<00:00,  2.64s/it]1.70s/it]\n",
      "100%|██████████| 179/179 [07:30<00:00,  2.51s/it]7.25s/it]\n",
      "100%|██████████| 179/179 [07:56<00:00,  2.66s/it]9.92s/it]\n",
      "100%|██████████| 179/179 [10:34<00:00,  3.54s/it]4.33s/it]\n",
      "100%|██████████| 179/179 [09:17<00:00,  3.12s/it]3.14s/it]\n",
      "100%|██████████| 179/179 [09:56<00:00,  3.33s/it]7.00s/it]\n",
      "100%|██████████| 179/179 [07:04<00:00,  2.37s/it]9.22s/it]\n",
      "100%|██████████| 179/179 [02:47<00:00,  1.07it/s]4.12s/it]\n",
      "100%|██████████| 179/179 [02:49<00:00,  1.06it/s]6.23s/it]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "100%|██████████| 179/179 [02:51<00:00,  1.04it/s]2.79s/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s]5.18s/it]\n",
      "100%|██████████| 179/179 [02:56<00:00,  1.01it/s]8.44s/it]\n",
      "100%|██████████| 179/179 [03:29<00:00,  1.17s/it]6.80s/it]\n",
      "100%|██████████| 179/179 [03:07<00:00,  1.05s/it]4.36s/it]\n",
      "100%|██████████| 179/179 [03:09<00:00,  1.06s/it].71s/it] \n",
      "100%|██████████| 179/179 [03:23<00:00,  1.14s/it].15s/it]\n",
      "100%|██████████| 179/179 [03:06<00:00,  1.04s/it].27s/it]\n",
      "100%|██████████| 179/179 [03:13<00:00,  1.08s/it].82s/it]\n",
      "100%|██████████| 179/179 [02:58<00:00,  1.00it/s].50s/it]\n",
      "100%|██████████| 179/179 [03:01<00:00,  1.01s/it].77s/it]\n",
      "100%|██████████| 179/179 [03:13<00:00,  1.08s/it].65s/it]\n",
      "100%|██████████| 179/179 [03:05<00:00,  1.04s/it].88s/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s].90s/it]\n",
      "100%|██████████| 179/179 [02:52<00:00,  1.04it/s].08s/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s].74s/it]\n",
      "100%|██████████| 179/179 [03:41<00:00,  1.24s/it].21s/it]\n",
      "100%|██████████| 179/179 [03:19<00:00,  1.12s/it].25s/it]\n",
      "100%|██████████| 179/179 [03:11<00:00,  1.07s/it].26s/it]\n",
      "100%|██████████| 179/179 [03:08<00:00,  1.05s/it].42s/it]\n",
      "100%|██████████| 179/179 [03:00<00:00,  1.01s/it]5.22s/it]\n",
      "100%|██████████| 179/179 [03:10<00:00,  1.07s/it].44s/it] \n",
      "100%|██████████| 179/179 [03:03<00:00,  1.02s/it].09s/it]\n",
      "100%|██████████| 179/179 [02:53<00:00,  1.03it/s].43s/it]\n",
      "100%|██████████| 179/179 [02:48<00:00,  1.06it/s].66s/it]\n",
      "100%|██████████| 179/179 [03:16<00:00,  1.10s/it].73s/it]\n",
      "100%|██████████| 179/179 [03:05<00:00,  1.04s/it].35s/it]\n",
      "100%|██████████| 179/179 [03:21<00:00,  1.13s/it].78s/it]\n",
      "100%|██████████| 179/179 [03:02<00:00,  1.02s/it].74s/it]\n",
      "100%|██████████| 179/179 [03:01<00:00,  1.02s/it].08s/it]\n",
      "100%|██████████| 179/179 [03:18<00:00,  1.11s/it].96s/it]\n",
      "100%|██████████| 179/179 [02:58<00:00,  1.00it/s].54s/it]\n",
      "100%|██████████| 179/179 [03:06<00:00,  1.04s/it].69s/it]\n",
      "100%|██████████| 179/179 [03:12<00:00,  1.07s/it].09s/it]\n",
      "100%|██████████| 179/179 [03:04<00:00,  1.03s/it].30s/it]\n",
      "100%|██████████| 179/179 [02:46<00:00,  1.08it/s].51s/it]\n",
      "100%|██████████| 179/179 [05:30<00:00,  1.85s/it].81s/it]\n",
      " 20%|█▉        | 197/1000 [25:04:37<102:13:02, 458.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Early\n",
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96c57faf6fd4883b444070c5f809732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1650.981 MB of 1650.981 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>FK ROI < 30</td><td>▄▆▆▇▇██▇▇▆▆▅▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▂▂▂▂▂</td></tr><tr><td>ROI</td><td>▁▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>ROI < 30</td><td>▄▆▆▇▇██▇▇▆▆▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▂▂▂▂▂</td></tr><tr><td>accuracy</td><td>▁▁▁▂▂▃▄▄▄▅▆▆▆▆▇▇▇▇▇▇████████████████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█████▇▃▇▇▇▇▇▆▆▆▆▆▆▆▂▆▅▆▅▆▅▅▅▅▅▅▅▁▅▄▅▅▅▄▄</td></tr><tr><td>correct</td><td>▁▁▁▂▂▃▄▄▄▅▆▆▆▆▇▇▇▇▇▇████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▇▇▆▆▆▆▆▅▅▅▅▄▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂</td></tr><tr><td>multibet outlay</td><td>▅▇███▇▇▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>multibet profit < 30</td><td>▅▆▆▇▇███▇▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▂▂▂▂</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>▆████▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁</td></tr><tr><td>profit</td><td>▆█▇█▇▇▇▇▅▅▄▄▃▃▂▃▃▃▃▂▃▂▂▁▂▂▁▂▁▂▂▁▁▂▂▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.04618</td></tr><tr><td>FK ROI < 30</td><td>-0.01335</td></tr><tr><td>ROI</td><td>-0.0529</td></tr><tr><td>ROI < 30</td><td>-0.01272</td></tr><tr><td>accuracy</td><td>0.2672</td></tr><tr><td>batch_before_backwards</td><td>7</td></tr><tr><td>batch_loss</td><td>8.35129</td></tr><tr><td>correct</td><td>5678</td></tr><tr><td>epoch</td><td>197</td></tr><tr><td>epoch_loss</td><td>8.35129</td></tr><tr><td>loss_val</td><td>1.88182</td></tr><tr><td>multibet outlay</td><td>631575.5818</td></tr><tr><td>multibet outlay < 30</td><td>418164.51893</td></tr><tr><td>multibet profit < 30</td><td>-5317.31729</td></tr><tr><td>multibet profit < 30 sd</td><td>21.73285</td></tr><tr><td>multibet profit sd</td><td>41.32926</td></tr><tr><td>profit</td><td>14489.48188</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crisp-forest-285</strong>: <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/fv7tkten\" target=\"_blank\">https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing/runs/fv7tkten</a><br/>Synced 5 W&B file(s), 297 media file(s), 297 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_111857-fv7tkten\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static)\n",
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'ROI < 30'},\n",
      " 'parameters': {'batch_before_backwards': {'values': [5, 10, 15, 50]},\n",
      "                'batch_size': {'values': [250, 500, 1000]},\n",
      "                'dropout': {'values': [0.3]},\n",
      "                'epochs': {'values': [200]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'hidden_size': {'value': 64},\n",
      "                'l1_beta': {'value': 0.1},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.001,\n",
      "                                  'min': 1e-05},\n",
      "                'len_data': {'value': 111168},\n",
      "                'loss': {'values': ['CEL']},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adamW'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'metric': {'name': 'ROI < 30', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adamW'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3]},\n",
       "  'len_data': {'value': 111168},\n",
       "  'hidden_size': {'value': 64},\n",
       "  'epochs': {'values': [200]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'values': ['CEL']},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 1e-05, 'max': 0.001},\n",
       "  'l1_beta': {'value': 0.1},\n",
       "  'batch_size': {'values': [250, 500, 1000]},\n",
       "  'batch_before_backwards': {'values': [5, 10, 15, 50]}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"ROI < 30\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": len(raceDB.raceIDs)},\n",
    "    \"hidden_size\": {\"value\":64}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [200]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"CEL\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00001,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [250,500,1000]\n",
    "        },\n",
    "        \"batch_before_backwards\": {\n",
    "            'values': [5,10,15,50]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: mzjxl651\n",
      "Sweep URL: https://wandb.ai/nickojelly/GRU_sweeps/sweeps/mzjxl651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o4lw7zlw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 3.598900158654535e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 111168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_002450-o4lw7zlw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/o4lw7zlw\" target=\"_blank\">eternal-sweep-1</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/mzjxl651\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/mzjxl651</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 50, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 3.598900158654535e-05, 'len_data': 111168, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "200\n",
      "{'batch_before_backwards': 50, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 3.598900158654535e-05, 'len_data': 111168, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:33<00:00,  2.62it/s]\n",
      "100%|██████████| 89/89 [01:29<00:00,  1.00s/it]/it]\n",
      "100%|██████████| 89/89 [00:52<00:00,  1.69it/s]/it]\n",
      "100%|██████████| 89/89 [00:51<00:00,  1.73it/s]/it]\n",
      "100%|██████████| 89/89 [00:51<00:00,  1.71it/s]/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.95it/s]/it]\n",
      "100%|██████████| 89/89 [00:46<00:00,  1.93it/s]/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.08it/s]/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.08it/s]/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.09it/s]/it]\n",
      "100%|██████████| 89/89 [00:47<00:00,  1.87it/s]s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.68it/s]s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.31it/s]s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.36it/s]28s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s]05s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.06it/s]93s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.07it/s]55s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s]09s/it]\n",
      "100%|██████████| 89/89 [00:48<00:00,  1.83it/s]94s/it]\n",
      "100%|██████████| 89/89 [00:49<00:00,  1.79it/s]70s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.66it/s]49s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s]61s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.08it/s]00s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.22it/s]23s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  2.00it/s]83s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.97it/s]69s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.10it/s]65s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.04it/s]02s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.36it/s]32s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.34it/s]31s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s]55s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.41it/s]32s/it]\n",
      "100%|██████████| 89/89 [00:47<00:00,  1.86it/s]32s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.34it/s]42s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.34it/s]91s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.65it/s]11s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.49it/s]97s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.48it/s]81s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s]56s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.31it/s]77s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.31it/s]82s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s]89s/it]\n",
      "100%|██████████| 89/89 [00:54<00:00,  1.63it/s]95s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  1.99it/s]05s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.05it/s]45s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.32it/s]03s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.03it/s]01s/it]\n",
      "100%|██████████| 89/89 [01:05<00:00,  1.37it/s]45s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.07it/s]52s/it]\n",
      "100%|██████████| 89/89 [00:54<00:00,  1.62it/s]86s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.05it/s]05s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.65it/s]66s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.06it/s]99s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.07it/s]29s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.94it/s]21s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s]15s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.34it/s]09s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  1.98it/s]53s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.03it/s]57s/it]\n",
      "100%|██████████| 89/89 [01:05<00:00,  1.35it/s]86s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.34it/s]82s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.10it/s]20s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.10it/s]30s/it]\n",
      "100%|██████████| 89/89 [01:10<00:00,  1.25it/s]79s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.31it/s]76s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.07it/s]85s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.03it/s]42s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.31it/s]41s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s]69s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s]4s/it] \n",
      "100%|██████████| 89/89 [00:47<00:00,  1.89it/s]2s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.32it/s]20s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.34it/s]25s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s]21s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.04it/s]8s/it] \n",
      "100%|██████████| 89/89 [00:48<00:00,  1.83it/s]1s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.96it/s]9s/it]\n",
      "100%|██████████| 89/89 [00:48<00:00,  1.84it/s]9s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  1.98it/s]7s/it]\n",
      "100%|██████████| 89/89 [00:47<00:00,  1.88it/s]6s/it]\n",
      "100%|██████████| 89/89 [00:52<00:00,  1.69it/s]1s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.05it/s]3s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.05it/s]5s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.03it/s]1s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s]3s/it]\n",
      "100%|██████████| 89/89 [00:47<00:00,  1.88it/s]8s/it]\n",
      "100%|██████████| 89/89 [00:51<00:00,  1.73it/s]8s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.66it/s]6s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.65it/s]2s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.11it/s]8s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.97it/s]6s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.32it/s]7s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.05it/s]4s/it]\n",
      "100%|██████████| 89/89 [00:54<00:00,  1.64it/s]1s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.11it/s]9s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.31it/s]2s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.68it/s]3s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.03it/s]4s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.97it/s]3s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.65it/s]4s/it]\n",
      "100%|██████████| 89/89 [00:54<00:00,  1.63it/s]94s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.44it/s]42s/it]\n",
      "100%|██████████| 89/89 [00:52<00:00,  1.68it/s]97s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  2.00it/s].50s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.33it/s].01s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.22it/s]91s/it] \n",
      "100%|██████████| 89/89 [00:47<00:00,  1.88it/s]60s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.37it/s]83s/it]\n",
      "100%|██████████| 89/89 [00:48<00:00,  1.83it/s]43s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  2.02it/s]46s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  2.01it/s]78s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.94it/s]23s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  2.02it/s]92s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.10it/s]61s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.06it/s]03s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.38it/s]25s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.32it/s]12s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.95it/s]72s/it]\n",
      "100%|██████████| 89/89 [00:38<00:00,  2.30it/s]09s/it]\n",
      "100%|██████████| 89/89 [00:34<00:00,  2.56it/s]52s/it]\n",
      "100%|██████████| 89/89 [00:56<00:00,  1.57it/s]89s/it]\n",
      "100%|██████████| 89/89 [00:36<00:00,  2.44it/s]56s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.21it/s]25s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.38it/s]50s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.02it/s].39s/it]\n",
      "100%|██████████| 89/89 [00:35<00:00,  2.50it/s].31s/it]\n",
      "100%|██████████| 89/89 [01:04<00:00,  1.37it/s].95s/it]\n",
      "100%|██████████| 89/89 [00:46<00:00,  1.90it/s].60s/it]\n",
      "100%|██████████| 89/89 [00:36<00:00,  2.47it/s].98s/it]\n",
      "100%|██████████| 89/89 [01:05<00:00,  1.36it/s].13s/it]\n",
      "100%|██████████| 89/89 [00:34<00:00,  2.55it/s].16s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.36it/s].74s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.11it/s].97s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  1.98it/s].71s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.09it/s].54s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.21it/s].50s/it]\n",
      "100%|██████████| 89/89 [00:50<00:00,  1.77it/s].94s/it]\n",
      "100%|██████████| 89/89 [00:36<00:00,  2.44it/s].82s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.65it/s].09s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.24it/s].41s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.11it/s].12s/it]\n",
      "100%|██████████| 89/89 [00:36<00:00,  2.42it/s].45s/it]\n",
      "100%|██████████| 89/89 [00:42<00:00,  2.08it/s].15s/it]\n",
      "100%|██████████| 89/89 [00:58<00:00,  1.53it/s].25s/it]\n",
      "100%|██████████| 89/89 [00:50<00:00,  1.75it/s].03s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.68it/s].71s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.40it/s].01s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  1.99it/s].91s/it]\n",
      "100%|██████████| 89/89 [00:43<00:00,  2.03it/s].03s/it]\n",
      "100%|██████████| 89/89 [00:51<00:00,  1.72it/s].99s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.36it/s].44s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  2.01it/s].92s/it]\n",
      "100%|██████████| 89/89 [00:35<00:00,  2.53it/s].99s/it]\n",
      "100%|██████████| 89/89 [00:55<00:00,  1.62it/s].52s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.21it/s].84s/it]\n",
      "100%|██████████| 89/89 [00:41<00:00,  2.13it/s].56s/it]\n",
      "100%|██████████| 89/89 [00:35<00:00,  2.48it/s].97s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.26it/s].56s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.38it/s].19s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.97it/s].55s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s].23s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.19it/s].51s/it]\n",
      "100%|██████████| 89/89 [00:50<00:00,  1.78it/s].10s/it]\n",
      "100%|██████████| 89/89 [00:50<00:00,  1.76it/s].67s/it]\n",
      "100%|██████████| 89/89 [00:36<00:00,  2.41it/s].35s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.25it/s].55s/it]\n",
      "100%|██████████| 89/89 [00:37<00:00,  2.34it/s].41s/it]\n",
      "100%|██████████| 89/89 [00:50<00:00,  1.76it/s].69s/it]\n",
      "100%|██████████| 89/89 [00:50<00:00,  1.77it/s].28s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.21it/s].59s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.23it/s].37s/it]\n",
      "100%|██████████| 89/89 [00:49<00:00,  1.80it/s].06s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.97it/s].96s/it]\n",
      "100%|██████████| 89/89 [00:49<00:00,  1.79it/s].85s/it]\n",
      "100%|██████████| 89/89 [00:56<00:00,  1.57it/s].30s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.44it/s].94s/it]\n",
      "100%|██████████| 89/89 [00:53<00:00,  1.68it/s].65s/it]\n",
      "100%|██████████| 89/89 [00:47<00:00,  1.88it/s].77s/it]\n",
      "100%|██████████| 89/89 [00:45<00:00,  1.98it/s].64s/it]\n",
      "100%|██████████| 89/89 [00:47<00:00,  1.89it/s].71s/it]\n",
      "100%|██████████| 89/89 [00:47<00:00,  1.89it/s].21s/it]\n",
      "100%|██████████| 89/89 [01:10<00:00,  1.27it/s].04s/it]\n",
      "100%|██████████| 89/89 [00:44<00:00,  1.99it/s].99s/it]\n",
      "100%|██████████| 89/89 [00:54<00:00,  1.65it/s].71s/it]\n",
      "100%|██████████| 89/89 [00:47<00:00,  1.89it/s].22s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.19it/s].18s/it]\n",
      "100%|██████████| 89/89 [00:47<00:00,  1.88it/s].53s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.23it/s].77s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.20it/s]3s/it]  \n",
      "100%|██████████| 89/89 [00:54<00:00,  1.63it/s]8s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.24it/s]5s/it]\n",
      "100%|██████████| 89/89 [00:56<00:00,  1.58it/s]5s/it]\n",
      "100%|██████████| 89/89 [00:48<00:00,  1.85it/s]5s/it]\n",
      "100%|██████████| 89/89 [00:40<00:00,  2.22it/s]9s/it]\n",
      "100%|██████████| 89/89 [01:03<00:00,  1.39it/s]2s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.23it/s]8s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.26it/s]5s/it]\n",
      "100%|██████████| 89/89 [00:50<00:00,  1.75it/s]6s/it]\n",
      "100%|██████████| 89/89 [00:39<00:00,  2.28it/s]8s/it]\n",
      "100%|██████████| 89/89 [00:36<00:00,  2.41it/s]6s/it]\n",
      "100%|██████████| 200/200 [15:58:11<00:00, 287.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d6fc1b4eb44277aba7c3d3de2e54ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1648.333 MB of 1648.333 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>FK ROI < 30</td><td>▁▁▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>ROI < 30</td><td>▁▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████</td></tr><tr><td>accuracy</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>correct</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▂▂▂▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>multibet profit < 30</td><td>▁▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>multibet profit sd</td><td>▁▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>profit</td><td>▁▁▁▁▂▄▄▅▅▅▅▄▅▄▄▅▅▅▅▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆█▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.0947</td></tr><tr><td>FK ROI < 30</td><td>0.00452</td></tr><tr><td>ROI</td><td>-0.1025</td></tr><tr><td>ROI < 30</td><td>0.00562</td></tr><tr><td>accuracy</td><td>0.19896</td></tr><tr><td>batch_before_backwards</td><td>50</td></tr><tr><td>batch_loss</td><td>70.79708</td></tr><tr><td>correct</td><td>4228</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>epoch_loss</td><td>70.79708</td></tr><tr><td>loss_val</td><td>1.9867</td></tr><tr><td>multibet outlay</td><td>721176.67931</td></tr><tr><td>multibet outlay < 30</td><td>312458.49036</td></tr><tr><td>multibet profit < 30</td><td>1757.51788</td></tr><tr><td>multibet profit < 30 sd</td><td>17.2182</td></tr><tr><td>multibet profit sd</td><td>52.57356</td></tr><tr><td>profit</td><td>16514.28096</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eternal-sweep-1</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/o4lw7zlw\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/o4lw7zlw</a><br/>Synced 5 W&B file(s), 300 media file(s), 300 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_002450-o4lw7zlw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9onj9j75 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009297879614048912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 111168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_162719-9onj9j75</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/9onj9j75\" target=\"_blank\">sunny-sweep-2</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/mzjxl651\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/mzjxl651</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009297879614048912, 'len_data': 111168, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "200\n",
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009297879614048912, 'len_data': 111168, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [02:06<00:00,  1.42s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.38s/it]/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.37s/it]/it]\n",
      "100%|██████████| 89/89 [02:14<00:00,  1.51s/it]/it]\n",
      "100%|██████████| 89/89 [02:14<00:00,  1.52s/it]/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.43s/it]/it]\n",
      "100%|██████████| 89/89 [02:16<00:00,  1.54s/it]/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.35s/it]/it]\n",
      "100%|██████████| 89/89 [02:12<00:00,  1.49s/it]/it]\n",
      "100%|██████████| 89/89 [02:09<00:00,  1.45s/it]/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it]s/it]\n",
      "100%|██████████| 89/89 [02:12<00:00,  1.49s/it]18s/it]\n",
      "100%|██████████| 89/89 [01:58<00:00,  1.33s/it]26s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.35s/it]35s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it]03s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.35s/it]19s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.38s/it]53s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.35s/it]55s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.34s/it]76s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it]66s/it]\n",
      "100%|██████████| 89/89 [01:57<00:00,  1.32s/it]55s/it]\n",
      "100%|██████████| 89/89 [01:56<00:00,  1.31s/it]27s/it]\n",
      "100%|██████████| 89/89 [01:58<00:00,  1.33s/it]96s/it]\n",
      "100%|██████████| 89/89 [01:55<00:00,  1.30s/it]39s/it]\n",
      "100%|██████████| 89/89 [01:54<00:00,  1.28s/it]69s/it]\n",
      "100%|██████████| 89/89 [01:56<00:00,  1.31s/it]75s/it]\n",
      "100%|██████████| 89/89 [01:56<00:00,  1.31s/it]07s/it]\n",
      "100%|██████████| 89/89 [01:53<00:00,  1.28s/it]57s/it]\n",
      "100%|██████████| 89/89 [01:58<00:00,  1.33s/it]18s/it]\n",
      "100%|██████████| 89/89 [01:54<00:00,  1.28s/it]60s/it]\n",
      "100%|██████████| 89/89 [01:53<00:00,  1.28s/it]17s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it]95s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it]15s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it]13s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.34s/it]99s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it]37s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.38s/it]78s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.38s/it]94s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it]39s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.38s/it]96s/it]\n",
      "100%|██████████| 89/89 [02:04<00:00,  1.40s/it]96s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it]87s/it]\n",
      "100%|██████████| 89/89 [02:08<00:00,  1.45s/it]83s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.42s/it]32s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.34s/it]88s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it]67s/it]\n",
      "100%|██████████| 89/89 [01:57<00:00,  1.32s/it]27s/it]\n",
      "100%|██████████| 89/89 [02:11<00:00,  1.48s/it]80s/it]\n",
      "100%|██████████| 89/89 [02:07<00:00,  1.43s/it]94s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.38s/it]41s/it]\n",
      "100%|██████████| 89/89 [01:56<00:00,  1.31s/it]40s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it]12s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.42s/it]00s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it]32s/it]\n",
      "100%|██████████| 89/89 [02:04<00:00,  1.39s/it]34s/it]\n",
      "100%|██████████| 89/89 [02:12<00:00,  1.49s/it]82s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.34s/it]77s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it]69s/it]\n",
      "100%|██████████| 89/89 [02:09<00:00,  1.46s/it]02s/it]\n",
      "100%|██████████| 89/89 [01:55<00:00,  1.30s/it]59s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.38s/it]33s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.37s/it]13s/it]\n",
      "100%|██████████| 89/89 [01:58<00:00,  1.33s/it]90s/it]\n",
      "100%|██████████| 89/89 [01:56<00:00,  1.30s/it]10s/it]\n",
      "100%|██████████| 89/89 [01:58<00:00,  1.33s/it]50s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.34s/it]61s/it]\n",
      "100%|██████████| 89/89 [01:58<00:00,  1.33s/it]79s/it]\n",
      "100%|██████████| 89/89 [01:56<00:00,  1.31s/it]92s/it]\n",
      "100%|██████████| 89/89 [01:55<00:00,  1.30s/it]44s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it]78s/it]\n",
      "100%|██████████| 89/89 [01:57<00:00,  1.32s/it]31s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it]18s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it]25s/it]\n",
      "100%|██████████| 89/89 [02:10<00:00,  1.47s/it]37s/it]\n",
      "100%|██████████| 89/89 [02:11<00:00,  1.47s/it]36s/it]\n",
      "100%|██████████| 89/89 [02:08<00:00,  1.44s/it]47s/it]\n",
      "100%|██████████| 89/89 [02:08<00:00,  1.45s/it]41s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.42s/it]52s/it]\n",
      "100%|██████████| 89/89 [02:08<00:00,  1.44s/it]09s/it]\n",
      "100%|██████████| 89/89 [01:57<00:00,  1.32s/it]40s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.35s/it]10s/it]\n",
      "100%|██████████| 89/89 [02:09<00:00,  1.46s/it]12s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it]50s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.38s/it]58s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it]05s/it]\n",
      "100%|██████████| 89/89 [02:10<00:00,  1.46s/it]72s/it]\n",
      "100%|██████████| 89/89 [01:54<00:00,  1.28s/it]51s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.43s/it]19s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.42s/it]64s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.34s/it]99s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.42s/it]88s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.42s/it]83s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it]29s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.36s/it]16s/it]\n",
      "100%|██████████| 89/89 [02:10<00:00,  1.47s/it]14s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it]4s/it] \n",
      "100%|██████████| 89/89 [02:11<00:00,  1.48s/it]9s/it]\n",
      "100%|██████████| 89/89 [02:11<00:00,  1.48s/it]7s/it]\n",
      "100%|██████████| 89/89 [02:08<00:00,  1.44s/it]2s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it]5s/it]\n",
      "100%|██████████| 89/89 [02:10<00:00,  1.46s/it]30s/it]\n",
      "100%|██████████| 89/89 [02:08<00:00,  1.44s/it].99s/it]\n",
      "100%|██████████| 89/89 [02:10<00:00,  1.46s/it]10s/it] \n",
      "100%|██████████| 89/89 [02:11<00:00,  1.48s/it]42s/it]\n",
      "100%|██████████| 89/89 [01:58<00:00,  1.33s/it]48s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it]52s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.34s/it]91s/it]\n",
      "100%|██████████| 89/89 [01:57<00:00,  1.32s/it].83s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it].14s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it].63s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.36s/it].73s/it]\n",
      "100%|██████████| 89/89 [02:16<00:00,  1.53s/it].22s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it].05s/it]\n",
      "100%|██████████| 89/89 [02:15<00:00,  1.52s/it].31s/it]\n",
      "100%|██████████| 89/89 [02:12<00:00,  1.49s/it].51s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.35s/it].55s/it]\n",
      "100%|██████████| 89/89 [02:13<00:00,  1.50s/it].11s/it]\n",
      "100%|██████████| 89/89 [02:16<00:00,  1.54s/it].04s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it].25s/it]\n",
      "100%|██████████| 89/89 [02:10<00:00,  1.46s/it].21s/it]\n",
      "100%|██████████| 89/89 [02:12<00:00,  1.48s/it].99s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.35s/it].58s/it]\n",
      "100%|██████████| 89/89 [02:12<00:00,  1.49s/it].25s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it].53s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.35s/it].48s/it]\n",
      "100%|██████████| 89/89 [02:17<00:00,  1.54s/it].64s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it].00s/it]\n",
      "100%|██████████| 89/89 [02:11<00:00,  1.48s/it].78s/it]\n",
      "100%|██████████| 89/89 [02:13<00:00,  1.50s/it].82s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.38s/it].73s/it]\n",
      "100%|██████████| 89/89 [02:11<00:00,  1.48s/it].73s/it]\n",
      "100%|██████████| 89/89 [02:17<00:00,  1.54s/it].63s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.38s/it].21s/it]\n",
      "100%|██████████| 89/89 [02:04<00:00,  1.40s/it].46s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it].25s/it]\n",
      "100%|██████████| 89/89 [02:04<00:00,  1.40s/it].08s/it]\n",
      "100%|██████████| 89/89 [02:12<00:00,  1.48s/it].71s/it]\n",
      "100%|██████████| 89/89 [02:13<00:00,  1.50s/it].77s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.38s/it].43s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.34s/it].45s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.35s/it].99s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it].41s/it]\n",
      "100%|██████████| 89/89 [02:08<00:00,  1.44s/it].65s/it]\n",
      "100%|██████████| 89/89 [02:25<00:00,  1.63s/it].47s/it]\n",
      "100%|██████████| 89/89 [02:09<00:00,  1.46s/it].92s/it]\n",
      "100%|██████████| 89/89 [02:04<00:00,  1.39s/it].95s/it]\n",
      "100%|██████████| 89/89 [02:16<00:00,  1.54s/it].95s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it].52s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.38s/it].65s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it].30s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.42s/it].16s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it].50s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it].68s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.34s/it].36s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it].41s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.35s/it].80s/it]\n",
      "100%|██████████| 89/89 [02:04<00:00,  1.39s/it].86s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it].14s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.43s/it].67s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it].30s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it].65s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it].36s/it]\n",
      "100%|██████████| 89/89 [02:10<00:00,  1.47s/it].44s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it].87s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.41s/it].20s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it].26s/it]\n",
      "100%|██████████| 89/89 [02:16<00:00,  1.53s/it].20s/it]\n",
      "100%|██████████| 89/89 [02:05<00:00,  1.40s/it].50s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it].85s/it]\n",
      "100%|██████████| 89/89 [02:24<00:00,  1.62s/it].62s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.38s/it].89s/it]\n",
      "100%|██████████| 89/89 [02:10<00:00,  1.47s/it].41s/it]\n",
      "100%|██████████| 89/89 [02:21<00:00,  1.59s/it].99s/it]\n",
      "100%|██████████| 89/89 [02:19<00:00,  1.57s/it].25s/it]\n",
      "100%|██████████| 89/89 [02:23<00:00,  1.61s/it].95s/it]\n",
      "100%|██████████| 89/89 [02:17<00:00,  1.55s/it].40s/it]\n",
      "100%|██████████| 89/89 [02:26<00:00,  1.65s/it].27s/it]\n",
      "100%|██████████| 89/89 [02:13<00:00,  1.51s/it].18s/it]\n",
      "100%|██████████| 89/89 [02:20<00:00,  1.58s/it].87s/it]\n",
      "100%|██████████| 89/89 [02:23<00:00,  1.62s/it].98s/it]\n",
      "100%|██████████| 89/89 [02:27<00:00,  1.65s/it].22s/it]\n",
      "100%|██████████| 89/89 [02:06<00:00,  1.42s/it].65s/it]\n",
      "100%|██████████| 89/89 [01:57<00:00,  1.32s/it].90s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.36s/it].39s/it]\n",
      "100%|██████████| 89/89 [02:08<00:00,  1.44s/it].98s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it].19s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it].98s/it]\n",
      "100%|██████████| 89/89 [01:59<00:00,  1.35s/it].14s/it]\n",
      "100%|██████████| 89/89 [02:02<00:00,  1.37s/it].14s/it]\n",
      "100%|██████████| 89/89 [01:54<00:00,  1.28s/it].78s/it]\n",
      "100%|██████████| 89/89 [01:51<00:00,  1.26s/it].47s/it]\n",
      "100%|██████████| 89/89 [01:55<00:00,  1.30s/it]8s/it]  \n",
      "100%|██████████| 89/89 [01:48<00:00,  1.22s/it]8s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.37s/it]1s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.36s/it]2s/it]\n",
      "100%|██████████| 89/89 [02:16<00:00,  1.54s/it]0s/it]\n",
      "100%|██████████| 89/89 [02:20<00:00,  1.58s/it]6s/it]\n",
      "100%|██████████| 89/89 [02:26<00:00,  1.65s/it]9s/it]\n",
      "100%|██████████| 89/89 [02:09<00:00,  1.45s/it]9s/it]\n",
      "100%|██████████| 89/89 [02:04<00:00,  1.40s/it]7s/it]\n",
      "100%|██████████| 200/200 [19:44:24<00:00, 355.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d243b07ec1d949188cdf28d8a4119155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1620.138 MB of 1620.138 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▄▃▄▄▄▅▅▅▆▇▇▇▇▇█▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▆▆▇▆▆▇</td></tr><tr><td>FK ROI < 30</td><td>▄▅▆▃▂▂▂▂▃▁▂▄▃▃▅▄▆▅▅▄▂▆█▆▆▅▆▆▅▅▅▅▅▄▃▄▅▄▄▅</td></tr><tr><td>ROI</td><td>▁▂▃▃▃▄▄▅▅▅▅▇▇▆▇▇█▇▇▇▇▇██▇▇▇▇▆▇▆▇▇▆▆▆▆▆▆▆</td></tr><tr><td>ROI < 30</td><td>▄▅▅▂▂▂▂▂▃▁▂▄▃▃▅▅▆▅▅▅▃▆█▆▆▅▇▆▅▅▅▅▅▄▄▄▅▄▅▅</td></tr><tr><td>accuracy</td><td>▁▃▆▇██▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▆▆▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>correct</td><td>▁▃▆▇██▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▆▆▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>▃▃▁▁▁▁▁▂▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█▇███████</td></tr><tr><td>multibet outlay</td><td>▄▄▂▁▁▁▁▂▂▃▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>multibet profit</td><td>▁▂▄▃▄▄▅▅▅▅▆▇▇▆▇▇█▇▇▇▇▇██▇▇▇▇▆▆▆▇▆▆▆▅▆▆▆▆</td></tr><tr><td>multibet profit < 30</td><td>▃▄▄▂▂▂▂▂▂▁▂▃▃▃▅▄▆▅▅▅▃▆█▆▆▅▇▇▅▅▅▅▅▄▃▄▅▄▄▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>multibet profit sd</td><td>█▇▄▂▂▁▁▂▂▃▄▄▅▆▆▆▇▆▆▇█▇▇█▇█▇▇▇▇▆█▇██▇▇▇█▇</td></tr><tr><td>profit</td><td>▇█▁▂▁▃▁▂▂▃▃▃▃▅▅▄▄▄▄▆▄▃▃▅▂▄▃▂▂▄▂▃▁▁▄▂▃▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.02417</td></tr><tr><td>FK ROI < 30</td><td>0.00622</td></tr><tr><td>ROI</td><td>-0.0279</td></tr><tr><td>ROI < 30</td><td>0.01237</td></tr><tr><td>accuracy</td><td>0.24005</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>5.38772</td></tr><tr><td>correct</td><td>5101</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>epoch_loss</td><td>5.38772</td></tr><tr><td>loss_val</td><td>2.29371</td></tr><tr><td>multibet outlay</td><td>858060.22237</td></tr><tr><td>multibet outlay < 30</td><td>668174.8876</td></tr><tr><td>multibet profit < 30</td><td>8263.33231</td></tr><tr><td>multibet profit < 30 sd</td><td>37.23985</td></tr><tr><td>multibet profit sd</td><td>51.82255</td></tr><tr><td>profit</td><td>15312.67258</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sunny-sweep-2</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/9onj9j75\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/9onj9j75</a><br/>Synced 5 W&B file(s), 300 media file(s), 300 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_162719-9onj9j75\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lr2vc938 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005642941511686169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 111168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_121652-lr2vc938</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/lr2vc938\" target=\"_blank\">rich-sweep-3</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/mzjxl651\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/mzjxl651</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 15, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005642941511686169, 'len_data': 111168, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "200\n",
      "{'batch_before_backwards': 15, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005642941511686169, 'len_data': 111168, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [01:46<00:00,  1.20s/it]\n",
      "100%|██████████| 89/89 [01:34<00:00,  1.07s/it]/it]\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]/it]\n",
      "100%|██████████| 89/89 [01:08<00:00,  1.30it/s]/it]\n",
      "100%|██████████| 89/89 [01:08<00:00,  1.31it/s]/it]\n",
      "100%|██████████| 89/89 [01:07<00:00,  1.33it/s]/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.48it/s]/it]\n",
      "100%|██████████| 89/89 [01:03<00:00,  1.40it/s]/it]\n",
      "100%|██████████| 89/89 [01:14<00:00,  1.19it/s]/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.43it/s]/it]\n",
      "100%|██████████| 89/89 [01:18<00:00,  1.13it/s]71s/it]\n",
      "100%|██████████| 89/89 [02:14<00:00,  1.51s/it]69s/it]\n",
      "100%|██████████| 89/89 [01:57<00:00,  1.32s/it]31s/it]\n",
      "100%|██████████| 89/89 [02:08<00:00,  1.44s/it]18s/it]\n",
      "100%|██████████| 89/89 [01:56<00:00,  1.30s/it]12s/it]\n",
      "100%|██████████| 89/89 [00:58<00:00,  1.51it/s]42s/it]\n",
      "100%|██████████| 89/89 [01:16<00:00,  1.16it/s]31s/it]\n",
      "100%|██████████| 89/89 [01:06<00:00,  1.33it/s]89s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.43it/s]09s/it]\n",
      "100%|██████████| 89/89 [01:45<00:00,  1.18s/it]23s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s]52s/it]\n",
      "100%|██████████| 89/89 [01:13<00:00,  1.22it/s]13s/it]\n",
      "100%|██████████| 89/89 [01:07<00:00,  1.32it/s]41s/it]\n",
      "100%|██████████| 89/89 [01:15<00:00,  1.18it/s]68s/it]\n",
      "100%|██████████| 89/89 [01:18<00:00,  1.14it/s]35s/it]\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.27it/s]15s/it]\n",
      "100%|██████████| 89/89 [01:05<00:00,  1.36it/s]94s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.48it/s]13s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.48it/s]16s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.46it/s]56s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.49it/s]05s/it]\n",
      "100%|██████████| 89/89 [01:07<00:00,  1.32it/s]65s/it]\n",
      "100%|██████████| 89/89 [01:03<00:00,  1.40it/s]13s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.49it/s]93s/it]\n",
      "100%|██████████| 89/89 [01:04<00:00,  1.39it/s]17s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s]04s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.41it/s]93s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s]81s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.43it/s]05s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.48it/s]80s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.41it/s]41s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s]99s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s]51s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.50it/s]36s/it]\n",
      "100%|██████████| 89/89 [03:24<00:00,  2.30s/it]56s/it]\n",
      "100%|██████████| 89/89 [01:14<00:00,  1.19it/s]59s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s]45s/it]\n",
      "100%|██████████| 89/89 [01:08<00:00,  1.30it/s]23s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.48it/s]72s/it]\n",
      "100%|██████████| 89/89 [00:58<00:00,  1.51it/s]45s/it]\n",
      "100%|██████████| 89/89 [01:19<00:00,  1.12it/s]75s/it]\n",
      "100%|██████████| 89/89 [01:17<00:00,  1.15it/s]63s/it]\n",
      "100%|██████████| 89/89 [01:03<00:00,  1.40it/s]33s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.50it/s]78s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.46it/s]66s/it]\n",
      "100%|██████████| 89/89 [02:00<00:00,  1.36s/it]77s/it]\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]08s/it]\n",
      "100%|██████████| 89/89 [02:34<00:00,  1.73s/it]47s/it]\n",
      "100%|██████████| 89/89 [02:28<00:00,  1.67s/it]87s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.48it/s]57s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s]57s/it]\n",
      "100%|██████████| 89/89 [02:34<00:00,  1.73s/it]08s/it]\n",
      "100%|██████████| 89/89 [01:08<00:00,  1.29it/s]07s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.48it/s]10s/it]\n",
      "100%|██████████| 89/89 [02:18<00:00,  1.56s/it]55s/it]\n",
      "100%|██████████| 89/89 [01:37<00:00,  1.10s/it]71s/it]\n",
      "100%|██████████| 89/89 [01:33<00:00,  1.05s/it]78s/it]\n",
      "100%|██████████| 89/89 [03:01<00:00,  2.04s/it]61s/it]\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s]78s/it]\n",
      "100%|██████████| 89/89 [02:33<00:00,  1.72s/it]90s/it]\n",
      "100%|██████████| 89/89 [01:34<00:00,  1.06s/it]64s/it]\n",
      "100%|██████████| 89/89 [03:02<00:00,  2.05s/it]62s/it]\n",
      "100%|██████████| 89/89 [02:40<00:00,  1.80s/it]43s/it]\n",
      "100%|██████████| 89/89 [02:44<00:00,  1.85s/it]84s/it]\n",
      "100%|██████████| 89/89 [01:25<00:00,  1.04it/s]14s/it]\n",
      "100%|██████████| 89/89 [02:48<00:00,  1.89s/it]75s/it]\n",
      "100%|██████████| 89/89 [01:16<00:00,  1.17it/s]20s/it]\n",
      "100%|██████████| 89/89 [02:20<00:00,  1.58s/it]00s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it]88s/it]\n",
      "100%|██████████| 89/89 [03:07<00:00,  2.10s/it]08s/it]\n",
      "100%|██████████| 89/89 [03:00<00:00,  2.03s/it]41s/it]\n",
      "100%|██████████| 89/89 [01:08<00:00,  1.30it/s]68s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s]62s/it]\n",
      "100%|██████████| 89/89 [02:35<00:00,  1.75s/it]26s/it]\n",
      "100%|██████████| 89/89 [02:34<00:00,  1.73s/it]57s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s]48s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.50it/s]58s/it]\n",
      "100%|██████████| 89/89 [02:51<00:00,  1.93s/it]32s/it]\n",
      "100%|██████████| 89/89 [03:56<00:00,  2.66s/it]69s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.43it/s].87s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s].46s/it]\n",
      "100%|██████████| 89/89 [02:29<00:00,  1.68s/it].50s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.44it/s].91s/it]\n",
      "100%|██████████| 89/89 [01:03<00:00,  1.40it/s].91s/it]\n",
      "100%|██████████| 89/89 [01:05<00:00,  1.37it/s].28s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.45it/s].93s/it]\n",
      "100%|██████████| 89/89 [01:12<00:00,  1.23it/s].61s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.46it/s].71s/it]\n",
      "100%|██████████| 89/89 [00:58<00:00,  1.51it/s].95s/it]\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.29it/s].07s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.49it/s]9.81s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.44it/s]5.73s/it]\n",
      "100%|██████████| 89/89 [01:05<00:00,  1.35it/s]2.24s/it]\n",
      "100%|██████████| 89/89 [01:04<00:00,  1.39it/s]5.24s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s]7.71s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.44it/s]1.93s/it]\n",
      "100%|██████████| 89/89 [01:07<00:00,  1.31it/s]5.21s/it]\n",
      "100%|██████████| 89/89 [01:27<00:00,  1.01it/s]1.91s/it]\n",
      "100%|██████████| 89/89 [01:57<00:00,  1.32s/it]8.24s/it]\n",
      "100%|██████████| 89/89 [02:51<00:00,  1.92s/it]6.21s/it]\n",
      "100%|██████████| 89/89 [02:11<00:00,  1.48s/it]1.01s/it]\n",
      "100%|██████████| 89/89 [02:27<00:00,  1.65s/it]1.91s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.43it/s]6.80s/it]\n",
      "100%|██████████| 89/89 [01:27<00:00,  1.01it/s]7.09s/it]\n",
      "100%|██████████| 89/89 [01:22<00:00,  1.08it/s]1.49s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.45it/s]3.87s/it]\n",
      "100%|██████████| 89/89 [02:01<00:00,  1.36s/it]3.36s/it]\n",
      "100%|██████████| 89/89 [02:04<00:00,  1.40s/it]3.74s/it]\n",
      "100%|██████████| 89/89 [02:30<00:00,  1.69s/it]6.02s/it]\n",
      "100%|██████████| 89/89 [01:55<00:00,  1.30s/it]0.24s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.46it/s]5.17s/it]\n",
      "100%|██████████| 89/89 [00:58<00:00,  1.51it/s]1.63s/it]\n",
      "100%|██████████| 89/89 [02:16<00:00,  1.53s/it]4.85s/it]\n",
      "100%|██████████| 89/89 [02:25<00:00,  1.64s/it]2.74s/it]\n",
      "100%|██████████| 89/89 [03:58<00:00,  2.68s/it]1.20s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s]1.62s/it]\n",
      "100%|██████████| 89/89 [01:52<00:00,  1.26s/it]7.61s/it]\n",
      "100%|██████████| 89/89 [04:26<00:00,  3.00s/it]2.32s/it]\n",
      "100%|██████████| 89/89 [01:04<00:00,  1.38it/s]8.20s/it]\n",
      "100%|██████████| 89/89 [03:16<00:00,  2.20s/it].54s/it] \n",
      "100%|██████████| 89/89 [01:13<00:00,  1.21it/s]6.47s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s].14s/it] \n",
      "100%|██████████| 89/89 [03:16<00:00,  2.21s/it].96s/it]\n",
      "100%|██████████| 89/89 [04:17<00:00,  2.90s/it].80s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.50it/s].89s/it]\n",
      "100%|██████████| 89/89 [02:30<00:00,  1.69s/it].26s/it]\n",
      "100%|██████████| 89/89 [02:13<00:00,  1.50s/it].47s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.41it/s].27s/it]\n",
      "100%|██████████| 89/89 [04:14<00:00,  2.86s/it].27s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s].82s/it]\n",
      "100%|██████████| 89/89 [03:18<00:00,  2.23s/it].10s/it]\n",
      "100%|██████████| 89/89 [05:22<00:00,  3.63s/it].43s/it]\n",
      "100%|██████████| 89/89 [01:22<00:00,  1.08it/s].82s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.43it/s].26s/it]\n",
      "100%|██████████| 89/89 [02:42<00:00,  1.83s/it].17s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.49it/s].70s/it]\n",
      "100%|██████████| 89/89 [01:18<00:00,  1.13it/s].71s/it]\n",
      "100%|██████████| 89/89 [02:14<00:00,  1.51s/it].99s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s].05s/it]\n",
      "100%|██████████| 89/89 [03:41<00:00,  2.49s/it].96s/it]\n",
      "100%|██████████| 89/89 [01:03<00:00,  1.40it/s].72s/it]\n",
      "100%|██████████| 89/89 [03:54<00:00,  2.64s/it].74s/it]\n",
      "100%|██████████| 89/89 [01:29<00:00,  1.00s/it].26s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.45it/s].92s/it]\n",
      "100%|██████████| 89/89 [02:50<00:00,  1.91s/it].51s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.45it/s].05s/it]\n",
      "100%|██████████| 89/89 [01:06<00:00,  1.33it/s].08s/it]\n",
      "100%|██████████| 89/89 [02:18<00:00,  1.56s/it].27s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.44it/s].10s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s].61s/it]\n",
      "100%|██████████| 89/89 [01:38<00:00,  1.11s/it].03s/it]\n",
      "100%|██████████| 89/89 [02:03<00:00,  1.39s/it].51s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.49it/s].36s/it]\n",
      "100%|██████████| 89/89 [03:37<00:00,  2.44s/it].26s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s].16s/it]\n",
      "100%|██████████| 89/89 [03:17<00:00,  2.21s/it].67s/it]\n",
      "100%|██████████| 89/89 [01:19<00:00,  1.12it/s].85s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s].36s/it]\n",
      "100%|██████████| 89/89 [01:09<00:00,  1.28it/s].45s/it]\n",
      "100%|██████████| 89/89 [02:21<00:00,  1.59s/it].50s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s].24s/it]\n",
      "100%|██████████| 89/89 [02:23<00:00,  1.61s/it].55s/it]\n",
      "100%|██████████| 89/89 [03:16<00:00,  2.21s/it].36s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.46it/s].28s/it]\n",
      "100%|██████████| 89/89 [02:12<00:00,  1.49s/it].86s/it]\n",
      "100%|██████████| 89/89 [01:01<00:00,  1.45it/s].27s/it]\n",
      "100%|██████████| 89/89 [02:48<00:00,  1.89s/it].73s/it]\n",
      "100%|██████████| 89/89 [01:32<00:00,  1.04s/it].97s/it]\n",
      "100%|██████████| 89/89 [00:59<00:00,  1.49it/s].33s/it]\n",
      "100%|██████████| 89/89 [01:04<00:00,  1.38it/s].75s/it]\n",
      "100%|██████████| 89/89 [01:21<00:00,  1.10it/s].10s/it]\n",
      "100%|██████████| 89/89 [02:59<00:00,  2.01s/it].01s/it]\n",
      "100%|██████████| 89/89 [01:06<00:00,  1.33it/s].46s/it]\n",
      "100%|██████████| 89/89 [01:34<00:00,  1.06s/it].82s/it]\n",
      "100%|██████████| 89/89 [01:11<00:00,  1.24it/s].27s/it]\n",
      "100%|██████████| 89/89 [01:03<00:00,  1.40it/s].58s/it]\n",
      "100%|██████████| 89/89 [03:18<00:00,  2.23s/it].60s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.43it/s].28s/it]\n",
      "100%|██████████| 89/89 [04:53<00:00,  3.29s/it].21s/it]\n",
      "100%|██████████| 89/89 [01:02<00:00,  1.42it/s].91s/it]\n",
      "100%|██████████| 89/89 [03:28<00:00,  2.34s/it].48s/it]\n",
      "100%|██████████| 89/89 [01:18<00:00,  1.14it/s].42s/it]\n",
      "100%|██████████| 89/89 [02:20<00:00,  1.58s/it].33s/it]\n",
      "100%|██████████| 89/89 [01:03<00:00,  1.41it/s]9s/it]  \n",
      "100%|██████████| 89/89 [03:37<00:00,  2.45s/it]3s/it]\n",
      "100%|██████████| 89/89 [01:03<00:00,  1.41it/s]3s/it]\n",
      "100%|██████████| 89/89 [01:23<00:00,  1.07it/s]7s/it]\n",
      "100%|██████████| 89/89 [01:00<00:00,  1.47it/s]4s/it]\n",
      "100%|██████████| 89/89 [03:53<00:00,  2.62s/it]5s/it]\n",
      "100%|██████████| 89/89 [00:58<00:00,  1.51it/s]4s/it]\n",
      "100%|██████████| 200/200 [25:05:15<00:00, 451.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20da11dd8d154aacb9121b21c207de74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1635.996 MB of 1635.996 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇█▇██████████▇▇</td></tr><tr><td>FK ROI < 30</td><td>▁▃▅▄▃▃▂▁▂▁▂▂▂▂▂▃▂▃▄▅▅▆▅▆█▇██▇▇██▇▇▆▇▇▆▆▄</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇█▇██████████▇▇</td></tr><tr><td>ROI < 30</td><td>▁▃▄▄▃▃▂▂▂▁▁▂▂▂▂▃▂▄▄▅▅▆▆▆█▇██▇▇██▇▇▆▇▇▆▆▅</td></tr><tr><td>accuracy</td><td>▁▁▂▃▅▅▆▇█████████▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▆▇▆▆▇▆▆▆</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>correct</td><td>▁▁▂▃▅▅▆▇█████████▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▆▇▆▆▇▆▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>▆▅▄▃▃▂▂▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>multibet outlay</td><td>▄▅▅▅▄▃▂▂▂▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>multibet profit</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇█▇██████████▇▇</td></tr><tr><td>multibet profit < 30</td><td>▁▃▃▃▂▂▂▁▂▁▁▁▂▂▂▂▂▃▄▄▅▅▅▆▇▇█▇▇▇██▇▇▆▇▇▆▆▄</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>multibet profit sd</td><td>▅▆▅▅▄▃▃▂▂▁▁▁▁▁▁▁▁▂▂▃▂▃▃▃▃▄▄▄▅▅▆▆▆▇▅▇▇█▆▇</td></tr><tr><td>profit</td><td>▆▇▇▄▂▁▁▂▁▁▁▃▃▄▃▅▄▄▄▃▄▅▅▃▅▅▄▅▃▄▇▅▇█▅██▇▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.00931</td></tr><tr><td>FK ROI < 30</td><td>0.00549</td></tr><tr><td>ROI</td><td>-0.00996</td></tr><tr><td>ROI < 30</td><td>0.0097</td></tr><tr><td>accuracy</td><td>0.25125</td></tr><tr><td>batch_before_backwards</td><td>15</td></tr><tr><td>batch_loss</td><td>16.82219</td></tr><tr><td>correct</td><td>5339</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>epoch_loss</td><td>16.82219</td></tr><tr><td>loss_val</td><td>2.12696</td></tr><tr><td>multibet outlay</td><td>780749.63053</td></tr><tr><td>multibet outlay < 30</td><td>598025.37957</td></tr><tr><td>multibet profit < 30</td><td>5802.35394</td></tr><tr><td>multibet profit < 30 sd</td><td>32.80283</td></tr><tr><td>multibet profit sd</td><td>56.71181</td></tr><tr><td>profit</td><td>15331.3711</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rich-sweep-3</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/lr2vc938\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/lr2vc938</a><br/>Synced 5 W&B file(s), 300 media file(s), 300 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_121652-lr2vc938\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 92ar0lvt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003426172313198346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 111168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230313_132820-92ar0lvt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/92ar0lvt\" target=\"_blank\">sweet-sweep-4</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/mzjxl651\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/mzjxl651</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003426172313198346, 'len_data': 111168, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "200\n",
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 200, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003426172313198346, 'len_data': 111168, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [03:16<00:00,  1.83it/s]\n",
      "100%|██████████| 359/359 [06:18<00:00,  1.06s/it]t]\n",
      "100%|██████████| 359/359 [05:16<00:00,  1.13it/s]t]\n",
      "100%|██████████| 359/359 [05:07<00:00,  1.17it/s]t]\n",
      "100%|██████████| 359/359 [03:27<00:00,  1.73it/s]t]\n",
      "100%|██████████| 359/359 [03:53<00:00,  1.53it/s]t]\n",
      "100%|██████████| 359/359 [05:37<00:00,  1.06it/s]/it]\n",
      "100%|██████████| 359/359 [04:04<00:00,  1.47it/s]/it]\n",
      "100%|██████████| 359/359 [05:16<00:00,  1.13it/s]/it]\n",
      "100%|██████████| 359/359 [05:20<00:00,  1.12it/s]/it]\n",
      "100%|██████████| 359/359 [08:36<00:00,  1.44s/it]s/it]\n",
      "100%|██████████| 359/359 [08:07<00:00,  1.36s/it]s/it]\n",
      "100%|██████████| 359/359 [05:36<00:00,  1.07it/s]s/it]\n",
      "100%|██████████| 359/359 [05:16<00:00,  1.13it/s]s/it]\n",
      "100%|██████████| 359/359 [05:12<00:00,  1.15it/s]s/it]\n",
      "100%|██████████| 359/359 [07:08<00:00,  1.19s/it]s/it]\n",
      "100%|██████████| 359/359 [06:35<00:00,  1.10s/it]s/it]\n",
      "100%|██████████| 359/359 [06:16<00:00,  1.05s/it]s/it]\n",
      "100%|██████████| 359/359 [03:42<00:00,  1.61it/s]s/it]\n",
      "100%|██████████| 359/359 [07:24<00:00,  1.24s/it]s/it]\n",
      "100%|██████████| 359/359 [04:14<00:00,  1.41it/s]s/it]\n",
      "100%|██████████| 359/359 [06:56<00:00,  1.16s/it]s/it]\n",
      "100%|██████████| 359/359 [05:26<00:00,  1.10it/s]s/it]\n",
      "100%|██████████| 359/359 [06:37<00:00,  1.11s/it]s/it]\n",
      "100%|██████████| 359/359 [07:40<00:00,  1.28s/it]s/it]\n",
      "100%|██████████| 359/359 [06:49<00:00,  1.14s/it]s/it]\n",
      "100%|██████████| 359/359 [04:26<00:00,  1.35it/s]s/it]\n",
      "100%|██████████| 359/359 [05:37<00:00,  1.07it/s]s/it]\n",
      "100%|██████████| 359/359 [05:29<00:00,  1.09it/s]s/it]\n",
      "100%|██████████| 359/359 [04:37<00:00,  1.29it/s]s/it]\n",
      "100%|██████████| 359/359 [05:42<00:00,  1.05it/s]s/it]\n",
      "100%|██████████| 359/359 [03:18<00:00,  1.81it/s]s/it]\n",
      "100%|██████████| 359/359 [06:45<00:00,  1.13s/it]s/it]\n",
      "100%|██████████| 359/359 [03:35<00:00,  1.67it/s]s/it]\n",
      "100%|██████████| 359/359 [06:24<00:00,  1.07s/it]s/it]\n",
      "100%|██████████| 359/359 [04:24<00:00,  1.36it/s]s/it]\n",
      "100%|██████████| 359/359 [05:17<00:00,  1.13it/s]s/it]\n",
      "100%|██████████| 359/359 [03:56<00:00,  1.52it/s]s/it]\n",
      "100%|██████████| 359/359 [04:38<00:00,  1.29it/s]s/it]\n",
      "100%|██████████| 359/359 [05:49<00:00,  1.03it/s]s/it]\n",
      "100%|██████████| 359/359 [03:48<00:00,  1.57it/s]s/it]\n",
      "100%|██████████| 359/359 [10:32<00:00,  1.76s/it]s/it]\n",
      "100%|██████████| 359/359 [05:26<00:00,  1.10it/s]s/it]\n",
      "100%|██████████| 359/359 [08:28<00:00,  1.42s/it]s/it]\n",
      "100%|██████████| 359/359 [06:34<00:00,  1.10s/it]s/it]\n",
      "100%|██████████| 359/359 [08:31<00:00,  1.42s/it]s/it]\n",
      "100%|██████████| 359/359 [04:50<00:00,  1.24it/s]s/it]\n",
      "100%|██████████| 359/359 [08:11<00:00,  1.37s/it]s/it]\n",
      "100%|██████████| 359/359 [05:33<00:00,  1.07it/s]s/it]\n",
      "100%|██████████| 359/359 [05:23<00:00,  1.11it/s]s/it]\n",
      "100%|██████████| 359/359 [06:56<00:00,  1.16s/it]s/it]\n",
      "100%|██████████| 359/359 [04:18<00:00,  1.39it/s]6s/it]\n",
      "100%|██████████| 359/359 [07:18<00:00,  1.22s/it]4s/it]\n",
      "100%|██████████| 359/359 [08:13<00:00,  1.37s/it]3s/it]\n",
      "100%|██████████| 359/359 [04:54<00:00,  1.22it/s]0s/it]\n",
      "100%|██████████| 359/359 [06:12<00:00,  1.04s/it]7s/it]\n",
      "100%|██████████| 359/359 [03:34<00:00,  1.67it/s]1s/it]\n",
      "100%|██████████| 359/359 [04:01<00:00,  1.49it/s]2s/it]\n",
      "100%|██████████| 359/359 [03:59<00:00,  1.50it/s]4s/it]\n",
      "100%|██████████| 359/359 [03:32<00:00,  1.69it/s]6s/it]\n",
      "100%|██████████| 359/359 [04:54<00:00,  1.22it/s]7s/it]\n",
      "100%|██████████| 359/359 [03:51<00:00,  1.55it/s]9s/it]\n",
      "100%|██████████| 359/359 [06:59<00:00,  1.17s/it]0s/it]\n",
      "100%|██████████| 359/359 [07:54<00:00,  1.32s/it]3s/it]\n",
      "100%|██████████| 359/359 [07:08<00:00,  1.19s/it]2s/it]\n",
      "100%|██████████| 359/359 [07:53<00:00,  1.32s/it]6s/it]\n",
      "100%|██████████| 359/359 [06:53<00:00,  1.15s/it]2s/it]\n",
      "100%|██████████| 359/359 [07:49<00:00,  1.31s/it]8s/it]\n",
      "100%|██████████| 359/359 [05:08<00:00,  1.16it/s]8s/it]\n",
      "100%|██████████| 359/359 [06:53<00:00,  1.15s/it]0s/it]\n",
      "100%|██████████| 359/359 [05:11<00:00,  1.15it/s]8s/it]\n",
      "100%|██████████| 359/359 [04:48<00:00,  1.25it/s]1s/it]\n",
      "100%|██████████| 359/359 [08:35<00:00,  1.44s/it]4s/it]\n",
      "100%|██████████| 359/359 [06:13<00:00,  1.04s/it]7s/it]\n",
      "100%|██████████| 359/359 [06:13<00:00,  1.04s/it]1s/it]\n",
      "100%|██████████| 359/359 [03:50<00:00,  1.56it/s]4s/it]\n",
      "100%|██████████| 359/359 [10:59<00:00,  1.84s/it]3s/it]\n",
      "100%|██████████| 359/359 [09:23<00:00,  1.57s/it]7s/it]\n",
      "100%|██████████| 359/359 [07:41<00:00,  1.29s/it]2s/it]\n",
      "100%|██████████| 359/359 [03:41<00:00,  1.62it/s]6s/it]\n",
      "100%|██████████| 359/359 [06:00<00:00,  1.00s/it]7s/it]\n",
      "100%|██████████| 359/359 [15:58<00:00,  2.67s/it]3s/it]\n",
      "100%|██████████| 359/359 [05:43<00:00,  1.04it/s]15s/it]\n",
      "100%|██████████| 359/359 [06:19<00:00,  1.06s/it]7s/it] \n",
      "100%|██████████| 359/359 [10:37<00:00,  1.78s/it]0s/it]\n",
      "100%|██████████| 359/359 [06:25<00:00,  1.07s/it]8s/it]\n",
      "100%|██████████| 359/359 [09:54<00:00,  1.66s/it]4s/it]\n",
      "100%|██████████| 359/359 [03:55<00:00,  1.52it/s]0s/it]\n",
      "100%|██████████| 359/359 [04:36<00:00,  1.30it/s]1s/it]\n",
      "100%|██████████| 359/359 [04:07<00:00,  1.45it/s]2s/it]\n",
      "100%|██████████| 359/359 [05:11<00:00,  1.15it/s]3s/it]\n",
      "100%|██████████| 359/359 [04:14<00:00,  1.41it/s]6s/it]\n",
      "100%|██████████| 359/359 [03:43<00:00,  1.60it/s]6s/it]\n",
      "100%|██████████| 359/359 [06:39<00:00,  1.11s/it]7s/it]\n",
      "100%|██████████| 359/359 [03:48<00:00,  1.57it/s]6s/it]\n",
      "100%|██████████| 359/359 [03:53<00:00,  1.54it/s]6s/it]\n",
      "100%|██████████| 359/359 [04:27<00:00,  1.34it/s]4s/it]\n",
      "100%|██████████| 359/359 [04:41<00:00,  1.27it/s]5s/it]\n",
      "100%|██████████| 359/359 [03:41<00:00,  1.62it/s]9s/it]\n",
      "100%|██████████| 359/359 [07:45<00:00,  1.30s/it]0s/it]\n",
      "100%|██████████| 359/359 [03:35<00:00,  1.66it/s]90s/it]\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"gru_sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stop\n\u001b[0;32m      2\u001b[0m model \u001b[39m=\u001b[39m GRUNet(\u001b[39m203\u001b[39m,\u001b[39m64\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(model_state_dict)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "stop\n",
    "model = GRUNet(203,64).to(device)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset.create_hidden_states_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48ca33c5a1168302a4f8eae355aad1c03b1396f568d40bc174a6e6aabe725d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
