{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "from rnn_classes import Dog, DogInput, Race, Races, GRUNet, smallGRUNet, smalll_lin_GRUNet, smalll_prelin_GRUNet\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n",
    "from training_testing import validate_model, train_regular, train_log, train_super_batch, train_super_batch_KL, train_super_batch_L1, train_regular_L1,train_regular_one_hot\n",
    "from model_saver import model_saver, model_saver_wandb\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(0).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_to_bf(model:GRUNet,raceDB:Races,example_ct):\n",
    "    with torch.no_grad():\n",
    "        sft_max = nn.Softmax(dim=-1)\n",
    "        l_sftmax = nn.LogSoftmax(dim=-1)\n",
    "        nnl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        full_test_races = raceDB.get_test_input(range(0,len(raceDB.test_race_ids)))\n",
    "        full_test_races_w_prices = []\n",
    "        excluded, included = 0,0\n",
    "        for r in full_test_races:\n",
    "            if 0 in r.prices or -1 in r.prices:\n",
    "                excluded+=1\n",
    "            else:\n",
    "                full_test_races_w_prices.append(r)\n",
    "                included+=1\n",
    "        print(included,excluded)\n",
    "\n",
    "        output = l_sftmax(model(full_test_races_w_prices))\n",
    "        bf_prices = torch.log(torch.tensor([x.implied_prob for x in full_test_races_w_prices ]).to('cuda:0'))\n",
    "        full_classes = torch.stack([x.classes for x in full_test_races_w_prices ])\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(f\"our loss = {nnl_loss(output,full_classes)}\")\n",
    "        print(f\"their loss = {nnl_loss(bf_prices ,full_classes)}\")\n",
    "        wandb.log({\"our loss\":nnl_loss(output,full_classes), \"their loss\":nnl_loss(bf_prices ,full_classes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168053, 19)\n",
      "(1168053, 19)\n",
      "(349251, 22)\n",
      "Latest date = 2023-03-06 00:00:00\n",
      "num_features_per_dog=77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14800 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 14800/14800 [02:17<00:00, 107.60it/s]\n",
      "  0%|          | 0/48862 [00:00<?, ?it/s]c:\\Users\\Nick\\.conda\\envs\\PYTORCH\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 48862/48862 [01:31<00:00, 532.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 48862, number of unique dogs = 14800\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "#dog_stats_file = open( 'new gru input 2023-01.npy', 'rb')\n",
    "hidden_size = 64\n",
    "raceDB = build_dataset('gru_inputs_new_pir.npy', hidden_size ,state_filter=\"NSW\", margin_type='boosted_sftmin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        (Healesville, 350.0)\n",
      "1            (Horsham, 410.0)\n",
      "2        (The Meadows, 525.0)\n",
      "3        (Warrnambool, 390.0)\n",
      "4        (The Meadows, 525.0)\n",
      "                 ...         \n",
      "48857       (Ballarat, 390.0)\n",
      "48858       (Ballarat, 390.0)\n",
      "48859       (Ballarat, 450.0)\n",
      "48860       (Ballarat, 450.0)\n",
      "48861       (Ballarat, 545.0)\n",
      "Length: 48862, dtype: object\n"
     ]
    }
   ],
   "source": [
    "raceDB.create_new_weights_v2()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 39923, Test examples 8939\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-08-01\", \"%Y-%m-%d\").date()\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0]\n",
    "model = smalll_prelin_GRUNet(input_size,64)\n",
    "prev_model_file = 'polar-paper-2'\n",
    "\n",
    "if prev_model_file!=None:\n",
    "    model_name = prev_model_file\n",
    "    model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_450.pt\"\n",
    "    model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "    raceDB.fill_hidden_states_from_dict(hidden_dict=model_data['db'])\n",
    "    model.load_state_dict(model_data['model_state_dict'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def predict_model(model,predDB):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        races_idx = range(0,len(predDB.raceIDs)-1)\n",
    "        race = predDB.get_race_input(races_idx)\n",
    "        X = race\n",
    "        # for i,r in enumerate(race):\n",
    "        #     print(r.raceid, r.track_name)\n",
    "        #     #print(i,r.lstm_input())\n",
    "\n",
    "        output = model(X)\n",
    "        \n",
    "        print(output)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            print(r.raceid, r.track_name, r.dogs[predicted[i].item()])\n",
    "\n",
    "        print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None,prev_model_file=None):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"GRU - FastTrack - AUS Testing - v2\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      wandb.define_metric(\"multibet profit\", summary=\"max\")\n",
    "      \n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "      input_size = raceDB.get_race_input([0,1])[0].full_input.shape[0] #create fix so messy\n",
    "\n",
    "      model = smalll_prelin_GRUNet(input_size,config['hidden_size'])\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      if prev_model_file!=None:\n",
    "        model_name = prev_model_file\n",
    "        model_loc = f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_450.pt\"\n",
    "        model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "        raceDB.fill_hidden_states_from_dict(hidden_dict=model_data['db'])\n",
    "        model.load_state_dict(model_data['model_state_dict'])\n",
    "        config['parent model'] = prev_model_file\n",
    "\n",
    "\n",
    "      raceDB.to_cuda()\n",
    "\n",
    "      criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "      #criterion = nn.SmoothL1Loss(reduction='none', beta=0.1)\n",
    "      # optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.Adadelta(model.parameters())\n",
    "      optimizer = optim.RMSprop(model.parameters(), lr=config['learning_rate'])\n",
    "      # optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9)\n",
    "      # optimizer = optim.ASGD(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "      print(criterion, optimizer)\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',threshold=0.0001, patience=10000, verbose=True, factor=0.5)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        train_regular(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      except KeyboardInterrupt:\n",
    "        print(\"finished Early\")\n",
    "      dataset.create_hidden_states_dict()\n",
    "      model_saver_wandb(model, optimizer, 450, 0.1, dataset.hidden_states_dict_gru, model_name=\"long nsw new  22000 RUN\")\n",
    "      if sweep:\n",
    "        raceDB.reset_all_lstm_states\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 500, 'dropout': 0.3, 'epochs': 2000, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.000087, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1,'batch_before_backwards':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230317_095045-3ian0saa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing%20-%20v2/runs/3ian0saa\" target=\"_blank\">neat-universe-4</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing%20-%20v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'batch_size': 500, 'dropout': 0.3, 'epochs': 2000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 8.7e-05, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 7}\n",
      "2000\n",
      "{'hidden_size': 64, 'batch_size': 500, 'dropout': 0.3, 'epochs': 2000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 8.7e-05, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1, 'batch_before_backwards': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48862/48862 [00:03<00:00, 15293.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled =1901\n",
      "empty  =388995\n",
      "0.004863186116000164null_dog=0\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 8.7e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(686, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(686, 64)\n",
      "  (gru2): GRUCell(686, 64)\n",
      "  (gru3): GRUCell(686, 64)\n",
      "  (gru4): GRUCell(686, 64)\n",
      "  (gru5): GRUCell(686, 64)\n",
      "  (gru6): GRUCell(686, 64)\n",
      "  (gru7): GRUCell(686, 64)\n",
      "  (gru8): GRUCell(686, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:43<00:00,  1.80it/s]\n",
      "100%|██████████| 79/79 [00:43<00:00,  1.81it/s]s/it]\n",
      "100%|██████████| 79/79 [00:54<00:00,  1.44it/s]s/it]\n",
      "100%|██████████| 79/79 [00:44<00:00,  1.78it/s]s/it]\n",
      "100%|██████████| 79/79 [01:14<00:00,  1.06it/s]s/it]\n",
      "100%|██████████| 79/79 [01:18<00:00,  1.01it/s]s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.58it/s]s/it]\n",
      "100%|██████████| 79/79 [00:53<00:00,  1.47it/s]s/it]\n",
      "100%|██████████| 79/79 [01:05<00:00,  1.20it/s]s/it]\n",
      "100%|██████████| 79/79 [00:47<00:00,  1.66it/s]s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.59it/s]3s/it]\n",
      "100%|██████████| 79/79 [00:54<00:00,  1.44it/s]2s/it]\n",
      "100%|██████████| 79/79 [00:51<00:00,  1.54it/s]4s/it]\n",
      "100%|██████████| 79/79 [00:53<00:00,  1.49it/s]9s/it]\n",
      "100%|██████████| 79/79 [01:02<00:00,  1.25it/s]3s/it]\n",
      "100%|██████████| 79/79 [00:51<00:00,  1.53it/s]5s/it]\n",
      "100%|██████████| 79/79 [00:50<00:00,  1.57it/s]4s/it]\n",
      "100%|██████████| 79/79 [00:42<00:00,  1.86it/s]5s/it]\n",
      "100%|██████████| 79/79 [00:42<00:00,  1.87it/s]1s/it]\n",
      "100%|██████████| 79/79 [00:52<00:00,  1.51it/s]6s/it]\n",
      "100%|██████████| 79/79 [00:43<00:00,  1.80it/s]2s/it]\n",
      "100%|██████████| 79/79 [00:40<00:00,  1.95it/s]2s/it]\n",
      "100%|██████████| 79/79 [00:41<00:00,  1.89it/s]1s/it]\n",
      "100%|██████████| 79/79 [00:43<00:00,  1.83it/s]3s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.61it/s].36s/it]\n",
      "100%|██████████| 79/79 [00:55<00:00,  1.42it/s].00s/it]\n",
      "100%|██████████| 79/79 [00:46<00:00,  1.69it/s].44s/it]\n",
      "100%|██████████| 79/79 [00:48<00:00,  1.61it/s].85s/it]\n",
      "100%|██████████| 79/79 [00:55<00:00,  1.42it/s].74s/it]\n",
      "100%|██████████| 79/79 [00:51<00:00,  1.54it/s].63s/it]\n",
      "100%|██████████| 79/79 [01:13<00:00,  1.07it/s].64s/it]\n",
      "100%|██████████| 79/79 [00:50<00:00,  1.56it/s].83s/it]\n",
      "100%|██████████| 79/79 [00:48<00:00,  1.64it/s].55s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.61it/s].10s/it]\n",
      "100%|██████████| 79/79 [00:51<00:00,  1.54it/s].53s/it]\n",
      "100%|██████████| 79/79 [00:47<00:00,  1.67it/s].25s/it]\n",
      "100%|██████████| 79/79 [00:50<00:00,  1.56it/s].13s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.60it/s].71s/it]\n",
      "100%|██████████| 79/79 [00:48<00:00,  1.62it/s].58s/it]\n",
      "100%|██████████| 79/79 [00:48<00:00,  1.63it/s].53s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.61it/s].87s/it]\n",
      "100%|██████████| 79/79 [00:47<00:00,  1.67it/s].53s/it]\n",
      "100%|██████████| 79/79 [00:42<00:00,  1.84it/s].05s/it]\n",
      "100%|██████████| 79/79 [00:40<00:00,  1.93it/s].71s/it]\n",
      "100%|██████████| 79/79 [00:40<00:00,  1.94it/s].43s/it]\n",
      "100%|██████████| 79/79 [00:40<00:00,  1.95it/s].99s/it]\n",
      "100%|██████████| 79/79 [00:41<00:00,  1.90it/s].98s/it]\n",
      "100%|██████████| 79/79 [00:42<00:00,  1.84it/s].65s/it]\n",
      "100%|██████████| 79/79 [01:00<00:00,  1.31it/s].18s/it]\n",
      "100%|██████████| 79/79 [00:51<00:00,  1.55it/s].00s/it]\n",
      "100%|██████████| 79/79 [00:50<00:00,  1.57it/s].92s/it]\n",
      "100%|██████████| 79/79 [00:59<00:00,  1.34it/s].66s/it]\n",
      "100%|██████████| 79/79 [00:41<00:00,  1.91it/s].04s/it]\n",
      "100%|██████████| 79/79 [00:58<00:00,  1.34it/s].67s/it]\n",
      "100%|██████████| 79/79 [00:43<00:00,  1.82it/s].60s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.61it/s].91s/it]\n",
      "100%|██████████| 79/79 [00:47<00:00,  1.65it/s].16s/it]\n",
      "100%|██████████| 79/79 [00:47<00:00,  1.65it/s].98s/it]\n",
      "100%|██████████| 79/79 [00:43<00:00,  1.83it/s].71s/it]\n",
      "100%|██████████| 79/79 [00:43<00:00,  1.83it/s].07s/it]\n",
      "100%|██████████| 79/79 [00:41<00:00,  1.90it/s].16s/it]\n",
      "100%|██████████| 79/79 [00:40<00:00,  1.95it/s].75s/it]\n",
      "100%|██████████| 79/79 [00:59<00:00,  1.33it/s].73s/it]\n",
      "100%|██████████| 79/79 [01:08<00:00,  1.16it/s].75s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.59it/s].93s/it]\n",
      "100%|██████████| 79/79 [01:13<00:00,  1.08it/s].68s/it]\n",
      "100%|██████████| 79/79 [00:58<00:00,  1.35it/s].92s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.60it/s].58s/it]\n",
      "100%|██████████| 79/79 [00:49<00:00,  1.60it/s].75s/it]\n",
      "100%|██████████| 79/79 [01:04<00:00,  1.23it/s].40s/it]\n",
      "100%|██████████| 79/79 [00:45<00:00,  1.72it/s].97s/it]\n",
      "100%|██████████| 79/79 [01:02<00:00,  1.26it/s].81s/it]\n",
      "100%|██████████| 79/79 [01:09<00:00,  1.14it/s].53s/it]\n",
      "100%|██████████| 79/79 [00:50<00:00,  1.57it/s].27s/it]\n",
      "100%|██████████| 79/79 [01:01<00:00,  1.28it/s].61s/it]\n",
      "100%|██████████| 79/79 [00:42<00:00,  1.85it/s].15s/it]\n",
      "100%|██████████| 79/79 [00:52<00:00,  1.50it/s].41s/it]\n",
      "100%|██████████| 79/79 [00:56<00:00,  1.39it/s].39s/it]\n",
      "100%|██████████| 79/79 [01:04<00:00,  1.23it/s].11s/it]\n",
      "100%|██████████| 79/79 [01:04<00:00,  1.22it/s].22s/it]\n",
      "100%|██████████| 79/79 [00:51<00:00,  1.52it/s].77s/it]\n",
      "100%|██████████| 79/79 [00:50<00:00,  1.58it/s].62s/it]\n",
      "100%|██████████| 79/79 [01:00<00:00,  1.30it/s].36s/it]\n",
      "100%|██████████| 79/79 [00:50<00:00,  1.57it/s].32s/it]\n",
      "100%|██████████| 79/79 [00:53<00:00,  1.49it/s].71s/it]\n",
      "100%|██████████| 79/79 [00:39<00:00,  2.02it/s].21s/it]\n",
      "100%|██████████| 79/79 [00:43<00:00,  1.83it/s].48s/it]\n",
      "  4%|▍         | 86/2000 [3:31:55<78:36:40, 147.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Early\n",
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26de5fac73cb4ea885d26c2abfe44b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='377.377 MB of 377.377 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>█▁▂▁▂▂▂▂▁▂▁▂▂▂▃▃▃▃▃▃▃▄▅▃▄▄▄▄▃▄▅▄▃▃▄▄▄▃▂▄</td></tr><tr><td>FK ROI < 30</td><td>█▁▂▁▃▂▂▃▃▃▂▃▃▄▅▅▃▃▃▃▃▄▇▄▄▅▅▇▆▆▆▇▆▅▆▆▄▃▃▄</td></tr><tr><td>ROI</td><td>█▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▆▄▄▄▄▄▃▄▅▄▃▃▄▃▄▃▂▄</td></tr><tr><td>ROI < 30</td><td>█▁▁▁▃▃▃▃▄▄▄▄▄▅▆▆▅▅▅▅▅▆█▆▅▆▆▇▆▆▆▇▆▆▆▅▅▄▄▄</td></tr><tr><td>accuracy</td><td>▂▁▁▂▂▂▂▃▄▃▄▄▄▄▄▄▄▄▅▄▅▅▅▄▆▅▆▆▆▆▆▇▇▇▇▇▇▇█▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█████▁█▁█▁▇█▇▇▇▇▁▇▁▇▁▇▇▇▇▁▇▁▇▁▇▁▇▇▇▇▁▇▁▇</td></tr><tr><td>correct</td><td>▂▁▁▂▂▂▂▃▄▃▄▄▄▄▄▄▄▄▅▄▅▅▅▄▆▅▆▆▆▆▆▇▇▇▇▇▇▇█▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▆▇█████▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▂▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>█▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▆▄▄▅▅▄▃▄▅▄▃▄▅▄▄▃▂▄</td></tr><tr><td>multibet profit < 30</td><td>█▁▁▁▃▃▃▃▄▄▄▄▄▅▆▅▄▅▅▄▅▆█▆▅▅▆▇▆▆▆▇▆▅▅▅▅▄▃▃</td></tr><tr><td>multibet profit < 30 sd</td><td>▄▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>multibet profit sd</td><td>█▇▇▇▇▇▆▆▆▆▅▆▅▅▅▅▅▅▅▅▅▄▅▃▄▄▄▃▂▃▃▂▂▂▂▂▂▂▁▂</td></tr><tr><td>profit</td><td>█▆▆▇▆▆▆▆▆▆▆▅▅▄▄▄▃▃▃▂▄▃▃▂▂▃▃▂▂▃▂▃▂▂▂▂▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.03882</td></tr><tr><td>FK ROI < 30</td><td>-0.00965</td></tr><tr><td>ROI</td><td>-0.0446</td></tr><tr><td>ROI < 30</td><td>-0.01322</td></tr><tr><td>accuracy</td><td>0.23771</td></tr><tr><td>batch_before_backwards</td><td>7</td></tr><tr><td>batch_loss</td><td>6.16114</td></tr><tr><td>correct</td><td>2080</td></tr><tr><td>epoch</td><td>86</td></tr><tr><td>epoch_loss</td><td>6.16114</td></tr><tr><td>loss_val</td><td>1.91542</td></tr><tr><td>multibet outlay</td><td>277965.37434</td></tr><tr><td>multibet outlay < 30</td><td>153969.53268</td></tr><tr><td>multibet profit < 30</td><td>-2036.19475</td></tr><tr><td>multibet profit < 30 sd</td><td>19.0213</td></tr><tr><td>multibet profit sd</td><td>47.97142</td></tr><tr><td>profit</td><td>6272.93487</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">neat-universe-4</strong>: <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing%20-%20v2/runs/3ian0saa\" target=\"_blank\">https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20AUS%20Testing%20-%20v2/runs/3ian0saa</a><br/>Synced 5 W&B file(s), 131 media file(s), 131 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230317_095045-3ian0saa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static,sweep=False, prev_model_file='polar-paper-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes',\n",
      " 'metric': {'goal': 'maximize', 'name': 'ROI < 30'},\n",
      " 'parameters': {'batch_before_backwards': {'values': [5, 10, 20]},\n",
      "                'batch_size': {'values': [100, 250, 500, 1000, 5000]},\n",
      "                'dropout': {'values': [0.3]},\n",
      "                'epochs': {'values': [50]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'hidden_size': {'value': 64},\n",
      "                'l1_beta': {'value': 0.1},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.001,\n",
      "                                  'min': 1e-05},\n",
      "                'len_data': {'value': 40482},\n",
      "                'loss': {'values': ['CEL']},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adamW'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'bayes',\n",
       " 'metric': {'name': 'ROI < 30', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adamW'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3]},\n",
       "  'len_data': {'value': 40482},\n",
       "  'hidden_size': {'value': 64},\n",
       "  'epochs': {'values': [50]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'values': ['CEL']},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 1e-05, 'max': 0.001},\n",
       "  'l1_beta': {'value': 0.1},\n",
       "  'batch_size': {'values': [100, 250, 500, 1000, 5000]},\n",
       "  'batch_before_backwards': {'values': [5, 10, 20]}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"bayes\"}\n",
    "\n",
    "metric = {\"name\": \"ROI < 30\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": len(raceDB.raceIDs)},\n",
    "    \"hidden_size\": {\"value\":64}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [50]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"CEL\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\":{\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00001,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [100,250,500,1000,5000]\n",
    "        },\n",
    "        \"batch_before_backwards\": {\n",
    "            'values': [5,10,20]\n",
    "        },\n",
    "\n",
    "        # \"batch_before_backwards\": {\n",
    "        #     # a flat distribution between 0 and 0.1\n",
    "        #     \"distribution\": \"uniform\",\n",
    "        #     \"min\": 3,\n",
    "        #     \"max\": 50,\n",
    "        # },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: vjcqqbaf\n",
      "Sweep URL: https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n9de0evp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008968546486164413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230308_220239-n9de0evp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/n9de0evp\" target=\"_blank\">sage-sweep-1</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008968546486164413, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008968546486164413, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0008968546486164413\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:05<00:00,  6.00it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.49it/s]t]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]] \n",
      "100%|██████████| 32/32 [00:12<00:00,  2.50it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.41it/s]]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.28it/s]]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.55it/s]]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.50it/s]t]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.29it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.45it/s]t] \n",
      "100%|██████████| 32/32 [00:12<00:00,  2.49it/s]  \n",
      "100%|██████████| 32/32 [00:12<00:00,  2.49it/s]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.25it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.50it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.48it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.48it/s]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.25it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.44it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.50it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.50it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.50it/s]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.17it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.31it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.18it/s]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.21it/s]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.26it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.59it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.47it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.45it/s]t]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.18it/s]t]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.30it/s]it]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.50it/s]t] \n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]t]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.53it/s]t]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]t]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.52it/s]t]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.56it/s]t]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.48it/s]t]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.52it/s]t]\n",
      "100%|██████████| 50/50 [1:17:20<00:00, 92.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32302ab533f343c28070204cecc27a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.843 MB of 180.843 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▃▃▄▄▅▅▅▅▅▅▄▆▆▆▇▇▇█▇▇▆▆▅▆▇▇███▇▇▇▇▆▇</td></tr><tr><td>FK ROI < 30</td><td>▇▄▅▅▄▅▆▇▇▇▇█▆▇▆▂▆▆▇▇▆▆▆▆▆▅▄▂▁▃▄▄█▇▆▅▄▃▁▁</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▃▃▄▄▅▅▅▅▅▅▄▆▆▆▇▇▇█▇▇▆▆▅▆▇▇███▇▇▇▆▆▇</td></tr><tr><td>ROI < 30</td><td>▆▃▄▄▄▅▅▆▇▇▇█▆▇▅▂▆▆▆▇▆▆▆▆▆▆▄▂▁▃▄▄▇▇▇▆▄▃▁▂</td></tr><tr><td>accuracy</td><td>▁▄▄▄▄▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇▇▇████▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▃▂▇▇▂▂▇▇▂▂▇▂▂▆▆▂▂▆▆▂▂▆▆▂▆▆▂▁▆▅▁▁▅▅▁▁▅▁</td></tr><tr><td>correct</td><td>▁▄▄▄▄▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇▇▇████▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▂▁▄▅▇▇▇▇▇▇▇▇▇▆▆█▆▆▆▆▅▅▅▅▄▄▅▅▅▄▃▃▄▃▂▂▂▃▃▃</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▆▆▆▆▆▆▆▇▇█▇██████</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▂▂▃▃▄▄▄▅▄▅▅▄▆▅▆▇▇▇█▇▇▆▆▅▆▇▇███▇▇▇▇▆▇</td></tr><tr><td>multibet profit < 30</td><td>▃▁▂▂▃▃▄▅▆▆▆▇▆▆▄▁▅▅▆▆▆▆▆▆▆▅▄▁▁▃▄▄██▇▆▄▃▁▂</td></tr><tr><td>multibet profit < 30 sd</td><td>▂▁▂▃▃▃▄▄▅▅▅▆▆▅▅▄▄▅▅▅▆▆▇▆▇▇▆▆▅▆▆▇█▇███▇▇▇</td></tr><tr><td>multibet profit sd</td><td>▁▂▂▃▃▃▄▄▄▄▅▅▄▅▆█▇▆▆▇▇██▇▅▃▅▇▆▆▅▆▆▆▄▁▂▃▄▃</td></tr><tr><td>profit</td><td>▆▅▅▅▄▅▆█████▅▅▆▃▅▃▅▅▅▇▇▆▅▅▇▅▁▁▁▂▃▃▄▅▆▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.07512</td></tr><tr><td>FK ROI < 30</td><td>0.03531</td></tr><tr><td>ROI</td><td>-0.08389</td></tr><tr><td>ROI < 30</td><td>0.04274</td></tr><tr><td>accuracy</td><td>0.229</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>21.46231</td></tr><tr><td>correct</td><td>1832</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>21.46231</td></tr><tr><td>loss_val</td><td>1.96103</td></tr><tr><td>multibet outlay</td><td>254242.89968</td></tr><tr><td>multibet outlay < 30</td><td>126820.88946</td></tr><tr><td>multibet profit < 30</td><td>5420.5944</td></tr><tr><td>multibet profit < 30 sd</td><td>19.97234</td></tr><tr><td>multibet profit sd</td><td>49.2321</td></tr><tr><td>profit</td><td>5445.23113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sage-sweep-1</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/n9de0evp\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/n9de0evp</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230308_220239-n9de0evp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: acsdhg01 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005987094319387174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230308_232022-acsdhg01</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/acsdhg01\" target=\"_blank\">spring-sweep-2</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005987094319387174, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005987094319387174, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0005987094319387174\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:11<00:00,  1.93s/it]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.69s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.93s/it]it] \n",
      "100%|██████████| 6/6 [00:12<00:00,  2.06s/it]it]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.67s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.95s/it]it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.05s/it]it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.94s/it]]  \n",
      "100%|██████████| 6/6 [00:12<00:00,  2.05s/it]]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.97s/it]/it]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.71s/it]t]  \n",
      "100%|██████████| 6/6 [00:12<00:00,  2.08s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.70s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.67s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.70s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.67s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.69s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.11s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.67s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.67s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.67s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.98s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.97s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.67s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.69s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.12s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.67s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.12s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.62s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.97s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.97s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.07s/it]/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.13s/it]/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.14s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.95s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]/it]\n",
      "100%|██████████| 50/50 [1:11:31<00:00, 85.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d346ff23747443eb6bf9573377de52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.167 MB of 180.167 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▄▃▄▄▅▅▅▅▅▄▄▅▆▆▆▆▅▆▆▇▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇█</td></tr><tr><td>FK ROI < 30</td><td>▁▂▄▄▄▄▄▄▆██▇▅▃▂▄▇▇██▄▃▃▃▃▄▅▅▆▅▃▃▁▂▂▂▂▃▃▄</td></tr><tr><td>ROI</td><td>▁▂▃▃▄▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▅▆▆▇█▇▇▇▇█▇▇▇▆▆▅▇█▇█</td></tr><tr><td>ROI < 30</td><td>▁▂▃▄▄▄▄▅▆██▇▅▃▃▅▇▇▇█▄▃▃▃▃▄▅▅▆▅▄▃▂▁▂▂▂▃▃▄</td></tr><tr><td>accuracy</td><td>▁▃▃▄▄▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████▇▇▇▇██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▂▂▇▇▂▂▇▇▂▂▇▂▂▇▇▂▂▆▆▂▂▆▆▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▁▃▃▄▄▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████▇▇▇▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>loss_val</td><td>█▆▆▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▂▁▁</td></tr><tr><td>multibet outlay</td><td>▁▄▇▇███████████▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▂▃▃▄▄▃▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█▇▇▇██▇█</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▃▂▃▃▄▄▄▄▄▄▄▄▅▅▅▆▄▆▆▆▇▇▇▇▇▇▇▇▇▆▅▅▆▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▂▄▄▄▄▄▅▆▇▇▇▅▄▄▅▇▇██▅▄▄▄▄▅▆▆▇▇▅▅▄▃▄▄▄▅▅▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆█▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>multibet profit sd</td><td>▅▆▇▆█▇█▇█▇▆▇▇▇▆▆▅▅▄▄▃▅▅▅▆▅▄▃▂▂▂▂▂▂▁▁▄▄▂▂</td></tr><tr><td>profit</td><td>█▃▃▄▂▁▄▃▄▄▂▃▄▁▄▄▄▃▃▄▃▃▂▅▅▆▃▂▄▅▅▄▃▁▁▂▄▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.06533</td></tr><tr><td>FK ROI < 30</td><td>0.0537</td></tr><tr><td>ROI</td><td>-0.07766</td></tr><tr><td>ROI < 30</td><td>0.05929</td></tr><tr><td>accuracy</td><td>0.24788</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>4.41887</td></tr><tr><td>correct</td><td>1983</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>4.41887</td></tr><tr><td>loss_val</td><td>2.00591</td></tr><tr><td>multibet outlay</td><td>251993.5046</td></tr><tr><td>multibet outlay < 30</td><td>132386.46552</td></tr><tr><td>multibet profit < 30</td><td>7849.51234</td></tr><tr><td>multibet profit < 30 sd</td><td>21.22772</td></tr><tr><td>multibet profit sd</td><td>46.11944</td></tr><tr><td>profit</td><td>5844.31913</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">spring-sweep-2</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/acsdhg01\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/acsdhg01</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230308_232022-acsdhg01\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4l4vf9jv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005747776142523702\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_003218-4l4vf9jv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/4l4vf9jv\" target=\"_blank\">worthy-sweep-3</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005747776142523702, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005747776142523702, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0005747776142523702\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.45it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.48it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.45it/s]t]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]t]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]] \n",
      "100%|██████████| 64/64 [00:26<00:00,  2.44it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.48it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.44it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.47it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]   \n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.48it/s]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.44it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.46it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s] \n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s] \n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.63it/s]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]t]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.43it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.41it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.63it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.60it/s]t] \n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.40it/s]t]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.55it/s]t]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]t]\n",
      "100%|██████████| 50/50 [1:22:35<00:00, 99.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc880a806be42e490439d14af747688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.915 MB of 180.915 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▄▄▅▄▅▇▄▇▇▄▇▆▆█▆▇▇▅█▆▆▇█▄▄█▄█▇▄▇▅▆▆▆▆</td></tr><tr><td>FK ROI < 30</td><td>█▇█▇▇▇▇▆▇▇▅▇▆▆▅▆▆▆▅▆▅▄▆▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▂▃</td></tr><tr><td>ROI</td><td>▁▂▃▃▄▄▅▄▅▇▄▇▇▄▇▆▆█▆▇▇▅█▆▆▆█▄▄█▄█▇▃▇▄▆▇▆▆</td></tr><tr><td>ROI < 30</td><td>█▇█▇█▇█▆▆▇▅▆▆▅▅▆▆▆▅▆▅▃▆▄▄▄▃▃▃▃▂▃▂▁▂▂▂▁▃▃</td></tr><tr><td>accuracy</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇██▇████████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▂▂▇▇▁▁▇▇▁▁▇▁▁▇▇▁▁▇▇▁▁▇▇▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇██▇████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>multibet outlay</td><td>▃▆▇██▇█▇▆▆▆▆▅▅▄▄▄▃▃▃▂▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▃▃▄▃▄▆▃▆▇▃▆▅▅█▅▇▇▅▇▆▆▆█▄▄█▄█▇▄▇▅▆▇▆▆</td></tr><tr><td>multibet profit < 30</td><td>▇▇█▇█▇█▆▇█▅▇▆▆▆▇▆▆▅▇▆▄▇▄▄▅▄▃▃▄▃▃▂▁▃▂▃▁▄▄</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▃▃▃▃▃▃▄▃▄▄▄▄▄▄▅▄▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>▇████▇▇▇▇▇▆▆▆▄▅▄▄▄▄▃▃▃▃▃▃▂▃▁▁▂▁▂▂▁▂▁▂▂▁▁</td></tr><tr><td>profit</td><td>█▄▅█▇▄█▅▅▆▅▆▇▃▆▃▃█▃▅▅▂▅▂▂▄▁▃▂▃▂▃▄▂▂▂▂▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.08293</td></tr><tr><td>FK ROI < 30</td><td>0.02246</td></tr><tr><td>ROI</td><td>-0.09257</td></tr><tr><td>ROI < 30</td><td>0.03521</td></tr><tr><td>accuracy</td><td>0.25238</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>8.17737</td></tr><tr><td>correct</td><td>2019</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>8.17737</td></tr><tr><td>loss_val</td><td>1.95222</td></tr><tr><td>multibet outlay</td><td>250360.10285</td></tr><tr><td>multibet outlay < 30</td><td>146470.80545</td></tr><tr><td>multibet profit < 30</td><td>5157.07799</td></tr><tr><td>multibet profit < 30 sd</td><td>23.2009</td></tr><tr><td>multibet profit sd</td><td>42.42009</td></tr><tr><td>profit</td><td>5478.08804</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">worthy-sweep-3</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/4l4vf9jv\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/4l4vf9jv</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_003218-4l4vf9jv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lx3yyfbc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000419134234464306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_015517-lx3yyfbc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/lx3yyfbc\" target=\"_blank\">icy-sweep-4</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000419134234464306, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000419134234464306, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.000419134234464306\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.68s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]it] \n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]]  \n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.01s/it]]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.15s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]  \n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.62s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.05s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.01s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.01s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.62s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.18s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.02s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.62s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]/it]\n",
      "100%|██████████| 50/50 [1:11:02<00:00, 85.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653bd63e744847379e2ca82db4382d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.198 MB of 180.198 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▆▅▆▆▇▇▇█████▇▇▆▇▇</td></tr><tr><td>FK ROI < 30</td><td>▁▄▆█▇▄▆▆▅▅▅▅▅▆▇▆▆▇▆▆▆▇▇▇▃▄▅▅▅▆▆▆▆▆▅▆▄▃▃▄</td></tr><tr><td>ROI</td><td>▁▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▆▅▆▆▇▇▇█████▇▇▆▇▇</td></tr><tr><td>ROI < 30</td><td>▁▄▆█▇▄▆▇▆▅▆▆▆▇▇▇▇▇▇▇▇██▇▄▄▅▆▆▇▇▇▇▇▆▇▄▃▄▄</td></tr><tr><td>accuracy</td><td>▁▃▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇██████▇██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▂▂▇▇▂▂▇▇▂▂▇▂▂▇▇▂▂▇▇▁▁▆▆▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▁▃▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇██████▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▄▆▇▇███████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇█▇▇█▇▇█████</td></tr><tr><td>multibet profit</td><td>▁▃▃▃▃▃▄▄▅▅▅▄▄▅▅▅▆▆▇▇▇▇▇▆▅▅▆▇▇▇█████▇▇▆▇▇</td></tr><tr><td>multibet profit < 30</td><td>▁▄▅▇▆▄▆▇▆▅▆▆▆▇▇▇▇▇▇▇▇███▅▅▆▇▇█████▇█▆▅▅▆</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▃▄▄▄▅▅▅▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇████████▇██</td></tr><tr><td>multibet profit sd</td><td>▄▆▆▇▆▇▆▆██▇▇▆▆▅▅▆▆▆▆▆▅▅▅▄▃▃▃▃▃▃▃▃▃▃▂▁▁▁▁</td></tr><tr><td>profit</td><td>▂▃▃▃▃▂▄▃▅▃▂▃▂▃▂▂▆▆▇▇█▇█▆▂▃▅▄▂▄▄▄▃▃▄▄▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.06859</td></tr><tr><td>FK ROI < 30</td><td>0.05228</td></tr><tr><td>ROI</td><td>-0.07885</td></tr><tr><td>ROI < 30</td><td>0.05966</td></tr><tr><td>accuracy</td><td>0.23938</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>4.59758</td></tr><tr><td>correct</td><td>1915</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>4.59758</td></tr><tr><td>loss_val</td><td>2.01401</td></tr><tr><td>multibet outlay</td><td>254397.43002</td></tr><tr><td>multibet outlay < 30</td><td>127568.04793</td></tr><tr><td>multibet profit < 30</td><td>7610.15867</td></tr><tr><td>multibet profit < 30 sd</td><td>20.33464</td></tr><tr><td>multibet profit sd</td><td>46.13456</td></tr><tr><td>profit</td><td>5493.9437</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">icy-sweep-4</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/lx3yyfbc\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/lx3yyfbc</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_015517-lx3yyfbc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ux97592m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00041223040882385273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_030642-ux97592m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/ux97592m\" target=\"_blank\">zesty-sweep-5</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00041223040882385273, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00041223040882385273, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00041223040882385273\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:09<00:00,  1.62s/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]it] \n",
      "100%|██████████| 6/6 [00:12<00:00,  2.04s/it]it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.13s/it]it]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.20s/it]it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.03s/it]it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]]  \n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.05s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]  \n",
      "100%|██████████| 6/6 [00:13<00:00,  2.17s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.05s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.03s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.05s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.68s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.04s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.70s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.06s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.06s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.04s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.08s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.63s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.62s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.05s/it]t]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.07s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.62s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.64s/it]/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.06s/it]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.65s/it]/it]\n",
      "100%|██████████| 50/50 [1:11:29<00:00, 85.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd5c2dab52343c6978add40e1b41b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.217 MB of 180.217 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▃▄▆▅▅▃▅▅▆▆▆▅▄▃▃▄▆▇▇███▇▆▅▅▆▆▇▆▇▇▇▇▆▇▇▆▆</td></tr><tr><td>FK ROI < 30</td><td>▅▂▆█▇▅▄▆▆▆▆▇▅▅▄▃▃▄▅▆▇▇▆▆▅▄▄▄▃▂▁▂▄▄▄▄▃▃▂▁</td></tr><tr><td>ROI</td><td>▁▃▄▆▅▅▄▅▅▆▆▆▅▄▃▃▄▆▇▇███▇▆▅▅▅▆▆▆▆▇▇▆▆▆▆▆▆</td></tr><tr><td>ROI < 30</td><td>▅▁▆█▇▅▄▆▆▇▇▇▆▆▅▄▃▄▅▆▇▇▇▇▅▄▄▄▄▃▁▃▅▅▄▄▃▃▂▂</td></tr><tr><td>accuracy</td><td>▁▁▂▃▃▃▃▃▄▄▄▄▅▅▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▂▂▇▇▂▂▇▇▂▂▇▂▂▇▇▂▂▆▆▁▁▆▆▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▁▁▂▃▃▃▃▃▄▄▄▄▅▅▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▅▅▆▇█████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>multibet profit</td><td>▁▂▃▆▃▃▂▃▃▅▅▆▄▃▁▁▃▅▆▇███▇▆▄▅▅▆▇▆▇▇▇▇▆▇▇▇▇</td></tr><tr><td>multibet profit < 30</td><td>▃▁▅▇▆▅▄▆▆▇▇▇▆▆▅▄▄▅▆▇███▇▆▅▅▅▅▄▃▄▆▆▆▅▅▅▄▄</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇██▇▇▇▇▇▇▇██</td></tr><tr><td>multibet profit sd</td><td>▆█▇█▇▇▇▇▆▇▆▇▆▆▅▅▅▅▅▅▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>profit</td><td>█▆▇▇▅▇▅▆▅▅▇▅▇▄▃▃▄▅▇▅▄▃▇▄▃▄▄▂▂▃▁▂▄▃▅▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.09287</td></tr><tr><td>FK ROI < 30</td><td>0.04366</td></tr><tr><td>ROI</td><td>-0.10489</td></tr><tr><td>ROI < 30</td><td>0.05293</td></tr><tr><td>accuracy</td><td>0.238</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>4.55622</td></tr><tr><td>correct</td><td>1904</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>4.55622</td></tr><tr><td>loss_val</td><td>2.01128</td></tr><tr><td>multibet outlay</td><td>252773.39132</td></tr><tr><td>multibet outlay < 30</td><td>129490.8521</td></tr><tr><td>multibet profit < 30</td><td>6854.51831</td></tr><tr><td>multibet profit < 30 sd</td><td>20.4204</td></tr><tr><td>multibet profit sd</td><td>42.98205</td></tr><tr><td>profit</td><td>5352.5914</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">zesty-sweep-5</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/ux97592m\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/ux97592m</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_030642-ux97592m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2qyscbdo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025510597000012394\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_041855-2qyscbdo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/2qyscbdo\" target=\"_blank\">mild-sweep-6</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00025510597000012394, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00025510597000012394, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00025510597000012394\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:53<00:00,  6.09it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.20it/s]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.91it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.17it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.89it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.15it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.13it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.87it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.85it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.88it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.85it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.88it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.87it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.83it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.12it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.19it/s] \n",
      "100%|██████████| 324/324 [00:55<00:00,  5.84it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.82it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.12it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.18it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.20it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.84it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.85it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.84it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.13it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.82it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.87it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.15it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.13it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.87it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.13it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.85it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.16it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.84it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.10it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.09it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.81it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.10it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.80it/s]]\n",
      "100%|██████████| 50/50 [1:45:38<00:00, 126.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de64742eefca43e29c0416889ada4f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='181.012 MB of 181.012 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▄▄▄▅▅▅▅▅▅▆▇▆▆▅▆▆▆▆▆▇▆▆▆▅▆▅▅▆▆▇▇▇█▇▇▇█</td></tr><tr><td>FK ROI < 30</td><td>▆▆▇▇▇▇▇█▇▇█▇███▇▆▆▆▅▅▅▅▃▄▃▂▃▁▂▂▂▃▄▃▃▁▂▁▂</td></tr><tr><td>ROI</td><td>▁▂▃▄▄▄▅▆▅▅▆▆▆▇▇▆▅▆▆▆▆▆▇▆▆▅▄▆▅▄▆▆▆▆▆█▇▇▇█</td></tr><tr><td>ROI < 30</td><td>▅▅▆▇▇▇▇█▆▇█▇▇██▇▆▆▆▅▅▅▅▃▄▂▂▃▁▁▂▂▃▃▃▃▂▃▂▃</td></tr><tr><td>accuracy</td><td>▁▂▂▂▂▃▃▃▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██████▁█▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▁▇▆▇▇▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>correct</td><td>▁▂▂▂▂▃▃▃▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇█▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▆████▇▇▇▆▆▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▃▃▄▅▅▄▅▅▅▆▇▇▆▅▆▇▆▆▇▇▆▇▆▅▆▆▅▇▆▇▇▇█▇▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▃▃▅▆▆▆▆▇▆▆█▆▇██▇▆▆▆▅▅▅▅▃▅▂▂▄▁▁▃▃▄▅▅▅▃▅▃▄</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>████▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▂▁▂▁▁▂▁▁▁▁</td></tr><tr><td>profit</td><td>▇▇██▅▅▃▂▃▃▃▃▄▄▄▃▂▂▃▃▂▂▂▂▂▃▂▃▃▃▂▁▂▂▃▂▃▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.0872</td></tr><tr><td>FK ROI < 30</td><td>0.02709</td></tr><tr><td>ROI</td><td>-0.10045</td></tr><tr><td>ROI < 30</td><td>0.03789</td></tr><tr><td>accuracy</td><td>0.256</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>8.30093</td></tr><tr><td>correct</td><td>2048</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>8.30093</td></tr><tr><td>loss_val</td><td>1.9598</td></tr><tr><td>multibet outlay</td><td>250311.13678</td></tr><tr><td>multibet outlay < 30</td><td>150351.19663</td></tr><tr><td>multibet profit < 30</td><td>5697.29392</td></tr><tr><td>multibet profit < 30 sd</td><td>23.34362</td></tr><tr><td>multibet profit sd</td><td>39.5157</td></tr><tr><td>profit</td><td>5264.28291</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">mild-sweep-6</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/2qyscbdo\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/2qyscbdo</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_041855-2qyscbdo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u90hpmro with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009017717239355458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_060503-u90hpmro</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/u90hpmro\" target=\"_blank\">ethereal-sweep-7</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009017717239355458, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009017717239355458, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0009017717239355458\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:54<00:00,  5.91it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.15it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.85it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.82it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.12it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.10it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.80it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.12it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.81it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.80it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.07it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.07it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.08it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.07it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.78it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.06it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.05it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.77it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.07it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.08it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.11it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.79it/s] \n",
      "100%|██████████| 324/324 [00:52<00:00,  6.12it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.79it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.10it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.08it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.06it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.07it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.01it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.03it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.04it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.06it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.04it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.06it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.02it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.05it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.03it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.04it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.06it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.02it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.09it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.09it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.08it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.10it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.07it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.05it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.09it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.06it/s]]\n",
      "100%|██████████| 50/50 [1:45:46<00:00, 126.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7282dfe8459747d8b9ccdbfe4c895be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.730 MB of 179.730 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▁▁▂▃▃▃▄▄▄▄▅▅▅▅▆▇▇▆▅▆▆▇▆▆▇▇▇▇██▇▆▇█████</td></tr><tr><td>FK ROI < 30</td><td>████▇▇▇▇█▆▆▆▆▆▇▅▄▆▆▅▄▅▄▅▄▃▅▃▃▃▃▄▁▂▂▃▂▂▃▂</td></tr><tr><td>ROI</td><td>▁▁▁▁▂▃▃▃▄▃▄▄▄▄▄▅▅▆▆▆▅▆▅▇▆▅▇▆▇▇▇▇▇▆▇█████</td></tr><tr><td>ROI < 30</td><td>████▇▇▇▆▇▆▆▆▆▆▆▅▄▆▆▅▄▄▄▅▄▃▅▃▃▃▃▄▁▂▂▃▂▂▃▁</td></tr><tr><td>accuracy</td><td>▁▁▂▂▄▅▅▆▇▇███▇████▇██▇▇▇▇▆▇▇▇▇▆▇▆▇▆▆▆▆▆▆</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██████▂▇▇▇▇▇▇▆▆▆▆▆▅▆▆▆▆▆▅▁▅▅▅▅▅▅▅▅▅▅▅▄▅▄</td></tr><tr><td>correct</td><td>▁▁▂▂▄▅▅▆▇▇███▇████▇██▇▇▇▇▆▇▇▇▇▆▇▆▇▆▆▆▆▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▁▂▂▂▂▁▁</td></tr><tr><td>loss_val</td><td>▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇█</td></tr><tr><td>multibet outlay</td><td>▂▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▆▅▆▆▆▇▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▁▁▁▂▃▃▃▄▄▄▅▅▅▅▅▆▇▆▆▅▆▅▇▆▅▇▆▇▇▇▇▇▆▇█▇███</td></tr><tr><td>multibet profit < 30</td><td>▇███▇▇▇▇█▆▇▆▇▇█▆▅▇█▇▅▆▆▇▅▄▇▄▄▃▄▅▁▃▂▄▃▃▃▁</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>multibet profit sd</td><td>▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▃▄▄▃▂▃▂▄▃▂▄▃▇▅▅▄▆▄▆▆▆▆▆█</td></tr><tr><td>profit</td><td>█▇▅▃▃▇▆▆▄▄▃▅▂▂▅▄▄▄▂▄▃▃▃▃▅▂▄▃▄▂▂▅▄▄▃▆▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.03603</td></tr><tr><td>FK ROI < 30</td><td>-0.01311</td></tr><tr><td>ROI</td><td>-0.03857</td></tr><tr><td>ROI < 30</td><td>-0.00848</td></tr><tr><td>accuracy</td><td>0.231</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>6.19656</td></tr><tr><td>correct</td><td>1848</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.19656</td></tr><tr><td>loss_val</td><td>2.29625</td></tr><tr><td>multibet outlay</td><td>307485.84232</td></tr><tr><td>multibet outlay < 30</td><td>225629.67808</td></tr><tr><td>multibet profit < 30</td><td>-1914.13085</td></tr><tr><td>multibet profit < 30 sd</td><td>33.35486</td></tr><tr><td>multibet profit sd</td><td>59.06437</td></tr><tr><td>profit</td><td>5347.27218</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ethereal-sweep-7</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/u90hpmro\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/u90hpmro</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_060503-u90hpmro\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: muo6ybgf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007090462678304148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_075118-muo6ybgf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/muo6ybgf\" target=\"_blank\">fresh-sweep-8</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007090462678304148, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007090462678304148, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007090462678304148\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.46it/s]t]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.48it/s]t]\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]] \n",
      "100%|██████████| 32/32 [00:13<00:00,  2.33it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.32it/s]]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.47it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.31it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.30it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.32it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.31it/s]t]\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.85it/s]it]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.46it/s]t] \n",
      "100%|██████████| 32/32 [00:13<00:00,  2.29it/s]  \n",
      "100%|██████████| 32/32 [00:12<00:00,  2.47it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.47it/s]\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.46it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.47it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.31it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.31it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.42it/s]]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.54it/s] \n",
      "100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.56it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.55it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.54it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.52it/s]\n",
      "100%|██████████| 32/32 [00:16<00:00,  2.00it/s]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.51it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.41it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.33it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.46it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.53it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.45it/s]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.47it/s]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.42it/s]t]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.26it/s]t]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.38it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.41it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.39it/s]t] \n",
      "100%|██████████| 32/32 [00:13<00:00,  2.32it/s]t]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s]t]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.21it/s]t]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.39it/s]t]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.37it/s]t]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.33it/s]t]\n",
      "100%|██████████| 50/50 [1:19:17<00:00, 95.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282d6f57b15943bf8e630249e81097f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.956 MB of 180.956 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▂▃▃▄▄▄▄▃▂▃▃▄▅▅▅▅▅▆▆▆▆▆▅▆▆▆▆▆▅▅▄▅▇▇██</td></tr><tr><td>FK ROI < 30</td><td>▁▃▅▅▅▅▅▅▆▅▅▄▄▄▄▅▄▄▅▆▇█▇▇▅▄▂▃▃▃▄▆▅▆▄▃▄▃▃▃</td></tr><tr><td>ROI</td><td>▁▂▂▂▂▃▃▄▄▄▄▃▂▃▃▄▅▅▅▅▅▆▆▆▅▆▅▆▆▆▆▆▅▄▄▄▇▇██</td></tr><tr><td>ROI < 30</td><td>▁▃▅▅▅▅▅▅▅▅▆▅▄▅▅▅▄▄▅▆▇█▇▇▅▄▃▃▃▃▄▆▅▆▄▄▄▃▃▃</td></tr><tr><td>accuracy</td><td>▁▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▃▃▇▇▂▂▇▇▂▂▇▂▂▆▆▂▂▆▆▂▂▆▆▂▆▆▁▁▅▅▁▁▅▅▁▁▅▁</td></tr><tr><td>correct</td><td>▁▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▅▇▇████████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▄▃▃▃▃▂▁▂▂▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▁▁▂▂▄▃▃▃▂▁▂▂▃▅▅▅▅▅▅▅▅▅▅▅▅▆▆▅▆▅▄▃▄▇▇██</td></tr><tr><td>multibet profit < 30</td><td>▁▃▄▅▅▅▅▅▅▅▅▅▄▅▅▅▅▄▅▆▇██▇▆▅▄▄▄▄▅▆▆▆▅▅▅▅▅▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>▆▇▇▆▆▇▇██▇█▇▅▅▅▅▆▆▆▆▅▅▄▄▄▅▇▆▅▆▆▅▃▂▁▁▃▃▄▄</td></tr><tr><td>profit</td><td>▁▇▇█▇▆▅▅▃▄▄▇▄▅▂▃▄▃▄▇▅▇▇▆▆▅▃▄▄▃▄▅▄▆▅▃▄▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.06924</td></tr><tr><td>FK ROI < 30</td><td>0.04637</td></tr><tr><td>ROI</td><td>-0.0812</td></tr><tr><td>ROI < 30</td><td>0.05411</td></tr><tr><td>accuracy</td><td>0.251</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>20.77695</td></tr><tr><td>correct</td><td>2008</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>20.77695</td></tr><tr><td>loss_val</td><td>1.94192</td></tr><tr><td>multibet outlay</td><td>248800.77109</td></tr><tr><td>multibet outlay < 30</td><td>135326.04998</td></tr><tr><td>multibet profit < 30</td><td>7322.67016</td></tr><tr><td>multibet profit < 30 sd</td><td>21.63724</td></tr><tr><td>multibet profit sd</td><td>44.69843</td></tr><tr><td>profit</td><td>5630.82429</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fresh-sweep-8</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/muo6ybgf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/muo6ybgf</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_075118-muo6ybgf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8q6c1ktt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003203411415097524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_091104-8q6c1ktt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/8q6c1ktt\" target=\"_blank\">fresh-sweep-9</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003203411415097524, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003203411415097524, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0003203411415097524\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:41<00:00,  3.09it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.26it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.28it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.07it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.28it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.08it/s]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.32it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.08it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.30it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.07it/s]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.31it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.32it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.30it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.29it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.29it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.03it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.21it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.24it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.90it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.29it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.20it/s] \n",
      "100%|██████████| 129/129 [00:39<00:00,  3.30it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.29it/s] \n",
      "100%|██████████| 129/129 [00:38<00:00,  3.32it/s]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.45it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.31it/s]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.51it/s]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.46it/s]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.39it/s]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.32it/s]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.40it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.05it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.22it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.29it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.35it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.20it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.21it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.23it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.02it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.78it/s]]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.08it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.95it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.97it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.97it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.93it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.90it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.93it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.93it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.91it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.92it/s]]\n",
      "100%|██████████| 50/50 [1:39:19<00:00, 119.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88696b41c24c4bd68e36921467ddc4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='181.025 MB of 181.025 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▇▇▇▆▆▇▇▇▇▆███▇██▆▇▇▇▆▇</td></tr><tr><td>FK ROI < 30</td><td>▆▆▆▇▇██▇▇▇▇▇▇▇▆▆▆▆▇▇▆▆▆▆▆▄▅▄▅▅▅▃▃▃▂▄▂▂▂▁</td></tr><tr><td>ROI</td><td>▁▃▃▄▄▅▄▄▄▅▄▅▆▆▆▆▇▇▇▇▇▆▆▇▇▇▇▆███▇██▆▇▇▇▆▆</td></tr><tr><td>ROI < 30</td><td>▆▆▆▇▇██▇▇▇▆▆▆▇▆▆▆▆▆▇▅▅▆▅▅▄▄▃▄▅▄▃▃▃▂▃▂▂▁▁</td></tr><tr><td>accuracy</td><td>▁▂▂▂▃▃▃▃▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇█████████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▄▇▇▇▇▇▆▆▆▆▆▆▆▃▅▅▅▅▅▂▅▄▅▄▄▄▄▄▄▄▃▃▁▃▃▃▃▃</td></tr><tr><td>correct</td><td>▁▂▂▂▃▃▃▃▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇█████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▆█████▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▃▃▄▃▄▄▄▄▅▅▅▆▅▆▆▇▇▇▆▇▇▇▇▇▆███▇██▆▇▇▇▆▇</td></tr><tr><td>multibet profit < 30</td><td>▄▅▅▆▇██▇▆▇▆▆▇▇▆▆▇▆▇█▆▆▇▆▆▄▅▄▅▆▆▄▄▃▂▅▃▃▂▁</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>multibet profit sd</td><td>▇███▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▇█▅▅▅▆▄▄▅▄▅▆▂▄▅▄▅▄▄▃▂▂▂▂▄▃▃▂▁▄▃▂▄▄▁▂▃▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.08467</td></tr><tr><td>FK ROI < 30</td><td>0.02878</td></tr><tr><td>ROI</td><td>-0.10242</td></tr><tr><td>ROI < 30</td><td>0.03409</td></tr><tr><td>accuracy</td><td>0.25638</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>15.1934</td></tr><tr><td>correct</td><td>2051</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>15.1934</td></tr><tr><td>loss_val</td><td>1.95307</td></tr><tr><td>multibet outlay</td><td>247998.32127</td></tr><tr><td>multibet outlay < 30</td><td>151438.30755</td></tr><tr><td>multibet profit < 30</td><td>5162.86346</td></tr><tr><td>multibet profit < 30 sd</td><td>23.43014</td></tr><tr><td>multibet profit sd</td><td>37.90195</td></tr><tr><td>profit</td><td>5286.55796</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fresh-sweep-9</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/8q6c1ktt\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/8q6c1ktt</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_091104-8q6c1ktt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dratnva5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007770419677007181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_105050-dratnva5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/dratnva5\" target=\"_blank\">snowy-sweep-10</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007770419677007181, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007770419677007181, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007770419677007181\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:56<00:00,  5.77it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.09it/s]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.76it/s]\n",
      "100%|██████████| 324/324 [00:51<00:00,  6.30it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.02it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.64it/s]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.93it/s]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.93it/s]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.37it/s]\n",
      "100%|██████████| 324/324 [01:08<00:00,  4.72it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.61it/s]]\n",
      "100%|██████████| 324/324 [01:22<00:00,  3.95it/s]]\n",
      "100%|██████████| 324/324 [01:12<00:00,  4.48it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.97it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.03it/s]]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.33it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.73it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.78it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.37it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.82it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.85it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.43it/s] \n",
      "100%|██████████| 324/324 [00:53<00:00,  6.00it/s]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.97it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.59it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.05it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.74it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.67it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.48it/s]]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.11it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.01it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.45it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.06it/s]]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.52it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.60it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.62it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.66it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.88it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.80it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.44it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  6.00it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.76it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.48it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.04it/s]]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.56it/s]]\n",
      "100%|██████████| 50/50 [1:53:45<00:00, 136.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d851dd641c4272a4d89ba284e52bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.880 MB of 179.880 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▃▃▃▃▃▄▃▄▄▅▅▄▅▅▆▇▆▆▆▆▇▆▇▇▆▇▇▆▆▆█▇▇▆▇</td></tr><tr><td>FK ROI < 30</td><td>▇▇███▇▇▆▇▅▇▇▆▅▆▆▄▄▅▆▅▄▄▄▂▄▄▃▅▃▄▂▂▁▃▄▃▂▁▂</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▂▃▃▃▃▄▃▄▄▄▅▄▄▅▆▇▅▆▆▆▇▆▇▇▆▇▇▆▆▆█▇▇▆▇</td></tr><tr><td>ROI < 30</td><td>▆▆███▇▇▆▇▅▇▆▆▅▅▆▃▃▅▆▆▄▄▅▃▅▅▄▆▄▅▃▂▂▃▅▄▃▁▂</td></tr><tr><td>accuracy</td><td>▁▁▂▃▄▅▆▅▇▇▇▇▇▇██▇█▇▇▇▇▇▇▇▇▇▇▆▇▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█████▇▂▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▁▅▅▅▅▅▅▅▅▅▅▅▄▅▅</td></tr><tr><td>correct</td><td>▁▁▂▃▄▅▆▅▇▇▇▇▇▇██▇█▇▇▇▇▇▇▇▇▇▇▆▇▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>multibet outlay</td><td>▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▂▃▃▃▃▄▃▄▄▅▅▄▄▅▆▇▅▆▆▆▇▆▆▇▆▇▇▆▆▆█▇▇▆▇</td></tr><tr><td>multibet profit < 30</td><td>▃▃▅▅▅▅▅▄▅▃▆▅▅▃▅▅▂▃▄▆▆▅▄▆▃▆▆▅█▅▆▄▂▂▅▇▅▄▁▃</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>▅▅▅▄▃▃▃▃▂▂▂▁▂▁▂▂▁▁▁▃▃▂▃▃▃▄▃▄▄▄▄▅▅▅▆█▇▆▆█</td></tr><tr><td>profit</td><td>▅▄▅▃▃▁▄▃▆▄▅▆▆▃█▇▄▃▃▃▆▃▄▃▃▄▂▃▃▂▃▄▂▄▄▇▇▃▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.01961</td></tr><tr><td>FK ROI < 30</td><td>0.01692</td></tr><tr><td>ROI</td><td>-0.0207</td></tr><tr><td>ROI < 30</td><td>0.02711</td></tr><tr><td>accuracy</td><td>0.23613</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>6.28451</td></tr><tr><td>correct</td><td>1889</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.28451</td></tr><tr><td>loss_val</td><td>2.24323</td></tr><tr><td>multibet outlay</td><td>299084.57748</td></tr><tr><td>multibet outlay < 30</td><td>216818.39196</td></tr><tr><td>multibet profit < 30</td><td>5876.86779</td></tr><tr><td>multibet profit < 30 sd</td><td>34.87529</td></tr><tr><td>multibet profit sd</td><td>57.59887</td></tr><tr><td>profit</td><td>5851.49309</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">snowy-sweep-10</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/dratnva5\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/dratnva5</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_105050-dratnva5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xw3nvdzy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004117360136067247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_124508-xw3nvdzy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/xw3nvdzy\" target=\"_blank\">laced-sweep-11</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004117360136067247, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004117360136067247, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004117360136067247\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:29<00:00,  2.20it/s]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]t]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.25it/s]t]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.26it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s]t]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.15it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.46it/s]t]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.17it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.15it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.95it/s]it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.23it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]]  \n",
      "100%|██████████| 64/64 [00:25<00:00,  2.50it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.15it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.18it/s]]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.01it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.17it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.57it/s]]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.12it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.15it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.44it/s]]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.08it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.14it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.44it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.20it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.53it/s]]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.37it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.20it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.16it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.14it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.14it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.13it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.42it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.19it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.19it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.53it/s]it]\n",
      "100%|██████████| 50/50 [1:27:46<00:00, 105.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b5ec5b4da14d23af1e61678184668a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='181.022 MB of 181.022 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▆▅▆▆▆▆▆▇▆▆▇▇█▇▇▇██</td></tr><tr><td>FK ROI < 30</td><td>▁▃▅▅▄▆▃▅▄▅▄▅▆▅▄▅▅▇▃▆▆▄█▅▆▇▅▇▆▇▇▄▆▇█▇█▃▆█</td></tr><tr><td>ROI</td><td>▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>ROI < 30</td><td>▁▃▄▄▃▅▃▅▄▅▄▄▅▄▄▄▃▆▂▅▄▃▆▄▅▅▄▆▅▅▆▄▆▆▇▆█▅▇█</td></tr><tr><td>accuracy</td><td>▁▁▂▂▂▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█▇█████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▁▁█▇▁▁▇▇▁▁▇▁▁▇▇▁▁▇▇▁▁▇▇▁▇▇▁▁▇▇▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▁▁▂▂▂▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█▇█████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▄▇▇█████▇▇▇▇▆▆▅▅▅▅▄▄▄▃▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▆▆▆▆▇▇▇▇██</td></tr><tr><td>multibet profit < 30</td><td>▁▂▃▃▃▄▃▄▄▄▃▄▅▄▄▄▄▅▃▅▄▄▆▄▅▅▅▆▆▆▆▅▆▆▇▇█▆▇█</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▃▃▃▃▃▄▄▄▄▄▄▅▄▅▅▅▅▅▆▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>▇████▇█▇▇▆▇▆▆▅▅▅▄▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▁▁▂▂▁▁▂▁</td></tr><tr><td>profit</td><td>▄█▅▄▅▅▄▅▃▁▄▂▃▂▂▂▄▂▃▃▂▁▄▂▂▃▂▄▄▅▄▄▆▅▅▄▅▅▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.05733</td></tr><tr><td>FK ROI < 30</td><td>0.06661</td></tr><tr><td>ROI</td><td>-0.06877</td></tr><tr><td>ROI < 30</td><td>0.07927</td></tr><tr><td>accuracy</td><td>0.256</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>8.48193</td></tr><tr><td>correct</td><td>2048</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>8.48193</td></tr><tr><td>loss_val</td><td>1.92725</td></tr><tr><td>multibet outlay</td><td>245692.34707</td></tr><tr><td>multibet outlay < 30</td><td>136829.66454</td></tr><tr><td>multibet profit < 30</td><td>10846.75057</td></tr><tr><td>multibet profit < 30 sd</td><td>21.50727</td></tr><tr><td>multibet profit sd</td><td>40.81329</td></tr><tr><td>profit</td><td>5758.16628</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">laced-sweep-11</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/xw3nvdzy\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/xw3nvdzy</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_124508-xw3nvdzy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 794i19vl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004730672169887841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_141317-794i19vl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/794i19vl\" target=\"_blank\">swift-sweep-12</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004730672169887841, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004730672169887841, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004730672169887841\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:00<00:00,  5.34it/s]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.56it/s]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.02it/s]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.21it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.06it/s]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.37it/s]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.76it/s]\n",
      "100%|██████████| 324/324 [00:50<00:00,  6.39it/s]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.38it/s]\n",
      "100%|██████████| 324/324 [00:50<00:00,  6.41it/s]\n",
      "100%|██████████| 324/324 [00:50<00:00,  6.43it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.60it/s]]\n",
      "100%|██████████| 324/324 [00:51<00:00,  6.28it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.84it/s]]\n",
      "100%|██████████| 324/324 [01:05<00:00,  4.97it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.01it/s]]\n",
      "100%|██████████| 324/324 [00:50<00:00,  6.35it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.46it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.93it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.69it/s]]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.06it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.82it/s]]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.11it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.68it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.76it/s] \n",
      "100%|██████████| 324/324 [01:01<00:00,  5.29it/s]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.98it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.88it/s]]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.35it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [01:01<00:00,  5.26it/s]]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.33it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.48it/s]]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.02it/s]]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.54it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.62it/s]]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.38it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.90it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.44it/s]]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.22it/s]]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.21it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.95it/s]]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.05it/s]]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.32it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.20it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.46it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.90it/s]]\n",
      "100%|██████████| 324/324 [01:05<00:00,  4.98it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.65it/s]]\n",
      "100%|██████████| 50/50 [1:53:12<00:00, 135.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09fa0d933d845c2adaca74ea3340779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.492 MB of 180.492 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▁▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇█▇</td></tr><tr><td>FK ROI < 30</td><td>▆███▇▆▇▇▅▆▅▄▅▄▃▄▄▃▄▅▄▄▂▃▂▄▂▃▃▂▃▃▂▂▄▂▂▃▄▁</td></tr><tr><td>ROI</td><td>▁▁▂▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▅▄▅▅▅▅▅▆▅▆▆▆▇▇▆▇▇▇▇▇█▇</td></tr><tr><td>ROI < 30</td><td>▆█▇▇▇▇▇▇▅▆▅▅▄▄▃▃▃▃▃▄▃▄▁▃▁▃▁▂▃▂▃▃▂▂▄▁▂▂▄▁</td></tr><tr><td>accuracy</td><td>▁▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇█▇████▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██████▁▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▁▆▆▆▆▅▆▆▆▅▅▅▅▅▅</td></tr><tr><td>correct</td><td>▁▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇█▇████▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▆▆▆▆▅▅▅▅▄▅▄▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>loss_val</td><td>▆▅▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>multibet outlay</td><td>▆▇▇▇▆▅▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▆▆▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▂▁▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇█▇</td></tr><tr><td>multibet profit < 30</td><td>▂▅▄▅▅▅▅▆▄▅▃▃▃▃▂▃▃▂▃▄▃▄▁▃▁▅▂▄▄▃▆▅▄▄█▄▅▆█▄</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>███▆▆▅▄▄▃▁▁▂▂▁▂▁▁▃▃▂▂▂▃▂▃▃▄▄▅▅▅▆▄▅▆▅▆▇▇▅</td></tr><tr><td>profit</td><td>▆▃▇▃▁▁▂▃▃▃▂▄▄▅▅▅▇▇█▅▆▅▅▅▄▅▅▅▅▅▆▅▅▆▅▃▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.02513</td></tr><tr><td>FK ROI < 30</td><td>0.02658</td></tr><tr><td>ROI</td><td>-0.03143</td></tr><tr><td>ROI < 30</td><td>0.03477</td></tr><tr><td>accuracy</td><td>0.25188</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>6.98049</td></tr><tr><td>correct</td><td>2015</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.98049</td></tr><tr><td>loss_val</td><td>2.06964</td></tr><tr><td>multibet outlay</td><td>269922.2226</td></tr><tr><td>multibet outlay < 30</td><td>186368.8172</td></tr><tr><td>multibet profit < 30</td><td>6480.96453</td></tr><tr><td>multibet profit < 30 sd</td><td>29.12243</td></tr><tr><td>multibet profit sd</td><td>47.89763</td></tr><tr><td>profit</td><td>5705.27707</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">swift-sweep-12</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/794i19vl\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/794i19vl</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_141317-794i19vl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qjvpnjdo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009065182390164584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_160652-qjvpnjdo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/qjvpnjdo\" target=\"_blank\">absurd-sweep-13</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009065182390164584, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009065182390164584, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0009065182390164584\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:38<00:00,  1.67it/s]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.56it/s]t]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.76it/s]t]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.63it/s]t]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.58it/s]t]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.55it/s]t]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.79it/s]t]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.60it/s]t]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.69it/s]t]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.76it/s]t]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.58it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.68it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.77it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.62it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.59it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.77it/s]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.67it/s]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.67it/s]it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.79it/s]it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.78it/s]]  \n",
      "100%|██████████| 64/64 [00:36<00:00,  1.74it/s]]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.55it/s]]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.78it/s]]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.74it/s]]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.60it/s]]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.70it/s]]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.81it/s]]\n",
      "100%|██████████| 64/64 [00:46<00:00,  1.39it/s]]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.64it/s]]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.80it/s]]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.57it/s]]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.61it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.73it/s]it]\n",
      "100%|██████████| 64/64 [00:46<00:00,  1.37it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.59it/s]it]\n",
      "100%|██████████| 64/64 [00:42<00:00,  1.52it/s]it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.79it/s]it]\n",
      "100%|██████████| 64/64 [00:44<00:00,  1.43it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.72it/s]it]\n",
      "100%|██████████| 64/64 [00:42<00:00,  1.51it/s]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.68it/s]it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.79it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.70it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.72it/s]it]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.46it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.98it/s]it]\n",
      "100%|██████████| 64/64 [00:44<00:00,  1.45it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.84it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.56it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.57it/s]it]\n",
      "100%|██████████| 50/50 [1:38:06<00:00, 117.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6e9891a249498291c036408dd8aa0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.236 MB of 180.236 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▁▁▂▂▂▁▂▃▃▄▄▃▄▄▃▅▄▅▄▄▆▅▅▇▆▆▆▄▅▅▆▆▇██▇██</td></tr><tr><td>FK ROI < 30</td><td>█▇█▇▇▇▆▄▅▇▆▇▆▅▅▄▃▄▅▆▃▃▅▄▄▅▄▄▄▁▁▃▃▃▅▅▃▂▅▂</td></tr><tr><td>ROI</td><td>▁▁▁▁▂▂▂▁▂▃▃▄▄▃▃▄▂▅▃▅▄▄▆▅▅▇▅▆▆▄▅▅▆▆▇▇█▇██</td></tr><tr><td>ROI < 30</td><td>█▇█▇▇▆▆▄▅▆▇▇▆▅▆▄▂▅▅▆▃▄▆▅▅▇▄▅▅▁▂▃▄▄▆▆▄▃▅▂</td></tr><tr><td>accuracy</td><td>▁▂▂▃▄▅▅▆▆▇▇▇▇▇█▇▇███▇██▇▇▇█▇▇▇▇█▇▇▇█▇▇▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▄▇▇▇▇▇▆▆▆▆▆▆▅▃▅▅▅▅▄▂▄▄▄▄▄▄▄▃▃▃▃▃▁▃▃▃▂▂</td></tr><tr><td>correct</td><td>▁▂▂▃▄▅▅▆▆▇▇▇▇▇█▇▇███▇██▇▇▇█▇▇▇▇█▇▇▇█▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▆▆▆▆▇▇██</td></tr><tr><td>multibet outlay</td><td>▅▅▅▅▄▄▃▃▂▂▂▂▁▁▁▁▂▁▂▁▂▂▂▂▃▄▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▁▁▂▂▂▂▂▃▃▄▄▃▄▄▃▅▄▅▄▄▆▅▆▇▆▆▆▄▅▅▆▆▇▇█▇██</td></tr><tr><td>multibet profit < 30</td><td>▅▅▆▅▅▅▄▂▄▅▆▆▅▄▅▃▂▅▅▆▂▄▇▅▆▇▅▆▆▁▂▄▅▅▇█▆▄▇▃</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇█▇██</td></tr><tr><td>multibet profit sd</td><td>▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▃▁▃▂▂▁▁▃▂▃▄▂▃▃▂▄▂▃▄▄▄█▅▇▇</td></tr><tr><td>profit</td><td>█▆▅▅▅▅▆▃▄▅▅▄▃▄▃▃▂▄▃▂▄▂▂▃▄▄▄▃▄▂▁▂▂▃▂▄▃▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.01971</td></tr><tr><td>FK ROI < 30</td><td>0.01133</td></tr><tr><td>ROI</td><td>-0.02047</td></tr><tr><td>ROI < 30</td><td>0.02049</td></tr><tr><td>accuracy</td><td>0.24825</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>6.67129</td></tr><tr><td>correct</td><td>1986</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.67129</td></tr><tr><td>loss_val</td><td>2.12948</td></tr><tr><td>multibet outlay</td><td>279589.74835</td></tr><tr><td>multibet outlay < 30</td><td>198854.46291</td></tr><tr><td>multibet profit < 30</td><td>4075.14744</td></tr><tr><td>multibet profit < 30 sd</td><td>30.76993</td></tr><tr><td>multibet profit sd</td><td>57.18478</td></tr><tr><td>profit</td><td>5389.16669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">absurd-sweep-13</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/qjvpnjdo\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/qjvpnjdo</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_160652-qjvpnjdo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: to9g4ly3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009565093728643342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_174523-to9g4ly3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/to9g4ly3\" target=\"_blank\">brisk-sweep-14</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009565093728643342, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009565093728643342, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0009565093728643342\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:58<00:00,  5.57it/s]\n",
      "100%|██████████| 324/324 [00:51<00:00,  6.23it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.22it/s]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.12it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.13it/s]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.22it/s]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.16it/s]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.15it/s]\n",
      "100%|██████████| 324/324 [01:01<00:00,  5.23it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.68it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.61it/s]]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.10it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.18it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.60it/s]]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.19it/s]]\n",
      "100%|██████████| 324/324 [00:51<00:00,  6.31it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.63it/s]]\n",
      "100%|██████████| 324/324 [01:01<00:00,  5.28it/s]]\n",
      "100%|██████████| 324/324 [00:51<00:00,  6.27it/s]]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.17it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.68it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.23it/s]]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.02it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.88it/s] \n",
      "100%|██████████| 324/324 [01:04<00:00,  5.04it/s]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.70it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.61it/s]]\n",
      "100%|██████████| 324/324 [01:07<00:00,  4.79it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.69it/s]]\n",
      "100%|██████████| 324/324 [00:51<00:00,  6.28it/s]]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.59it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.77it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.97it/s]]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.12it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.13it/s]]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.13it/s]]\n",
      "100%|██████████| 324/324 [01:01<00:00,  5.26it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.13it/s]]\n",
      "100%|██████████| 324/324 [01:01<00:00,  5.29it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.08it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.85it/s]]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.14it/s]]\n",
      "100%|██████████| 324/324 [00:51<00:00,  6.24it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.75it/s]]\n",
      "100%|██████████| 324/324 [01:01<00:00,  5.31it/s]]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.32it/s]]\n",
      "100%|██████████| 324/324 [01:05<00:00,  4.97it/s]]\n",
      "100%|██████████| 324/324 [01:01<00:00,  5.28it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.97it/s]]\n",
      "100%|██████████| 50/50 [1:53:06<00:00, 135.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa50718d69b4b4f846bcc963475d1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.527 MB of 179.527 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▅▆▆▇▆▆▆▇▇▇▇█▇██</td></tr><tr><td>FK ROI < 30</td><td>▇███▆▇▆▇▆▆▅▅▅▅▅▄▅▅▄▃▃▃▃▂▂▃▄▄▅▂▃▁▄▄▄▅▄▅▄▅</td></tr><tr><td>ROI</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▅▅▆▆▇▆▆▅▇▇▇▇█▇██</td></tr><tr><td>ROI < 30</td><td>▇█▇█▆▇▆▇▆▆▅▄▅▅▅▄▅▅▄▃▃▃▃▂▃▄▄▄▅▃▃▁▄▅▄▅▄▅▄▅</td></tr><tr><td>accuracy</td><td>▁▁▂▃▅▆▆▆▇▇██▇██████▇██▇▇▇█▇██▇▇▇▇▇▇▇▇▇▇▆</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█████▇▂▇▇▇▇▇▇▆▆▆▆▆▅▆▆▅▅▅▅▁▅▅▅▅▅▅▅▅▅▅▅▄▄▄</td></tr><tr><td>correct</td><td>▁▁▂▃▅▆▆▆▇▇██▇██████▇██▇▇▇█▇██▇▇▇▇▇▇▇▇▇▇▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▂▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇█</td></tr><tr><td>multibet outlay</td><td>▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▇▆▆▅▇▇▇▇█▇██</td></tr><tr><td>multibet profit < 30</td><td>▆▇▇▇▆▇▆▇▆▆▅▅▅▆▆▄▆▆▅▄▄▃▄▃▄▅▆▅█▄▄▁▇▇▆▇▆█▆█</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>▄▄▄▄▄▃▃▂▂▂▁▁▁▂▁▁▂▂▂▂▃▃▃▄▄▃▄▄▅▅▅▅▆▆▆▆█▇██</td></tr><tr><td>profit</td><td>▅▅▃▄▆▅▄▃▄▆▅▃▂▅▁▂▅▅▅▆▅▅▅▅▄▅▆▃▄▅▆▅▆▆▆▃█▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.01561</td></tr><tr><td>FK ROI < 30</td><td>0.02148</td></tr><tr><td>ROI</td><td>-0.01987</td></tr><tr><td>ROI < 30</td><td>0.02803</td></tr><tr><td>accuracy</td><td>0.2335</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>6.249</td></tr><tr><td>correct</td><td>1868</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.249</td></tr><tr><td>loss_val</td><td>2.33415</td></tr><tr><td>multibet outlay</td><td>313404.98422</td></tr><tr><td>multibet outlay < 30</td><td>229473.79988</td></tr><tr><td>multibet profit < 30</td><td>6431.49846</td></tr><tr><td>multibet profit < 30 sd</td><td>36.06902</td></tr><tr><td>multibet profit sd</td><td>57.16406</td></tr><tr><td>profit</td><td>5768.79275</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">brisk-sweep-14</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/to9g4ly3\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/to9g4ly3</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_174523-to9g4ly3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5ke5siz0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007272775458056072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_193858-5ke5siz0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/5ke5siz0\" target=\"_blank\">dandy-sweep-15</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007272775458056072, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007272775458056072, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007272775458056072\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:05<00:00,  4.95it/s]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.54it/s]\n",
      "100%|██████████| 324/324 [01:06<00:00,  4.84it/s]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.35it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.01it/s]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.05it/s]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.19it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.81it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.63it/s]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.09it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.61it/s]]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.04it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.67it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.03it/s]]\n",
      "100%|██████████| 324/324 [01:11<00:00,  4.54it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.11it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.12it/s]]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.19it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.09it/s]]\n",
      "100%|██████████| 324/324 [01:02<00:00,  5.22it/s]]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.01it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.01it/s]]\n",
      "100%|██████████| 324/324 [01:05<00:00,  4.93it/s]]\n",
      "100%|██████████| 324/324 [01:01<00:00,  5.31it/s]]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.57it/s]]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.00it/s] \n",
      "100%|██████████| 324/324 [00:52<00:00,  6.16it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.14it/s]]\n",
      "100%|██████████| 324/324 [01:01<00:00,  5.31it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.09it/s]]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.56it/s]]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.57it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.03it/s]]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.13it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.05it/s]]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.55it/s]]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.01it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.99it/s]]\n",
      "100%|██████████| 324/324 [01:04<00:00,  5.01it/s]]\n",
      "100%|██████████| 324/324 [01:03<00:00,  5.10it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  6.00it/s]]\n",
      "100%|██████████| 324/324 [01:00<00:00,  5.35it/s]]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.03it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.90it/s]]\n",
      "100%|██████████| 324/324 [01:09<00:00,  4.67it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.23it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.73it/s]]\n",
      "100%|██████████| 324/324 [00:59<00:00,  5.44it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.16it/s]]\n",
      "100%|██████████| 50/50 [1:56:15<00:00, 139.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c8e284b15840279a93b1b6dd3bba53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.920 MB of 179.920 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▃▄▂▅▆▅▅▆▆▆▇███▆▆▇▆▅▆▅▇▆▇▅▅▆▆▄▄▂▂▄▃▂▂</td></tr><tr><td>FK ROI < 30</td><td>██▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▂▃▂▂▃▂▃▂▂▂▂▁▂▁▂▁▁▁▁</td></tr><tr><td>ROI</td><td>▁▂▂▃▃▄▃▅▆▅▅▆▆▆▇███▆▆█▆▆▆▄▇▅▇▅▅▅▅▃▄▁▁▃▂▂▁</td></tr><tr><td>ROI < 30</td><td>██▇▇▆▆▆▆▆▅▅▅▄▄▅▄▄▄▃▃▃▃▃▂▂▃▂▃▂▂▂▂▁▂▁▂▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▁▂▂▃▄▅▅▆▇▇▇█▇▇███▇█▇▆▆▇▇▆▇▇▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██████▂▇▇▇▇▇▇▆▆▆▆▆▅▆▆▆▆▆▅▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>correct</td><td>▁▁▂▂▃▄▅▅▆▇▇▇█▇▇███▇█▇▆▆▇▇▆▇▇▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▃▃▃▂▂▂▂▂▂▁▁▁▂▁</td></tr><tr><td>loss_val</td><td>▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>multibet outlay</td><td>▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▃▄▄▄▄▅▄▆▇▆▆▇▇▇▇███▆▇▇▇▆▆▅▆▅▇▅▅▅▅▃▃▂▁▃▂▁▁</td></tr><tr><td>multibet profit < 30</td><td>███▇▇▇▇▆▆▆▆▆▅▅▆▅▅▅▅▄▄▄▄▃▃▃▃▄▃▂▂▃▂▂▁▂▁▁▁▁</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>multibet profit sd</td><td>████▇█▆▇▅▄▃▃▃▃▃▃▄▄▁▄▄▆▄▄▂▄▅▆▄▅▆▄▃▃▆▂▇▆▄▇</td></tr><tr><td>profit</td><td>██▆▄▃▃▂▅▂▄▄▅▄▅▅▅▅▄▅▃▄▂▃▅▂▃▃▃▂▁▃▃▃▃▄▄▄▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.1056</td></tr><tr><td>FK ROI < 30</td><td>-0.0593</td></tr><tr><td>ROI</td><td>-0.1211</td></tr><tr><td>ROI < 30</td><td>-0.06511</td></tr><tr><td>accuracy</td><td>0.23613</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>6.4464</td></tr><tr><td>correct</td><td>1889</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.4464</td></tr><tr><td>loss_val</td><td>2.22727</td></tr><tr><td>multibet outlay</td><td>296200.70906</td></tr><tr><td>multibet outlay < 30</td><td>214968.19233</td></tr><tr><td>multibet profit < 30</td><td>-13996.04602</td></tr><tr><td>multibet profit < 30 sd</td><td>30.69305</td></tr><tr><td>multibet profit sd</td><td>49.13189</td></tr><tr><td>profit</td><td>5318.41701</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dandy-sweep-15</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/5ke5siz0\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/5ke5siz0</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_193858-5ke5siz0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pvkm616x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.337015647761825e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_213538-pvkm616x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/pvkm616x\" target=\"_blank\">laced-sweep-16</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 7.337015647761825e-05, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 7.337015647761825e-05, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 7.337015647761825e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:23<00:00,  3.89it/s]\n",
      "100%|██████████| 324/324 [01:17<00:00,  4.19it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "100%|██████████| 324/324 [01:30<00:00,  3.60it/s]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.12it/s]\n",
      "100%|██████████| 324/324 [01:27<00:00,  3.72it/s]\n",
      "100%|██████████| 324/324 [01:42<00:00,  3.17it/s]\n",
      "100%|██████████| 324/324 [01:13<00:00,  4.39it/s]\n",
      "100%|██████████| 324/324 [01:44<00:00,  3.10it/s]\n",
      "100%|██████████| 324/324 [01:17<00:00,  4.20it/s]\n",
      "100%|██████████| 324/324 [01:28<00:00,  3.68it/s]\n",
      "100%|██████████| 324/324 [01:22<00:00,  3.91it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.09it/s]]\n",
      "100%|██████████| 324/324 [01:26<00:00,  3.76it/s]]\n",
      "100%|██████████| 324/324 [01:12<00:00,  4.47it/s]]\n",
      "100%|██████████| 324/324 [01:20<00:00,  4.02it/s]]\n",
      "100%|██████████| 324/324 [01:25<00:00,  3.78it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.15it/s]]\n",
      "100%|██████████| 324/324 [01:26<00:00,  3.75it/s]]\n",
      "100%|██████████| 324/324 [01:11<00:00,  4.51it/s]]\n",
      "100%|██████████| 324/324 [01:16<00:00,  4.22it/s]]\n",
      "100%|██████████| 324/324 [01:24<00:00,  3.86it/s]]\n",
      "100%|██████████| 324/324 [01:14<00:00,  4.33it/s]]\n",
      "100%|██████████| 324/324 [01:20<00:00,  4.04it/s]it]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.13it/s]it]\n",
      "100%|██████████| 324/324 [01:26<00:00,  3.74it/s]it]\n",
      "100%|██████████| 324/324 [01:12<00:00,  4.48it/s]it]\n",
      "100%|██████████| 324/324 [01:22<00:00,  3.91it/s]it]\n",
      "100%|██████████| 324/324 [01:24<00:00,  3.85it/s]]  \n",
      "100%|██████████| 324/324 [01:13<00:00,  4.40it/s]]\n",
      "100%|██████████| 324/324 [01:28<00:00,  3.66it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.14it/s]]\n",
      "100%|██████████| 324/324 [01:30<00:00,  3.58it/s]]\n",
      "100%|██████████| 324/324 [01:14<00:00,  4.33it/s]]\n",
      "100%|██████████| 324/324 [01:22<00:00,  3.95it/s]]\n",
      "100%|██████████| 324/324 [01:34<00:00,  3.43it/s]]\n",
      "100%|██████████| 324/324 [01:13<00:00,  4.40it/s]]\n",
      "100%|██████████| 324/324 [01:13<00:00,  4.40it/s]]\n",
      "100%|██████████| 324/324 [01:27<00:00,  3.69it/s]]\n",
      "100%|██████████| 324/324 [01:47<00:00,  3.01it/s]]\n",
      "100%|██████████| 324/324 [01:14<00:00,  4.35it/s]]\n",
      "100%|██████████| 324/324 [01:23<00:00,  3.89it/s]]\n",
      "100%|██████████| 324/324 [01:57<00:00,  2.75it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.12it/s]]\n",
      "100%|██████████| 324/324 [01:20<00:00,  4.04it/s]]\n",
      "100%|██████████| 324/324 [01:31<00:00,  3.56it/s]]\n",
      "100%|██████████| 324/324 [01:13<00:00,  4.40it/s]]\n",
      "100%|██████████| 324/324 [01:38<00:00,  3.29it/s]]\n",
      "100%|██████████| 324/324 [01:22<00:00,  3.92it/s]]\n",
      "100%|██████████| 324/324 [01:14<00:00,  4.34it/s]]\n",
      "100%|██████████| 324/324 [02:06<00:00,  2.56it/s]]\n",
      "100%|██████████| 50/50 [2:18:20<00:00, 166.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17eb570812da454fbded4b0b475307ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.969 MB of 180.969 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇████</td></tr><tr><td>FK ROI < 30</td><td>▁▃▄▅▆▇▇▇██▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▆▆▇▇▇▇▇</td></tr><tr><td>ROI</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇█▇██</td></tr><tr><td>ROI < 30</td><td>▁▃▄▅▆▆▇▇███▇▇████████████████▇█▇█▇▇▇█▇▇▇</td></tr><tr><td>accuracy</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▄▃▃▄▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇█▇██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>████▇████▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▁▇▇▇▇▇▇▇▇▇▇▆▅▇▇</td></tr><tr><td>correct</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▄▃▃▄▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇█▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▆▆▆▆▅▅▆▅▅▅▅▄▅▅▅▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▂</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▃▅▆▇▇▇████████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▅▆▆▇▇▇▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▃▃▄▅▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇███████████████████</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>▆▇▇█████████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>profit</td><td>▄▄▄▄▆▅▆▅▇█▇▅▅▄▃▃▂▄▁▂▄▄▃▂▅▄▂▃▂▃▄▁▅▂▃▁▄▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.09475</td></tr><tr><td>FK ROI < 30</td><td>0.06568</td></tr><tr><td>ROI</td><td>-0.10766</td></tr><tr><td>ROI < 30</td><td>0.07358</td></tr><tr><td>accuracy</td><td>0.23337</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>9.65386</td></tr><tr><td>correct</td><td>1867</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>9.65386</td></tr><tr><td>loss_val</td><td>1.9603</td></tr><tr><td>multibet outlay</td><td>256586.54132</td></tr><tr><td>multibet outlay < 30</td><td>121826.41375</td></tr><tr><td>multibet profit < 30</td><td>8964.431</td></tr><tr><td>multibet profit < 30 sd</td><td>19.40237</td></tr><tr><td>multibet profit sd</td><td>44.32807</td></tr><tr><td>profit</td><td>5634.5825</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">laced-sweep-16</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/pvkm616x\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/pvkm616x</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_213538-pvkm616x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o4elhbk4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007587015274339827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230309_235536-o4elhbk4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/o4elhbk4\" target=\"_blank\">silver-sweep-17</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007587015274339827, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007587015274339827, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007587015274339827\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:38<00:00,  3.36it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.82it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.76it/s]\n",
      "100%|██████████| 129/129 [00:50<00:00,  2.55it/s]\n",
      "100%|██████████| 129/129 [01:30<00:00,  1.43it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.26it/s]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.60it/s]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.56it/s]\n",
      "100%|██████████| 129/129 [00:52<00:00,  2.47it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.28it/s]\n",
      "100%|██████████| 129/129 [01:09<00:00,  1.86it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.26it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.04it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.85it/s]]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.08it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.24it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.21it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.54it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.18it/s]]\n",
      "100%|██████████| 129/129 [00:50<00:00,  2.54it/s] \n",
      "100%|██████████| 129/129 [00:58<00:00,  2.22it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.52it/s]]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.30it/s] \n",
      "100%|██████████| 129/129 [00:39<00:00,  3.23it/s]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.46it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.02it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.84it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.07it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.38it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.26it/s]]\n",
      "100%|██████████| 129/129 [01:32<00:00,  1.39it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.54it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.17it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.47it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.34it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.61it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.55it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.28it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.32it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.19it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.21it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.58it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.79it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.23it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.19it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.81it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.84it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.47it/s]]\n",
      "100%|██████████| 50/50 [1:45:17<00:00, 126.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a4f4d725a04b1197f72b37f0465dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.665 MB of 180.665 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▃▃▃▃▄▄▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇█▇▇▇▇▇▇▇█▇▇█▇▇</td></tr><tr><td>FK ROI < 30</td><td>▅▇▇▇█▇█▇▇▇▅▆▅▅▅▅▅▅▄▆▄▄▄▄▄▄▅▄▃▄▄▃▄▂▃▁▂▃▁▂</td></tr><tr><td>ROI</td><td>▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇█▇▇█▇▇</td></tr><tr><td>ROI < 30</td><td>▅▆▇▆█▇█▇▇▇▅▅▅▅▅▄▅▄▄▅▄▃▄▄▃▄▅▃▃▃▄▃▄▂▃▁▃▃▁▂</td></tr><tr><td>accuracy</td><td>▁▁▂▂▄▄▄▅▆▆▆▆▆▇▇▇▇▇▇██▇▇▇████████████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▃▇▇▂▆▇▇▆▇▇▇▇▆▆▆▆▂▆▆▂▅▆▁▅▅▅▅▅▅▅▅▅▅▅▄▁▄</td></tr><tr><td>correct</td><td>▁▁▂▂▄▄▄▅▆▆▆▆▆▇▇▇▇▇▇██▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇</td></tr><tr><td>multibet outlay</td><td>▆███▇▇▆▆▄▄▄▃▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▄▅▅▅▅▆▇▇█</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▃▃▃▃▃▄▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇██▇▇█▇▇</td></tr><tr><td>multibet profit < 30</td><td>▁▄▅▅█▆█▇▇▇▄▅▄▅▅▄▅▄▄▆▄▄▄▅▄▇▇▅▅▅▇▄▇▃▆▁▅█▂▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▂▂▃▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>▇█▇▇▇▆▇▆▅▅▄▄▃▃▂▂▂▁▁▂▁▁▂▁▂▂▂▁▂▂▂▂▂▃▃▃▂▃▂▂</td></tr><tr><td>profit</td><td>▄▆▄▃▅▄▅▆▅▃▄▂▃▄▂▃▁▄▁▃▂▃▄▄▄▅▅▄▅▄█▅▆▆▄▆▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.0354</td></tr><tr><td>FK ROI < 30</td><td>0.036</td></tr><tr><td>ROI</td><td>-0.04437</td></tr><tr><td>ROI < 30</td><td>0.04676</td></tr><tr><td>accuracy</td><td>0.25625</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>13.0032</td></tr><tr><td>correct</td><td>2050</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>13.0032</td></tr><tr><td>loss_val</td><td>2.03899</td></tr><tr><td>multibet outlay</td><td>265789.51678</td></tr><tr><td>multibet outlay < 30</td><td>181183.13251</td></tr><tr><td>multibet profit < 30</td><td>8472.58451</td></tr><tr><td>multibet profit < 30 sd</td><td>27.82669</td></tr><tr><td>multibet profit sd</td><td>43.57619</td></tr><tr><td>profit</td><td>5766.15611</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">silver-sweep-17</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/o4elhbk4\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/o4elhbk4</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230309_235536-o4elhbk4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bfhy5ixb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004548589007197005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_014119-bfhy5ixb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/bfhy5ixb\" target=\"_blank\">generous-sweep-18</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004548589007197005, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004548589007197005, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004548589007197005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:27<00:00,  1.15it/s]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.15it/s]t]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.22it/s]t]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.23it/s]t]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.15it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.32it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.32it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.28it/s]t]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.23it/s]t]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.17it/s]t]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.25it/s]it]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.29it/s]it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.57it/s]it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.59it/s]it]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.18it/s]it]\n",
      "100%|██████████| 32/32 [00:30<00:00,  1.06it/s]it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.57it/s]]  \n",
      "100%|██████████| 32/32 [00:20<00:00,  1.58it/s]]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.28it/s]]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]]\n",
      "100%|██████████| 32/32 [00:33<00:00,  1.03s/it]]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.20it/s]]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.56it/s]]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.24it/s]]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.58it/s]]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.18it/s]]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.26it/s]]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.33it/s]]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.28it/s]]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.15it/s]]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.23it/s]it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.23it/s]it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.26it/s]it]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.32it/s]it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.59it/s]it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.22it/s]it]\n",
      "100%|██████████| 32/32 [00:30<00:00,  1.05it/s]it]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.16it/s]it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.35it/s]it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.55it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]it]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.14it/s]it]\n",
      "100%|██████████| 32/32 [00:31<00:00,  1.02it/s]it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.57it/s]it]\n",
      "100%|██████████| 50/50 [1:29:37<00:00, 107.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034dac49ff3c4824ad5e64bbe22e5986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='181.030 MB of 181.030 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>FK ROI < 30</td><td>▁▅▆█▇█▇▇▆▇▆▆▅▄▅▄▅▄▅▄▄▄▃▄▅▄▃▃▄▃▄▄▃▄▂▃▃▃▃▄</td></tr><tr><td>ROI</td><td>▁▂▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▅▆▅▆▆▆▇▆▆▆▇▇▇▇▇▇███▇▇▇█</td></tr><tr><td>ROI < 30</td><td>▁▅▆▇▇█▇▇▆▆▆▆▅▄▅▄▅▄▄▃▄▃▂▄▄▄▃▄▄▃▄▄▄▅▃▄▄▃▄▅</td></tr><tr><td>accuracy</td><td>▁▁▁▂▂▂▃▃▄▄▄▄▅▅▆▅▆▆▆▆▆▆▇▇▇▆▇▇▇▇██▇▇▇█████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▂▂▇▇▂▂▇▇▂▂▇▁▁▇▇▁▁▇▇▁▁▇▇▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▁▁▁▂▂▂▃▃▄▄▄▄▅▅▆▅▆▆▆▆▆▆▇▇▇▆▇▇▇▇██▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▅▇▇████▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▂▃▃▃▄▃▄▄▄▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇█████▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▅▅▇▇█▇▇▇▇▇▆▆▅▆▅▆▅▅▅▆▅▄▆▆▆▅▆▆▆▆▆▆▇▆▇▇▆▇█</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>▆▇███▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>profit</td><td>▇▆▇█▅▆▄▆▇▅▇▇▆▄▅▂▃▅▄▂▂▂▃▂▄▁▃▃▁▂▂▃▂▁▁▂▂▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.06966</td></tr><tr><td>FK ROI < 30</td><td>0.04883</td></tr><tr><td>ROI</td><td>-0.08174</td></tr><tr><td>ROI < 30</td><td>0.0601</td></tr><tr><td>accuracy</td><td>0.254</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>5.49187</td></tr><tr><td>correct</td><td>2032</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>5.49187</td></tr><tr><td>loss_val</td><td>1.93016</td></tr><tr><td>multibet outlay</td><td>245821.11819</td></tr><tr><td>multibet outlay < 30</td><td>140683.32165</td></tr><tr><td>multibet profit < 30</td><td>8454.87975</td></tr><tr><td>multibet profit < 30 sd</td><td>22.3633</td></tr><tr><td>multibet profit sd</td><td>41.28423</td></tr><tr><td>profit</td><td>5319.57061</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">generous-sweep-18</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/bfhy5ixb\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/bfhy5ixb</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_014119-bfhy5ixb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wu051q76 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003420744762439221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_031127-wu051q76</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/wu051q76\" target=\"_blank\">noble-sweep-19</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003420744762439221, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003420744762439221, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0003420744762439221\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [01:11<00:00,  1.79it/s]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.59it/s]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.54it/s]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.76it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.27it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.89it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.11it/s]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.12it/s]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.66it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.13it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.87it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.20it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.88it/s]]\n",
      "100%|██████████| 129/129 [01:01<00:00,  2.08it/s]]\n",
      "100%|██████████| 129/129 [00:53<00:00,  2.39it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.89it/s]]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.89it/s]]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.94it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.19it/s]]\n",
      "100%|██████████| 129/129 [01:12<00:00,  1.79it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.69it/s]]\n",
      "100%|██████████| 129/129 [00:26<00:00,  4.79it/s]]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.16it/s]]\n",
      "100%|██████████| 129/129 [01:33<00:00,  1.38it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.31it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.62it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.88it/s]]\n",
      "100%|██████████| 129/129 [00:26<00:00,  4.86it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.58it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.24it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.46it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.42it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.53it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.90it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.80it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.79it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.14it/s]]\n",
      "100%|██████████| 129/129 [01:20<00:00,  1.61it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.50it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.87it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.36it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.44it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.39it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.31it/s]]\n",
      "100%|██████████| 129/129 [00:26<00:00,  4.79it/s]]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.91it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.98it/s]]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.70it/s]]\n",
      "100%|██████████| 129/129 [00:50<00:00,  2.53it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.85it/s]]\n",
      "100%|██████████| 50/50 [1:51:41<00:00, 134.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd1fc59fe694cd48c64382cc83e26cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='181.029 MB of 181.029 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▄▅▄▄▄▄▄▅▄▅▅▅▆▆▅▅▆▅▆▆▇▇▇▆▇▇▆▇▇▇▇▇██▇▇</td></tr><tr><td>FK ROI < 30</td><td>▄▇▇███▇▇▆▅▆▅▅▅▅▄▅▅▅▄▃▃▄▃▄▄▄▃▃▂▂▃▃▂▂▂▃▃▂▁</td></tr><tr><td>ROI</td><td>▁▂▃▃▅▅▄▅▄▄▅▅▅▅▅▅▆▆▆▅▆▅▆▆▇▆▇▇▇▇▆▇▇▇█▇██▇▇</td></tr><tr><td>ROI < 30</td><td>▄▆▇███▇▇▆▅▆▅▅▅▅▄▅▅▅▄▃▄▄▃▃▄▄▃▃▃▃▄▄▃▃▃▃▃▂▁</td></tr><tr><td>accuracy</td><td>▁▁▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▂▇▇▂▆▇▇▆▇▇▇▇▇▇▇▇▂▇▆▁▆▆▁▅▆▆▆▆▆▆▆▆▆▆▆▁▆</td></tr><tr><td>correct</td><td>▁▁▁▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▅▇████▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▄▄▄▄▄▄▄▄▄▅▅▅▆▆▅▅▆▅▆▆▇▇▇▇▇▇▇▇▇▇█▇██▇▇</td></tr><tr><td>multibet profit < 30</td><td>▁▅▆▇██▇▇▅▄▅▅▅▅▅▄▅▅▅▅▃▄▅▃▄▅▅▃▄▃▃▅▅▄▄▄▄▄▃▂</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>██████▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁</td></tr><tr><td>profit</td><td>▅█▅▄▇▆▇▄▅▃▄▄▄▅▆▅▆▆▆▅▄▆▅▅▄▄▂▂▅▃▃▁▄▄▂▂▂▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.07834</td></tr><tr><td>FK ROI < 30</td><td>0.03442</td></tr><tr><td>ROI</td><td>-0.09228</td></tr><tr><td>ROI < 30</td><td>0.04242</td></tr><tr><td>accuracy</td><td>0.257</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>15.23651</td></tr><tr><td>correct</td><td>2056</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>15.23651</td></tr><tr><td>loss_val</td><td>1.93877</td></tr><tr><td>multibet outlay</td><td>246753.46453</td></tr><tr><td>multibet outlay < 30</td><td>144452.54566</td></tr><tr><td>multibet profit < 30</td><td>6127.18346</td></tr><tr><td>multibet profit < 30 sd</td><td>23.18574</td></tr><tr><td>multibet profit sd</td><td>39.24114</td></tr><tr><td>profit</td><td>5352.23114</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">noble-sweep-19</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/wu051q76\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/wu051q76</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_031127-wu051q76\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q8joj9qf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004629128740366676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_050334-q8joj9qf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/q8joj9qf\" target=\"_blank\">mild-sweep-20</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004629128740366676, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004629128740366676, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004629128740366676\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:37<00:00,  1.72it/s]\n",
      "100%|██████████| 64/64 [01:29<00:00,  1.40s/it]t]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.58it/s]t]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.56it/s]t]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.09it/s]t]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.00it/s]t]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.89it/s]t]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.01it/s]t]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.17it/s]t]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.13it/s]t]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.10it/s]it]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.54it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.57it/s]it]\n",
      "100%|██████████| 64/64 [00:47<00:00,  1.36it/s]it]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.56it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.98it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.07it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.11it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.01it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.96it/s]]  \n",
      "100%|██████████| 64/64 [00:42<00:00,  1.51it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.20it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.10it/s]]  \n",
      "100%|██████████| 64/64 [00:54<00:00,  1.17it/s]]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.78it/s]]\n",
      "100%|██████████| 64/64 [01:08<00:00,  1.07s/it]]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.01it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.40it/s]]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.89it/s]]\n",
      "100%|██████████| 64/64 [01:01<00:00,  1.05it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.63it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.71it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.62it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]it]\n",
      "100%|██████████| 64/64 [01:30<00:00,  1.41s/it]it]\n",
      "100%|██████████| 64/64 [00:46<00:00,  1.38it/s]it]\n",
      "100%|██████████| 64/64 [01:08<00:00,  1.07s/it]it]\n",
      "100%|██████████| 64/64 [01:20<00:00,  1.25s/it]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.72it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.35it/s]it]\n",
      "100%|██████████| 64/64 [01:08<00:00,  1.07s/it]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.66it/s]it]\n",
      "100%|██████████| 64/64 [00:45<00:00,  1.42it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.33it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.63it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.02it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.69it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.69it/s]it]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "100%|██████████| 50/50 [1:44:23<00:00, 125.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec84f39756145d9b50ff5231707a861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.931 MB of 180.931 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▅▅▆▆▆▇▆▆▆▇▇█▇▇▇█▇▇▇▇█▇▇</td></tr><tr><td>FK ROI < 30</td><td>▄█▇▇▇▇▇█▆▆▆▆▆▅▄▄▄▃▃▃▃▃▅▃▂▃▂▄▄▂▁▂▃▂▃▃▃▃▁▂</td></tr><tr><td>ROI</td><td>▁▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▅▅▆▆▆▇▆▆▆▆▇█▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>ROI < 30</td><td>▃▇▆▇▆▆▇█▆▆▅▆▆▄▄▄▄▂▂▂▂▂▄▂▂▂▂▃▄▂▁▁▂▂▂▃▃▃▁▁</td></tr><tr><td>accuracy</td><td>▁▂▂▂▃▄▄▄▅▅▅▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇█████▇████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▂▆▇▂▆▇▇▆▇▇▇▇▇▇▆▆▂▆▆▂▅▆▁▅▆▆▆▆▆▆▅▅▅▅▅▁▅</td></tr><tr><td>correct</td><td>▁▂▂▂▃▄▄▄▅▅▅▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇█████▇████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▆▇███▇▇▇▆▅▅▅▄▄▄▃▃▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>multibet profit</td><td>▁▂▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▅▅▆▆▆▇▆▇▆▇▇█▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>multibet profit < 30</td><td>▁▅▅▆▆▆▇█▅▆▅▆▆▄▄▄▄▂▂▃▂▂▅▃▃▂▃▅▅▃▂▂▄▃▄▅▆▅▃▄</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>▇███▇▇▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▃▂▂▂▁▂▁▁▁▂▁▁</td></tr><tr><td>profit</td><td>▇█▆▇▆▇▇▅▄▂▁▃▄▃▃▄▄▃▂▂▂▁▂▁▃▂▂▃▂▂▃▁▅▂▃▃▂▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.06791</td></tr><tr><td>FK ROI < 30</td><td>0.02999</td></tr><tr><td>ROI</td><td>-0.08197</td></tr><tr><td>ROI < 30</td><td>0.03758</td></tr><tr><td>accuracy</td><td>0.25938</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>7.92768</td></tr><tr><td>correct</td><td>2075</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>7.92768</td></tr><tr><td>loss_val</td><td>1.95622</td></tr><tr><td>multibet outlay</td><td>248580.15558</td></tr><tr><td>multibet outlay < 30</td><td>155149.65741</td></tr><tr><td>multibet profit < 30</td><td>5830.96921</td></tr><tr><td>multibet profit < 30 sd</td><td>24.12374</td></tr><tr><td>multibet profit sd</td><td>40.80156</td></tr><tr><td>profit</td><td>5261.9896</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">mild-sweep-20</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/q8joj9qf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/q8joj9qf</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_050334-q8joj9qf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r1kd60v8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003338978197423405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_064830-r1kd60v8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/r1kd60v8\" target=\"_blank\">dutiful-sweep-21</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003338978197423405, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003338978197423405, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0003338978197423405\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.80it/s]\n",
      "100%|██████████| 6/6 [01:51<00:00, 18.54s/it]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.79it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.75it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.80it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.72it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.01it/s]/it]\n",
      "100%|██████████| 6/6 [00:39<00:00,  6.58s/it]/it]\n",
      "100%|██████████| 6/6 [00:22<00:00,  3.75s/it]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.71it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.76it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.75it/s]s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.92it/s]s/it]\n",
      "100%|██████████| 6/6 [02:01<00:00, 20.26s/it]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.76it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.67it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.82it/s]s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.39s/it]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.77it/s]s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  3.00it/s]it]  \n",
      "100%|██████████| 6/6 [00:25<00:00,  4.28s/it]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.74it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.78it/s]it]  \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.81it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.78it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.60it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.78it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.74it/s]it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.70it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.81it/s]s/it]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.26s/it]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.72it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.28it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.79it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.30it/s]/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.44it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.52it/s]/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.79it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.20it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.56it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.74it/s]/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.75it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.56it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.47it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.26it/s]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.50s/it]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.21it/s]/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.87it/s]/it]\n",
      "100%|██████████| 50/50 [1:34:14<00:00, 113.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7604435b6345e999326423e6b182d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.057 MB of 180.057 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▃▄▃▅▅▄▅▄▄▆▄▆▆▄▇▄▄▇▄▇▇▃█▃▃█▄██▅█▅▅█▅▅</td></tr><tr><td>FK ROI < 30</td><td>▁▄▂▆▇▄▆▅▆▇▆██▆▇▇▇▇▇██▆▇▇▇▆▇▆▆▇▆▇▇▇▆▇▆▆▆▅</td></tr><tr><td>ROI</td><td>▁▁▂▃▃▄▃▅▅▄▅▄▄▆▃▆▆▄▇▄▄▇▃▇▇▃█▃▃█▄█▇▅▇▅▅█▅▅</td></tr><tr><td>ROI < 30</td><td>▁▃▂▅▆▄▆▅▆▇▆▇▇▆▆▇▇▇▇██▆▇▇▇▇▇▆▅▇▆█▇▇▆▇▆▆▆▆</td></tr><tr><td>accuracy</td><td>▃▄▄▁▄▄▄▅▅▅▅▅▄▄▄▅▅▆▅▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>correct</td><td>▃▄▄▁▄▄▄▅▅▅▅▅▄▅▄▅▅▆▅▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▃▅▅▆▇▇▇▇▇▇██████████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▆▆</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▄▃▃▅▄▅▅▅▆▅▅▇▅▆▆▆▇▆▆▇▆▇▇▇▇▇▇█▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▁▂▂▂▁▄▄▂▃▂▂▅▁▄▅▂▆▂▂▇▂▇▇▂█▁▁█▂█▇▅▇▄▄█▄▅</td></tr><tr><td>multibet profit < 30</td><td>▁▃▂▄▅▄▅▅▆▆▆▇▇▇▆▇▇▇▇██▆▇▇▇▇█▆▆█▇█▇█▇▇▇▇▇▆</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▅▂▃▅▄▆▅▅▆▅▅█▅▇▇▅▇▆▆▇▆▇▇▆█▆▆█▇█▇▇▇▇▇▇██</td></tr><tr><td>multibet profit sd</td><td>▂▃▅▇▆▆▅█▇▆▆▆▆▅▅▅▅▄▆▃▃▆▃▆▅▂▅▂▃▅▂▄▄▂▄▂▁▃▁▁</td></tr><tr><td>profit</td><td>▁▄▄█▅▃▅▃▃▄▃▄▆▄▃▃▃▄▂▄▄▂▃▃▃▃▄▃▃▄▂▂▂▂▁▃▃▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.09742</td></tr><tr><td>FK ROI < 30</td><td>0.05546</td></tr><tr><td>ROI</td><td>-0.10775</td></tr><tr><td>ROI < 30</td><td>0.06476</td></tr><tr><td>accuracy</td><td>0.22687</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>11.36085</td></tr><tr><td>correct</td><td>1815</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>11.36085</td></tr><tr><td>loss_val</td><td>2.04455</td></tr><tr><td>multibet outlay</td><td>262053.90786</td></tr><tr><td>multibet outlay < 30</td><td>119860.29945</td></tr><tr><td>multibet profit < 30</td><td>7761.63499</td></tr><tr><td>multibet profit < 30 sd</td><td>19.19575</td></tr><tr><td>multibet profit sd</td><td>47.83247</td></tr><tr><td>profit</td><td>5739.20733</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dutiful-sweep-21</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/r1kd60v8\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/r1kd60v8</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_064830-r1kd60v8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lq5eseli with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004229634405814034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_082309-lq5eseli</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/lq5eseli\" target=\"_blank\">fluent-sweep-22</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004229634405814034, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004229634405814034, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004229634405814034\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:35<00:00,  3.65it/s]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.57it/s]\n",
      "100%|██████████| 129/129 [00:26<00:00,  4.81it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.97it/s]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.30it/s]\n",
      "100%|██████████| 129/129 [00:27<00:00,  4.77it/s]\n",
      "100%|██████████| 129/129 [00:26<00:00,  4.81it/s]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.86it/s]\n",
      "100%|██████████| 129/129 [00:27<00:00,  4.77it/s]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.26it/s]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.78it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.86it/s]]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.98it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.33it/s]]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.65it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.40it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.22it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.18it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.33it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.73it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.16it/s] \n",
      "100%|██████████| 129/129 [00:42<00:00,  3.02it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.44it/s] \n",
      "100%|██████████| 129/129 [00:37<00:00,  3.43it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.77it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.03it/s]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.44it/s]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.94it/s]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.84it/s]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.20it/s]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.88it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.75it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.19it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.52it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.99it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.74it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.47it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.61it/s]]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.40it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.29it/s]]\n",
      "100%|██████████| 129/129 [00:50<00:00,  2.55it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.42it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.65it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.98it/s]]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.13it/s]]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.95it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.77it/s]]\n",
      "100%|██████████| 129/129 [00:52<00:00,  2.44it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.01it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.72it/s]]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "100%|██████████| 50/50 [1:43:10<00:00, 123.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79a614245bc4d4aaf8df488e98d1b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.968 MB of 180.968 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▃▃▃▃▃▄▄▄▄▄▅▄▅▅▅▅▅▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇████</td></tr><tr><td>FK ROI < 30</td><td>▃▆▇▆█▇█▇▆██▆▆▆▆▅▃▃▃▄▄▃▂▄▁▂▄▂▃▂▃▁▂▂▃▃▄▅▅▃</td></tr><tr><td>ROI</td><td>▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▄▅▅▅▆▆▅▆▇▆▇▇▇▇▇███</td></tr><tr><td>ROI < 30</td><td>▃▆▇▆█▇▇▆▆██▆▆▅▆▅▃▃▃▃▃▃▁▅▁▂▄▃▄▄▅▃▃▃▅▄▆▆█▅</td></tr><tr><td>accuracy</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███▇███████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▂▇▇▂▆▇▇▆▇▇▇▇▇▇▇▆▂▆▆▂▅▆▁▅▆▆▆▆▆▆▆▅▅▅▅▁▅</td></tr><tr><td>correct</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███▇███████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▆▇████▇▇▆▆▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇████</td></tr><tr><td>multibet profit < 30</td><td>▁▃▄▄▄▄▄▄▄▅▅▄▄▄▄▄▃▃▃▃▃▄▂▄▂▃▄▄▄▄▅▄▄▅▅▅▆▇█▆</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>▇████▇▇▇▆▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▂▂▁▂▂▂▂▂▂</td></tr><tr><td>profit</td><td>█▇▆▆▆▅▆▆▃▃▂▅▁▃▃▅▄▄▄▅▅▄▅▆▄▆▆▅▆▆▇▆▆▇█▇██▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.04471</td></tr><tr><td>FK ROI < 30</td><td>0.04635</td></tr><tr><td>ROI</td><td>-0.05391</td></tr><tr><td>ROI < 30</td><td>0.05942</td></tr><tr><td>accuracy</td><td>0.25962</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>14.64502</td></tr><tr><td>correct</td><td>2077</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>14.64502</td></tr><tr><td>loss_val</td><td>1.9493</td></tr><tr><td>multibet outlay</td><td>248195.44311</td></tr><tr><td>multibet outlay < 30</td><td>153271.49262</td></tr><tr><td>multibet profit < 30</td><td>9107.01923</td></tr><tr><td>multibet profit < 30 sd</td><td>24.43823</td></tr><tr><td>multibet profit sd</td><td>42.6096</td></tr><tr><td>profit</td><td>6005.0957</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fluent-sweep-22</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/lq5eseli\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/lq5eseli</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_082309-lq5eseli\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z4yj5nb7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000621323391543195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_100647-z4yj5nb7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/z4yj5nb7\" target=\"_blank\">zesty-sweep-23</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000621323391543195, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000621323391543195, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.000621323391543195\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:35<00:00,  1.80it/s]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.85it/s]t]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.14it/s]t]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.62it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.45it/s]t]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.86it/s]t]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.04it/s]t]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.67it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]t]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.82it/s]t]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.98it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.64it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.35it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.74it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.95it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.77it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.08it/s]it]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.04it/s]it]\n",
      "100%|██████████| 64/64 [00:44<00:00,  1.45it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.62it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.17it/s]it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.22it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.66it/s]]  \n",
      "100%|██████████| 64/64 [00:27<00:00,  2.35it/s]]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.04it/s]]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.05it/s]]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.76it/s]]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.48it/s]]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.94it/s]]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.81it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.41it/s]it]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.54it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.37it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.41it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.95it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.00it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.50it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.50it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.57it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.55it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.94it/s]it]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.94it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.40it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.46it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.41it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.98it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.04it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.54it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.63it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.95it/s]it]\n",
      "100%|██████████| 50/50 [1:39:40<00:00, 119.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3939c930ab9e4cb8be32da1b2d18e24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.935 MB of 180.935 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▃▃▄▃▄▃▄▃▄▄▃▅▅▄▄▅▆▅▆▅▆▆▆▆▆▇▅▇▇█▆█▇█▇█</td></tr><tr><td>FK ROI < 30</td><td>▆▇▇▇▇▇▇██▇▆▆▆▆▅▇▅▄▄▆▅▄▄▃▄▄▄▄▅▃▃▃▃▃▂▃▂▃▁▁</td></tr><tr><td>ROI</td><td>▁▁▂▂▃▃▃▃▄▃▃▃▃▄▃▄▄▃▄▅▆▅▅▅▅▅▆▆▆▇▅▇▇▇▆█▇█▇█</td></tr><tr><td>ROI < 30</td><td>▆▇▇▇▇▇▆███▆▆▆▅▄▇▅▃▄▅▅▄▄▄▃▃▄▄▅▃▄▃▃▄▂▄▃▃▂▁</td></tr><tr><td>accuracy</td><td>▁▂▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇█▇██▇██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▂▂█▇▂▁▇▇▁▁▇▁▁▇▇▁▁▇▇▁▁▇▆▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▁▂▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇█▇██▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▅▆███████▆▆▆▅▅▄▄▄▄▃▄▃▂▂▂▂▂▂▂▁▂▁▂▂▁▂▁▁▂▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▄▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▂▃▂▃▃▃▂▃▄▃▄▄▃▄▅▆▅▅▅▆▅▆▆▆▇▅▇▇▇▆█████</td></tr><tr><td>multibet profit < 30</td><td>▃▄▅▆▆▅▅▇█▇▅▅▆▅▃█▄▂▃▅▅▄▄▃▃▃▅▅▆▄▄▄▃▅▁▆▄▅▂▁</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▃▂▃▃▃▃▃▃▃▄▄▄▄▄▅▄▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>multibet profit sd</td><td>█▇█████▇▇▆▆▆▅▅▄▄▄▄▃▄▄▃▄▂▂▃▂▃▂▃▁▃▃▂▂▂▂▂▂▂</td></tr><tr><td>profit</td><td>▇▆▆▅▆▅█▇▆▆▆▂▄▂▄▄▂▄▃▄▃▁▄▂▃▂▃▂▂▃▂▃▄▂▃▃▄▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.05557</td></tr><tr><td>FK ROI < 30</td><td>0.03114</td></tr><tr><td>ROI</td><td>-0.06557</td></tr><tr><td>ROI < 30</td><td>0.03972</td></tr><tr><td>accuracy</td><td>0.25225</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>8.00343</td></tr><tr><td>correct</td><td>2018</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>8.00343</td></tr><tr><td>loss_val</td><td>1.95574</td></tr><tr><td>multibet outlay</td><td>249760.37845</td></tr><tr><td>multibet outlay < 30</td><td>149554.03102</td></tr><tr><td>multibet profit < 30</td><td>5939.97102</td></tr><tr><td>multibet profit < 30 sd</td><td>23.75849</td></tr><tr><td>multibet profit sd</td><td>42.46483</td></tr><tr><td>profit</td><td>5519.48776</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">zesty-sweep-23</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/z4yj5nb7\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/z4yj5nb7</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_100647-z4yj5nb7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mnhq0c80 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006727499970895868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_114652-mnhq0c80</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/mnhq0c80\" target=\"_blank\">super-sweep-24</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006727499970895868, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006727499970895868, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0006727499970895868\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.26it/s]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.94it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.03it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.03it/s]/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.76it/s]/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.77it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.14it/s]/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.86it/s]/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.51it/s]/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.45it/s]/it]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.70s/it]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.31it/s]s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  3.00it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.13it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.42it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.31it/s]it]  \n",
      "100%|██████████| 6/6 [00:02<00:00,  2.65it/s]it]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "100%|██████████| 6/6 [00:15<00:00,  2.55s/it]it]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.45it/s]s/it]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.54it/s]s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.29it/s]s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.47it/s]s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.87it/s]s/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.71it/s]it]  \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.34it/s]it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.97it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.16it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.34it/s]t] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.19it/s]t]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.92it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.16it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.04it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.25it/s]t] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.36it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.04it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.33it/s]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.57s/it]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.50it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.37it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.19it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.52it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.29it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.49it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.50it/s]/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.59s/it]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.23it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.29it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.47it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.48it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.23it/s]/it]\n",
      "100%|██████████| 50/50 [1:24:54<00:00, 101.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6fbcad7f1d437aa79baffb7fc05456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.991 MB of 179.991 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▄▁▂▃▃▃▃▃▃▅▃▅▄▅▄▅▅▄▅▅▆▃▆▂▂▇▄▆▆▅▆▅▄█▄██▅▇█</td></tr><tr><td>FK ROI < 30</td><td>▁▆▆▆▆▇▇▇▇█▇█▇▇▇▇▇█▇██▆█▆▆█▇▇▇▇▇▇▇▇▆█▇▇▇▆</td></tr><tr><td>ROI</td><td>▄▁▁▂▃▂▃▃▃▅▃▅▄▅▄▅▅▄▅▅▆▃▆▂▂▇▃▆▆▅▆▅▄█▄█▇▅▇█</td></tr><tr><td>ROI < 30</td><td>▁▆▆▆▆▇▆▇▇▇▆█▇▇▇▇▇█▇██▆█▆▆█▇▇▇▇▇▇▆▇▆█▇▇▇▆</td></tr><tr><td>accuracy</td><td>▄▁▅▄▃▄▅▅▅▄▅▅▅▅▅▅▆▅▆▆▅▅▆▆▆▆▆▇▇▇▇▇▇▇▆██▇█▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▇█▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>correct</td><td>▄▁▅▄▃▄▅▅▅▄▅▅▅▅▅▅▆▅▆▆▅▅▆▆▆▆▆▇▇▇▇▇▇▇▆██▇█▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>▇█▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>█▁▂▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▆▅▅▅▄▅</td></tr><tr><td>multibet outlay < 30</td><td>█▁▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▄▅▅▄▅▅▅▅▅▅▅▅▅▅▅▆▅▆▅▆▆▆</td></tr><tr><td>multibet profit</td><td>▂▁▁▂▂▁▂▂▂▄▂▄▃▄▂▅▅▃▅▃▅▂▆▁▁▇▂▆▅▄▆▄▃█▃█▇▅▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇██▆█▆▆█▇▇█▇▇▇▆█▆█▇▇▇▆</td></tr><tr><td>multibet profit < 30 sd</td><td>█▁▁▂▂▃▂▃▃▃▃▃▃▃▄▃▃▄▃▄▄▃▄▃▄▄▄▄▄▄▄▄▄▅▄▅▄▄▄▄</td></tr><tr><td>multibet profit sd</td><td>█▂▃▄▄▃▄▄▄▄▅▄▄▅▃▅▅▃▅▂▃▄▃▃▃▃▄▁▁▄▁▄▃▂▂▂▃▁▃▄</td></tr><tr><td>profit</td><td>▂▅▄▂▁▃▃▃▄▅▆▄▃▆▄██▄▆▂▂▅▃▃▄▄▅▇▇▅▆▇▆▃▄▄▃▃▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.07839</td></tr><tr><td>FK ROI < 30</td><td>0.05285</td></tr><tr><td>ROI</td><td>-0.08876</td></tr><tr><td>ROI < 30</td><td>0.05869</td></tr><tr><td>accuracy</td><td>0.22037</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>11.13285</td></tr><tr><td>correct</td><td>1763</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>11.13285</td></tr><tr><td>loss_val</td><td>2.04721</td></tr><tr><td>multibet outlay</td><td>264634.86815</td></tr><tr><td>multibet outlay < 30</td><td>125234.58851</td></tr><tr><td>multibet profit < 30</td><td>7350.49785</td></tr><tr><td>multibet profit < 30 sd</td><td>20.14154</td></tr><tr><td>multibet profit sd</td><td>51.5795</td></tr><tr><td>profit</td><td>6246.63795</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">super-sweep-24</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/mnhq0c80\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/mnhq0c80</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_114652-mnhq0c80\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9m562inp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005504303353470316\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_131218-9m562inp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/9m562inp\" target=\"_blank\">efficient-sweep-25</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005504303353470316, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005504303353470316, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0005504303353470316\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:49<00:00,  2.95it/s]\n",
      "100%|██████████| 324/324 [01:51<00:00,  2.91it/s]\n",
      "100%|██████████| 324/324 [01:52<00:00,  2.89it/s]\n",
      "100%|██████████| 324/324 [02:04<00:00,  2.61it/s]\n",
      "100%|██████████| 324/324 [02:05<00:00,  2.58it/s]\n",
      "100%|██████████| 324/324 [01:56<00:00,  2.79it/s]\n",
      "100%|██████████| 324/324 [02:04<00:00,  2.60it/s]\n",
      "100%|██████████| 324/324 [02:06<00:00,  2.55it/s]\n",
      "100%|██████████| 324/324 [02:03<00:00,  2.63it/s]\n",
      "100%|██████████| 324/324 [01:56<00:00,  2.77it/s]\n",
      "100%|██████████| 324/324 [02:07<00:00,  2.55it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.81it/s]]\n",
      "100%|██████████| 324/324 [02:01<00:00,  2.66it/s]]\n",
      "100%|██████████| 324/324 [02:02<00:00,  2.64it/s]]\n",
      "100%|██████████| 324/324 [02:03<00:00,  2.63it/s]]\n",
      "100%|██████████| 324/324 [01:57<00:00,  2.75it/s]]\n",
      "100%|██████████| 324/324 [01:57<00:00,  2.75it/s]]\n",
      "100%|██████████| 324/324 [02:02<00:00,  2.64it/s]]\n",
      "100%|██████████| 324/324 [01:59<00:00,  2.71it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.80it/s]it]\n",
      "100%|██████████| 324/324 [01:53<00:00,  2.86it/s]it]\n",
      "100%|██████████| 324/324 [01:54<00:00,  2.82it/s]it]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.80it/s]it]\n",
      "100%|██████████| 324/324 [01:54<00:00,  2.83it/s]it]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.82it/s]it]\n",
      "100%|██████████| 324/324 [01:59<00:00,  2.72it/s]it]\n",
      "100%|██████████| 324/324 [02:09<00:00,  2.50it/s]it]\n",
      "100%|██████████| 324/324 [02:09<00:00,  2.51it/s]it]\n",
      "100%|██████████| 324/324 [01:57<00:00,  2.76it/s]it]\n",
      "100%|██████████| 324/324 [02:05<00:00,  2.58it/s]it]\n",
      "100%|██████████| 324/324 [01:56<00:00,  2.77it/s]it]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.81it/s]it]\n",
      "100%|██████████| 324/324 [02:01<00:00,  2.67it/s]it]\n",
      "100%|██████████| 324/324 [01:49<00:00,  2.95it/s]]  \n",
      "100%|██████████| 324/324 [01:53<00:00,  2.85it/s]]\n",
      "100%|██████████| 324/324 [01:50<00:00,  2.93it/s]]\n",
      "100%|██████████| 324/324 [01:50<00:00,  2.94it/s]]\n",
      "100%|██████████| 324/324 [01:50<00:00,  2.94it/s]]\n",
      "100%|██████████| 324/324 [01:52<00:00,  2.87it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.80it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.80it/s]]\n",
      "100%|██████████| 324/324 [01:54<00:00,  2.83it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.80it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.80it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.81it/s]]\n",
      "100%|██████████| 324/324 [01:56<00:00,  2.78it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.80it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.81it/s]]\n",
      "100%|██████████| 324/324 [01:55<00:00,  2.80it/s]]\n",
      "100%|██████████| 324/324 [01:56<00:00,  2.78it/s]]\n",
      "100%|██████████| 50/50 [2:43:32<00:00, 196.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5421baf9a0f84cedb75c8046c5b5641d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.530 MB of 179.530 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▃▄▄▄▄▄▄▅▅▅▆▅▆▆▆▅▅▆▆▇▆▆▅▇▆▇▇▇▇█▇▇▆█▇██</td></tr><tr><td>FK ROI < 30</td><td>▇████▇▇▆▆▅▅▅▅▅▄▃▃▂▂▂▃▁▃▂▂▁▂▁▂▃▁▂▃▂▂▁▃▃▂▂</td></tr><tr><td>ROI</td><td>▁▂▂▃▄▄▄▄▄▃▅▄▅▅▅▆▆▆▅▅▆▆▇▆▆▅▇▆▇▇▆▇█▇▆▆█▇▇█</td></tr><tr><td>ROI < 30</td><td>▇█████▇▇▆▅▅▆▅▄▄▄▃▂▂▂▃▁▃▂▃▁▂▁▂▃▁▂▄▂▂▁▃▃▃▂</td></tr><tr><td>accuracy</td><td>▁▂▃▃▅▆▇▇▇▇▇█▇▇▇█▇██▇▇███▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▇▇▇▆▇▆▆▆▅▅▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▁▁▂▁▁</td></tr><tr><td>correct</td><td>▁▂▃▃▅▆▇▇▇▇▇█▇▇▇█▇██▇▇███▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>multibet outlay</td><td>▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▂▂▃▄▄▄▄▅▄▅▅▅▆▆▆▆▆▅▆▆▆▇▆▆▅▇▆▇▇▆▇█▇▆▆▇▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▇▇█████▇▇▆▆▆▆▅▅▄▄▂▂▂▃▁▄▂▃▂▂▂▃▄▂▃▅▃▃▁▄▄▄▂</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>▅▅▅▄▃▃▂▂▂▁▂▁▁▁▁▂▂▄▂▃▃▄▄▄▃▂▅▄▄▄▆▃▅▅▅▅▆▆█▇</td></tr><tr><td>profit</td><td>▆▆▇▅▅▂▅▅▃▂▅▇▄▄▂▃▄▄▄▆▃▆▇▄▅▁█▃▅▆▃▅▆▃▄▅▃▃█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.03271</td></tr><tr><td>FK ROI < 30</td><td>-0.00155</td></tr><tr><td>ROI</td><td>-0.03666</td></tr><tr><td>ROI < 30</td><td>0.00407</td></tr><tr><td>accuracy</td><td>0.24213</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>6.025</td></tr><tr><td>correct</td><td>1937</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.025</td></tr><tr><td>loss_val</td><td>2.30761</td></tr><tr><td>multibet outlay</td><td>306609.07117</td></tr><tr><td>multibet outlay < 30</td><td>229106.88561</td></tr><tr><td>multibet profit < 30</td><td>931.656</td></tr><tr><td>multibet profit < 30 sd</td><td>35.17739</td></tr><tr><td>multibet profit sd</td><td>53.56014</td></tr><tr><td>profit</td><td>5612.58402</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">efficient-sweep-25</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/9m562inp\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/9m562inp</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_131218-9m562inp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 630tqw2n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.475700198875622e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_155623-630tqw2n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/630tqw2n\" target=\"_blank\">bright-sweep-26</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 6.475700198875622e-05, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 6.475700198875622e-05, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 6.475700198875622e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:55<00:00,  5.80it/s]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.72it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.68it/s]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.74it/s]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.63it/s]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.92it/s]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.95it/s]\n",
      "100%|██████████| 324/324 [00:47<00:00,  6.85it/s]\n",
      "100%|██████████| 324/324 [00:46<00:00,  6.91it/s]\n",
      "100%|██████████| 324/324 [00:46<00:00,  6.96it/s]\n",
      "100%|██████████| 324/324 [00:47<00:00,  6.85it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.90it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.85it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.86it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.63it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.68it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.69it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.83it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.77it/s]]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.54it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.87it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.92it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.91it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.81it/s] \n",
      "100%|██████████| 324/324 [00:56<00:00,  5.73it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.86it/s]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.86it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.97it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.91it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.92it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.79it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.83it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.68it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.82it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.90it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.89it/s]]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.86it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.92it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.91it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.94it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.95it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.97it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.95it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.95it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.97it/s]]\n",
      "100%|██████████| 50/50 [1:49:44<00:00, 131.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af440d329d254c249aed67488a8c5c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.879 MB of 180.879 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>FK ROI < 30</td><td>▁▃▃▄▅▅▅▆▆▆▇▇▇▇█████████████▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>ROI</td><td>▁▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>ROI < 30</td><td>▁▃▃▄▅▅▅▆▆▆▆▆▆▇▇▇███████████▇▇█▇██▇█▇▇▇▇▇</td></tr><tr><td>accuracy</td><td>▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██████▁████▇██████▇▇▇▇██▇▁▇▇▇█▇▇▇▇▇▇▇▆▇▇</td></tr><tr><td>correct</td><td>▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▆▆▆▆▆▅▅▆▅▅▄▅▄▄▄▄▃▄▄▃▃▃▃▃▂▃▃▃▂▂▂▂▂▁▁▂▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▃▄▅▆▆▇▇▇▇████████████████████▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>multibet profit</td><td>▁▂▂▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit < 30</td><td>▁▂▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇█▇█████████████████████</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>multibet profit sd</td><td>▁▄▅▆▇▇██████████▇▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂</td></tr><tr><td>profit</td><td>███▇▆▆▅▅▁▂▃▂▄▅▄▆▄▂▄▃▄▅▄▅▄▄▅▂▃▅▅▅▄▅▅▅▆▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.09939</td></tr><tr><td>FK ROI < 30</td><td>0.05975</td></tr><tr><td>ROI</td><td>-0.11147</td></tr><tr><td>ROI < 30</td><td>0.06537</td></tr><tr><td>accuracy</td><td>0.22362</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>9.7899</td></tr><tr><td>correct</td><td>1789</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>9.7899</td></tr><tr><td>loss_val</td><td>1.98098</td></tr><tr><td>multibet outlay</td><td>263071.93392</td></tr><tr><td>multibet outlay < 30</td><td>118530.73195</td></tr><tr><td>multibet profit < 30</td><td>7748.81626</td></tr><tr><td>multibet profit < 30 sd</td><td>18.71153</td></tr><tr><td>multibet profit sd</td><td>48.4028</td></tr><tr><td>profit</td><td>5724.65203</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bright-sweep-26</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/630tqw2n\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/630tqw2n</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_155623-630tqw2n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k1wfe1rk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003150476301233806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_174629-k1wfe1rk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/k1wfe1rk\" target=\"_blank\">peach-sweep-27</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003150476301233806, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003150476301233806, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0003150476301233806\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:41<00:00,  3.13it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.11it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.89it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.11it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.09it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.09it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.82it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.09it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.12it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.05it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.81it/s]]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.08it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.88it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.79it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.94it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.67it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.93it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.95it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.96it/s] \n",
      "100%|██████████| 129/129 [00:43<00:00,  2.94it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.67it/s] \n",
      "100%|██████████| 129/129 [00:35<00:00,  3.64it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.97it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.96it/s]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.65it/s]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.65it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.95it/s]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.74it/s]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.17it/s]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.36it/s]]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.69it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.61it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.65it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.64it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.90it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.91it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.60it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.69it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.93it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.92it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.66it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.65it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.04it/s]]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.07it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.75it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.80it/s]]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.08it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.06it/s]]\n",
      "100%|██████████| 50/50 [1:41:09<00:00, 121.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5d2bf4066f4b618f86ade2616e0f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='181.028 MB of 181.028 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▂▂▁▂▃▃▃▄▄▄▄▄▄▅▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇█▇███</td></tr><tr><td>FK ROI < 30</td><td>▇▇██▇▆▆▅▅▆▅▅▆▅▄▅▃▃▃▃▃▂▂▃▃▃▃▃▃▃▃▂▃▂▂▂▁▁▂▁</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▂▂▁▂▃▃▃▃▄▄▄▄▄▅▄▅▅▅▅▆▆▆▆▆▇▇▆▇▇▇█▇███</td></tr><tr><td>ROI < 30</td><td>▇▇██▇▇▆▅▆▆▅▅▆▅▄▄▃▃▃▃▃▂▂▃▃▂▃▃▂▂▃▂▂▂▂▂▁▁▂▁</td></tr><tr><td>accuracy</td><td>▁▁▂▂▃▃▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▄▇▇▇▇▇▆▆▆▆▆▆▆▃▅▅▅▅▅▂▅▅▅▄▅▄▄▄▄▄▄▃▁▃▃▃▃▃</td></tr><tr><td>correct</td><td>▁▁▂▂▃▃▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▇████▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▆▅▅▆▆▆▇▇▇▇▇▇▇▇▇█▇███</td></tr><tr><td>multibet profit < 30</td><td>▅▇███▇▆▅▅▆▅▅▆▆▄▄▃▃▃▃▃▂▂▂▂▂▃▃▂▃▃▂▃▂▂▃▁▁▃▁</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>█▇██▇▇▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▂▂▂▂▁▂▁▁</td></tr><tr><td>profit</td><td>▆█▆▃▅▄▄▂▅▅█▅▄▃▆▄▁▄▄▃▄▆▄▂▂▃▄▃▁▄▁▃▂▂▂▂▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.04732</td></tr><tr><td>FK ROI < 30</td><td>0.03029</td></tr><tr><td>ROI</td><td>-0.05943</td></tr><tr><td>ROI < 30</td><td>0.0349</td></tr><tr><td>accuracy</td><td>0.263</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>15.08763</td></tr><tr><td>correct</td><td>2104</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>15.08763</td></tr><tr><td>loss_val</td><td>1.93502</td></tr><tr><td>multibet outlay</td><td>245817.69003</td></tr><tr><td>multibet outlay < 30</td><td>151725.14485</td></tr><tr><td>multibet profit < 30</td><td>5295.68827</td></tr><tr><td>multibet profit < 30 sd</td><td>22.90233</td></tr><tr><td>multibet profit sd</td><td>42.78848</td></tr><tr><td>profit</td><td>5693.88889</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">peach-sweep-27</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/k1wfe1rk\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/k1wfe1rk</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_174629-k1wfe1rk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: feffgjpy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006281281340359523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_192802-feffgjpy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/feffgjpy\" target=\"_blank\">true-sweep-28</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006281281340359523, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006281281340359523, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0006281281340359523\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:17<00:00,  4.21it/s]\n",
      "100%|██████████| 324/324 [01:09<00:00,  4.67it/s]\n",
      "100%|██████████| 324/324 [01:09<00:00,  4.65it/s]\n",
      "100%|██████████| 324/324 [01:17<00:00,  4.18it/s]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.15it/s]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.61it/s]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.60it/s]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.13it/s]\n",
      "100%|██████████| 324/324 [01:17<00:00,  4.17it/s]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.62it/s]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.60it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.12it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.09it/s]]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.58it/s]]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.61it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.14it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.09it/s]]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.59it/s]]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.57it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.13it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.14it/s]]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.57it/s]]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.60it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.12it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.10it/s]it]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.58it/s]it]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.12it/s]]  \n",
      "100%|██████████| 324/324 [01:18<00:00,  4.11it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.11it/s]]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.59it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.10it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.10it/s]]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.58it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.10it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.10it/s]]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.11it/s]]\n",
      "100%|██████████| 324/324 [01:11<00:00,  4.56it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.10it/s]]\n",
      "100%|██████████| 324/324 [01:20<00:00,  4.05it/s]]\n",
      "100%|██████████| 324/324 [01:11<00:00,  4.54it/s]]\n",
      "100%|██████████| 324/324 [01:11<00:00,  4.52it/s]]\n",
      "100%|██████████| 324/324 [01:20<00:00,  4.05it/s]]\n",
      "100%|██████████| 324/324 [01:20<00:00,  4.04it/s]]\n",
      "100%|██████████| 324/324 [01:11<00:00,  4.54it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.07it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.09it/s]]\n",
      "100%|██████████| 324/324 [01:11<00:00,  4.55it/s]]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.57it/s]]\n",
      "100%|██████████| 324/324 [01:20<00:00,  4.04it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.08it/s]]\n",
      "100%|██████████| 50/50 [2:06:52<00:00, 152.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882b17b33a544a59a3c2f1da2ad0cad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.798 MB of 179.798 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▁▂▂▂▃▄▄▄▅▅▅▅▅▆▇▆▆▇▆▆▇▆▆▇▆▇▇▇█▇▇▇▆▆▆▆▇</td></tr><tr><td>FK ROI < 30</td><td>███▇▇▆▆▇▆▆▆▇▅▆▆▅▅▅▅▄▄▄▃▄▃▄▃▃▃▂▃▄▂▃▃▁▁▁▁▂</td></tr><tr><td>ROI</td><td>▁▁▂▁▂▂▂▃▃▃▄▅▅▄▅▅▆▆▆▅▇▆▆▇▆▆▇▆▇▇▇█▇▇▇▆▇▆▆▇</td></tr><tr><td>ROI < 30</td><td>▇██▇▇▆▆▇▆▇▇▇▆▆▆▅▆▅▅▄▅▅▃▄▃▄▃▃▄▃▃▄▂▂▃▂▁▁▁▃</td></tr><tr><td>accuracy</td><td>▁▂▃▄▅▅▆▆▆▇▇▇▇▇██▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▆▅▅▅▅▅▅▁▅▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>correct</td><td>▁▂▃▄▅▅▆▆▆▇▇▇▇▇██▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁</td></tr><tr><td>loss_val</td><td>▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇███</td></tr><tr><td>multibet outlay</td><td>▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▂▁▂▂▂▃▄▄▄▅▅▅▅▅▆▆▆▅▇▆▆▇▆▆▇▆▇▇▆█▇▇▇▆▆▆▆▇</td></tr><tr><td>multibet profit < 30</td><td>▇▇█▇▇▆▆█▇▇██▇▇█▇█▇▆▅▇▆▄▆▅▆▅▄▆▄▅▇▄▄▄▂▂▁▂▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█▇████</td></tr><tr><td>multibet profit sd</td><td>▇▆▅▄▂▂▂▁▁▁▁▂▂▁▂▂▂▄▃▃▄▃▂▄▅▅▅▆▆▆▆▇▇▇█▆█▇██</td></tr><tr><td>profit</td><td>█▅▇▆▄▅▅▂▅▁▂▆▃▁▆▆▄▃▃▃▂▄▄▆▅▅▆▆▅▆▅▅▃▃▄▅▆▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.03065</td></tr><tr><td>FK ROI < 30</td><td>0.01135</td></tr><tr><td>ROI</td><td>-0.03133</td></tr><tr><td>ROI < 30</td><td>0.02485</td></tr><tr><td>accuracy</td><td>0.23825</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>6.24719</td></tr><tr><td>correct</td><td>1906</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.24719</td></tr><tr><td>loss_val</td><td>2.22914</td></tr><tr><td>multibet outlay</td><td>297967.78169</td></tr><tr><td>multibet outlay < 30</td><td>218610.14818</td></tr><tr><td>multibet profit < 30</td><td>5432.16988</td></tr><tr><td>multibet profit < 30 sd</td><td>33.62042</td></tr><tr><td>multibet profit sd</td><td>51.97374</td></tr><tr><td>profit</td><td>5754.24608</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-28</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/feffgjpy\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/feffgjpy</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_192802-feffgjpy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uvwa4n9h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009816497103935775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_213519-uvwa4n9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/uvwa4n9h\" target=\"_blank\">comic-sweep-29</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009816497103935775, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009816497103935775, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0009816497103935775\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:42<00:00,  3.03it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.03it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.06it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.77it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.04it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.04it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.77it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.84it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.01it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.04it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.82it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.03it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.02it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.04it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.06it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.81it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.02it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.05it/s] \n",
      "100%|██████████| 129/129 [00:34<00:00,  3.79it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.81it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.01it/s] \n",
      "100%|██████████| 129/129 [00:33<00:00,  3.81it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.80it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.03it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.99it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.78it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.02it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.78it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.82it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.01it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.82it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.02it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  3.00it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.82it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.77it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.02it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.76it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.77it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.95it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.66it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.90it/s]]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.64it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.77it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.90it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.07it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.68it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.91it/s]]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.94it/s]]\n",
      "100%|██████████| 50/50 [1:38:02<00:00, 117.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8622caabb56a4e119229a89fe667329f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.977 MB of 179.977 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▇▅▆▇▇▅▆▇▇▅▇▆▇▇▆▇▇▆▇▇█▅▆▆</td></tr><tr><td>FK ROI < 30</td><td>▆▇█████▆▄▆▆▅▇▆▇▇█▆▆▆▇▄▄▆▅▃▅▄▅▅▄▄▂▂▂▃▄▁▃▂</td></tr><tr><td>ROI</td><td>▁▂▂▂▃▃▄▄▄▄▄▅▅▄▆▆▇▅▆▆▇▅▆▆▇▅▇▆▆▇▆▇▇▆▇▇█▅▆▆</td></tr><tr><td>ROI < 30</td><td>▆▇▇███▇▆▄▆▆▅▇▆▇▆█▆▆▇▇▄▄▆▅▃▆▄▆▅▄▅▂▃▂▃▅▁▃▂</td></tr><tr><td>accuracy</td><td>▁▂▂▃▄▅▅▆▆▆▇▇▇█▇██▇█▇▇▇▇▇▇▇▇▇▇▇█▇▆▆▇▇▇▇▆▆</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▅▇▇▇▇▇▆▆▆▆▅▅▅▃▅▅▄▄▄▃▃▄▃▃▃▃▃▂▂▂▂▂▁▂▂▂▂▁</td></tr><tr><td>correct</td><td>▁▂▂▃▄▅▅▆▆▆▇▇▇█▇██▇█▇▇▇▇▇▇▇▇▇▇▇█▇▆▆▇▇▇▇▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇███</td></tr><tr><td>multibet outlay</td><td>▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▃▃▄▄▄▄▄▅▅▄▆▆▇▅▆▆▇▅▆▆▇▅▇▆▆▇▆▇▇▆▆▇█▅▆▅</td></tr><tr><td>multibet profit < 30</td><td>▄▅▅▆▆▆▆▅▃▄▅▄▆▅▆▆█▆▆▇█▄▄▇▆▄▇▅▇▇▅▆▃▃▃▅▇▁▅▂</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▅▆▆▆▇▆▇▇▇▇▇█▇██</td></tr><tr><td>multibet profit sd</td><td>▆▆▆▇▆▆▇█▆▅▅▅▃▃▅▄▄▂▃▃▄▁▄▄▅▂▄▂▄▅▄▅▆▅▆▅█▄▅▅</td></tr><tr><td>profit</td><td>▆▅▅▄▄▆▅▄▁▁▅▃▆▅▃▅█▄▇▆▆▂▄▄▅▂▅▅▅▆▆▅▃▂▄▃▆▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.03221</td></tr><tr><td>FK ROI < 30</td><td>0.01417</td></tr><tr><td>ROI</td><td>-0.03782</td></tr><tr><td>ROI < 30</td><td>0.02169</td></tr><tr><td>accuracy</td><td>0.2375</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>11.69423</td></tr><tr><td>correct</td><td>1900</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>11.69423</td></tr><tr><td>loss_val</td><td>2.1888</td></tr><tr><td>multibet outlay</td><td>295495.02682</td></tr><tr><td>multibet outlay < 30</td><td>209285.15945</td></tr><tr><td>multibet profit < 30</td><td>4539.05806</td></tr><tr><td>multibet profit < 30 sd</td><td>32.4192</td></tr><tr><td>multibet profit sd</td><td>50.33415</td></tr><tr><td>profit</td><td>5666.38221</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">comic-sweep-29</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/uvwa4n9h\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/uvwa4n9h</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_213519-uvwa4n9h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y59tykth with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00032357287877980196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230310_231352-y59tykth</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/y59tykth\" target=\"_blank\">magic-sweep-30</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00032357287877980196, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00032357287877980196, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00032357287877980196\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.91s/it]/it]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.45s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]it] \n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.87s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.88s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.88s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]t] \n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.93s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.91s/it]t]  \n",
      "100%|██████████| 6/6 [00:20<00:00,  3.48s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.81s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.82s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.88s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.88s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]t]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.49s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.91s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.92s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.80s/it]t]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.80s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.90s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.91s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.89s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.09s/it]t]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.45s/it]/it]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.49s/it]/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.40s/it]s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.43s/it]s/it]\n",
      "100%|██████████| 6/6 [00:23<00:00,  3.89s/it]s/it]\n",
      "100%|██████████| 6/6 [00:24<00:00,  4.16s/it]s/it]\n",
      "100%|██████████| 6/6 [00:22<00:00,  3.70s/it]s/it]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.32s/it]s/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.11s/it]s/it]\n",
      "100%|██████████| 6/6 [00:45<00:00,  7.56s/it]/it] \n",
      "100%|██████████| 6/6 [00:22<00:00,  3.77s/it]s/it]\n",
      "100%|██████████| 50/50 [1:19:49<00:00, 95.79s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827a1c29262b40fcae5767f761da8176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.207 MB of 180.207 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▂▁▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇██▇▇▇▇▇█</td></tr><tr><td>FK ROI < 30</td><td>▂▁▄▄▅▆▆▆▆▆▅▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▆▇▇▇███▇▇█▇▇</td></tr><tr><td>ROI</td><td>▂▁▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇██▇▇▇▇▇█</td></tr><tr><td>ROI < 30</td><td>▂▁▄▄▄▅▅▆▅▆▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▆▇▇▇████▇▇▇▇</td></tr><tr><td>accuracy</td><td>▂▁▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▂▂▇▇▂▂▇▇▂▂▇▂▂▇▇▁▁▇▇▁▁▆▆▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▂▁▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▅▅▇▇▇██████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▃▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██▇▇▇████</td></tr><tr><td>multibet profit</td><td>▂▁▂▂▂▃▃▄▃▃▃▃▄▄▅▅▅▅▅▆▆▅▅▆▆▆▆▆▇▇▇▇██▇▇▇▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▁▃▃▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇████▇█▇█</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇█</td></tr><tr><td>multibet profit sd</td><td>▅▇▅▆▆▆▇██▇▆▆▆▆▆▅▅▅▄▅▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▃▃▂▂▁</td></tr><tr><td>profit</td><td>▃▆▅▅▅▆▆▆█▆▅▅▅▄▃▃▅▃▃▃▁▄▄▂▃▃▃▄▂▃▃▂▁▃▁▃▄▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.07187</td></tr><tr><td>FK ROI < 30</td><td>0.07412</td></tr><tr><td>ROI</td><td>-0.08178</td></tr><tr><td>ROI < 30</td><td>0.08654</td></tr><tr><td>accuracy</td><td>0.24363</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>4.69331</td></tr><tr><td>correct</td><td>1949</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>4.69331</td></tr><tr><td>loss_val</td><td>2.00886</td></tr><tr><td>multibet outlay</td><td>254229.41209</td></tr><tr><td>multibet outlay < 30</td><td>124013.98146</td></tr><tr><td>multibet profit < 30</td><td>10732.67301</td></tr><tr><td>multibet profit < 30 sd</td><td>20.35583</td></tr><tr><td>multibet profit sd</td><td>46.97329</td></tr><tr><td>profit</td><td>5478.0239</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">magic-sweep-30</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/y59tykth\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/y59tykth</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230310_231352-y59tykth\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g40kmuh0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008463133040101959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_003405-g40kmuh0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/g40kmuh0\" target=\"_blank\">apricot-sweep-31</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008463133040101959, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008463133040101959, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0008463133040101959\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:56<00:00,  2.29it/s]\n",
      "100%|██████████| 129/129 [01:17<00:00,  1.66it/s]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.92it/s]\n",
      "100%|██████████| 129/129 [01:14<00:00,  1.74it/s]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.25it/s]\n",
      "100%|██████████| 129/129 [01:17<00:00,  1.67it/s]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.25it/s]\n",
      "100%|██████████| 129/129 [01:12<00:00,  1.78it/s]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.23it/s]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.88it/s]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.25it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.27it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.28it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.21it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.27it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.93it/s]]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.16it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.28it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.28it/s]]\n",
      "100%|██████████| 129/129 [01:16<00:00,  1.69it/s]]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.93it/s]]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.89it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.20it/s]]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.94it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.24it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  1.99it/s]]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.89it/s]]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.15it/s]]\n",
      "100%|██████████| 129/129 [01:02<00:00,  2.08it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.23it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.23it/s]]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.93it/s]]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.93it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.27it/s]]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.93it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.26it/s]]\n",
      "100%|██████████| 129/129 [01:17<00:00,  1.67it/s]]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.88it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.12it/s]]\n",
      "100%|██████████| 129/129 [01:11<00:00,  1.81it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.12it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.24it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.14it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.27it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.12it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.29it/s]]\n",
      "100%|██████████| 129/129 [01:01<00:00,  2.08it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.29it/s]]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.18it/s]]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.88it/s]]\n",
      "100%|██████████| 50/50 [1:59:40<00:00, 143.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016cefafe704487fbbe6a0c6279e5f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.752 MB of 179.752 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▁▁▂▂▂▃▂▃▂▃▃▃▃▄▃▄▄▅▅▅▅▆▇▆▆▅▇▇▇██▇▆▇▆▆▆▆</td></tr><tr><td>FK ROI < 30</td><td>██▇▇▇▆▅▆▅▅▄▄▂▃▁▃▂▂▂▂▁▂▂▂▄▃▃▁▃▄▁▄▄▃▁▄▂▃▃▂</td></tr><tr><td>ROI</td><td>▁▁▁▁▂▂▂▃▂▂▂▃▂▂▃▄▃▄▄▄▅▅▅▆▇▆▆▅▆▇▇██▇▆▇▆▆▆▆</td></tr><tr><td>ROI < 30</td><td>██▇▇▇▆▅▆▅▅▄▄▂▃▁▃▂▂▂▂▂▂▃▃▄▃▃▁▃▅▁▄▄▄▂▄▂▃▃▁</td></tr><tr><td>accuracy</td><td>▁▁▂▃▄▅▅▆▇▇▇▇██████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▆▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>correct</td><td>▁▁▂▃▄▅▅▆▇▇▇▇██████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>████▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇███</td></tr><tr><td>multibet outlay</td><td>▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>multibet profit</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▃▄▄▅▅▅▅▆▇▆▆▅▆▆▆██▇▅▇▅▆▆▆</td></tr><tr><td>multibet profit < 30</td><td>▇▇▆▆▇▆▄▆▅▅▄▄▂▄▁▃▂▃▃▃▂▄▄▄▆▄▅▂▅█▃▇▇▇▃█▄▆▅▃</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇█████</td></tr><tr><td>multibet profit sd</td><td>█▇▇▆▅▅▄▄▂▂▂▂▃▁▂▄▁▂▃▃▅▄▅▇▅▇▄▃▅▄▆▇▇▆▆▆▆▆▆▇</td></tr><tr><td>profit</td><td>█▆▃▅▆▃▄▃▂▂▁▅▃▃▃▄▂▄▃▂▆▄▃▄▆▆▃▄▆▆▄▄▇▇▅▇▅▆▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.0344</td></tr><tr><td>FK ROI < 30</td><td>0.01815</td></tr><tr><td>ROI</td><td>-0.0458</td></tr><tr><td>ROI < 30</td><td>0.0203</td></tr><tr><td>accuracy</td><td>0.2465</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>6.14952</td></tr><tr><td>correct</td><td>1972</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.14952</td></tr><tr><td>loss_val</td><td>2.2132</td></tr><tr><td>multibet outlay</td><td>298237.45492</td></tr><tr><td>multibet outlay < 30</td><td>219056.79881</td></tr><tr><td>multibet profit < 30</td><td>4446.1366</td></tr><tr><td>multibet profit < 30 sd</td><td>32.91103</td></tr><tr><td>multibet profit sd</td><td>51.36855</td></tr><tr><td>profit</td><td>5819.51338</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">apricot-sweep-31</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/g40kmuh0\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/g40kmuh0</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_003405-g40kmuh0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xqoj8no7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008299136229496265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_023411-xqoj8no7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/xqoj8no7\" target=\"_blank\">rich-sweep-32</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008299136229496265, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008299136229496265, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0008299136229496265\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:12<00:00,  2.14s/it]\n",
      "100%|██████████| 6/6 [00:15<00:00,  2.59s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.99s/it]/it]\n",
      "100%|██████████| 6/6 [00:27<00:00,  4.54s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.96s/it]/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.13s/it]it] \n",
      "100%|██████████| 6/6 [00:27<00:00,  4.55s/it]it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.03s/it]/it]\n",
      "100%|██████████| 6/6 [00:15<00:00,  2.59s/it]it] \n",
      "100%|██████████| 6/6 [00:26<00:00,  4.38s/it]it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.02s/it]s/it]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.24s/it]s/it]\n",
      "100%|██████████| 6/6 [00:27<00:00,  4.54s/it]s/it]\n",
      "100%|██████████| 6/6 [00:24<00:00,  4.08s/it]s/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.16s/it]s/it]\n",
      "100%|██████████| 6/6 [00:21<00:00,  3.60s/it]it]  \n",
      "100%|██████████| 6/6 [00:14<00:00,  2.35s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.97s/it]t] \n",
      "100%|██████████| 6/6 [00:22<00:00,  3.76s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.06s/it]it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.94s/it]t] \n",
      "100%|██████████| 6/6 [00:11<00:00,  2.00s/it]it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.01s/it]it]\n",
      "100%|██████████| 6/6 [00:18<00:00,  3.01s/it]t] \n",
      "100%|██████████| 6/6 [00:13<00:00,  2.32s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.01s/it]t]\n",
      "100%|██████████| 6/6 [00:27<00:00,  4.54s/it]t]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.14s/it]it]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.22s/it]t] \n",
      "100%|██████████| 6/6 [00:27<00:00,  4.53s/it]t]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.98s/it]it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.12s/it]it]\n",
      "100%|██████████| 6/6 [00:27<00:00,  4.54s/it]it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.47s/it]it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.12s/it]it]\n",
      "100%|██████████| 6/6 [00:20<00:00,  3.38s/it]t] \n",
      "100%|██████████| 6/6 [00:13<00:00,  2.17s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.98s/it]/it]\n",
      "100%|██████████| 6/6 [00:15<00:00,  2.57s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  2.00s/it]/it]\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.97s/it]/it]\n",
      "100%|██████████| 6/6 [00:27<00:00,  4.55s/it]s/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.10s/it]s/it]\n",
      "100%|██████████| 6/6 [00:15<00:00,  2.57s/it]s/it]\n",
      "100%|██████████| 6/6 [00:22<00:00,  3.83s/it]/it] \n",
      "100%|██████████| 6/6 [00:12<00:00,  2.07s/it]s/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.01s/it]/it] \n",
      "100%|██████████| 6/6 [00:18<00:00,  3.11s/it]/it]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.33s/it]/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.38s/it]/it]\n",
      "100%|██████████| 50/50 [1:23:22<00:00, 100.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5bae9bf7dc45bdb4eec35f74347c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.160 MB of 180.160 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▃▄▄▄▄▃▄▄▅▅▅▅▄▄▄▄▅▅▆▆▆▇▇▆▆▆▅▅▅▅▅▆▆▇██</td></tr><tr><td>FK ROI < 30</td><td>▁▂▂▃▂▄▄▄▄▂▄▆█▇▇▆▇▆▄▂▃▃▂▄▆▆▇█▇▇██▄▂▃▄▄▆▇▇</td></tr><tr><td>ROI</td><td>▁▂▃▃▃▄▄▄▄▃▄▅▅▆▅▅▄▄▄▄▅▅▆▆▆▇▇▆▅▆▅▅▅▅▅▆▆▇▇█</td></tr><tr><td>ROI < 30</td><td>▁▂▂▃▂▄▄▄▄▂▄▆▇▇▇▇▇▆▄▂▃▃▂▄▅▅▆▇▇▇██▄▂▂▄▃▅▇▇</td></tr><tr><td>accuracy</td><td>▁▃▄▄▄▄▅▅▆▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▂▂▇▇▂▂▇▇▂▂▇▂▂▇▇▂▂▆▆▂▂▆▆▁▆▆▁▁▆▆▁▁▆▆▁▁▅▁</td></tr><tr><td>correct</td><td>▁▃▄▄▄▄▅▅▆▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▅▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▆▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂▁▁▁▂▁▂▂▁▁▁▁▂</td></tr><tr><td>multibet outlay</td><td>▁▄▅▆▇▇▇▇▇███▇▇▇▇█▆▆▇▅▆▅▅▄▅▆▄▄▄▄▅▄▄▃▃▂▂▃▄</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▇▇▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▂▂▃▃▃▄▄▄▂▃▄▅▅▅▅▃▄▄▄▅▅▆▆▆▇▇▆▅▆▅▅▅▅▅▆▆▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▂▂▃▂▃▄▄▄▃▄▆▆▆▇▆▇▆▄▃▄▃▃▄▅▆▇▇▇▇██▅▃▄▅▅▆██</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▃▃▃▃▃▄▄▄▅▄▄▅▅▅▅▅▅▅▅▅▅▅▆▇▆▆▆▇▇▆▆▆▆▇▇▇█</td></tr><tr><td>multibet profit sd</td><td>▆▆▇▇████▇▆▆▆▆▆▆▅▄▄▅▆▆▆▆▅▅▅▄▃▂▂▁▁▂▄▄▃▂▂▁▃</td></tr><tr><td>profit</td><td>█▇▃▄▃▃▄▄▆▄▅▄▄▆▅▃▄▃▃▂▂▃▃▃▄▅▃▃▃▂▂▂▂▂▁▁▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.05668</td></tr><tr><td>FK ROI < 30</td><td>0.0768</td></tr><tr><td>ROI</td><td>-0.06927</td></tr><tr><td>ROI < 30</td><td>0.08613</td></tr><tr><td>accuracy</td><td>0.24063</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>4.4414</td></tr><tr><td>correct</td><td>1925</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>4.4414</td></tr><tr><td>loss_val</td><td>2.035</td></tr><tr><td>multibet outlay</td><td>257112.63775</td></tr><tr><td>multibet outlay < 30</td><td>136529.39998</td></tr><tr><td>multibet profit < 30</td><td>11759.5133</td></tr><tr><td>multibet profit < 30 sd</td><td>22.6706</td></tr><tr><td>multibet profit sd</td><td>45.69054</td></tr><tr><td>profit</td><td>5599.02365</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rich-sweep-32</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/xqoj8no7\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/xqoj8no7</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_023411-xqoj8no7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v0v6drpw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006788196993519005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_035810-v0v6drpw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/v0v6drpw\" target=\"_blank\">treasured-sweep-33</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006788196993519005, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006788196993519005, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0006788196993519005\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:25<00:00,  2.46it/s]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.75it/s]t]\n",
      "100%|██████████| 64/64 [00:44<00:00,  1.44it/s]t]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.79it/s]t]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.88it/s]t]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.63it/s]t]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.69it/s]t]\n",
      "100%|██████████| 64/64 [00:49<00:00,  1.29it/s]t]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.68it/s]t]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.71it/s]t]\n",
      "100%|██████████| 64/64 [00:45<00:00,  1.39it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.53it/s]it]\n",
      "100%|██████████| 64/64 [00:47<00:00,  1.36it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.86it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.77it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.30it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.53it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.53it/s]]  \n",
      "100%|██████████| 64/64 [00:46<00:00,  1.36it/s]]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.76it/s]]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.77it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.41it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]]\n",
      "100%|██████████| 64/64 [00:46<00:00,  1.37it/s]]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.80it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.54it/s]]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.74it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]]\n",
      "100%|██████████| 64/64 [00:45<00:00,  1.41it/s]]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.70it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.63it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.54it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.59it/s]it]\n",
      "100%|██████████| 64/64 [00:47<00:00,  1.35it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.55it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.65it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.31it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.72it/s]it]\n",
      "100%|██████████| 64/64 [00:56<00:00,  1.13it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.73it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.62it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.74it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.76it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.71it/s]it]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.46it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.67it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.76it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]it]\n",
      "100%|██████████| 64/64 [00:53<00:00,  1.21it/s]it]\n",
      "100%|██████████| 50/50 [1:33:00<00:00, 111.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d0875a49af4251a8243c08d52688a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.921 MB of 180.921 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▃▃▄▄▄▄▅▅▅▅▅▆▅▆▅▅▇▅▆▆▆▆▇▇▇▇▇▇▆▇▆▆█▆█▇█▇▇</td></tr><tr><td>FK ROI < 30</td><td>▄▅▇██▇█▇█▇▇▇▇▆▇▅▄▇▅▅▄▅▄▅▅▄▄▄▄▃▃▂▂▄▂▅▃▁▃▂</td></tr><tr><td>ROI</td><td>▁▃▄▄▄▄▄▅▆▅▅▅▆▆▆▅▅▇▅▆▆▆▆▇▇▇▇▇▇▆▇▆▆▇▆█▇▇▇▇</td></tr><tr><td>ROI < 30</td><td>▄▅▇██▇█▇█▇▇▇▇▆▇▅▅▆▅▅▄▄▄▅▅▄▄▄▄▃▃▂▁▄▂▄▄▁▃▃</td></tr><tr><td>accuracy</td><td>▁▂▂▂▃▃▃▄▅▅▆▅▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇███▇▇█▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▂▂▇▇▁▁▇▇▁▁▇▁▁▇▇▁▁▆▆▁▁▆▆▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▁▂▂▂▃▃▃▄▅▅▆▅▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇███▇▇█▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▃▆▇▇████▇▇▇▆▅▅▅▅▄▄▃▃▃▂▃▂▂▂▂▁▁▂▁▂▁▂▁▃▂▁▂▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▃▃▄▄▄▄▅▅▅▅▆▅▆▄▅▆▅▆▆▆▆▇▇▇▇▇▇▆▇▆▆█▆█▇█▇▇</td></tr><tr><td>multibet profit < 30</td><td>▂▄▆▇▇▆█▇█▇▇▇▇▇█▅▅▇▅▅▄▅▄▆▆▄▅▅▄▄▃▂▁▅▂▆▅▁▄▃</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▃▃▃▄▃▄▄▄▄▄▄▅▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>▆▇█▇▇▇▇▇█▆▇▆▆▆▅▄▄▅▃▅▄▃▃▃▃▃▃▃▃▂▂▂▁▂▁▃▂▂▂▂</td></tr><tr><td>profit</td><td>▅▄▂▃▅▁▃▅█▅▆▆▃▇▆▄▅▄▂▄▂▄▂▂▆▁▃▁▁▃▃▂▃▄▂▃▂▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.06887</td></tr><tr><td>FK ROI < 30</td><td>0.03492</td></tr><tr><td>ROI</td><td>-0.0832</td></tr><tr><td>ROI < 30</td><td>0.0392</td></tr><tr><td>accuracy</td><td>0.24825</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>8.09049</td></tr><tr><td>correct</td><td>1986</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>8.09049</td></tr><tr><td>loss_val</td><td>1.95609</td></tr><tr><td>multibet outlay</td><td>252528.93449</td></tr><tr><td>multibet outlay < 30</td><td>147217.24482</td></tr><tr><td>multibet profit < 30</td><td>5770.92328</td></tr><tr><td>multibet profit < 30 sd</td><td>22.8918</td></tr><tr><td>multibet profit sd</td><td>41.11331</td></tr><tr><td>profit</td><td>5656.43435</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">treasured-sweep-33</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/v0v6drpw\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/v0v6drpw</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_035810-v0v6drpw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l9jcsoux with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004294791566187644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_053135-l9jcsoux</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/l9jcsoux\" target=\"_blank\">distinctive-sweep-34</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004294791566187644, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004294791566187644, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004294791566187644\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [01:00<00:00,  2.15it/s]\n",
      "100%|██████████| 129/129 [01:12<00:00,  1.77it/s]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.16it/s]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.01it/s]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.17it/s]\n",
      "100%|██████████| 129/129 [01:01<00:00,  2.11it/s]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.16it/s]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.19it/s]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.17it/s]\n",
      "100%|██████████| 129/129 [01:01<00:00,  2.11it/s]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.20it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.24it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.91it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.13it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.14it/s]]\n",
      "100%|██████████| 129/129 [01:11<00:00,  1.79it/s]]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.17it/s]]\n",
      "100%|██████████| 129/129 [01:11<00:00,  1.81it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.19it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.90it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.22it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.22it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.14it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.25it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.21it/s]]\n",
      "100%|██████████| 129/129 [01:12<00:00,  1.78it/s] \n",
      "100%|██████████| 129/129 [01:03<00:00,  2.03it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.91it/s]]\n",
      "100%|██████████| 129/129 [01:03<00:00,  2.03it/s]]\n",
      "100%|██████████| 129/129 [01:09<00:00,  1.87it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.92it/s]]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.18it/s]]\n",
      "100%|██████████| 129/129 [01:17<00:00,  1.66it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.21it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.26it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.21it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.24it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.26it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.22it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.24it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.20it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.22it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.90it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.21it/s]]\n",
      "100%|██████████| 129/129 [01:24<00:00,  1.53it/s]]\n",
      "100%|██████████| 129/129 [01:00<00:00,  2.13it/s]]\n",
      "100%|██████████| 129/129 [01:18<00:00,  1.65it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.20it/s]]\n",
      "100%|██████████| 129/129 [01:17<00:00,  1.67it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.23it/s]]\n",
      "100%|██████████| 50/50 [1:58:58<00:00, 142.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3dfe166bfd48048651afc817d9c222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.581 MB of 180.581 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▅▆▆▆▆▇▇▇▇█▇▇█▇█▇▇▇▇▇▇█</td></tr><tr><td>FK ROI < 30</td><td>▄▆▇█▆▇▇▇▇▆▅▆▇▆▇▄▆▅▃▄▄▄▅▅▄▅▆█▄▅▅▂▅▃▂▃▂▂▁▃</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▃▃▃▄▃▄▄▅▅▅▅▆▆▅▆▆▆▆▇▆▇▇▇▇▇█▇█▇▇▇▇█▇█</td></tr><tr><td>ROI < 30</td><td>▁▃▅▆▅▅▆▅▆▄▅▅▇▆▇▅▇▆▃▅▅▅▆▅▄▅▆█▄▅▅▂▅▄▂▄▂▃▂▄</td></tr><tr><td>accuracy</td><td>▁▁▂▃▄▄▅▆▆▆▆▇▇▇▇▇▇█▇█▇█▇▇████████████▇▇▇█</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▆▇▇▇▇▇▆▆▆▆▅▅▅▄▅▅▅▄▄▃▄▄▄▃▃▃▃▃▃▂▂▂▁▂▂▂▂▁</td></tr><tr><td>correct</td><td>▁▁▂▃▄▄▅▆▆▆▆▇▇▇▇▇▇█▇█▇█▇▇████████████▇▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>loss_val</td><td>▇▆▅▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▇▇▇█</td></tr><tr><td>multibet outlay</td><td>▇███▇▆▆▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▄▅▅▆▆▆▇</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█▇▇█▇█▇▇▇▇█▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▂▃▃▃▄▄▄▄▃▄▄▅▅▅▄▆▅▄▅▅▆▆▆▆▆▇█▆▇▇▅▇▇▆▇▆▇▆█</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>multibet profit sd</td><td>█▇▇▆▅▅▄▄▄▃▃▃▂▂▃▂▃▂▂▁▂▁▁▁▂▁▂▁▁▂▂▂▂▁▁▁▂▂▁▂</td></tr><tr><td>profit</td><td>▄▁▃▆▅▆▇█▅▄▅▅▅▃▂▂▃▅▃▃▂▃▂▂▃▂▃▄▃▁▃▂▂▄▂▄▃▃▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.02446</td></tr><tr><td>FK ROI < 30</td><td>0.05576</td></tr><tr><td>ROI</td><td>-0.02943</td></tr><tr><td>ROI < 30</td><td>0.07667</td></tr><tr><td>accuracy</td><td>0.25875</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>7.20646</td></tr><tr><td>correct</td><td>2070</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>7.20646</td></tr><tr><td>loss_val</td><td>2.05004</td></tr><tr><td>multibet outlay</td><td>264349.96209</td></tr><tr><td>multibet outlay < 30</td><td>187437.51659</td></tr><tr><td>multibet profit < 30</td><td>14371.10233</td></tr><tr><td>multibet profit < 30 sd</td><td>30.64414</td></tr><tr><td>multibet profit sd</td><td>42.87048</td></tr><tr><td>profit</td><td>5810.23193</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">distinctive-sweep-34</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/l9jcsoux\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/l9jcsoux</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_053135-l9jcsoux\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rsut0czl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004794103190683222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_073057-rsut0czl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/rsut0czl\" target=\"_blank\">ruby-sweep-35</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004794103190683222, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004794103190683222, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004794103190683222\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [01:28<00:00,  3.67it/s]\n",
      "100%|██████████| 324/324 [01:20<00:00,  4.04it/s]\n",
      "100%|██████████| 324/324 [01:25<00:00,  3.77it/s]\n",
      "100%|██████████| 324/324 [01:13<00:00,  4.39it/s]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.07it/s]\n",
      "100%|██████████| 324/324 [01:29<00:00,  3.62it/s]\n",
      "100%|██████████| 324/324 [01:14<00:00,  4.34it/s]\n",
      "100%|██████████| 324/324 [01:36<00:00,  3.37it/s]\n",
      "100%|██████████| 324/324 [01:17<00:00,  4.19it/s]\n",
      "100%|██████████| 324/324 [01:41<00:00,  3.19it/s]\n",
      "100%|██████████| 324/324 [01:14<00:00,  4.33it/s]]\n",
      "100%|██████████| 324/324 [01:15<00:00,  4.28it/s]]\n",
      "100%|██████████| 324/324 [01:49<00:00,  2.97it/s]]\n",
      "100%|██████████| 324/324 [01:16<00:00,  4.26it/s]]\n",
      "100%|██████████| 324/324 [01:26<00:00,  3.73it/s]]\n",
      "100%|██████████| 324/324 [01:15<00:00,  4.30it/s]]\n",
      "100%|██████████| 324/324 [01:28<00:00,  3.66it/s]]\n",
      "100%|██████████| 324/324 [01:31<00:00,  3.55it/s]]\n",
      "100%|██████████| 324/324 [01:15<00:00,  4.28it/s]]\n",
      "100%|██████████| 324/324 [01:35<00:00,  3.39it/s]]\n",
      "100%|██████████| 324/324 [01:31<00:00,  3.56it/s]]\n",
      "100%|██████████| 324/324 [03:00<00:00,  1.80it/s]]\n",
      "100%|██████████| 324/324 [01:34<00:00,  3.43it/s]it]\n",
      "100%|██████████| 324/324 [07:40<00:00,  1.42s/it]it]\n",
      "100%|██████████| 324/324 [01:40<00:00,  3.22it/s]it]\n",
      "100%|██████████| 324/324 [01:18<00:00,  4.15it/s]it]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.10it/s]it]\n",
      "100%|██████████| 324/324 [01:16<00:00,  4.25it/s]it]\n",
      "100%|██████████| 324/324 [01:22<00:00,  3.92it/s]it]\n",
      "100%|██████████| 324/324 [01:31<00:00,  3.54it/s]it]\n",
      "100%|██████████| 324/324 [01:13<00:00,  4.39it/s]it]\n",
      "100%|██████████| 324/324 [01:14<00:00,  4.35it/s]]  \n",
      "100%|██████████| 324/324 [01:28<00:00,  3.65it/s]]\n",
      "100%|██████████| 324/324 [01:12<00:00,  4.48it/s]]\n",
      "100%|██████████| 324/324 [01:30<00:00,  3.58it/s]]\n",
      "100%|██████████| 324/324 [01:13<00:00,  4.42it/s]]\n",
      "100%|██████████| 324/324 [01:31<00:00,  3.54it/s]]\n",
      "100%|██████████| 324/324 [01:12<00:00,  4.44it/s]]\n",
      "100%|██████████| 324/324 [01:32<00:00,  3.51it/s]]\n",
      "100%|██████████| 324/324 [01:14<00:00,  4.37it/s]]\n",
      "100%|██████████| 324/324 [01:29<00:00,  3.64it/s]]\n",
      "100%|██████████| 324/324 [01:19<00:00,  4.09it/s]]\n",
      "100%|██████████| 324/324 [01:12<00:00,  4.47it/s]]\n",
      "100%|██████████| 324/324 [01:30<00:00,  3.59it/s]]\n",
      "100%|██████████| 324/324 [01:23<00:00,  3.88it/s]]\n",
      "100%|██████████| 324/324 [01:17<00:00,  4.19it/s]]\n",
      "100%|██████████| 324/324 [01:17<00:00,  4.17it/s]]\n",
      "100%|██████████| 324/324 [01:15<00:00,  4.28it/s]]\n",
      "100%|██████████| 324/324 [01:38<00:00,  3.28it/s]]\n",
      "100%|██████████| 324/324 [01:15<00:00,  4.30it/s]]\n",
      "100%|██████████| 50/50 [2:27:21<00:00, 176.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f978a167eefb4b25be3ea40e9278eb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.226 MB of 180.226 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▃▃▃▃▄▃▄▄▄▃▄▅▅▅▆▄▆▆▆▆▇▇▆▆▅▆▆█▆▇▇▆▇█▇█</td></tr><tr><td>FK ROI < 30</td><td>██▇▇▆▇▆▆▅▄▄▄▄▃▄▄▄▄▅▃▄▄▃▃▄▄▂▂▂▃▂▃▁▃▃▂▂▃▂▃</td></tr><tr><td>ROI</td><td>▁▂▂▃▃▃▃▃▄▂▄▄▄▃▄▅▅▅▆▄▆▆▆▆▇▇▆▆▅▆▆█▆▇▇▆▇█▆█</td></tr><tr><td>ROI < 30</td><td>████▆▇▇▆▅▄▄▄▄▃▅▅▄▅▅▂▃▄▃▃▄▄▂▃▂▃▃▄▁▃▃▂▃▃▂▄</td></tr><tr><td>accuracy</td><td>▁▂▃▃▄▅▆▆▆▇▇▇▇███▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>████▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▁▅▅▅▅▅▅▅▅▄▄▄▄▄▄</td></tr><tr><td>correct</td><td>▁▂▃▃▄▅▆▆▆▇▇▇▇███▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁</td></tr><tr><td>loss_val</td><td>▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>multibet outlay</td><td>▄▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▅▅▅▆▆▆▆▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▂▂▃▃▃▄▄▄▃▅▅▅▄▅▆▆▆▇▅▇▇▇▆██▇▇▆▆▆█▆▇▇▆▇█▆█</td></tr><tr><td>multibet profit < 30</td><td>▇▇▇▇▆▆▆▆▅▃▃▃▃▂▅▆▄▆▆▂▄▅▃▄▇▇▃▅▂▄▅▇▁▅▆▄▆▅▄█</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>███▇▆▅▄▄▃▂▃▂▂▁▁▁▁▁▂▁▂▂▂▂▃▂▂▂▂▂▂▃▂▂▂▁▂▃▂▃</td></tr><tr><td>profit</td><td>▆▇█▅▅▄▃▄▂▄▄▆▅▄▄▅▃▃▅▂▂▂▃▃▃▃▁▂▁▃▂▄▃▃▃▂▂▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.05525</td></tr><tr><td>FK ROI < 30</td><td>0.0264</td></tr><tr><td>ROI</td><td>-0.06574</td></tr><tr><td>ROI < 30</td><td>0.03905</td></tr><tr><td>accuracy</td><td>0.24775</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>6.53655</td></tr><tr><td>correct</td><td>1982</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.53655</td></tr><tr><td>loss_val</td><td>2.14716</td></tr><tr><td>multibet outlay</td><td>284275.5346</td></tr><tr><td>multibet outlay < 30</td><td>203031.21209</td></tr><tr><td>multibet profit < 30</td><td>7928.03844</td></tr><tr><td>multibet profit < 30 sd</td><td>31.82784</td></tr><tr><td>multibet profit sd</td><td>43.89797</td></tr><tr><td>profit</td><td>5664.29951</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ruby-sweep-35</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/rsut0czl\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/rsut0czl</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_073057-rsut0czl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e9fvhokz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006041661784452575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_095841-e9fvhokz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/e9fvhokz\" target=\"_blank\">glorious-sweep-36</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006041661784452575, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0006041661784452575, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0006041661784452575\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:38<00:00,  3.33it/s]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.19it/s]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.73it/s]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.53it/s]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.78it/s]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.46it/s]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.11it/s]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.48it/s]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.29it/s]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.20it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.00it/s]]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.42it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.80it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.47it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.89it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.25it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.16it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.71it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.48it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.58it/s] \n",
      "100%|██████████| 129/129 [00:29<00:00,  4.32it/s]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.51it/s]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.49it/s]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.34it/s]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.73it/s]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.50it/s]\n",
      "100%|██████████| 129/129 [00:51<00:00,  2.49it/s]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.55it/s]\n",
      "100%|██████████| 129/129 [00:27<00:00,  4.64it/s]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.29it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.27it/s]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.44it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.52it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.47it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.80it/s]]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.30it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.53it/s]]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.12it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.28it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.91it/s]]\n",
      "100%|██████████| 129/129 [00:26<00:00,  4.85it/s]]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.87it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.49it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.19it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.51it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.41it/s]]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.41it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.25it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.78it/s]]\n",
      "100%|██████████| 129/129 [00:28<00:00,  4.48it/s]]\n",
      "100%|██████████| 50/50 [1:36:22<00:00, 115.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d58452acb642f1af3e595170b76c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.790 MB of 180.790 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▃▄▄▄▄▅▄▅▅▅▆▆▆▆▆▅▅▆▆▇▇▇█</td></tr><tr><td>FK ROI < 30</td><td>▆▇██▇▇▆▆▆▆▆▅▅▅▄▄▅▄▅▄▃▄▄▃▄▃▄▅▄▄▅▃▃▁▂▂▂▄▂▄</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▆▅▆▆▅▅▅▆▆▇▇▇█</td></tr><tr><td>ROI < 30</td><td>▆▇██▇▇▆▆▆▅▅▅▄▄▃▃▄▃▄▃▂▃▃▂▄▃▃▅▅▄▅▃▂▁▃▁▂▄▂▄</td></tr><tr><td>accuracy</td><td>▁▁▂▂▃▃▃▄▅▅▅▆▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇█▇▇██▇█▇█▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▂▇▇▂▆▇▇▆▇▇▇▇▆▆▆▆▂▆▆▂▅▆▁▅▆▅▅▅▅▅▅▅▅▅▅▁▅</td></tr><tr><td>correct</td><td>▁▁▂▂▃▃▃▄▅▅▅▆▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇█▇▇██▇█▇█▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄</td></tr><tr><td>multibet outlay</td><td>▆███▇▇▇▆▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▅</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▃▄▄▄▄▅▄▅▄▅▆▆▆▆▅▅▅▆▆▇▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▄▅▇▇▆▇▅▅▅▄▄▄▃▃▂▂▄▃▅▃▁▃▄▂▅▃▄▆▇▆█▄▄▁▄▂▄▇▄█</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>multibet profit sd</td><td>███▇▇▇▆▅▅▄▃▃▃▃▂▃▂▂▁▂▂▂▁▁▂▁▂▂▁▂▂▁▁▂▃▃▃▃▃▄</td></tr><tr><td>profit</td><td>█▇▄▄▄▂▃▁▅▄▂▂▃▃▅▂▄▅▅▄▅▆▅▅▆▅▅▅▅▆█▆▆▆▇▇▇▇▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.02844</td></tr><tr><td>FK ROI < 30</td><td>0.036</td></tr><tr><td>ROI</td><td>-0.03393</td></tr><tr><td>ROI < 30</td><td>0.04872</td></tr><tr><td>accuracy</td><td>0.25225</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>13.5676</td></tr><tr><td>correct</td><td>2018</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>13.5676</td></tr><tr><td>loss_val</td><td>1.9881</td></tr><tr><td>multibet outlay</td><td>257088.6477</td></tr><tr><td>multibet outlay < 30</td><td>170133.68369</td></tr><tr><td>multibet profit < 30</td><td>8288.67811</td></tr><tr><td>multibet profit < 30 sd</td><td>27.17835</td></tr><tr><td>multibet profit sd</td><td>46.57519</td></tr><tr><td>profit</td><td>5792.79927</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glorious-sweep-36</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/e9fvhokz\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/e9fvhokz</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_095841-e9fvhokz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7o95puv3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005065245129560701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_113530-7o95puv3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/7o95puv3\" target=\"_blank\">stellar-sweep-37</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005065245129560701, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005065245129560701, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0005065245129560701\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.75it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.69it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.63it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.62it/s]it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.78it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.77it/s]/it]\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.13s/it]it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.70it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.71it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.63it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.18it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.72it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.32it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.70it/s]t]   \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.76it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.43it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.74it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.62it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.72it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.34it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.77it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.74it/s]t] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.72it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.67it/s]t]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.19s/it]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.67it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.65it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.70it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.60it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.76it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.74it/s]t] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.67it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.62it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.78it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.53it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.36it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.78it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.38it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.44it/s]/it] \n",
      "100%|██████████| 6/6 [00:12<00:00,  2.14s/it]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.72it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.73it/s]/it] \n",
      "100%|██████████| 50/50 [1:21:22<00:00, 97.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de73b798fe87494e80bce633e33348df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.019 MB of 180.019 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▃▁▁▂▂▅▁▄▅▄▅▃▃▄▄▄▃▆▃▆▆▃▇▂▃▅▄▆▇▂█▂▃▇▄▆▆▅▆▅</td></tr><tr><td>FK ROI < 30</td><td>▁▆▅▅▅▆▆▆▆▆▆▆▇▅▇▅▄█▄█▇▅▆▆▆▅▆▆▆▅▇▅▅▆▅▆▆▅▇▇</td></tr><tr><td>ROI</td><td>▄▂▁▂▂▅▁▄▄▄▅▃▃▅▅▄▃▆▃▆▆▃▇▂▃▆▄▆▇▂█▂▃▇▄▆▆▅▆▅</td></tr><tr><td>ROI < 30</td><td>▁▇▅▅▅▆▅▆▆▆▆▆▇▅▇▅▄█▄█▇▅▆▆▆▆▆▆▆▅▇▅▅▆▆▆▆▅▆▆</td></tr><tr><td>accuracy</td><td>▄▁▅▅▄▅▄▅▅▆▅▅▄▆▅▆▆▆▆▆▆▇▆▄▆▇▇▇▇█▇▇▇███████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▇▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>correct</td><td>▄▁▅▅▄▅▄▅▅▆▅▅▄▆▅▆▆▆▆▆▆▇▆▄▆▇▇▇▇█▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▅▄▄▄▄▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▃▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▆▁▂▃▅▆▅▅▆▆▆▆▇▆▆▆▆▇▆▆▆▆▆█▆▅▅▅▅▅▅▅▅▅▅▅▅▄▅▅</td></tr><tr><td>multibet outlay < 30</td><td>█▁▂▂▃▅▃▄▄▄▄▄▄▅▄▅▅▅▅▅▅▅▆▅▅▅▅▅▅▅▆▆▆▅▆▆▆▆▆▆</td></tr><tr><td>multibet profit</td><td>▃▃▂▂▂▅▁▄▄▃▅▃▂▄▄▄▃▅▃▆▆▃▇▁▃▆▄▆▇▂█▂▄▇▄▆▆▅▆▅</td></tr><tr><td>multibet profit < 30</td><td>▁▆▅▄▄▆▅▆▆▆▆▆▇▅▇▅▄█▄█▇▅▆▆▆▆▆▆▆▅▇▅▅▆▆▆▆▆▇▆</td></tr><tr><td>multibet profit < 30 sd</td><td>█▁▁▂▂▄▂▃▃▃▃▃▃▄▃▃▃▄▃▄▄▃▅▄▃▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>multibet profit sd</td><td>▆▃▄▅▆▇▄▆▇▇█▆▅█▆▆▆▆▆▆▅▆▅▆▅▅▄▅▆▁▇▁▁▅▁▅▅▂▄▂</td></tr><tr><td>profit</td><td>▂▄▄▄▅▅▆▃▁▄▁▃█▅▅▄▃▄▂▄▅▅▄▇▇▄▃▄▆▄▄▅▃▆▇▅▁▆▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.09632</td></tr><tr><td>FK ROI < 30</td><td>0.05833</td></tr><tr><td>ROI</td><td>-0.10906</td></tr><tr><td>ROI < 30</td><td>0.06279</td></tr><tr><td>accuracy</td><td>0.22325</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>11.1467</td></tr><tr><td>correct</td><td>1786</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>11.1467</td></tr><tr><td>loss_val</td><td>2.04443</td></tr><tr><td>multibet outlay</td><td>263013.03961</td></tr><tr><td>multibet outlay < 30</td><td>120933.7037</td></tr><tr><td>multibet profit < 30</td><td>7593.1711</td></tr><tr><td>multibet profit < 30 sd</td><td>19.10968</td></tr><tr><td>multibet profit sd</td><td>48.61828</td></tr><tr><td>profit</td><td>5817.12609</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stellar-sweep-37</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/7o95puv3\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/7o95puv3</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_113530-7o95puv3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8wblh3z8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00011412554987816694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_125717-8wblh3z8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/8wblh3z8\" target=\"_blank\">effortless-sweep-38</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00011412554987816694, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00011412554987816694, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00011412554987816694\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:44<00:00,  2.90it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.87it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.85it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.98it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.69it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.71it/s]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.28it/s]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.64it/s]\n",
      "100%|██████████| 129/129 [00:52<00:00,  2.44it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.96it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.85it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.59it/s]]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.68it/s]]\n",
      "100%|██████████| 129/129 [00:52<00:00,  2.47it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.62it/s]]\n",
      "100%|██████████| 129/129 [00:58<00:00,  2.22it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.62it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.61it/s]]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.84it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.71it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.77it/s] \n",
      "100%|██████████| 129/129 [00:47<00:00,  2.74it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.05it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.67it/s] \n",
      "100%|██████████| 129/129 [01:04<00:00,  2.01it/s]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.73it/s]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.76it/s]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.87it/s]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.60it/s]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.58it/s]]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.70it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.79it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.45it/s]]\n",
      "100%|██████████| 129/129 [00:51<00:00,  2.49it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.48it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.52it/s]]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.30it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.57it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.61it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.62it/s]]\n",
      "100%|██████████| 129/129 [00:59<00:00,  2.18it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.51it/s]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.00it/s]]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.65it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.01it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.54it/s]]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.70it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.51it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.57it/s]]\n",
      "100%|██████████| 129/129 [00:52<00:00,  2.44it/s]]\n",
      "100%|██████████| 50/50 [1:44:19<00:00, 125.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90e26e3421444f68c04c52c35a57817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.997 MB of 180.997 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>FK ROI < 30</td><td>▁▃▄▅▆▇▇▇▇▇▇▇▇█▇▇██▇███▇█████▇▇▇▇▇▇▆▆▆▅▅▅</td></tr><tr><td>ROI</td><td>▁▂▃▃▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>ROI < 30</td><td>▁▃▄▅▆▇▇▇▇▇▇███▇███▇███▇▇▇█▇▇▇▇▇▇▇▇▆▇▆▆▆▆</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▃▇▇▇▇▇▇▇▇▆▆▇▆▂▆▆▆▆▆▂▆▆▆▆▆▅▆▆▅▅▅▅▁▅▅▅▅▅</td></tr><tr><td>correct</td><td>▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▄▅▆▇▇████████████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▃▃▃▄▄▅▄▄▅▅▄▄▅▅▅▅▆▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>multibet profit < 30</td><td>▁▃▃▄▆▆▇▇▇▇▇▇▇█▇███▇█████████▇▇████▇▇▇▇▇▇</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>multibet profit sd</td><td>▃▅▆▆▇▇████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▃▂▂▂▂▁▁▁▁</td></tr><tr><td>profit</td><td>▆█▇▇▅▄▄▆▃▄▅▂▂▄▃▁▂▅▃▂▄▄▄▆▇▅▄▂▃▄▄▃▃▅▅▅▆▅▇▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.09357</td></tr><tr><td>FK ROI < 30</td><td>0.05154</td></tr><tr><td>ROI</td><td>-0.10441</td></tr><tr><td>ROI < 30</td><td>0.06049</td></tr><tr><td>accuracy</td><td>0.231</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>17.79211</td></tr><tr><td>correct</td><td>1848</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>17.79211</td></tr><tr><td>loss_val</td><td>1.96251</td></tr><tr><td>multibet outlay</td><td>257553.31041</td></tr><tr><td>multibet outlay < 30</td><td>122095.42947</td></tr><tr><td>multibet profit < 30</td><td>7386.08201</td></tr><tr><td>multibet profit < 30 sd</td><td>19.37151</td></tr><tr><td>multibet profit sd</td><td>47.24776</td></tr><tr><td>profit</td><td>5645.6125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">effortless-sweep-38</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/8wblh3z8\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/8wblh3z8</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_125717-8wblh3z8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8qbsvv9h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00013660042012338146\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_144159-8qbsvv9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/8qbsvv9h\" target=\"_blank\">tough-sweep-39</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00013660042012338146, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00013660042012338146, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00013660042012338146\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:14<00:00,  2.24it/s]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.08it/s]t]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.30it/s]t]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.23it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]t]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.38it/s]t]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.18it/s]t]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.09it/s]t]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.27it/s]t]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.40it/s]t]\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.62it/s]it]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.47it/s]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.52it/s]it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.26it/s]it]\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.12it/s]it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.26it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.29it/s]it]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.26it/s]]  \n",
      "100%|██████████| 32/32 [00:18<00:00,  1.71it/s]]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.14it/s]]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.18it/s]]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.23it/s]]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.29it/s]]\n",
      "100%|██████████| 32/32 [00:40<00:00,  1.28s/it]]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.16it/s]]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.27it/s]]\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.26it/s]]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.50it/s]]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.48it/s]]\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.09it/s]]\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.99it/s]]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.16it/s]]\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.27it/s]]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.33it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.39it/s]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.49it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.29it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.39it/s]it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.09it/s]t] \n",
      "100%|██████████| 32/32 [00:13<00:00,  2.30it/s]it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.09it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.31it/s]it]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.49it/s]it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.09it/s]it]\n",
      "100%|██████████| 32/32 [00:13<00:00,  2.43it/s]it]\n",
      "100%|██████████| 32/32 [00:12<00:00,  2.54it/s]it]\n",
      "100%|██████████| 32/32 [00:34<00:00,  1.08s/it]t] \n",
      "100%|██████████| 32/32 [00:13<00:00,  2.31it/s]it]\n",
      "100%|██████████| 50/50 [1:28:36<00:00, 106.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5fc27450914391a1c819045383eaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.823 MB of 180.823 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>FK ROI < 30</td><td>▁▁▂▃▅▅▆▇▇▇▇▇▇▇▇▇▇███████▇▇███▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>ROI</td><td>▁▂▂▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇█▇█▇▇▇▇█▇▇▇█▇▇▇▇██████</td></tr><tr><td>ROI < 30</td><td>▁▂▃▄▅▅▆▇▇▇▇▇▇▇▇▇█▇███████████▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>accuracy</td><td>▁▃▃▃▄▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇█▇████▇██▇██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▂▂▇▇▂▂▇▇▁▁▇▁▁▇▇▁▁▇▇▁▁▆▆▁▆▆▁▁▆▆▁▁▆▆▁▁▆▁</td></tr><tr><td>correct</td><td>▁▃▃▃▄▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇█▇████▇██▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▂▃▄▅▆▆▇▇▇▇▇███████████████████████████▇</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▃▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▂▃▄▅▅▅▆▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>multibet profit sd</td><td>▁▁▂▂▄▅▅▆▇▇▇▇████████▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄</td></tr><tr><td>profit</td><td>▂▆██▆▄▄▅▄▄▇▇▂▂▂▂▂▂▂▃▅▃▄▁▂▂▃▃▁▁▃▄▂▂▂▂▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.09601</td></tr><tr><td>FK ROI < 30</td><td>0.06475</td></tr><tr><td>ROI</td><td>-0.10673</td></tr><tr><td>ROI < 30</td><td>0.07269</td></tr><tr><td>accuracy</td><td>0.216</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>23.39172</td></tr><tr><td>correct</td><td>1728</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>23.39172</td></tr><tr><td>loss_val</td><td>1.9888</td></tr><tr><td>multibet outlay</td><td>263179.66241</td></tr><tr><td>multibet outlay < 30</td><td>116757.36289</td></tr><tr><td>multibet profit < 30</td><td>8487.08934</td></tr><tr><td>multibet profit < 30 sd</td><td>18.79912</td></tr><tr><td>multibet profit sd</td><td>49.45849</td></tr><tr><td>profit</td><td>5616.13151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">tough-sweep-39</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/8qbsvv9h\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/8qbsvv9h</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_144159-8qbsvv9h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w01z0yne with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005123066985294236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_161110-w01z0yne</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/w01z0yne\" target=\"_blank\">vivid-sweep-40</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005123066985294236, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005123066985294236, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0005123066985294236\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.57it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.63it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.76it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.75it/s]it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.71it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.44it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.30it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.60it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.59it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.60it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.60it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.76it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.72it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.44it/s]t]   \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.76it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.78it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.70it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.75it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.74it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.31it/s]t] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.63it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.29it/s]t] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.57it/s]t]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.35s/it]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.71it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.52it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.37it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.70it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.65it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.70it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.59it/s]t] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.54it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.60it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.71it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.51it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.32it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.57it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.27it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.56it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.49it/s]/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.28it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.38it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.63it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.36it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.58it/s]/it]\n",
      "100%|██████████| 50/50 [1:20:36<00:00, 96.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a49ef5f9f974a16aff88a4f696e8db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.076 MB of 180.076 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▆▁▅▃▄▅▅▅▆▅▆▅▅▇▅▇█▅█▄▄█▄█▇▅▇▆▇▆▇▆▆▆▇▆▅▇▅▅</td></tr><tr><td>FK ROI < 30</td><td>▁▄▆▂▅▆▆▆▇▄▇▄▆█▅██▆█▅▆█▆▇▆█▆█▇▇▆▇▇▅▇▅▅▇▆▆</td></tr><tr><td>ROI</td><td>▆▁▅▃▄▅▅▅▆▅▆▅▅▇▅▇█▅█▄▄█▄█▇▅▇▆▇▆▇▆▆▆▇▆▅▇▅▅</td></tr><tr><td>ROI < 30</td><td>▁▄▆▂▅▆▅▆▇▄▇▄▅▇▅██▆█▆▆▇▆▇▆█▆█▇▇▆██▅█▅▅█▆▆</td></tr><tr><td>accuracy</td><td>▅▁▆▃▆▆▆▆▆▅▆▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▇▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>correct</td><td>▅▁▆▃▆▆▆▆▆▅▆▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▇▆▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▃▄▅▅▅▆▇▇▇▇▇███▇▇▇▇▇█▇█▇▆█▆█▇▆▇▆▆▆▆▆▆▅▆▆</td></tr><tr><td>multibet outlay < 30</td><td>▃▁▄▂▃▃▃▄▅▄▅▄▅▆▅▆▆▅▆▆▆▆▆▇▇▆▇▆▆█▆█▇▇█▇▇█▇▇</td></tr><tr><td>multibet profit</td><td>▇▁▆▃▄▅▅▅▅▅▅▄▅▇▄▇▇▄█▄▃█▃██▅▇▆▇▅▇▆▆▆▇▅▅▇▅▅</td></tr><tr><td>multibet profit < 30</td><td>▁▃▅▂▄▅▅▆▇▄▇▄▅▇▅▇█▅█▅▅▇▆▇▆█▆█▇▇▆██▅█▅▅█▆▆</td></tr><tr><td>multibet profit < 30 sd</td><td>▅▁▅▁▂▃▃▄▅▃▆▃▄▆▄▆▆▄▆▅▅▆▅▆▆▆▇▆▆█▅██▅█▆▆█▆▆</td></tr><tr><td>multibet profit sd</td><td>▇▃▄▆▅▆▆▆▅█▅▇▆▆▆▆▆▅▆▄▄▅▃▅▅▄▄▄▆▁▆▁▁▃▁▃▂▁▂▁</td></tr><tr><td>profit</td><td>▅▂▆▇▄▅▅▅▇▆▆▂▅▅▁▆▄▅▃▃▁▁▂▂▅▂▄▃▆▄█▃▃▄▄▄▅▄▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.10792</td></tr><tr><td>FK ROI < 30</td><td>0.05625</td></tr><tr><td>ROI</td><td>-0.11975</td></tr><tr><td>ROI < 30</td><td>0.06424</td></tr><tr><td>accuracy</td><td>0.22312</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>11.20554</td></tr><tr><td>correct</td><td>1785</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>11.20554</td></tr><tr><td>loss_val</td><td>2.04466</td></tr><tr><td>multibet outlay</td><td>262591.91353</td></tr><tr><td>multibet outlay < 30</td><td>120243.24913</td></tr><tr><td>multibet profit < 30</td><td>7723.99639</td></tr><tr><td>multibet profit < 30 sd</td><td>19.10378</td></tr><tr><td>multibet profit sd</td><td>46.28386</td></tr><tr><td>profit</td><td>5571.0086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vivid-sweep-40</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/w01z0yne\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/w01z0yne</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_161110-w01z0yne\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: juzzm50u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003435094665759176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_173215-juzzm50u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/juzzm50u\" target=\"_blank\">driven-sweep-41</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003435094665759176, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003435094665759176, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0003435094665759176\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [02:04<00:00,  2.60it/s]\n",
      "100%|██████████| 324/324 [02:00<00:00,  2.68it/s]\n",
      "100%|██████████| 324/324 [02:00<00:00,  2.70it/s]\n",
      "100%|██████████| 324/324 [02:03<00:00,  2.61it/s]\n",
      "100%|██████████| 324/324 [01:59<00:00,  2.72it/s]\n",
      "100%|██████████| 324/324 [02:04<00:00,  2.60it/s]\n",
      "100%|██████████| 324/324 [02:00<00:00,  2.68it/s]\n",
      "100%|██████████| 324/324 [01:57<00:00,  2.77it/s]\n",
      "100%|██████████| 324/324 [02:03<00:00,  2.62it/s]\n",
      "100%|██████████| 324/324 [01:57<00:00,  2.77it/s]\n",
      "100%|██████████| 324/324 [02:02<00:00,  2.64it/s]]\n",
      "100%|██████████| 324/324 [01:51<00:00,  2.92it/s]]\n",
      "100%|██████████| 324/324 [02:00<00:00,  2.70it/s]]\n",
      "100%|██████████| 324/324 [02:04<00:00,  2.59it/s]]\n",
      "100%|██████████| 324/324 [01:59<00:00,  2.70it/s]]\n",
      "100%|██████████| 324/324 [01:59<00:00,  2.70it/s]]\n",
      "100%|██████████| 324/324 [01:59<00:00,  2.71it/s]]\n",
      "100%|██████████| 324/324 [02:00<00:00,  2.68it/s]]\n",
      "100%|██████████| 324/324 [01:48<00:00,  2.98it/s]]\n",
      "100%|██████████| 324/324 [01:59<00:00,  2.71it/s]it]\n",
      "100%|██████████| 324/324 [02:04<00:00,  2.60it/s]it]\n",
      "100%|██████████| 324/324 [02:01<00:00,  2.67it/s]it]\n",
      "100%|██████████| 324/324 [02:01<00:00,  2.67it/s]it]\n",
      "100%|██████████| 324/324 [02:04<00:00,  2.59it/s]it]\n",
      "100%|██████████| 324/324 [02:01<00:00,  2.66it/s]it]\n",
      "100%|██████████| 324/324 [02:04<00:00,  2.60it/s]it]\n",
      "100%|██████████| 324/324 [02:03<00:00,  2.61it/s]it]\n",
      "100%|██████████| 324/324 [02:01<00:00,  2.66it/s]it]\n",
      "100%|██████████| 324/324 [02:08<00:00,  2.53it/s]it]\n",
      "100%|██████████| 324/324 [01:49<00:00,  2.95it/s]it]\n",
      "100%|██████████| 324/324 [02:02<00:00,  2.64it/s]it]\n",
      "100%|██████████| 324/324 [02:04<00:00,  2.61it/s]it]\n",
      "100%|██████████| 324/324 [02:00<00:00,  2.70it/s]it]\n",
      "100%|██████████| 324/324 [02:02<00:00,  2.64it/s]]  \n",
      "100%|██████████| 324/324 [01:58<00:00,  2.73it/s]]\n",
      "100%|██████████| 324/324 [02:02<00:00,  2.64it/s]]\n",
      "100%|██████████| 324/324 [01:45<00:00,  3.06it/s]]\n",
      "100%|██████████| 324/324 [01:58<00:00,  2.74it/s]]\n",
      "100%|██████████| 324/324 [02:00<00:00,  2.70it/s]]\n",
      "100%|██████████| 324/324 [01:45<00:00,  3.06it/s]]\n",
      "100%|██████████| 324/324 [02:03<00:00,  2.62it/s]]\n",
      "100%|██████████| 324/324 [02:01<00:00,  2.67it/s]]\n",
      "100%|██████████| 324/324 [02:00<00:00,  2.68it/s]]\n",
      "100%|██████████| 324/324 [02:06<00:00,  2.56it/s]]\n",
      "100%|██████████| 324/324 [02:00<00:00,  2.68it/s]]\n",
      "100%|██████████| 324/324 [02:03<00:00,  2.63it/s]]\n",
      "100%|██████████| 324/324 [01:50<00:00,  2.94it/s]]\n",
      "100%|██████████| 324/324 [01:59<00:00,  2.70it/s]]\n",
      "100%|██████████| 324/324 [02:04<00:00,  2.60it/s]]\n",
      "100%|██████████| 324/324 [01:48<00:00,  3.00it/s]]\n",
      "100%|██████████| 50/50 [2:45:47<00:00, 198.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbefbdb73e5b4b57ad9bd577862290f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.398 MB of 180.398 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▃▃▃▄▄▄▄▄▅▄▅▄▅▅▅▅▅▅▅▅▇▆▆▇▇▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>FK ROI < 30</td><td>▇███▇▇▇▇▇▆▆▆▅▅▅▄▅▄▄▃▃▃▃▄▄▃▃▄▄▄▄▅▃▃▂▃▃▂▃▁</td></tr><tr><td>ROI</td><td>▁▂▂▂▃▃▄▄▄▄▄▄▅▄▅▄▅▅▅▄▅▅▅▅▇▆▆▇▇▇▇█▆▇▇▇▇▇▇▇</td></tr><tr><td>ROI < 30</td><td>▇█████▇█▇▇▇▆▅▅▅▅▅▄▅▄▃▃▃▄▄▃▄▅▅▄▄▆▃▄▃▃▃▂▃▁</td></tr><tr><td>accuracy</td><td>▁▂▃▃▄▅▅▆▇▇▇▇▇████▇█▇███████████████████▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▇▇▇▇▇▆▆▆▆▅▆▆▅▄▅▅▅▄▄▄▃▂▃▂▃▃▃▂▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>correct</td><td>▁▂▃▃▄▅▅▆▇▇▇▇▇████▇█▇███████████████████▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▄▅▄▄▄▄▄▄▄▃▃▃▃▂▃▃▂▂▂▂▂▁▁▂▁</td></tr><tr><td>loss_val</td><td>▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▇▇▇█</td></tr><tr><td>multibet outlay</td><td>▆▆▆▆▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▆▆▆▇▇▇█</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▇▆▆▇▇▇▇█▆▇▇▇▇▇▇▇</td></tr><tr><td>multibet profit < 30</td><td>▅▆▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▅▄▄▃▄▅▅▃▄▆▆▅▅█▃▅▃▄▅▃▄▁</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>████▇▇▆▆▄▄▃▃▃▃▂▂▂▂▂▁▂▂▂▂▂▃▂▃▂▃▃▃▃▃▃▃▅▆▅▅</td></tr><tr><td>profit</td><td>▅▅▇▄▅▅▆▇▄▇▁▅▂▁▃▃▄▄▂▁▂▃▃▄▂▃▅▅▇▄▄█▅▄▅▇▆▅█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.02951</td></tr><tr><td>FK ROI < 30</td><td>0.01219</td></tr><tr><td>ROI</td><td>-0.03619</td></tr><tr><td>ROI < 30</td><td>0.01696</td></tr><tr><td>accuracy</td><td>0.25012</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>6.85017</td></tr><tr><td>correct</td><td>2001</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>6.85017</td></tr><tr><td>loss_val</td><td>2.11606</td></tr><tr><td>multibet outlay</td><td>275223.8188</td></tr><tr><td>multibet outlay < 30</td><td>195932.14147</td></tr><tr><td>multibet profit < 30</td><td>3322.41163</td></tr><tr><td>multibet profit < 30 sd</td><td>29.41866</td></tr><tr><td>multibet profit sd</td><td>47.78588</td></tr><tr><td>profit</td><td>5608.31903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">driven-sweep-41</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/juzzm50u\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/juzzm50u</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_173215-juzzm50u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8s0sm4x6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007072684337190881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_201846-8s0sm4x6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/8s0sm4x6\" target=\"_blank\">swift-sweep-42</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007072684337190881, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007072684337190881, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007072684337190881\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n",
      "100%|██████████| 32/32 [00:33<00:00,  1.06s/it]t]\n",
      "100%|██████████| 32/32 [00:32<00:00,  1.03s/it]t]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.07it/s]t]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.51it/s]t]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.57it/s]t]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.51it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]t]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.11it/s]it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.54it/s]it]\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.65it/s]it]\n",
      "100%|██████████| 32/32 [00:38<00:00,  1.22s/it]it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.55it/s]it]\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.69it/s]]  \n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.35it/s]]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.23it/s]]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.36it/s]]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.50it/s]]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.11it/s]]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.24it/s]]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.47it/s]]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.53it/s]]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.30it/s]]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.51it/s]]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.53it/s]]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.22it/s]]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.52it/s]]\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.61it/s]]\n",
      "100%|██████████| 32/32 [00:34<00:00,  1.06s/it]]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.25it/s]]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.53it/s]it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.24it/s]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.52it/s]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.46it/s]it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.10it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.50it/s]it]\n",
      "100%|██████████| 32/32 [00:38<00:00,  1.20s/it]it]\n",
      "100%|██████████| 32/32 [00:36<00:00,  1.15s/it]it]\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.65it/s]it]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.33it/s]it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.08it/s]it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.55it/s]it]\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.61it/s]it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.23it/s]it]\n",
      "100%|██████████| 50/50 [1:27:02<00:00, 104.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d240c7b002ff4ba0a376aca11df01481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.921 MB of 180.921 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▃▃▃▄▅▅▅▅▅▆▆▆▆▇▆▇█▇█▇▇██▇▇▆▇▆▇▆▇▇█▆▆▇▇▆▇</td></tr><tr><td>FK ROI < 30</td><td>▅▇▇████▇▇▇▇▇▆▇▇▆▅▇▅▆▆▄▅▅▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▁</td></tr><tr><td>ROI</td><td>▁▃▄▃▄▅▅▅▅▆▆▆▇▇▇▆▆█▇█▇▆▇▇▇▇▅▆▅▆▆▆▆▇▄▅▆▆▅▆</td></tr><tr><td>ROI < 30</td><td>▅▆▇█▇███▇▇▇▇▆▇▇▆▅▇▅▆▅▄▅▄▄▃▃▄▂▃▃▃▃▃▂▂▁▂▂▁</td></tr><tr><td>accuracy</td><td>▁▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇█▇██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▂▂▇▇▂▂▇▇▂▂▇▂▁▆▆▁▁▆▆▁▁▆▆▁▆▆▁▁▆▆▁▁▆▅▁▁▅▁</td></tr><tr><td>correct</td><td>▁▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇█▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▂▃▂▂▂▂▂▂▁▁</td></tr><tr><td>loss_val</td><td>█▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▃▅▇█████▇▇▇▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▁▂▂▁▂▁▁▂▁▁▁▂▂▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>multibet profit</td><td>▁▂▃▂▃▃▄▄▄▅▅▅▆▆▇▆▆█▇█▇▇██▇▇▆▇▅▆▆▆▆▇▅▅▇▆▆▆</td></tr><tr><td>multibet profit < 30</td><td>▄▆▆▇▇███▇▇█▇▇▇▇▆▅▇▅▆▆▄▅▅▄▄▃▄▂▃▃▃▄▃▂▂▁▃▂▁</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▃▃▃▃▃▃▃▄▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>multibet profit sd</td><td>██████▇█▇▇▇▇▇▆▆▅▅▅▅▅▄▄▄▃▃▃▂▃▃▂▂▂▁▂▂▁▂▂▁▂</td></tr><tr><td>profit</td><td>█▆▅▆▄▅▅▅▄▅▆▆▄▄▆▅▄▃▂▃▃▄▂▃▁▃▂▃▁▂▃▃▂▂▂▂▁▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.08819</td></tr><tr><td>FK ROI < 30</td><td>0.01614</td></tr><tr><td>ROI</td><td>-0.10379</td></tr><tr><td>ROI < 30</td><td>0.02019</td></tr><tr><td>accuracy</td><td>0.2545</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>5.32286</td></tr><tr><td>correct</td><td>2036</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>5.32286</td></tr><tr><td>loss_val</td><td>1.95585</td></tr><tr><td>multibet outlay</td><td>250672.40283</td></tr><tr><td>multibet outlay < 30</td><td>149335.93083</td></tr><tr><td>multibet profit < 30</td><td>3015.74407</td></tr><tr><td>multibet profit < 30 sd</td><td>23.14172</td></tr><tr><td>multibet profit sd</td><td>39.95271</td></tr><tr><td>profit</td><td>5255.24729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">swift-sweep-42</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/8s0sm4x6\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/8s0sm4x6</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_201846-8s0sm4x6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9km4his6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007418941276416419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_214611-9km4his6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/9km4his6\" target=\"_blank\">legendary-sweep-43</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007418941276416419, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007418941276416419, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007418941276416419\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]t]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.11it/s]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.48it/s]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.52it/s]t]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.50it/s]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.48it/s]t]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.17it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]it]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.11it/s]it]\n",
      "100%|██████████| 32/32 [00:35<00:00,  1.10s/it]it]\n",
      "100%|██████████| 32/32 [00:35<00:00,  1.12s/it]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.46it/s]it]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.12it/s]it]\n",
      "100%|██████████| 32/32 [00:34<00:00,  1.09s/it]]  \n",
      "100%|██████████| 32/32 [00:33<00:00,  1.06s/it]]\n",
      "100%|██████████| 32/32 [00:40<00:00,  1.26s/it]]\n",
      "100%|██████████| 32/32 [00:34<00:00,  1.08s/it]]\n",
      "100%|██████████| 32/32 [00:34<00:00,  1.08s/it]]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.09it/s]]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.46it/s]]\n",
      "100%|██████████| 32/32 [00:37<00:00,  1.17s/it]]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.11it/s]]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]]\n",
      "100%|██████████| 32/32 [00:37<00:00,  1.18s/it]]\n",
      "100%|██████████| 32/32 [00:41<00:00,  1.29s/it]]\n",
      "100%|██████████| 32/32 [00:36<00:00,  1.13s/it]]\n",
      "100%|██████████| 32/32 [00:37<00:00,  1.16s/it]]\n",
      "100%|██████████| 32/32 [00:38<00:00,  1.21s/it]]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.35it/s]]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.18it/s]]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.39it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]it]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.15it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.40it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.08it/s]it]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.18it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]it]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.14it/s]it]\n",
      "100%|██████████| 32/32 [00:36<00:00,  1.15s/it]it]\n",
      "100%|██████████| 32/32 [00:34<00:00,  1.09s/it]it]\n",
      "100%|██████████| 32/32 [00:35<00:00,  1.11s/it]it]\n",
      "100%|██████████| 32/32 [00:39<00:00,  1.22s/it]it]\n",
      "100%|██████████| 32/32 [00:41<00:00,  1.30s/it]it]\n",
      "100%|██████████| 32/32 [00:35<00:00,  1.10s/it]it]\n",
      "100%|██████████| 32/32 [00:36<00:00,  1.14s/it]it]\n",
      "100%|██████████| 50/50 [1:29:26<00:00, 107.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6123a4bfc9134f01ae80c855d3784baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.846 MB of 180.846 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▅▆▆▆▅▅▇▅▇▆█▆▇▇▇▇▇▆█▆▇</td></tr><tr><td>FK ROI < 30</td><td>▇█▇█▇▇▆▆▅▆▆▆▅▇▇▅▄▇▅▆▅▅▄▄▂▄▄▃▃▄▄▄▂▅▄▃▁▅▂▄</td></tr><tr><td>ROI</td><td>▁▂▂▂▂▃▃▃▃▃▄▃▄▄▅▄▅▅▅▅▅▅▆▅▅▇▅▆▆█▆▇▇▇▇▆▆█▆▇</td></tr><tr><td>ROI < 30</td><td>▆███▇▆▆▆▅▆▅▅▄▇▇▅▄█▅▆▅▄▄▃▁▄▄▂▃▄▄▄▂▅▃▃▁▇▂▆</td></tr><tr><td>accuracy</td><td>▁▁▁▁▂▃▃▄▅▅▆▆▆▆▇▆▇▇▇██▇▇██▇█▇████████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▃▅▇▃▅▇▇▄▇▇▇▇▆▆▆▆▂▆▆▂▃▆▂▃▅▅▅▅▅▅▅▅▅▄▄▁▄</td></tr><tr><td>correct</td><td>▁▁▁▁▂▃▃▄▅▅▆▆▆▆▇▆▇▇▇██▇▇██▇█▇████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▃▂▃▃▃▃▃▄</td></tr><tr><td>multibet outlay</td><td>▅▇████▇▇▆▆▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▂▁▂▁▁▂▂▃▂▂▂▃▄▃▄</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▂▃▂▃▃▃▄▄▄▄▅▄▅▅▅▅▅▆▆▅▅▇▅▇▆█▆▇▇▇▇▆▆█▆▇</td></tr><tr><td>multibet profit < 30</td><td>▂▃▃▄▃▃▃▃▂▃▃▂▂▄▄▃▂▅▃▄▄▃▃▃▁▄▄▂▃▄▄▄▃▅▄▄▂█▄▇</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▄▅▅▅▅▆▆▆▆▆▇▇▇▇█▇█</td></tr><tr><td>multibet profit sd</td><td>▆▇███▇▇▇▇▆▇▅▅▆▅▅▅▃▅▃▃▄▃▂▂▄▁▇▄▅▂▅▆▄▄▂▂▅▄▂</td></tr><tr><td>profit</td><td>▇█▇▇▆▆▄▄▃▂▄▃▁▃▅▂▃▃▄▃▅▂▁▂▃▄▂▃▃▁▂▃▅▂▃▃▃▆▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.04181</td></tr><tr><td>FK ROI < 30</td><td>0.04126</td></tr><tr><td>ROI</td><td>-0.0484</td></tr><tr><td>ROI < 30</td><td>0.05784</td></tr><tr><td>accuracy</td><td>0.25575</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>5.01477</td></tr><tr><td>correct</td><td>2046</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>5.01477</td></tr><tr><td>loss_val</td><td>1.98222</td></tr><tr><td>multibet outlay</td><td>255398.58633</td></tr><tr><td>multibet outlay < 30</td><td>165853.64313</td></tr><tr><td>multibet profit < 30</td><td>9593.34675</td></tr><tr><td>multibet profit < 30 sd</td><td>25.88611</td></tr><tr><td>multibet profit sd</td><td>43.8936</td></tr><tr><td>profit</td><td>5420.13637</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">legendary-sweep-43</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/9km4his6\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/9km4his6</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_214611-9km4his6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h5xdrgle with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008720856461993309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230311_231615-h5xdrgle</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/h5xdrgle\" target=\"_blank\">northern-sweep-44</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008720856461993309, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008720856461993309, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0008720856461993309\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:37<00:00,  3.44it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.69it/s]\n",
      "100%|██████████| 129/129 [00:56<00:00,  2.30it/s]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.62it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.31it/s]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.16it/s]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.49it/s]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.89it/s]\n",
      "100%|██████████| 129/129 [00:51<00:00,  2.50it/s]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.58it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.08it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.56it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.35it/s]]\n",
      "100%|██████████| 129/129 [00:51<00:00,  2.50it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.61it/s]]\n",
      "100%|██████████| 129/129 [00:54<00:00,  2.37it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.65it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.59it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.07it/s]]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.71it/s]]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.68it/s] \n",
      "100%|██████████| 129/129 [00:38<00:00,  3.32it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.89it/s] \n",
      "100%|██████████| 129/129 [00:34<00:00,  3.73it/s]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.12it/s]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.64it/s]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.76it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.27it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.76it/s]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.91it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.04it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.65it/s]]\n",
      "100%|██████████| 129/129 [00:53<00:00,  2.42it/s]]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.73it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.81it/s]]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.03it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.53it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.52it/s]]\n",
      "100%|██████████| 129/129 [00:53<00:00,  2.43it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.62it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.35it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.63it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.52it/s]]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.12it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.59it/s]]\n",
      "100%|██████████| 129/129 [00:52<00:00,  2.44it/s]]\n",
      "100%|██████████| 129/129 [00:52<00:00,  2.48it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.49it/s]]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.28it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.38it/s]]\n",
      "100%|██████████| 50/50 [1:42:38<00:00, 123.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728f422d5b5b487bb4b84f53d223b7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.139 MB of 180.139 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▂▃▂▃▄▄▄▄▄▅▄▄▅▅▄▆▅▆▆▇▇▆▇▆▇▇▆▇▇▇█▇▇█▇▇</td></tr><tr><td>FK ROI < 30</td><td>▅██▇▇▇▇▆▆▅▆▆▄▅▄▃▄▅▁▄▃▅▄▆▄▄▃▄▄▅▁▄▃▃▄▃▄▄▄▂</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▂▂▃▄▃▃▃▃▄▄▄▄▅▄▅▅▆▅▇▇▆▇▆▇▇▅▇▇▇█▇▆█▇▇</td></tr><tr><td>ROI < 30</td><td>▆██▇██▇▆▆▅▆▆▄▅▅▄▅▅▁▄▄▆▅█▅▆▄▅▆▇▂▅▄▅▅▄▆▅▅▃</td></tr><tr><td>accuracy</td><td>▁▁▂▃▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇█████▇██▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▅▇▇▇▇▇▆▆▆▆▆▅▅▃▅▅▄▄▄▂▄▄▃▃▃▃▃▂▃▃▂▂▁▂▂▂▂▁</td></tr><tr><td>correct</td><td>▁▁▂▃▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇█████▇██▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇█</td></tr><tr><td>multibet outlay</td><td>▃▄▄▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁▂▁▂▂▃▃▃▃▃▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▂▂▃▄▄▄▃▄▅▄▄▅▅▄▆▅▆▅█▇▆▇▆▇▇▅▇▇▇█▇▆▇▆▇</td></tr><tr><td>multibet profit < 30</td><td>▃▄▅▄▅▅▅▄▄▄▄▄▃▄▄▃▄▄▁▄▄▆▅█▆▆▅▆▇█▃▇▆▆▇▆█▇▇▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>███▇▆▅▄▄▄▃▃▂▂▃▂▂▁▁▁▂▁▂▂▃▃▂▃▂▃▄▃▃▄▃▄▃▃▄▃▅</td></tr><tr><td>profit</td><td>█▇███▁▄▄▆▇▃▄▂▅▂▁▅▄▄▄▆█▄▅▃▆▃▅▅▅▃█▃▃█▇▂▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.02814</td></tr><tr><td>FK ROI < 30</td><td>0.03029</td></tr><tr><td>ROI</td><td>-0.03458</td></tr><tr><td>ROI < 30</td><td>0.04138</td></tr><tr><td>accuracy</td><td>0.24825</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>11.84693</td></tr><tr><td>correct</td><td>1986</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>11.84693</td></tr><tr><td>loss_val</td><td>2.16007</td></tr><tr><td>multibet outlay</td><td>287826.31097</td></tr><tr><td>multibet outlay < 30</td><td>207175.43565</td></tr><tr><td>multibet profit < 30</td><td>8572.67647</td></tr><tr><td>multibet profit < 30 sd</td><td>33.25341</td></tr><tr><td>multibet profit sd</td><td>47.65729</td></tr><tr><td>profit</td><td>5778.65811</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">northern-sweep-44</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/h5xdrgle\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/h5xdrgle</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230311_231615-h5xdrgle\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s78gikg6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007553718077780758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_005918-s78gikg6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/s78gikg6\" target=\"_blank\">devoted-sweep-45</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007553718077780758, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007553718077780758, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007553718077780758\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.12it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.48it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.31it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.57it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.45it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.69it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.46it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.52it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.67it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.44it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.60it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.19it/s]t]  \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.44it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.62it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.50it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.50it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.37it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.53it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.62it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.71it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.76it/s]t] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.73it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.67it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.47it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.65it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.54it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.46it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.75it/s]t] \n",
      "100%|██████████| 6/6 [00:15<00:00,  2.52s/it]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.75it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.54it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.67it/s]t]\n",
      "100%|██████████| 6/6 [00:15<00:00,  2.53s/it]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.30it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.65it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.62it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.40it/s]/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.45it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.60it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]/it]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.48it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.59it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]/it]\n",
      "100%|██████████| 50/50 [1:20:53<00:00, 97.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53881f6bae5e446ba4cbb5e21355bd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.799 MB of 179.799 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>█▁▂▃▄▄▄▅▅▄▅▅▅▅▅▄▄▆▄▇█▃▇▄▅▄▇▄▄▆▆▅▅▇▄▇█▅██</td></tr><tr><td>FK ROI < 30</td><td>▁▄▆▅▆▆▆▇▇▆▆▇▇▆▇▆▆▇▆▇▇▆▇▆▆▆▆▇▇▅█▅▄█▄▇▇▅▇▆</td></tr><tr><td>ROI</td><td>█▁▂▃▃▄▄▅▅▄▅▅▄▅▅▄▄▆▄▇█▃▆▄▅▄▇▃▄▆▆▅▄▇▄▇█▅▇▇</td></tr><tr><td>ROI < 30</td><td>▁▄▅▅▅▆▆▇▇▆▆▇▇▆▇▆▆▇▆▇▇▆▇▆▆▆▆▇█▄█▅▄█▄▇▇▅▆▆</td></tr><tr><td>accuracy</td><td>▄▁▄▄▄▅▅▅▅▅▆▅▅▆▆▆▆▆▆▆▆▆▇▆▅▆▆▇▇▇▇▇▇█▇██▇▇█</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▆█▆▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>correct</td><td>▄▁▄▄▄▅▅▅▅▅▆▅▅▆▆▆▆▆▆▆▆▆▇▆▅▆▆▇▇▇▇▇▇█▇██▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>▆█▆▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▂▁▁</td></tr><tr><td>multibet outlay</td><td>█▁▁▂▃▃▃▃▃▄▃▄▄▃▄▃▃▃▃▄▃▃▃▃▄▃▃▃▄▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>multibet outlay < 30</td><td>█▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▃▄▄▃▄▃▄▄▄▄▄▄▄▄</td></tr><tr><td>multibet profit</td><td>▇▁▂▃▃▃▃▄▅▄▅▄▄▄▅▃▃▆▃▇█▂▇▄▄▄▇▃▄▅▆▅▄▇▄▇█▅██</td></tr><tr><td>multibet profit < 30</td><td>▁▃▅▄▅▆▅▆▆▆▆▆▇▅▇▅▆▆▅▇▇▅▆▆▆▆▆▇█▄▇▄▄█▃▇▇▅▆▆</td></tr><tr><td>multibet profit < 30 sd</td><td>█▁▁▁▂▂▂▂▂▂▂▂▂▂▃▂▂▃▂▃▃▂▃▂▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>multibet profit sd</td><td>█▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▂▄▂▄▅▂▃▂▃▂▄▁▁▄▂▃▃▂▃▂▄▂▄▄</td></tr><tr><td>profit</td><td>▃█▇▆▄▅▁▅▅▄▅▃▅▄▄▃▂▃▃▃▃▄▃▆▇▄▄▅▆▅▄▁▂▅▃▆▃▅▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.07744</td></tr><tr><td>FK ROI < 30</td><td>0.0521</td></tr><tr><td>ROI</td><td>-0.08808</td></tr><tr><td>ROI < 30</td><td>0.05659</td></tr><tr><td>accuracy</td><td>0.22462</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>11.1076</td></tr><tr><td>correct</td><td>1797</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>11.1076</td></tr><tr><td>loss_val</td><td>2.04277</td></tr><tr><td>multibet outlay</td><td>261981.75534</td></tr><tr><td>multibet outlay < 30</td><td>123024.83841</td></tr><tr><td>multibet profit < 30</td><td>6961.3954</td></tr><tr><td>multibet profit < 30 sd</td><td>19.54524</td></tr><tr><td>multibet profit sd</td><td>53.44846</td></tr><tr><td>profit</td><td>5816.43194</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devoted-sweep-45</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/s78gikg6\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/s78gikg6</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_005918-s78gikg6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 78as63n8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00031678848227501515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_022048-78as63n8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/78as63n8\" target=\"_blank\">polished-sweep-46</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00031678848227501515, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00031678848227501515, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00031678848227501515\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:28<00:00,  2.27it/s]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.03it/s]t]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.59it/s]t]\n",
      "100%|██████████| 64/64 [00:42<00:00,  1.51it/s]t]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.46it/s]t]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.60it/s]t]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.58it/s]t]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.08it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.38it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.39it/s]t]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.11it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.29it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.13it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.29it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.30it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.03it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.33it/s]it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.23it/s]]  \n",
      "100%|██████████| 64/64 [00:45<00:00,  1.40it/s]]\n",
      "100%|██████████| 64/64 [00:48<00:00,  1.33it/s]]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.54it/s]]\n",
      "100%|██████████| 64/64 [00:49<00:00,  1.29it/s]]\n",
      "100%|██████████| 64/64 [00:43<00:00,  1.47it/s]]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.55it/s]]\n",
      "100%|██████████| 64/64 [00:45<00:00,  1.42it/s]]\n",
      "100%|██████████| 64/64 [00:44<00:00,  1.44it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.38it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.18it/s]]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.00it/s]]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.27it/s]]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.03it/s]]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.34it/s]it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.26it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  2.00it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.11it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.56it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.11it/s]it]\n",
      "100%|██████████| 64/64 [00:46<00:00,  1.38it/s]it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.67it/s]it]\n",
      "100%|██████████| 64/64 [00:49<00:00,  1.29it/s]it]\n",
      "100%|██████████| 64/64 [00:41<00:00,  1.53it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.56it/s]it]\n",
      "100%|██████████| 64/64 [00:44<00:00,  1.45it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.20it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.46it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.30it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.02it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.53it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.34it/s]it]\n",
      "100%|██████████| 50/50 [1:34:32<00:00, 113.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f02235430e9427eb54875d3ffc1cfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='181.044 MB of 181.044 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▄▅▅▆▆▆▆▆▆▆▇▇▆█▇█▇▇▇▇▇▇▇█▇▇▇▆▆▇▆▆▇▇▆▆▇</td></tr><tr><td>FK ROI < 30</td><td>▄▆▇█████▇▇▇▇▇▇▆▅▇▆▇▅▅▅▄▄▄▃▄▃▃▂▂▁▂▂▃▃▂▁▁▂</td></tr><tr><td>ROI</td><td>▁▂▃▄▅▅▆▆▆▆▇▇▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇▇▆▆▆▇▆▆▆▇▅▆▆</td></tr><tr><td>ROI < 30</td><td>▄▆▇█████▇▇▇▇▇▇▆▆▇▆▆▅▅▄▄▄▄▄▄▃▃▂▂▂▂▂▃▃▂▁▁▂</td></tr><tr><td>accuracy</td><td>▁▁▁▂▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▂▆▇▂▆▇▇▆▇▇▇▇▇▇▇▇▂▇▇▂▅▇▁▅▆▆▆▆▆▆▆▆▆▆▆▁▆</td></tr><tr><td>correct</td><td>▁▁▁▂▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▃▂▂▂▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▆▇█████▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▃▄▅▅▅▅▆▆▆▆▇▇▇█▇███▇▇▇█▇█▇▇▇▇▇█▇▇▇█▇▇▇</td></tr><tr><td>multibet profit < 30</td><td>▃▅▆▇▇▇██▇▇▇█▇▇▇▆▇▇▇▅▅▅▄▄▅▄▄▃▃▂▂▂▂▂▃▃▂▁▁▃</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇██▇██</td></tr><tr><td>multibet profit sd</td><td>█████▇█▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>profit</td><td>▆█▄▅▅▆▇█▅▇█▆▄▃▂▂▄▃▄▂▅▃▃▃▃▃▅▂▁▂▃▂▁▂▂▄▁▁▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.08444</td></tr><tr><td>FK ROI < 30</td><td>0.02584</td></tr><tr><td>ROI</td><td>-0.0993</td></tr><tr><td>ROI < 30</td><td>0.03015</td></tr><tr><td>accuracy</td><td>0.2555</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>8.55318</td></tr><tr><td>correct</td><td>2044</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>8.55318</td></tr><tr><td>loss_val</td><td>1.93323</td></tr><tr><td>multibet outlay</td><td>245426.73617</td></tr><tr><td>multibet outlay < 30</td><td>139467.75888</td></tr><tr><td>multibet profit < 30</td><td>4204.33897</td></tr><tr><td>multibet profit < 30 sd</td><td>21.85752</td></tr><tr><td>multibet profit sd</td><td>40.73264</td></tr><tr><td>profit</td><td>5531.6563</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">polished-sweep-46</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/78as63n8\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/78as63n8</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_022048-78as63n8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tx5nou3m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000573870136863793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_035545-tx5nou3m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/tx5nou3m\" target=\"_blank\">true-sweep-47</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000573870136863793, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000573870136863793, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.000573870136863793\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:33<00:00,  3.90it/s]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.29it/s]\n",
      "100%|██████████| 129/129 [00:32<00:00,  4.01it/s]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.57it/s]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.44it/s]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.05it/s]\n",
      "100%|██████████| 129/129 [00:52<00:00,  2.45it/s]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.86it/s]\n",
      "100%|██████████| 129/129 [00:51<00:00,  2.50it/s]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.82it/s]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.23it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.44it/s]]\n",
      "100%|██████████| 129/129 [00:32<00:00,  4.02it/s]]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.06it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.54it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.43it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.56it/s]]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.63it/s]]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.87it/s] \n",
      "100%|██████████| 129/129 [00:52<00:00,  2.43it/s]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.05it/s]]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.12it/s] \n",
      "100%|██████████| 129/129 [00:35<00:00,  3.60it/s]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.44it/s]\n",
      "100%|██████████| 129/129 [00:29<00:00,  4.31it/s]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.60it/s]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.62it/s]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.06it/s]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.16it/s]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.50it/s]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.91it/s]]\n",
      "100%|██████████| 129/129 [01:39<00:00,  1.29it/s]]\n",
      "100%|██████████| 129/129 [00:50<00:00,  2.58it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.27it/s]]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.07it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.20it/s]]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.09it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.90it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.65it/s]]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.09it/s]]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.36it/s]]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.81it/s]]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.71it/s]]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.63it/s]]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.09it/s]]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.05it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.40it/s]]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.06it/s]]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.24it/s]]\n",
      "100%|██████████| 50/50 [1:42:00<00:00, 122.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fade86eb99c24f8f8f226c77bceb0e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.878 MB of 180.878 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▄▄▄▅▅▅▅▅▅▅▅▅▄▄▅▄▄▅▅▆▆▆▆▅▆▅▅█▆▇▆▇▇█▇██</td></tr><tr><td>FK ROI < 30</td><td>▆▇▇▇███▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▄▄▃▃▃▃▂▂▂▂▂▁▂▂▁▁▁▁</td></tr><tr><td>ROI</td><td>▁▂▃▄▅▅▅▅▆▅▅▅▆▆▆▄▄▅▄▄▄▅▆▅▅▆▅▅▄▅▇▅▇▅▆▇█▇▇█</td></tr><tr><td>ROI < 30</td><td>▆▆▇▇███▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▄▄▃▃▃▃▂▂▂▂▂▁▂▂▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▁▁▁▃▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇█▇████▇███████████▇█</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▃▇▇▂▆▇▇▆▇▇▇▇▇▆▆▆▂▆▆▂▅▆▂▅▆▅▆▅▅▅▅▅▅▅▅▁▅</td></tr><tr><td>correct</td><td>▁▁▁▁▃▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇█▇████▇███████████▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▄▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄</td></tr><tr><td>multibet outlay</td><td>▆████▇▇▇▆▅▅▅▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▃▃▄▄▅▅▅▅▅▅▆▆▆▅▅▅▅▅▅▅▇▆▆▇▆▆▅▅█▆▇▆▇▇█▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▅▆▇▇█████▆▆▆▆▆▅▄▄▄▄▄▃▃▄▄▃▄▃▃▃▂▃▂▃▁▃▂▂▁▂▁</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>multibet profit sd</td><td>█▇███▇▇▇▇▆▆▆▅▅▅▄▄▃▃▃▃▃▃▃▂▃▂▂▁▂▃▁▂▁▁▂▃▂▂▂</td></tr><tr><td>profit</td><td>▇▆█▄▆▆▄▆▂▂▁▁▁▂▄▃▂▃▂▁▃▃▂▂▂▁▂▂▂▂▃▂▃▄▄▂▃▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.07014</td></tr><tr><td>FK ROI < 30</td><td>0.0076</td></tr><tr><td>ROI</td><td>-0.08531</td></tr><tr><td>ROI < 30</td><td>0.00987</td></tr><tr><td>accuracy</td><td>0.255</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>13.80376</td></tr><tr><td>correct</td><td>2040</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>13.80376</td></tr><tr><td>loss_val</td><td>1.98861</td></tr><tr><td>multibet outlay</td><td>255779.76412</td></tr><tr><td>multibet outlay < 30</td><td>168756.44957</td></tr><tr><td>multibet profit < 30</td><td>1665.35849</td></tr><tr><td>multibet profit < 30 sd</td><td>25.53252</td></tr><tr><td>multibet profit sd</td><td>41.75276</td></tr><tr><td>profit</td><td>5505.42928</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-47</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/tx5nou3m\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/tx5nou3m</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_035545-tx5nou3m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mv8bko3g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 5000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008467228603468119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_053811-mv8bko3g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/mv8bko3g\" target=\"_blank\">ethereal-sweep-48</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008467228603468119, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 5000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0008467228603468119, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0008467228603468119\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.96it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.60it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.23it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.65it/s]/it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.68it/s]it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.78it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.70it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.06it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.35it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.56it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]/it] \n",
      "100%|██████████| 6/6 [00:02<00:00,  2.65it/s]t]  \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]it]\n",
      "100%|██████████| 6/6 [00:15<00:00,  2.62s/it]t] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.28it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.58it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.72it/s]t]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.77it/s]t]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.88it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.17it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.56it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.59it/s]t] \n",
      "100%|██████████| 6/6 [00:02<00:00,  2.95it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.67it/s]it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.57it/s]it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.84it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.43it/s]it]\n",
      "100%|██████████| 6/6 [00:15<00:00,  2.59s/it]it]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.63it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.66it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.73it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.12it/s]it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.78it/s]s/it]\n",
      "100%|██████████| 6/6 [00:16<00:00,  2.69s/it]/it] \n",
      "100%|██████████| 6/6 [00:02<00:00,  2.86it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.22it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.70it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.07it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.61it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.50it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.68it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.15it/s]s/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.71it/s]/it] \n",
      "100%|██████████| 6/6 [00:01<00:00,  3.64it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.75it/s]/it]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.08it/s]/it]\n",
      "100%|██████████| 50/50 [1:26:01<00:00, 103.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8182a109b1413e983aea4862d892ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='179.254 MB of 179.254 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>█▂▁▁▂▂▂▂▂▃▃▄▄▃▄▃▃▄▃▄▄▃▅▂▃▄▄▃▃▄▃▅▅▃▆▂▂▆▂▃</td></tr><tr><td>FK ROI < 30</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▅▅█▅▇▇▅▇▆▆▆▆▆▆▆▆▆</td></tr><tr><td>ROI</td><td>█▂▁▁▂▂▂▂▂▃▂▃▄▂▃▃▃▄▃▄▄▂▄▂▃▄▄▃▃▄▃▄▅▃▅▂▂▅▂▃</td></tr><tr><td>ROI < 30</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▆▇▅▄█▄▇▇▅▇▅▅▆▅▆▆▅▆▆</td></tr><tr><td>accuracy</td><td>▄▁▂▂▄▅▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇█▇██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>▄█▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>correct</td><td>▄▁▂▂▄▅▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇█▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>▄█▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>█▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>multibet outlay < 30</td><td>█▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>multibet profit</td><td>█▁▁▁▁▁▂▁▁▃▂▄▄▂▄▂▃▄▂▅▅▂▅▂▃▄▄▃▃▅▃▆▆▂▇▂▁▇▁▃</td></tr><tr><td>multibet profit < 30</td><td>▁▄▅▅▅▆▆▆▆▆▆▇▇▆▇▆▆▇▆▇▇▆▇▅▄█▄▇▇▅▇▅▅▆▅▆▆▅▆▆</td></tr><tr><td>multibet profit < 30 sd</td><td>█▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>multibet profit sd</td><td>█▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▃▁▁▃▁▃▃▁▃▁▁▃▁▁</td></tr><tr><td>profit</td><td>▂▆█▆▄▃▂▁▁▃▁▃▃▁▂▁▁▂▁▃▂▁▂▂▂▃▂▂▂▁▂▁▂▂▃▃▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.10211</td></tr><tr><td>FK ROI < 30</td><td>0.05146</td></tr><tr><td>ROI</td><td>-0.11341</td></tr><tr><td>ROI < 30</td><td>0.05784</td></tr><tr><td>accuracy</td><td>0.22237</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>11.30989</td></tr><tr><td>correct</td><td>1779</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>11.30989</td></tr><tr><td>loss_val</td><td>2.05972</td></tr><tr><td>multibet outlay</td><td>263905.92393</td></tr><tr><td>multibet outlay < 30</td><td>120589.52986</td></tr><tr><td>multibet profit < 30</td><td>6974.95612</td></tr><tr><td>multibet profit < 30 sd</td><td>19.40445</td></tr><tr><td>multibet profit sd</td><td>49.25751</td></tr><tr><td>profit</td><td>5764.86948</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ethereal-sweep-48</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/mv8bko3g\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/mv8bko3g</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_053811-mv8bko3g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dwogyml9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002025026130667287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_070436-dwogyml9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/dwogyml9\" target=\"_blank\">ethereal-sweep-49</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0002025026130667287, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0002025026130667287, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0002025026130667287\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:23<00:00,  2.67it/s]\n",
      "100%|██████████| 64/64 [00:21<00:00,  2.93it/s]t]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.66it/s]t]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.15it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.54it/s]t]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.90it/s]t]\n",
      "100%|██████████| 64/64 [00:59<00:00,  1.07it/s]t]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.34it/s]t]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.51it/s]t]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.41it/s]t]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.13it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.56it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.49it/s]it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.25it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.66it/s]it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.79it/s]it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.58it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]]  \n",
      "100%|██████████| 64/64 [00:23<00:00,  2.67it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.17it/s]]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.56it/s]]\n",
      "100%|██████████| 64/64 [00:49<00:00,  1.30it/s]]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.08it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.54it/s]]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.45it/s]]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.31it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.49it/s]]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.67it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.52it/s]]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.16it/s]]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.70it/s]]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.50it/s]]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.13it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.68it/s]it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.79it/s]it]\n",
      "100%|██████████| 64/64 [01:00<00:00,  1.06it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.37it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.64it/s]it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.27it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.11it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.47it/s]it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.22it/s]it]\n",
      "100%|██████████| 64/64 [00:27<00:00,  2.37it/s]it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.90it/s]it]\n",
      "100%|██████████| 64/64 [00:49<00:00,  1.29it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.06it/s]it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.76it/s]it]\n",
      "100%|██████████| 64/64 [00:26<00:00,  2.46it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.11it/s]it]\n",
      "100%|██████████| 64/64 [00:25<00:00,  2.55it/s]it]\n",
      "100%|██████████| 50/50 [1:36:39<00:00, 115.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2433631ccbf4780a4ec28d6926cb620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.996 MB of 180.996 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▅▆▆▆▇▆▆▇▇▇▇▇▇█▇█▇█▇████</td></tr><tr><td>FK ROI < 30</td><td>▁▅▆▇▇▇██▇▇█▇█▇▇▆▇▇▆▇▇█▇▇▇▆▆▇▇▇▇▇▆▆▅▅▅▅▅▅</td></tr><tr><td>ROI</td><td>▁▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▅▆▆▆▇▇▇▇▇▇▇█▇███▇█▇████</td></tr><tr><td>ROI < 30</td><td>▁▅▆▆▇▇███████▇▇▇▇▇▆▇▇█▇▇▇▇▆▇▇▆▇▇▆▅▅▄▅▅▅▄</td></tr><tr><td>accuracy</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇█▇███</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▁▁██▁▁█▇▁▁▇▁▁▇▇▁▁▇▇▁▁▇▇▁▇▇▁▁▇▇▁▁▇▇▁▁▇▁</td></tr><tr><td>correct</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇█▇███</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▂▃▂▃▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▄▅▆▇█████████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▅▄▅▅▅▆▆▆▆▇▇▇▇▇█▇█▇█▇████</td></tr><tr><td>multibet profit < 30</td><td>▁▄▅▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇██▇██▇██▇▇▇▇▆▆▆▆▆▆▆</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>multibet profit sd</td><td>▆████████▇█▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁</td></tr><tr><td>profit</td><td>▂▄▃▃▅▅█▆▅▁▂▃▃▂▄▇█▆▄▃▅▆▅▅▅▅▃▆▅▃▄▄▆▅▂▃▂▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.08431</td></tr><tr><td>FK ROI < 30</td><td>0.04116</td></tr><tr><td>ROI</td><td>-0.09665</td></tr><tr><td>ROI < 30</td><td>0.04461</td></tr><tr><td>accuracy</td><td>0.24463</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>9.43204</td></tr><tr><td>correct</td><td>1957</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>9.43204</td></tr><tr><td>loss_val</td><td>1.9508</td></tr><tr><td>multibet outlay</td><td>253230.25715</td></tr><tr><td>multibet outlay < 30</td><td>124370.89979</td></tr><tr><td>multibet profit < 30</td><td>5548.37749</td></tr><tr><td>multibet profit < 30 sd</td><td>19.28759</td></tr><tr><td>multibet profit sd</td><td>45.51613</td></tr><tr><td>profit</td><td>5824.5695</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ethereal-sweep-49</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/dwogyml9\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/dwogyml9</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_070436-dwogyml9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h38z2f86 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5.864557040382762e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_084142-h38z2f86</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/h38z2f86\" target=\"_blank\">wandering-sweep-50</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 5.864557040382762e-05, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 5.864557040382762e-05, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 5.864557040382762e-05\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:22<00:00,  1.29s/it]\n",
      "100%|██████████| 64/64 [00:45<00:00,  1.40it/s]t]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.01it/s]t]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.74it/s]t]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.01it/s]t]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.12it/s]t]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.75it/s]t]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.02it/s]t]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.94it/s]t]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.96it/s]t]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.80it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.06it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.77it/s]it]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.90it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.02it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.74it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.98it/s]it]\n",
      "100%|██████████| 64/64 [00:39<00:00,  1.62it/s]it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.79it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.11it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.04it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.77it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.04it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.87it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.83it/s]]  \n",
      "100%|██████████| 64/64 [00:33<00:00,  1.93it/s]]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.91it/s]]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.85it/s]it]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.91it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.84it/s]it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.84it/s]it]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.93it/s]it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.78it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.95it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.01it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.70it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.97it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.01it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.00it/s]it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.79it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.98it/s]it]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.88it/s]it]\n",
      "100%|██████████| 64/64 [00:30<00:00,  2.07it/s]it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.02it/s]it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.82it/s]it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.99it/s]it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.74it/s]it]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.91it/s]it]\n",
      "100%|██████████| 64/64 [00:29<00:00,  2.17it/s]it]\n",
      "100%|██████████| 64/64 [01:35<00:00,  1.49s/it]it]\n",
      "100%|██████████| 50/50 [1:54:19<00:00, 137.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0fc6199b9a4f5fbdd86a36291a02e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.861 MB of 180.861 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>FK ROI < 30</td><td>▁▁▂▃▄▄▅▅▇▇▇▆▇███████▇▇█▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▆▆</td></tr><tr><td>ROI</td><td>▁▂▂▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>ROI < 30</td><td>▁▂▃▄▅▅▆▆▇▇▇▇▇▇███▇██████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▇▆</td></tr><tr><td>accuracy</td><td>▁▁▁▁▂▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇█</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▃▇▇▇▇▇▇▇▇▆▇▇▇▂▇▇▇▇▇▁▇▇▇▇▇▆▆▇▆▆▇▆▁▆▆▇▆▆</td></tr><tr><td>correct</td><td>▁▁▁▁▂▁▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▁▃▄▄▅▆▆▆▇▇▇▇▇██████████████████████████▇</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>multibet profit</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▂▃▄▅▅▆▆▇▇▇▇▇▇███▇██████████████████████</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>multibet profit sd</td><td>▁▃▄▄▅▆▆▇▇▇▇██████████▇▇▇▇▇▇▇▇▇▆▇▇▇▇▆▇▆▇▆</td></tr><tr><td>profit</td><td>▄▄▃▃▃▂▃▃▃▄▃▄▃▃▃▄▂▂▂▁▂▁▂▂▂▂▂▁▂▂▃▁▂▃▂▂▃▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.09255</td></tr><tr><td>FK ROI < 30</td><td>0.06159</td></tr><tr><td>ROI</td><td>-0.10318</td></tr><tr><td>ROI < 30</td><td>0.06764</td></tr><tr><td>accuracy</td><td>0.2215</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>10.09142</td></tr><tr><td>correct</td><td>1772</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>10.09142</td></tr><tr><td>loss_val</td><td>1.99383</td></tr><tr><td>multibet outlay</td><td>265214.45594</td></tr><tr><td>multibet outlay < 30</td><td>116431.76176</td></tr><tr><td>multibet profit < 30</td><td>7875.62864</td></tr><tr><td>multibet profit < 30 sd</td><td>18.42223</td></tr><tr><td>multibet profit sd</td><td>51.75315</td></tr><tr><td>profit</td><td>6200.94501</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wandering-sweep-50</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/h38z2f86\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/h38z2f86</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_084142-h38z2f86\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mklgqya8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00034945768586949223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_103629-mklgqya8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/mklgqya8\" target=\"_blank\">absurd-sweep-51</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00034945768586949223, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00034945768586949223, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00034945768586949223\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:46<00:00,  2.79it/s]\n",
      "100%|██████████| 129/129 [01:15<00:00,  1.70it/s]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.73it/s]\n",
      "100%|██████████| 129/129 [01:37<00:00,  1.33it/s]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.95it/s]\n",
      "100%|██████████| 129/129 [01:48<00:00,  1.19it/s]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.95it/s]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.86it/s]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.89it/s]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.89it/s]\n",
      "100%|██████████| 129/129 [02:09<00:00,  1.01s/it]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  1.99it/s]]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.67it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.90it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.77it/s]]\n",
      "100%|██████████| 129/129 [01:33<00:00,  1.39it/s]]\n",
      "100%|██████████| 129/129 [01:34<00:00,  1.36it/s]]\n",
      "100%|██████████| 129/129 [01:01<00:00,  2.10it/s]]\n",
      "100%|██████████| 129/129 [01:38<00:00,  1.31it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.78it/s]]\n",
      "100%|██████████| 129/129 [02:05<00:00,  1.03it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.92it/s]]\n",
      "100%|██████████| 129/129 [02:06<00:00,  1.02it/s]it]\n",
      "100%|██████████| 129/129 [01:12<00:00,  1.78it/s]it]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.77it/s]it]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.89it/s]it]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.87it/s]it]\n",
      "100%|██████████| 129/129 [01:16<00:00,  1.69it/s]it]\n",
      "100%|██████████| 129/129 [01:08<00:00,  1.89it/s]it]\n",
      "100%|██████████| 129/129 [02:17<00:00,  1.07s/it]it]\n",
      "100%|██████████| 129/129 [01:06<00:00,  1.95it/s]it]\n",
      "100%|██████████| 129/129 [00:49<00:00,  2.62it/s]]  \n",
      "100%|██████████| 129/129 [01:08<00:00,  1.88it/s]]\n",
      "100%|██████████| 129/129 [01:18<00:00,  1.64it/s]]\n",
      "100%|██████████| 129/129 [01:15<00:00,  1.71it/s]]\n",
      "100%|██████████| 129/129 [01:20<00:00,  1.61it/s]]\n",
      "100%|██████████| 129/129 [00:50<00:00,  2.57it/s]]\n",
      "100%|██████████| 129/129 [02:10<00:00,  1.01s/it]]\n",
      "100%|██████████| 129/129 [01:04<00:00,  2.01it/s]]\n",
      "100%|██████████| 129/129 [01:07<00:00,  1.91it/s]]\n",
      "100%|██████████| 129/129 [02:04<00:00,  1.04it/s]]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.79it/s]]\n",
      "100%|██████████| 129/129 [01:16<00:00,  1.70it/s]]\n",
      "100%|██████████| 129/129 [01:02<00:00,  2.08it/s]]\n",
      "100%|██████████| 129/129 [01:14<00:00,  1.73it/s]]\n",
      "100%|██████████| 129/129 [01:10<00:00,  1.83it/s]]\n",
      "100%|██████████| 129/129 [00:57<00:00,  2.25it/s]]\n",
      "100%|██████████| 129/129 [02:55<00:00,  1.36s/it]]\n",
      "100%|██████████| 129/129 [01:21<00:00,  1.59it/s]]\n",
      "100%|██████████| 129/129 [02:19<00:00,  1.08s/it]]\n",
      "100%|██████████| 50/50 [2:26:34<00:00, 175.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70289feada584a6eb17d2ad52f527bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.806 MB of 180.806 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▅▅▅▆▆▅▆▆▆▇▇▇▇█▇█▇</td></tr><tr><td>FK ROI < 30</td><td>███▇▇▇▇▆▇▆▇▇▆▆▆▆▅▅▅▆▅▄▅▃▃▃▃▃▂▂▁▁▁▂▂▂▂▂▂▁</td></tr><tr><td>ROI</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▃▃▄▃▄▄▄▅▅▅▅▅▅▅▅▆▅▆▆▆▆▇▇▇█▇█▇</td></tr><tr><td>ROI < 30</td><td>███▇▇▇▇▆▆▆▇▇▆▅▆▅▄▅▅▆▅▄▅▄▃▃▃▃▂▂▂▁▁▂▃▂▂▂▃▁</td></tr><tr><td>accuracy</td><td>▁▁▂▂▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███▇█████▇█</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▆▇▇▇▇▇▆▆▆▆▆▅▅▄▅▅▅▄▄▃▃▃▄▃▃▃▃▃▂▂▂▂▁▁▁▂▂▁</td></tr><tr><td>correct</td><td>▁▁▂▂▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███▇█████▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▂▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▆</td></tr><tr><td>multibet outlay</td><td>▇███▇▇▆▆▅▅▄▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▆▅▆▅▅▅▆▆▅▆▇▇▇▇▇▇█▇█▇</td></tr><tr><td>multibet profit < 30</td><td>███▇▇▇▇▆▇▆▇▇▇▆▇▆▅▆▆▇▆▄▇▄▃▄▄▄▃▂▂▁▁▃▄▃▃▃▄▂</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>██▇█▆▅▅▅▄▃▃▃▂▂▂▂▃▂▂▂▂▂▂▂▁▁▂▂▁▃▃▄▃▄▃▃▄▃▄▂</td></tr><tr><td>profit</td><td>█▅▅▇▅▅▂▃▅▅▄▆▇▇▇▅▄▆▆▆▅▄▄▅▅▄▂▁▃▆█▅▄▆▄▅▆▅▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.04533</td></tr><tr><td>FK ROI < 30</td><td>0.00964</td></tr><tr><td>ROI</td><td>-0.05381</td></tr><tr><td>ROI < 30</td><td>0.01542</td></tr><tr><td>accuracy</td><td>0.25838</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>7.57771</td></tr><tr><td>correct</td><td>2067</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>7.57771</td></tr><tr><td>loss_val</td><td>2.00046</td></tr><tr><td>multibet outlay</td><td>254823.24559</td></tr><tr><td>multibet outlay < 30</td><td>170584.36018</td></tr><tr><td>multibet profit < 30</td><td>2631.13849</td></tr><tr><td>multibet profit < 30 sd</td><td>25.33101</td></tr><tr><td>multibet profit sd</td><td>44.70472</td></tr><tr><td>profit</td><td>5187.73291</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">absurd-sweep-51</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/mklgqya8\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/mklgqya8</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_103629-mklgqya8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fhza7vtt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003289376325516247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_130332-fhza7vtt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/fhza7vtt\" target=\"_blank\">desert-sweep-52</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003289376325516247, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0003289376325516247, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0003289376325516247\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:59<00:00,  2.17it/s]\n",
      "100%|██████████| 129/129 [01:50<00:00,  1.17it/s]\n",
      "100%|██████████| 129/129 [01:13<00:00,  1.76it/s]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.95it/s]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.21it/s]\n",
      "100%|██████████| 129/129 [01:03<00:00,  2.02it/s]\n",
      "100%|██████████| 129/129 [00:48<00:00,  2.67it/s]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.67it/s]\n",
      "100%|██████████| 129/129 [03:01<00:00,  1.40s/it]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.73it/s]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.97it/s]]\n",
      "100%|██████████| 129/129 [00:45<00:00,  2.81it/s]]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.44it/s]]\n",
      "100%|██████████| 129/129 [02:21<00:00,  1.09s/it]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.87it/s]]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.62it/s]]\n",
      "100%|██████████| 129/129 [01:43<00:00,  1.24it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.72it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.81it/s]]\n",
      "100%|██████████| 129/129 [02:26<00:00,  1.13s/it]]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.97it/s]it]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.77it/s]it]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.50it/s]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.88it/s]it]\n",
      "100%|██████████| 129/129 [02:51<00:00,  1.33s/it]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.80it/s]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.90it/s]it]\n",
      "100%|██████████| 129/129 [02:47<00:00,  1.30s/it]it]\n",
      "100%|██████████| 129/129 [00:46<00:00,  2.80it/s]it]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.74it/s]it]\n",
      "100%|██████████| 129/129 [04:03<00:00,  1.89s/it]]  \n",
      "100%|██████████| 129/129 [00:49<00:00,  2.59it/s]it]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.91it/s]it]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.69it/s]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.90it/s]]  \n",
      "100%|██████████| 129/129 [02:56<00:00,  1.37s/it]]\n",
      "100%|██████████| 129/129 [00:47<00:00,  2.71it/s]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.84it/s]]  \n",
      "100%|██████████| 129/129 [03:20<00:00,  1.55s/it]]\n",
      "100%|██████████| 129/129 [01:37<00:00,  1.33it/s]]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.84it/s]]\n",
      "100%|██████████| 129/129 [06:07<00:00,  2.85s/it]]\n",
      "100%|██████████| 129/129 [08:47<00:00,  4.09s/it]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.75it/s]]\n",
      "100%|██████████| 129/129 [05:01<00:00,  2.34s/it]]\n",
      "100%|██████████| 129/129 [05:16<00:00,  2.46s/it]]\n",
      "100%|██████████| 129/129 [01:27<00:00,  1.47it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.71it/s]]\n",
      "100%|██████████| 129/129 [08:19<00:00,  3.87s/it]]\n",
      "100%|██████████| 129/129 [05:19<00:00,  2.47s/it]]\n",
      "100%|██████████| 50/50 [3:17:52<00:00, 237.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56821369a4604e328ea35ce99d3b4d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.974 MB of 180.974 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▃▄▄▄▅▄▅▅▅▅▅▅▅▆▇▆▇▆▇▆▆▇▇▇█</td></tr><tr><td>FK ROI < 30</td><td>▄▇█▆▄▄▄▄▄▃▄▅▇▅▃▃▃▃▄▄▂▄▃▄▂▂▃▃▆▆▅▅▅▄▃▁▂▃▃▃</td></tr><tr><td>ROI</td><td>▁▂▂▂▂▃▃▃▃▃▃▃▄▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▇▆▆▆▇▆▆▇▇▇█</td></tr><tr><td>ROI < 30</td><td>▄▆█▇▄▅▄▄▅▄▄▅█▄▃▂▂▃▄▂▁▃▂▄▂▃▃▃▇▇▆▅▆▄▃▁▃▅▆▅</td></tr><tr><td>accuracy</td><td>▁▁▁▂▃▃▃▄▄▅▅▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇█▇████████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▄▇▇▇▇▇▆▆▆▆▆▆▆▃▅▅▅▅▅▂▄▄▅▄▅▄▄▄▃▃▄▃▁▃▃▃▃▂</td></tr><tr><td>correct</td><td>▁▁▁▂▃▃▃▄▄▅▅▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇█▇████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▇████▇▇▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▃▄▄▄▅▄▅▅▅▅▅▆▆▆▇▆▇▆▇▆▆▇▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▂▃▃▂▂▂▂▃▃▃▃▅▃▃▂▃▃▄▃▃▄▃▄▃▄▅▅▇▇▇▆▇▆▆▅▆███</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>multibet profit sd</td><td>▇██▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▂▁▂</td></tr><tr><td>profit</td><td>█▆▄▆▂▂▄▆▆▆▇▅▅▂▁▃▅▄▆▅▄▃▆▄▃▄▅▂▄▇▄▃▄▃▂▁▃▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.04057</td></tr><tr><td>FK ROI < 30</td><td>0.04958</td></tr><tr><td>ROI</td><td>-0.05269</td></tr><tr><td>ROI < 30</td><td>0.05731</td></tr><tr><td>accuracy</td><td>0.2605</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>14.99019</td></tr><tr><td>correct</td><td>2084</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>14.99019</td></tr><tr><td>loss_val</td><td>1.94805</td></tr><tr><td>multibet outlay</td><td>246989.54003</td></tr><tr><td>multibet outlay < 30</td><td>153762.10183</td></tr><tr><td>multibet profit < 30</td><td>8812.30649</td></tr><tr><td>multibet profit < 30 sd</td><td>23.55518</td></tr><tr><td>multibet profit sd</td><td>42.94039</td></tr><tr><td>profit</td><td>5495.33257</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">desert-sweep-52</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/fhza7vtt\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/fhza7vtt</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_130332-fhza7vtt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bz96w7dj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004319295228570668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_162333-bz96w7dj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/bz96w7dj\" target=\"_blank\">colorful-sweep-53</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004319295228570668, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0004319295228570668, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0004319295228570668\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:23<00:00,  1.36it/s]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.48it/s]t]\n",
      "100%|██████████| 32/32 [06:46<00:00, 12.69s/it]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.48it/s]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.50it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]t]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.31it/s]t]\n",
      "100%|██████████| 32/32 [03:22<00:00,  6.34s/it]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.51it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]t]\n",
      "100%|██████████| 32/32 [00:37<00:00,  1.16s/it]it]\n",
      "100%|██████████| 32/32 [00:34<00:00,  1.07s/it]it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.36it/s]s/it]\n",
      "100%|██████████| 32/32 [07:54<00:00, 14.83s/it]s/it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.46it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]s/it]\n",
      "100%|██████████| 32/32 [00:35<00:00,  1.10s/it]s/it]\n",
      "100%|██████████| 32/32 [02:47<00:00,  5.22s/it]s/it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.46it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]s/it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.48it/s]s/it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.10it/s]s/it]\n",
      "100%|██████████| 32/32 [02:36<00:00,  4.90s/it]s/it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.39it/s]s/it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.47it/s]s/it]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.28it/s]s/it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.38it/s]s/it]\n",
      "100%|██████████| 32/32 [03:04<00:00,  5.76s/it]s/it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.48it/s]s/it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.46it/s]s/it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.49it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]it]  \n",
      "100%|██████████| 32/32 [00:25<00:00,  1.26it/s]it]\n",
      "100%|██████████| 32/32 [02:43<00:00,  5.11s/it]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.50it/s]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.50it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]it]\n",
      "100%|██████████| 32/32 [02:33<00:00,  4.79s/it]it]\n",
      "100%|██████████| 32/32 [03:29<00:00,  6.54s/it]it]\n",
      "100%|██████████| 32/32 [00:35<00:00,  1.11s/it]it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.07it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]it]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.12it/s]it]\n",
      "100%|██████████| 32/32 [02:44<00:00,  5.14s/it]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.35it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.40it/s]it]\n",
      "100%|██████████| 50/50 [3:32:16<00:00, 254.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1056498de6c4c06a16ce3d0ab6b0f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.970 MB of 180.970 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▅▆▆▇▇▆▇▇▇▇▇██</td></tr><tr><td>FK ROI < 30</td><td>▁▂▃▂▂▂▃▃▂▂▃▂▄▃▄▆▅▆▇▅▅▄▄▄▅▄▅▄▄▃▆▅▄▆▆▅▆▅██</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>ROI < 30</td><td>▁▂▂▂▃▂▃▃▂▂▂▁▂▂▃▄▃▄▅▃▃▃▃▃▄▄▄▄▃▃▆▅▄▅▆▆▆▅▇█</td></tr><tr><td>accuracy</td><td>▁▁▂▂▃▃▃▄▄▄▅▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▃▅▇▃▄▇▇▄▇▇▇▇▆▆▆▆▂▆▆▂▃▆▂▃▆▅▆▆▅▅▅▅▅▅▅▁▅</td></tr><tr><td>correct</td><td>▁▁▂▂▃▃▃▄▄▄▅▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂</td></tr><tr><td>multibet outlay</td><td>▆▇███▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▁▁▁▁▁▂▂▃▃▃▃▃▄▄▄▄▄▅▄▅▅▅▅▅▅▆▅▆▆▇▇▆▇▇▇▇▇▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▂▂▂▂▂▂▃▂▂▂▂▂▂▃▄▃▄▄▃▃▃▃▄▄▄▄▄▄▄▆▅▅▆▆▆▆▆▇█</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>multibet profit sd</td><td>▇███▇▇▇▇▆▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▂▂▂▁▂▂</td></tr><tr><td>profit</td><td>▆▅█▄▄▆█▇▆▅▆▄▃▃▁▂▃▂▂▃▂▂▁▂▂▂▄▃▃▃▄▃▃▅▅▄▅▅▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.0491</td></tr><tr><td>FK ROI < 30</td><td>0.05882</td></tr><tr><td>ROI</td><td>-0.05926</td></tr><tr><td>ROI < 30</td><td>0.07365</td></tr><tr><td>accuracy</td><td>0.25388</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>5.33653</td></tr><tr><td>correct</td><td>2031</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>5.33653</td></tr><tr><td>loss_val</td><td>1.94618</td></tr><tr><td>multibet outlay</td><td>247206.6105</td></tr><tr><td>multibet outlay < 30</td><td>149079.51812</td></tr><tr><td>multibet profit < 30</td><td>10979.9722</td></tr><tr><td>multibet profit < 30 sd</td><td>23.99557</td></tr><tr><td>multibet profit sd</td><td>42.94924</td></tr><tr><td>profit</td><td>5615.56058</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">colorful-sweep-53</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/bz96w7dj\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/bz96w7dj</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_162333-bz96w7dj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a84wgsnq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005708782786467419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_195619-a84wgsnq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/a84wgsnq\" target=\"_blank\">unique-sweep-54</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005708782786467419, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 10, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0005708782786467419, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0005708782786467419\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.26it/s]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.41it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.71it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.73it/s]\n",
      "100%|██████████| 129/129 [02:50<00:00,  1.32s/it]\n",
      "100%|██████████| 129/129 [03:07<00:00,  1.45s/it]\n",
      "100%|██████████| 129/129 [02:59<00:00,  1.39s/it]\n",
      "100%|██████████| 129/129 [04:00<00:00,  1.86s/it]\n",
      "100%|██████████| 129/129 [03:06<00:00,  1.45s/it]\n",
      "100%|██████████| 129/129 [03:00<00:00,  1.40s/it]]\n",
      "100%|██████████| 129/129 [03:55<00:00,  1.83s/it]]\n",
      "100%|██████████| 129/129 [04:48<00:00,  2.24s/it]]\n",
      "100%|██████████| 129/129 [04:10<00:00,  1.94s/it]]\n",
      "100%|██████████| 129/129 [02:31<00:00,  1.18s/it]it]\n",
      "100%|██████████| 129/129 [03:44<00:00,  1.74s/it]it]\n",
      "100%|██████████| 129/129 [02:05<00:00,  1.03it/s]it]\n",
      "100%|██████████| 129/129 [02:42<00:00,  1.26s/it]it]\n",
      "100%|██████████| 129/129 [03:02<00:00,  1.42s/it]it]\n",
      "100%|██████████| 129/129 [03:09<00:00,  1.47s/it]it]\n",
      "100%|██████████| 129/129 [03:26<00:00,  1.60s/it]it]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.71it/s]it]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.63it/s]it]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.55it/s]it]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.93it/s]it]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.71it/s]it]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.71it/s]it]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.31it/s]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]it]\n",
      "100%|██████████| 129/129 [00:37<00:00,  3.41it/s]it]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.21it/s]it]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.16it/s]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.84it/s]it]\n",
      "100%|██████████| 129/129 [03:16<00:00,  1.53s/it]]  \n",
      "100%|██████████| 129/129 [04:08<00:00,  1.93s/it]]\n",
      "100%|██████████| 129/129 [03:18<00:00,  1.54s/it]]\n",
      "100%|██████████| 129/129 [05:56<00:00,  2.76s/it]]\n",
      "100%|██████████| 129/129 [04:03<00:00,  1.89s/it]it]\n",
      "100%|██████████| 129/129 [02:09<00:00,  1.01s/it]it]\n",
      "100%|██████████| 129/129 [03:29<00:00,  1.62s/it]]  \n",
      "100%|██████████| 129/129 [05:29<00:00,  2.56s/it]]\n",
      "100%|██████████| 129/129 [04:19<00:00,  2.01s/it]]\n",
      "100%|██████████| 129/129 [02:31<00:00,  1.18s/it]]\n",
      "100%|██████████| 129/129 [02:48<00:00,  1.30s/it]]\n",
      "100%|██████████| 129/129 [06:01<00:00,  2.80s/it]]\n",
      "100%|██████████| 129/129 [03:34<00:00,  1.67s/it]]\n",
      "100%|██████████| 129/129 [04:35<00:00,  2.14s/it]]\n",
      "100%|██████████| 129/129 [08:10<00:00,  3.80s/it]]\n",
      "100%|██████████| 129/129 [02:26<00:00,  1.14s/it]]\n",
      "100%|██████████| 129/129 [03:34<00:00,  1.67s/it]]\n",
      "100%|██████████| 50/50 [3:54:37<00:00, 281.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5225fa14adca479d836d1dd937ab842e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.507 MB of 180.507 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▄▃▃▄▃▄▄▄▄▅▅▄▆▆▆▅▆▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>FK ROI < 30</td><td>▇▇█▇▇▇▆▇▆▅▅▅▅▃▄▄▃▃▄▄▃▄▃▂▂▃▄▁▃▂▂▂▁▃▃▃▃▃▅▄</td></tr><tr><td>ROI</td><td>▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▃▄▄▄▄▅▅▄▆▆▆▅▅▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>ROI < 30</td><td>▆▇█▇▇▇▆▇▆▅▅▆▅▃▄▄▂▃▄▄▂▄▃▂▂▄▄▁▃▂▂▂▁▃▃▃▄▃▅▄</td></tr><tr><td>accuracy</td><td>▁▂▁▂▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇▇▆▇▇▇▇▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▅▇▇▇▇▇▆▆▆▅▅▅▅▃▅▅▅▄▄▂▄▄▄▃▃▃▃▃▃▃▂▂▁▂▂▂▂▂</td></tr><tr><td>correct</td><td>▁▂▁▂▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇▇▆▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>loss_val</td><td>▇▆▅▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▆▆▆▇▇▇█</td></tr><tr><td>multibet outlay</td><td>▆▇▇▇▆▆▅▄▃▃▃▂▂▂▁▁▁▁▁▁▂▁▂▂▂▂▃▃▄▄▄▅▅▆▅▆▇▇▇█</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▂▂▂▃▃▃▃▃▃▄▃▄▄▄▄▄▅▄▅▅▄▆▆▆▆▆▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>multibet profit < 30</td><td>▄▅▆▆▆▆▅▅▅▄▄▅▄▃▄▃▂▂▄▄▂▄▃▂▂▄▄▁▃▃▂▃▁▄▅▄▅▅█▇</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>multibet profit sd</td><td>▇█▇▇▆▆▆▅▅▄▄▃▃▂▃▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▃▃▃▂▂▂▃▃</td></tr><tr><td>profit</td><td>█▇▆▅▄▅▄▅▆▄▃▃▃▁▃▁▁▂▂▂▂▂▂▂▃▃▂▂▅▃▃▃▃▄▄▅▆▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.02412</td></tr><tr><td>FK ROI < 30</td><td>0.033</td></tr><tr><td>ROI</td><td>-0.03085</td></tr><tr><td>ROI < 30</td><td>0.04277</td></tr><tr><td>accuracy</td><td>0.2515</td></tr><tr><td>batch_before_backwards</td><td>10</td></tr><tr><td>batch_loss</td><td>12.59196</td></tr><tr><td>correct</td><td>2012</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>12.59196</td></tr><tr><td>loss_val</td><td>2.05091</td></tr><tr><td>multibet outlay</td><td>268879.03658</td></tr><tr><td>multibet outlay < 30</td><td>188339.12571</td></tr><tr><td>multibet profit < 30</td><td>8055.32304</td></tr><tr><td>multibet profit < 30 sd</td><td>29.22135</td></tr><tr><td>multibet profit sd</td><td>45.85081</td></tr><tr><td>profit</td><td>5610.89864</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">unique-sweep-54</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/a84wgsnq\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/a84wgsnq</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_195619-a84wgsnq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5j0luacj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009114180231264782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230312_235132-5j0luacj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/5j0luacj\" target=\"_blank\">sweepy-sweep-55</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009114180231264782, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0009114180231264782, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0009114180231264782\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [07:13<00:00,  1.34s/it]\n",
      "100%|██████████| 324/324 [03:42<00:00,  1.46it/s]\n",
      "100%|██████████| 324/324 [04:27<00:00,  1.21it/s]\n",
      "100%|██████████| 324/324 [06:34<00:00,  1.22s/it]\n",
      "100%|██████████| 324/324 [03:10<00:00,  1.70it/s]\n",
      "100%|██████████| 324/324 [05:18<00:00,  1.02it/s]\n",
      "100%|██████████| 324/324 [07:27<00:00,  1.38s/it]\n",
      "100%|██████████| 324/324 [06:20<00:00,  1.17s/it]t]\n",
      "100%|██████████| 324/324 [07:18<00:00,  1.35s/it]t]\n",
      "100%|██████████| 324/324 [10:27<00:00,  1.94s/it]t]\n",
      "100%|██████████| 324/324 [08:27<00:00,  1.57s/it]it]\n",
      "100%|██████████| 324/324 [09:20<00:00,  1.73s/it]it]\n",
      "100%|██████████| 324/324 [04:30<00:00,  1.20it/s]it]\n",
      "100%|██████████| 324/324 [05:57<00:00,  1.10s/it]it]\n",
      "100%|██████████| 324/324 [05:45<00:00,  1.07s/it]it]\n",
      "100%|██████████| 324/324 [04:23<00:00,  1.23it/s]it]\n",
      "100%|██████████| 324/324 [04:45<00:00,  1.14it/s]it]\n",
      "100%|██████████| 324/324 [04:37<00:00,  1.17it/s]it]\n",
      "100%|██████████| 324/324 [07:20<00:00,  1.36s/it]it]\n",
      "100%|██████████| 324/324 [09:13<00:00,  1.71s/it]it]\n",
      "100%|██████████| 324/324 [06:51<00:00,  1.27s/it]it]\n",
      "100%|██████████| 324/324 [11:26<00:00,  2.12s/it]it]\n",
      "100%|██████████| 324/324 [04:53<00:00,  1.10it/s]it]\n",
      "100%|██████████| 324/324 [03:34<00:00,  1.51it/s]it]\n",
      "100%|██████████| 324/324 [04:25<00:00,  1.22it/s]it]\n",
      "100%|██████████| 324/324 [06:29<00:00,  1.20s/it]it]\n",
      "100%|██████████| 324/324 [02:07<00:00,  2.54it/s]it]\n",
      "100%|██████████| 324/324 [05:31<00:00,  1.02s/it]it]\n",
      "100%|██████████| 324/324 [04:42<00:00,  1.15it/s]it]\n",
      "100%|██████████| 324/324 [05:57<00:00,  1.10s/it]it]\n",
      "100%|██████████| 324/324 [11:33<00:00,  2.14s/it]it]\n",
      "100%|██████████| 324/324 [08:29<00:00,  1.57s/it]it]\n",
      "100%|██████████| 324/324 [08:45<00:00,  1.62s/it]it]\n",
      "100%|██████████| 324/324 [07:41<00:00,  1.42s/it]it]\n",
      "100%|██████████| 324/324 [04:54<00:00,  1.10it/s]it]\n",
      "100%|██████████| 324/324 [04:19<00:00,  1.25it/s]it]\n",
      "100%|██████████| 324/324 [04:57<00:00,  1.09it/s]it]\n",
      "100%|██████████| 324/324 [01:50<00:00,  2.94it/s]it]\n",
      "100%|██████████| 324/324 [05:31<00:00,  1.02s/it]it]\n",
      "100%|██████████| 324/324 [02:41<00:00,  2.01it/s]it]\n",
      "100%|██████████| 324/324 [05:48<00:00,  1.07s/it]it]\n",
      "100%|██████████| 324/324 [04:44<00:00,  1.14it/s]it]\n",
      "100%|██████████| 324/324 [04:00<00:00,  1.35it/s]it]\n",
      "100%|██████████| 324/324 [06:39<00:00,  1.23s/it]it]\n",
      "100%|██████████| 324/324 [03:24<00:00,  1.59it/s]]  \n",
      "100%|██████████| 324/324 [08:01<00:00,  1.49s/it]]\n",
      "100%|██████████| 324/324 [09:35<00:00,  1.78s/it]]\n",
      "100%|██████████| 324/324 [14:49<00:00,  2.75s/it]]\n",
      "100%|██████████| 324/324 [10:35<00:00,  1.96s/it]]\n",
      "100%|██████████| 324/324 [12:23<00:00,  2.29s/it]]\n",
      "100%|██████████| 50/50 [8:27:59<00:00, 609.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdfaf07f3ca4d6ab08239caf65e7909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='178.967 MB of 178.967 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▂▃▃▄▄▄▅▄▅▆▆▅▇▇▆▇▇▇▇█▇▆▆██▆▇█</td></tr><tr><td>FK ROI < 30</td><td>▄▅▅▅▅▂▄▄▄▃▄▃▁▂▂▂▃▃▄▃▅▄▆▄▆▆▄▇▆█▆▇▆▅▆▆█▄▄▆</td></tr><tr><td>ROI</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▅▄▅▅▆▅▇▆▅▇▇▇▇█▇▆▆██▆▇█</td></tr><tr><td>ROI < 30</td><td>▄▄▅▄▅▂▄▄▄▃▄▃▁▂▂▃▃▃▄▃▅▄▅▄▆▇▄▆▆█▆▇▆▅▆▆█▄▄▆</td></tr><tr><td>accuracy</td><td>▁▂▃▃▅▆▆▇▇██████▇██▇▇▇██▆▇▇▇▇██▇▇▆▇▇▇▇▇▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▃▄▃▃▃▂▃▂▂▂▃▂▂▂▁▁▂▂▂▁▁▁</td></tr><tr><td>correct</td><td>▁▂▃▃▅▆▆▇▇██████▇██▇▇▇██▆▇▇▇▇██▇▇▆▇▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet outlay</td><td>▂▂▂▂▂▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇████</td></tr><tr><td>multibet profit</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▂▃▃▃▄▄▅▄▅▅▆▅▆▆▅▇▇▇▇▇▆▆▆██▆▇█</td></tr><tr><td>multibet profit < 30</td><td>▂▂▂▂▂▁▂▂▂▂▃▂▁▁▂▂▃▃▄▃▅▄▅▄▆▆▄▆▆█▆▇▆▅▆▆█▄▄▇</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇█▇████</td></tr><tr><td>multibet profit sd</td><td>▄▄▃▃▂▂▂▁▁▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▄▅▆▆▆▆▆▇▆██▇▇█</td></tr><tr><td>profit</td><td>▆▄▅▄▁▂▁▄▁▄▄▃▂▅▃▄▄▆▅▃▄▅▆▄▆▇▇▆█▇▇▇▅▆▆█▆▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>0.02831</td></tr><tr><td>FK ROI < 30</td><td>0.06029</td></tr><tr><td>ROI</td><td>0.02772</td></tr><tr><td>ROI < 30</td><td>0.07057</td></tr><tr><td>accuracy</td><td>0.2425</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>5.83727</td></tr><tr><td>correct</td><td>1940</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>5.83727</td></tr><tr><td>loss_val</td><td>2.37826</td></tr><tr><td>multibet outlay</td><td>316994.98664</td></tr><tr><td>multibet outlay < 30</td><td>233322.25444</td></tr><tr><td>multibet profit < 30</td><td>16464.50275</td></tr><tr><td>multibet profit < 30 sd</td><td>38.43834</td></tr><tr><td>multibet profit sd</td><td>60.29953</td></tr><tr><td>profit</td><td>6272.04086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sweepy-sweep-55</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/5j0luacj\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/5j0luacj</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_235132-5j0luacj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4agidoqz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007762725411903438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230313_082005-4agidoqz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/4agidoqz\" target=\"_blank\">solar-sweep-56</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007762725411903438, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.0007762725411903438, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0007762725411903438\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:22<00:00,  2.80it/s]\n",
      "100%|██████████| 64/64 [03:45<00:00,  3.53s/it]t]\n",
      "100%|██████████| 64/64 [00:21<00:00,  2.93it/s]t]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.01it/s]t]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.57it/s]t]\n",
      "100%|██████████| 64/64 [00:21<00:00,  2.93it/s]t]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.88it/s]t]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.60it/s]t]\n",
      "100%|██████████| 64/64 [00:20<00:00,  3.14it/s]t]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.74it/s]t]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.77it/s]it]\n",
      "100%|██████████| 64/64 [00:21<00:00,  3.04it/s]it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.90it/s]s/it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.63it/s]s/it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.88it/s]s/it]\n",
      "100%|██████████| 64/64 [00:21<00:00,  2.97it/s]s/it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.79it/s]s/it]\n",
      "100%|██████████| 64/64 [05:46<00:00,  5.41s/it]s/it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.90it/s]s/it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.89it/s]s/it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.72it/s]s/it]\n",
      "100%|██████████| 64/64 [00:21<00:00,  2.98it/s]s/it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.76it/s]s/it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.75it/s]s/it]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.90it/s]s/it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.87it/s]s/it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.67it/s]s/it]\n",
      "100%|██████████| 64/64 [06:22<00:00,  5.98s/it]s/it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.76it/s]s/it]\n",
      "100%|██████████| 64/64 [00:40<00:00,  1.59it/s]s/it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.99it/s]s/it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.68it/s]s/it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.23it/s]s/it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.72it/s]s/it]\n",
      "100%|██████████| 64/64 [00:23<00:00,  2.75it/s]s/it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.87it/s]s/it]\n",
      "100%|██████████| 64/64 [00:21<00:00,  2.94it/s]s/it]\n",
      "100%|██████████| 64/64 [00:21<00:00,  2.92it/s]s/it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.86it/s]s/it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.82it/s]s/it]\n",
      "100%|██████████| 64/64 [07:21<00:00,  6.90s/it]it]  \n",
      "100%|██████████| 64/64 [00:21<00:00,  2.93it/s]it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.89it/s]it]\n",
      "100%|██████████| 64/64 [00:22<00:00,  2.88it/s]it]\n",
      "100%|██████████| 64/64 [00:21<00:00,  3.01it/s]it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.71it/s]it]\n",
      "100%|██████████| 64/64 [00:20<00:00,  3.11it/s]it]\n",
      "100%|██████████| 64/64 [00:21<00:00,  3.01it/s]it]\n",
      "100%|██████████| 64/64 [00:24<00:00,  2.63it/s]it]\n",
      "100%|██████████| 64/64 [00:21<00:00,  2.91it/s]it]\n",
      "100%|██████████| 50/50 [4:09:11<00:00, 299.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f5e6f4290346e3af1a0defae908858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.884 MB of 180.884 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▂▂▂▃▃▃▃▄▃▄▄▄▅▄▄▅▅▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇█▇█</td></tr><tr><td>FK ROI < 30</td><td>▁▃▅▄▄▅▅▅▅▅▅▇▇▄█▄▄▇▅▆▇▄▆▆▅▆▅▅▃▇▂▆▅▄▆▄▃▇▃▅</td></tr><tr><td>ROI</td><td>▁▂▂▂▂▃▃▃▃▄▃▄▄▄▄▄▄▅▄▅▅▅▅▅▅▆▅▆▇▆▆▆▇▇▇▇▇█▇█</td></tr><tr><td>ROI < 30</td><td>▁▃▄▄▅▅▆▅▅▆▅▇▇▄█▄▅▆▅▆▇▄▆▆▅▆▅▆▃▇▃▆▅▄▇▅▄▇▃▆</td></tr><tr><td>accuracy</td><td>▁▃▄▄▄▅▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇█▇█████▇████████▇██</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▇▂▂▇▇▂▁▇▇▁▁▇▁▁▇▇▁▁▆▆▁▁▆▆▁▆▆▁▁▆▆▁▁▆▆▁▁▅▁</td></tr><tr><td>correct</td><td>▁▃▄▄▄▅▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇█▇█████▇████████▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▂▂▂▂▂</td></tr><tr><td>multibet outlay</td><td>▃▆▇█████▇▇▆▆▅▅▅▄▃▃▃▃▃▂▂▂▁▂▁▂▂▁▁▁▂▁▂▁▂▃▂▂</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█▇██</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▄▅▅▅▅▅▅▆▅▆▇▆▆▆▇▇█▇▇█▇█</td></tr><tr><td>multibet profit < 30</td><td>▁▂▄▃▄▄▅▄▄▅▄▆▆▄▇▄▅▆▅▆▇▅▆▆▆▆▆▆▅▇▄▇▆▆▇▆▆█▆█</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▃▃▃▃▃▄▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>multibet profit sd</td><td>▇███▇█▇█▇▇▆▆▅▅▄▄▃▄▃▄▃▂▂▂▃▂▂▂▄▁▂▂▃▂▃▂▂▃▂▂</td></tr><tr><td>profit</td><td>█▄▅▅▄▇▄▆▃▂▆▁▃▄█▃▁▅▂▅▅▃▂▄▄▄▄▅▂▃▂▆▄▁▄▁▃▁▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.03318</td></tr><tr><td>FK ROI < 30</td><td>0.0679</td></tr><tr><td>ROI</td><td>-0.04596</td></tr><tr><td>ROI < 30</td><td>0.07686</td></tr><tr><td>accuracy</td><td>0.25338</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>7.85075</td></tr><tr><td>correct</td><td>2027</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>7.85075</td></tr><tr><td>loss_val</td><td>1.95983</td></tr><tr><td>multibet outlay</td><td>251222.89111</td></tr><tr><td>multibet outlay < 30</td><td>153339.31488</td></tr><tr><td>multibet profit < 30</td><td>11785.59626</td></tr><tr><td>multibet profit < 30 sd</td><td>24.74129</td></tr><tr><td>multibet profit sd</td><td>43.28007</td></tr><tr><td>profit</td><td>5941.22375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">solar-sweep-56</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/4agidoqz\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/4agidoqz</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230313_082005-4agidoqz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e0nuw3f5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000654563052810772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230313_122948-e0nuw3f5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/e0nuw3f5\" target=\"_blank\">legendary-sweep-57</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000654563052810772, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 1000, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000654563052810772, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.000654563052810772\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:36<00:00, 10.51s/it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.53it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]t]\n",
      "100%|██████████| 32/32 [05:27<00:00, 10.24s/it]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.50it/s]t]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.47it/s]t]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]t]\n",
      "100%|██████████| 32/32 [03:43<00:00,  6.99s/it]t]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.36it/s]it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.36it/s]it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.33it/s]s/it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.37it/s]s/it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.27it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]s/it]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.31it/s]s/it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.09it/s]s/it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.08it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.42it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]s/it]\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.55it/s]s/it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.24it/s]s/it]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.14it/s]s/it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.46it/s]s/it]\n",
      "100%|██████████| 32/32 [05:16<00:00,  9.88s/it]s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]s/it]\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.09it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.40it/s]s/it]\n",
      "100%|██████████| 32/32 [08:00<00:00, 15.01s/it]s/it]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.17it/s]s/it]\n",
      "100%|██████████| 32/32 [00:30<00:00,  1.05it/s]s/it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.20it/s]s/it]\n",
      "100%|██████████| 32/32 [06:41<00:00, 12.55s/it]s/it]\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.18it/s]s/it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]s/it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.26it/s]s/it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.39it/s]s/it]\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.38it/s]it]  \n",
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]it]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.28it/s]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.48it/s]it]\n",
      "100%|██████████| 32/32 [07:20<00:00, 13.77s/it]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.49it/s]it]\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.10it/s]it]\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.40it/s]it]\n",
      "100%|██████████| 32/32 [04:54<00:00,  9.21s/it]it]\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.51it/s]it]\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]it]\n",
      "100%|██████████| 50/50 [4:41:36<00:00, 337.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea83f50c13749109fd2cfffe98a65d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.863 MB of 180.863 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▄▃▄▄▄▅▅▅▅▅▅▅▆▆▆▇▆▆▇▆█▆██▇▇▇</td></tr><tr><td>FK ROI < 30</td><td>▇█▇█▇▇▇█▇▆▇▅▆▅▄▄▄▄▄▅▄▅▄▄▂▄▃▄▄▄▄▃▁▅▂▂▄▁▃▂</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▄▃▄▄▄▄▅▅▅▅▅▅▆▆▆▇▆▆▇▆█▆██▇▇▇</td></tr><tr><td>ROI < 30</td><td>▇█▇█▇▇███▆▇▆▆▅▅▅▄▃▄▅▄▄▄▄▂▄▃▄▅▃▃▃▁▅▂▂▄▁▃▃</td></tr><tr><td>accuracy</td><td>▁▁▁▁▂▂▃▄▅▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███▇███▇█▇▇▇▇</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▃▅▇▃▄▇▇▄▇▇▇▇▆▆▆▆▂▆▆▂▃▆▂▃▅▅▅▅▅▅▅▅▅▅▄▁▄</td></tr><tr><td>correct</td><td>▁▁▁▁▂▂▃▄▅▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███▇███▇█▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▁▂▂▁▁▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▃▃▃▃▄</td></tr><tr><td>multibet outlay</td><td>▅▇████▇▇▆▆▅▅▄▄▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▂▁▂▂▂▂▃▃▃▄</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▆▆▇▆█▆██▇▇▇</td></tr><tr><td>multibet profit < 30</td><td>▆▇▇█▇▇███▆▇▆▆▅▄▅▄▃▄▅▅▅▄▄▂▅▄▅▆▄▄▄▁█▂▃▆▁▄▄</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▃▄▄▄▅▄▅▅▅▅▆▆▆▆▇▇▇▇▇█▇██</td></tr><tr><td>multibet profit sd</td><td>▆▇██████▇▆▇▆▅▅▄▄▄▃▃▅▄▂▃▂▂▃▂▂▃▁▃▂▁▂▁▄▄▂▂▂</td></tr><tr><td>profit</td><td>▆▇▅▅█▃▇▆▄▁▃▃▄▅▄▃▅▅▄▆▅▆▇█▇▅▇▇▇▆▅▆█▇▅▇▇▄▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.03736</td></tr><tr><td>FK ROI < 30</td><td>0.01967</td></tr><tr><td>ROI</td><td>-0.04244</td></tr><tr><td>ROI < 30</td><td>0.02982</td></tr><tr><td>accuracy</td><td>0.25012</td></tr><tr><td>batch_before_backwards</td><td>5</td></tr><tr><td>batch_loss</td><td>5.1001</td></tr><tr><td>correct</td><td>2001</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>5.1001</td></tr><tr><td>loss_val</td><td>1.98555</td></tr><tr><td>multibet outlay</td><td>255558.41036</td></tr><tr><td>multibet outlay < 30</td><td>161497.14045</td></tr><tr><td>multibet profit < 30</td><td>4816.43085</td></tr><tr><td>multibet profit < 30 sd</td><td>25.04849</td></tr><tr><td>multibet profit sd</td><td>44.47091</td></tr><tr><td>profit</td><td>5714.52512</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">legendary-sweep-57</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/e0nuw3f5\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/e0nuw3f5</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230313_122948-e0nuw3f5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ey0j5vq6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00029608773596650107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230313_171152-ey0j5vq6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/ey0j5vq6\" target=\"_blank\">avid-sweep-58</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00029608773596650107, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 100, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00029608773596650107, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00029608773596650107\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:50<00:00,  6.47it/s]\n",
      "100%|██████████| 324/324 [00:48<00:00,  6.63it/s]\n",
      "100%|██████████| 324/324 [00:47<00:00,  6.76it/s]\n",
      "100%|██████████| 324/324 [00:48<00:00,  6.70it/s]\n",
      "100%|██████████| 324/324 [00:49<00:00,  6.52it/s]\n",
      "100%|██████████| 324/324 [00:47<00:00,  6.77it/s]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.02it/s]\n",
      "100%|██████████| 324/324 [00:50<00:00,  6.47it/s]\n",
      "100%|██████████| 324/324 [05:05<00:00,  1.06it/s]\n",
      "100%|██████████| 324/324 [05:11<00:00,  1.04it/s]t]\n",
      "100%|██████████| 324/324 [09:05<00:00,  1.68s/it]it]\n",
      "100%|██████████| 324/324 [04:24<00:00,  1.23it/s]it]\n",
      "100%|██████████| 324/324 [05:29<00:00,  1.02s/it]it]\n",
      "100%|██████████| 324/324 [05:01<00:00,  1.08it/s]it]\n",
      "100%|██████████| 324/324 [07:02<00:00,  1.31s/it]it]\n",
      "100%|██████████| 324/324 [05:35<00:00,  1.04s/it]it]\n",
      "100%|██████████| 324/324 [06:02<00:00,  1.12s/it]it]\n",
      "100%|██████████| 324/324 [05:49<00:00,  1.08s/it]it]\n",
      "100%|██████████| 324/324 [07:30<00:00,  1.39s/it]it]\n",
      "100%|██████████| 324/324 [00:49<00:00,  6.60it/s]it]\n",
      "100%|██████████| 324/324 [00:49<00:00,  6.52it/s]it]\n",
      "100%|██████████| 324/324 [00:50<00:00,  6.41it/s]it]\n",
      "100%|██████████| 324/324 [00:48<00:00,  6.64it/s]it]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.72it/s]it]\n",
      "100%|██████████| 324/324 [06:01<00:00,  1.11s/it]it]\n",
      "100%|██████████| 324/324 [01:10<00:00,  4.57it/s]it]\n",
      "100%|██████████| 324/324 [00:51<00:00,  6.33it/s]it]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.76it/s]it]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.72it/s]it]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.06it/s]it]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.76it/s]it]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.02it/s]it]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.86it/s]it]\n",
      "100%|██████████| 324/324 [06:38<00:00,  1.23s/it]it]\n",
      "100%|██████████| 324/324 [00:58<00:00,  5.58it/s]it]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.99it/s]it]\n",
      "100%|██████████| 324/324 [06:44<00:00,  1.25s/it]it]\n",
      "100%|██████████| 324/324 [00:56<00:00,  5.78it/s]it]\n",
      "100%|██████████| 324/324 [00:55<00:00,  5.84it/s]it]\n",
      "100%|██████████| 324/324 [07:11<00:00,  1.33s/it]it]\n",
      "100%|██████████| 324/324 [00:53<00:00,  6.05it/s]it]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.67it/s]it]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.17it/s]it]\n",
      "100%|██████████| 324/324 [06:52<00:00,  1.27s/it]]  \n",
      "100%|██████████| 324/324 [00:55<00:00,  5.84it/s]]\n",
      "100%|██████████| 324/324 [00:54<00:00,  5.95it/s]]\n",
      "100%|██████████| 324/324 [06:32<00:00,  1.21s/it]]\n",
      "100%|██████████| 324/324 [00:57<00:00,  5.68it/s]]\n",
      "100%|██████████| 324/324 [00:52<00:00,  6.17it/s]]\n",
      "100%|██████████| 324/324 [06:42<00:00,  1.24s/it]]\n",
      "100%|██████████| 50/50 [6:40:30<00:00, 480.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d4cc4601a7448c820919f72d755d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='180.933 MB of 180.933 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▇▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>FK ROI < 30</td><td>▅▇▇▇▆█▇▇▇▇▅▅▅▅▅▄▃▃▅▃▄▄▅▆▆▅▄▄▅▃▃▅▃▁▁▁▂▂▁▁</td></tr><tr><td>ROI</td><td>▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▆▇▇▆▇▇▇███</td></tr><tr><td>ROI < 30</td><td>▄▇▇█▇███▇▇▆▆▆▆▅▄▄▄▅▄▆▅▆▇▇▅▄▄▆▄▅▅▃▂▂▂▃▄▂▁</td></tr><tr><td>accuracy</td><td>▁▁▂▂▃▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>██████▁█▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▁▆▆▆▇▆▆▆▆▆▆▆▅▆▆</td></tr><tr><td>correct</td><td>▁▁▂▂▃▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▅▅▄▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃</td></tr><tr><td>multibet outlay</td><td>▆████▇▇▆▅▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃</td></tr><tr><td>multibet outlay < 30</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>multibet profit</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>multibet profit < 30</td><td>▁▃▄▄▄▅▅▅▅▅▄▄▅▅▄▄▄▄▅▄▆▆▆██▇▆▆█▇▇█▆▅▅▆▇█▆▅</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>████▇▇▇▇▆▆▆▅▄▄▄▄▃▃▃▃▃▂▂▂▃▂▂▂▁▂▁▂▂▁▂▁▁▂▂▁</td></tr><tr><td>profit</td><td>█▇▅██▇▇▆▆▄▄▄▃▄▄▃▃▄▂▂▃▂▄▃▃▃▁▂▄▄▄▄▃▃▅▃▄▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.05203</td></tr><tr><td>FK ROI < 30</td><td>0.0417</td></tr><tr><td>ROI</td><td>-0.0629</td></tr><tr><td>ROI < 30</td><td>0.05269</td></tr><tr><td>accuracy</td><td>0.25438</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>7.79666</td></tr><tr><td>correct</td><td>2035</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>7.79666</td></tr><tr><td>loss_val</td><td>1.97093</td></tr><tr><td>multibet outlay</td><td>252461.31165</td></tr><tr><td>multibet outlay < 30</td><td>159584.49698</td></tr><tr><td>multibet profit < 30</td><td>8407.75586</td></tr><tr><td>multibet profit < 30 sd</td><td>25.13852</td></tr><tr><td>multibet profit sd</td><td>41.31801</td></tr><tr><td>profit</td><td>5428.82097</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">avid-sweep-58</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/ey0j5vq6\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/ey0j5vq6</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230313_171152-ey0j5vq6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 43f0mbf5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 250\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00029645602916952287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230313_235254-43f0mbf5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/43f0mbf5\" target=\"_blank\">comfy-sweep-59</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00029645602916952287, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 20, 'batch_size': 250, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.00029645602916952287, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.00029645602916952287\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:37<00:00,  3.48it/s]\n",
      "100%|██████████| 129/129 [05:40<00:00,  2.64s/it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.86it/s]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.54it/s]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.52it/s]\n",
      "100%|██████████| 129/129 [10:59<00:00,  5.11s/it]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.13it/s]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.93it/s]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.96it/s]t]\n",
      "100%|██████████| 129/129 [13:15<00:00,  6.17s/it]t]\n",
      "100%|██████████| 129/129 [00:30<00:00,  4.27it/s]it]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.51it/s]it]\n",
      "100%|██████████| 129/129 [00:44<00:00,  2.90it/s]it]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.04it/s]it]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.04it/s]it]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.64it/s]it]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.60it/s]it]\n",
      "100%|██████████| 129/129 [06:29<00:00,  3.02s/it]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.86it/s]it]\n",
      "100%|██████████| 129/129 [00:38<00:00,  3.34it/s]it]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.62it/s]it]\n",
      "100%|██████████| 129/129 [08:41<00:00,  4.04s/it]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.83it/s]it]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.77it/s]it]\n",
      "100%|██████████| 129/129 [00:42<00:00,  3.06it/s]it]\n",
      "100%|██████████| 129/129 [07:42<00:00,  3.59s/it]it]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.12it/s]it]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.51it/s]it]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.63it/s]it]\n",
      "100%|██████████| 129/129 [08:10<00:00,  3.81s/it]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.89it/s]it]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.21it/s]it]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.70it/s]it]\n",
      "100%|██████████| 129/129 [08:07<00:00,  3.78s/it]it]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.16it/s]it]\n",
      "100%|██████████| 129/129 [00:41<00:00,  3.09it/s]it]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.60it/s]it]\n",
      "100%|██████████| 129/129 [08:41<00:00,  4.05s/it]it]\n",
      "100%|██████████| 129/129 [00:32<00:00,  3.91it/s]it]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.73it/s]it]\n",
      "100%|██████████| 129/129 [00:33<00:00,  3.90it/s]it]\n",
      "100%|██████████| 129/129 [08:11<00:00,  3.81s/it]it]\n",
      "100%|██████████| 129/129 [00:39<00:00,  3.25it/s]it]\n",
      "100%|██████████| 129/129 [00:43<00:00,  2.95it/s]it]\n",
      "100%|██████████| 129/129 [00:35<00:00,  3.68it/s]]  \n",
      "100%|██████████| 129/129 [00:34<00:00,  3.72it/s]]\n",
      "100%|██████████| 129/129 [00:36<00:00,  3.50it/s]]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.71it/s]]\n",
      "100%|██████████| 129/129 [00:40<00:00,  3.22it/s]]\n",
      "100%|██████████| 129/129 [00:31<00:00,  4.03it/s]]\n",
      "100%|██████████| 50/50 [6:31:41<00:00, 470.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1457fc29054d4c24bdf13bd9f8ec9ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='181.067 MB of 181.067 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>▁▂▃▃▄▄▅▅▆▆▆▇▆▆▇▇▆▆▆▇▇▆▇▇▇██████▇▇▇▇▇▇▇██</td></tr><tr><td>FK ROI < 30</td><td>▆▆▇▇█▇███▇▇▇▇▇▇▇▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▂</td></tr><tr><td>ROI</td><td>▁▂▃▄▅▅▅▅▆▆▆▇▆▆▇▇▆▆▆▇▇▆▆▆▇▇█▇▇▇▇▇▇▇▆▆▆▇▇▇</td></tr><tr><td>ROI < 30</td><td>▅▅▆▇█▇███▇▇▇▇▇▇▇▆▅▅▅▅▄▄▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▇▇▇▇████▇████████</td></tr><tr><td>batch_before_backwards</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>███▂▇▇▂▆▇▇▆▇▇▇▇▇▇▇▇▁▇▇▁▆▇▁▆▆▆▆▆▆▆▆▆▆▆▆▁▆</td></tr><tr><td>correct</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▇▇▇▇████▇████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▁</td></tr><tr><td>loss_val</td><td>█▇▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay</td><td>▆▇█████▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>multibet outlay < 30</td><td>▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit</td><td>▁▂▂▃▃▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▆▆▇▇▇███▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>multibet profit < 30</td><td>▁▃▄▅▇▇███▇▇▇▇▇▇█▆▅▅▅▅▄▄▃▄▃▄▂▃▃▃▃▂▃▂▂▂▂▂▂</td></tr><tr><td>multibet profit < 30 sd</td><td>▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>multibet profit sd</td><td>▇███▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>profit</td><td>▅▄▅▅█▆▆▇█▇▆▆▄▅▅▂▄▃▄▃▄▂▁▂▃▃▄▄▄▃▄▂▄▃▃▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FK ROI</td><td>-0.07975</td></tr><tr><td>FK ROI < 30</td><td>0.0495</td></tr><tr><td>ROI</td><td>-0.09494</td></tr><tr><td>ROI < 30</td><td>0.05853</td></tr><tr><td>accuracy</td><td>0.25388</td></tr><tr><td>batch_before_backwards</td><td>20</td></tr><tr><td>batch_loss</td><td>15.71526</td></tr><tr><td>correct</td><td>2031</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_loss</td><td>15.71526</td></tr><tr><td>loss_val</td><td>1.93273</td></tr><tr><td>multibet outlay</td><td>245722.14453</td></tr><tr><td>multibet outlay < 30</td><td>140680.05843</td></tr><tr><td>multibet profit < 30</td><td>8234.35347</td></tr><tr><td>multibet profit < 30 sd</td><td>22.2847</td></tr><tr><td>multibet profit sd</td><td>38.6486</td></tr><tr><td>profit</td><td>5559.27247</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">comfy-sweep-59</strong>: <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/43f0mbf5\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/runs/43f0mbf5</a><br/>Synced 5 W&B file(s), 75 media file(s), 75 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230313_235254-43f0mbf5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bkajow1z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_before_backwards: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000439383053806039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlen_data: 40482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: CEL\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamW\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230314_062503-bkajow1z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU_sweeps/runs/bkajow1z\" target=\"_blank\">hardy-sweep-60</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU_sweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf\" target=\"_blank\">https://wandb.ai/nickojelly/GRU_sweeps/sweeps/vjcqqbaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_before_backwards': 5, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000439383053806039, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "50\n",
      "{'batch_before_backwards': 5, 'batch_size': 500, 'dropout': 0.3, 'epochs': 50, 'f1_layer_size': 256, 'f2_layer_size': 64, 'hidden_size': 64, 'l1_beta': 0.1, 'learning_rate': 0.000439383053806039, 'len_data': 40482, 'loss': 'CEL', 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "CrossEntropyLoss() RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.000439383053806039\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "smalll_prelin_GRUNet(\n",
      "  (batchnorm): BatchNorm1d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gru1): GRUCell(510, 64)\n",
      "  (gru2): GRUCell(510, 64)\n",
      "  (gru3): GRUCell(510, 64)\n",
      "  (gru4): GRUCell(510, 64)\n",
      "  (gru5): GRUCell(510, 64)\n",
      "  (gru6): GRUCell(510, 64)\n",
      "  (gru7): GRUCell(510, 64)\n",
      "  (gru8): GRUCell(510, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [07:33<00:00,  7.09s/it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.71it/s]t]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.89it/s]t]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.92it/s]t]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.72it/s]t]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.73it/s]t]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.84it/s]t]\n",
      "100%|██████████| 64/64 [10:22<00:00,  9.73s/it]/it]\n",
      "100%|██████████| 64/64 [10:04<00:00,  9.45s/it]/it]\n",
      "100%|██████████| 64/64 [09:12<00:00,  8.64s/it]/it]\n",
      "100%|██████████| 64/64 [00:32<00:00,  1.95it/s]s/it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.84it/s]s/it]\n",
      "100%|██████████| 64/64 [00:33<00:00,  1.91it/s]s/it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.87it/s]s/it]\n",
      "100%|██████████| 64/64 [00:34<00:00,  1.85it/s]s/it]\n",
      "100%|██████████| 64/64 [00:38<00:00,  1.64it/s]s/it]\n",
      "100%|██████████| 64/64 [13:50<00:00, 12.97s/it]s/it]\n",
      "100%|██████████| 64/64 [09:15<00:00,  8.68s/it]s/it]\n",
      "100%|██████████| 64/64 [09:43<00:00,  9.11s/it]s/it]\n",
      "100%|██████████| 64/64 [10:33<00:00,  9.90s/it]s/it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.73it/s]s/it]\n",
      "100%|██████████| 64/64 [00:37<00:00,  1.70it/s]s/it]\n",
      "100%|██████████| 64/64 [00:31<00:00,  2.02it/s]s/it]\n",
      "100%|██████████| 64/64 [00:35<00:00,  1.78it/s]s/it]\n",
      "100%|██████████| 64/64 [00:36<00:00,  1.78it/s]s/it]\n",
      " 50%|█████     | 25/50 [4:26:29<4:55:05, 708.21s/it]"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"GRU_sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a48ca33c5a1168302a4f8eae355aad1c03b1396f568d40bc174a6e6aabe725d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
