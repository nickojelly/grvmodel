{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "with torch.profiler.profile() as profiler:\n",
    "        pass\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogInput:\n",
    "    def __init__(self, dogid, raceid,stats, dog,dog_box, hidden_state, bfsp, sp) -> None:\n",
    "        self.dogid= dogid\n",
    "        self.raceid = raceid\n",
    "        self.stats = stats.to('cuda:0')\n",
    "        self.dog = dog\n",
    "        self.gru_cell = hidden_state.float().to('cuda:0')\n",
    "        self.visited = 0\n",
    "        self.bfsp = bfsp\n",
    "        self.gru_cell_out = None\n",
    "\n",
    "        \n",
    "        \n",
    "    def lstm_i(self, hidden_state):\n",
    "        self.gru_cell = hidden_state\n",
    "        # self.lstmCellh=self.lstmCellh.to(device)\n",
    "        # self.lstmCellc=self.lstmCellc.to(device)\n",
    "        self.visited = self.visited + 1\n",
    "        # if self.visited>1:\n",
    "        #     print(\"FOUND LEAK\")\n",
    "        #     sasdfasd\n",
    "\n",
    "    def nextrace(self, raceid):\n",
    "        self.nextrace_id = raceid\n",
    "\n",
    "    def prevrace(self, raceid):\n",
    "        self.prevrace_id = raceid\n",
    "\n",
    "    def lstm_o(self, lstm_o):\n",
    "        # print(lstm_o[0]._version)\n",
    "        hidden_state = lstm_o\n",
    "        self.gru_cell_out = lstm_o\n",
    "        if self.nextrace_id==-1:\n",
    "            pass\n",
    "        else:\n",
    "            self.dog.races[self.nextrace_id].lstm_i(hidden_state) #((lh.detach(), lc.detach())) #DETACH\n",
    "\n",
    "    def detach_state(self):\n",
    "        self.gru_cell = self.gru_cell.detach()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    def __init__(self, dogid,dog_name, hidden_size, layers) -> None:\n",
    "        self.dogid = dogid\n",
    "        self.dog_name = dog_name\n",
    "        # self.raceids = raceids #possible dictionary of race id keys dog stat outs\n",
    "        self.lstmcell = 0\n",
    "        self.layers = layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l_debug = None\n",
    "        self.races = {}\n",
    "\n",
    "    def add_races(self, raceid, racedate, stats,nextraceid, prevraceid, box, bfsp=None, sp=None):\n",
    "        self.races[raceid] = DogInput(self.dogid, raceid, stats, self, box, torch.randn(self.hidden_size), bfsp, sp) #this is the change\n",
    "        self.races[raceid].nextrace(nextraceid)\n",
    "        self.races[raceid].prevrace(prevraceid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Race:\n",
    "    def __init__(self, raceid,trackOHE, dist, classes=None):\n",
    "        self.raceid = raceid\n",
    "        self.race_dist = dist.to('cuda:0')\n",
    "        self.race_track = trackOHE.to('cuda:0')\n",
    "        self.track_name = None\n",
    "        if classes!=None:\n",
    "            self.classes =  classes.to('cuda:0')\n",
    "\n",
    "    def add_dogs(self, dogs_list:DogInput):\n",
    "        self.dog1 = dogs_list[0]\n",
    "        self.dog2 = dogs_list[1]\n",
    "        self.dog3 = dogs_list[2]\n",
    "        self.dog4 = dogs_list[3]\n",
    "        self.dog5 = dogs_list[4]\n",
    "        self.dog6 = dogs_list[5]\n",
    "        self.dog7 = dogs_list[6]\n",
    "        self.dog8 = dogs_list[7]\n",
    "        self.dogs = dogs_list\n",
    "\n",
    "    def add_track_name(self, track_name):\n",
    "        self.track_name = track_name\n",
    "\n",
    "\n",
    "    def nn_input(self):\n",
    "        input = torch.cat([x.stats for x in self.dogs], dim = 0)\n",
    "        full_input = torch.cat((self.race_dist,self.race_track, input), dim=0).to(device='cuda:0')\n",
    "        self.full_input = full_input\n",
    "        return full_input\n",
    "\n",
    "    def lstm_input(self, pred=False):\n",
    "        if pred:\n",
    "            print('pred')\n",
    "        else:\n",
    "            l_input = [x.gru_cell for x in self.dogs]\n",
    "        return l_input\n",
    "\n",
    "    def lstm_detach(self):\n",
    "        [x.detach_state for x in self.dogs]\n",
    "\n",
    "    def list_dogs(self):\n",
    "        dogs_l = [x for x in self.dogs]\n",
    "        return dogs_l\n",
    "\n",
    "    def pass_gru_output(self, hidden_states):\n",
    "        for i,dog in enumerate(self.dogs):\n",
    "            hs = hidden_states[i]\n",
    "            #hs = hs.detach()\n",
    "            dog.lstm_o(hs) #.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Races:\n",
    "    def __init__(self, hidden_size, layers, batch_size = 100) -> None:\n",
    "        self.racesDict = {}\n",
    "        self.dogsDict = {}\n",
    "        self.raceIDs = []\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.getter = operator.itemgetter(*range(batch_size))\n",
    "\n",
    "    def add_race(self,raceid:str, trackOHE, dist, classes=None):\n",
    "        self.racesDict[raceid] = Race(raceid, trackOHE, dist, classes)\n",
    "        self.raceIDs.append(raceid)\n",
    "\n",
    "    def add_dog(self,dogid, dog_name):\n",
    "        if dogid not in self.dogsDict.keys():\n",
    "            self.dogsDict[dogid] = Dog(dogid,dog_name, self.hidden_size, self.layers)\n",
    "        # else:\n",
    "        #     self.dogsDict[dogid] = self.dogsDict[dogid]\n",
    "\n",
    "    def get_race_input(self, idx) -> Race:\n",
    "        if len(idx)==1:\n",
    "            race = self.racesDict[self.raceIDs[idx]]\n",
    "            print(f\"returing race {race}\")\n",
    "            return race\n",
    "        else:\n",
    "            raceidx = operator.itemgetter(*idx)\n",
    "            race_batch_id = raceidx(self.raceIDs)\n",
    "            races = [self.racesDict[x] for x in race_batch_id] #Returns list of class Race\n",
    "        \n",
    "        return races #self.racesDict[raceidx]\n",
    "\n",
    "    def get_race_classes(self, idx):\n",
    "        raceidx = self.raceIDs[idx]\n",
    "        classes = [x for x in self.raceDict[raceidx].classes]\n",
    "        return classes\n",
    "\n",
    "    def reset_all_lstm_states(self):\n",
    "        for race in self.racesDict.values:\n",
    "            for dog in race.dogs:\n",
    "                dog.lstmCellc = torch.rand(self.hidden_size)\n",
    "                dog.lstmCellh = torch.rand(self.hidden_size)\n",
    "                dog.gru_cell = torch.rand(self.hidden_size)\n",
    "\n",
    "    def detach_all_hidden_states(self):\n",
    "        for race in self.racesDict.values():\n",
    "            for dog in race.dogs:\n",
    "                dog.gru_cell = dog.gru_cell.detach()\n",
    "\n",
    "    def create_hidden_states_dict(self):\n",
    "        self.hidden_states_dict = {}\n",
    "        for race in self.racesDict.values():\n",
    "            race_id = race.raceid\n",
    "            for dog in race.dogs:\n",
    "                dog_id = dog.dogid\n",
    "                key = race_id+'_'+dog_id\n",
    "                val = dog.gru_cell_out\n",
    "                self.hidden_states_dict[key] = val\n",
    "\n",
    "    def fill_hidden_states_from_dict(self, hidden_dict):\n",
    "        for race in self.racesDict.values():\n",
    "            race_id = race.raceid\n",
    "            for dog in race.dogs:\n",
    "                dog_id = dog.dogid\n",
    "                dog_prev_race_id = dog.prevrace_id\n",
    "                key = str(dog_prev_race_id)+'_'+dog_id\n",
    "                try:\n",
    "                    val = hidden_dict[key]\n",
    "                    if val != None:\n",
    "                        dog.gru_cell = val\n",
    "                    else:\n",
    "                        dog.gru_cell = torch.rand(self.hidden_size)\n",
    "                except KeyError as e:\n",
    "                    print(f'Key error {e}')\n",
    "                    val = torch.rand(self.hidden_size)\n",
    "                    dog.gru_cell = val\n",
    "                    print(f\"race in = {dog.gru_cell}\")\n",
    "                print(key,val)\n",
    "\n",
    "    def to_cuda(self):\n",
    "        for race in self.racesDict.values():\n",
    "            race_id = race.raceid\n",
    "            for dog in race.dogs:\n",
    "                dog.gru_cell = dog.gru_cell.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.3):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.gru1 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru2 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru3 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru4 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru5 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru6 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru7 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.gru8 = nn.GRUCell(input_size, hidden_size)\n",
    "        self.rl1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size * 8, 64)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.rl2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 8)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, race: Race):\n",
    "        x = torch.stack([r.full_input.float() for r in race]).detach()\n",
    "\n",
    "        # creates list of LSTM data\n",
    "        hidden_state_in = [list(i) for i in zip(*[r.lstm_input() for r in race])]\n",
    "\n",
    "        # creates list of tensors for lstm Cells\n",
    "        hCell = [torch.stack([x for x in y]) for y in hidden_state_in]\n",
    "        # print(f\"{hCell=}\")\n",
    "        # for h in hCell:\n",
    "        #     print(h._version)\n",
    "        #     if h.grad_fn != None:\n",
    "        #         print(h.grad_fn._saved_self)\n",
    "        #         print(h.grad_fn._saved_other)\n",
    "        # for h in hCell:\n",
    "        #     print(h)\n",
    "\n",
    "        h1 = self.gru1(x, hCell[0])\n",
    "        h2 = self.gru2(x, hCell[1])\n",
    "        h3 = self.gru3(x, hCell[2])\n",
    "        h4 = self.gru4(x, hCell[3])\n",
    "        h5 = self.gru5(x, hCell[4])\n",
    "        h6 = self.gru6(x, hCell[5])\n",
    "        h7 = self.gru7(x, hCell[6])\n",
    "        h8 = self.gru8(x, hCell[7])\n",
    "\n",
    "        lstm_list = [\n",
    "            h1,\n",
    "            h2,\n",
    "            h3,\n",
    "            h4,\n",
    "            h5,\n",
    "            h6,\n",
    "            h7,\n",
    "            h8,\n",
    "        ]\n",
    "\n",
    "        hCello = [i for i in zip(*[x for x in lstm_list])]\n",
    "        # cCello = [i for i in zip(*[x[1] for x in lstm_list])]\n",
    "\n",
    "        for i, r in enumerate(race):\n",
    "            r.pass_gru_output(hCello[i])\n",
    "            # r.lstm_detach()\n",
    "        xhh = torch.cat((h1, h2, h3, h4, h5, h6, h7, h8), dim=1)\n",
    "        xr1 = self.rl1(xhh)\n",
    "        xd1 = self.drop1(xr1)\n",
    "        xh = self.fc2(xd1)\n",
    "        xd2 = self.drop2(xh)\n",
    "        xr2 = self.rl2(xd2)\n",
    "        xf = self.fc3(xr2)\n",
    "\n",
    "        output = F.softmax(xf, dim=1)\n",
    "        #output = nn.LogSoftmax(xf)\n",
    "        #output = xf\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pred_dataset(data, hidden_size):\n",
    "\n",
    "    #Load in pickeled dataframe\n",
    "    resultsdf = pickle.load(data)\n",
    "    dog_stats_df = pd.DataFrame(resultsdf)\n",
    "    dog_stats_df = dog_stats_df.fillna(-1).drop_duplicates(subset=['dogid', 'raceid'])\n",
    "    dog_stats_df['stats_cuda'] = dog_stats_df.apply(lambda x: torch.tensor(x['stats']), axis =1)\n",
    "    dog_stats_df['box'] = dog_stats_df['stats'].apply(lambda x: x[0])\n",
    "\n",
    "    #Created RaceDB\n",
    "    raceDB = Races(hidden_size, 1)\n",
    "\n",
    "    #Fill in dog portion:\n",
    "\n",
    "    dog_stats_group = dog_stats_df.sort_values(['date']).groupby([\"dogid\"])\n",
    "\n",
    "    for i,j in tqdm(dog_stats_group):\n",
    "        raceDB.add_dog(i, j.dog_name.iloc[0])\n",
    "        j.apply(lambda x: raceDB.dogsDict[i].add_races(x['raceid'], x['date'], torch.Tensor(x['stats']),-1, x['prev_race'], x['box']), axis=1)\n",
    "\n",
    "    #Fill in races portion\n",
    "    softmin = nn.Softmin(dim=0)\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "\n",
    "    null_dog = Dog(\"nullDog\", \"no_name\", raceDB.hidden_size, raceDB.layers)\n",
    "    null_dog_i = DogInput(\"nullDog\", \"-1\", torch.zeros(16), null_dog,0, torch.zeros(raceDB.hidden_size),0,0)\n",
    "    null_dog_i.nextrace(-1)\n",
    "    null_dog_i.prevrace(-1)\n",
    "\n",
    "    null_dog_list = [null_dog] * 8\n",
    "    #TO FIX LATER PROPER BOX PLACEMENT #FIXED\n",
    "\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "    for i,j in tqdm(races_group):\n",
    "    #Track info tensors\n",
    "        dist = torch.tensor([j.dist.iloc[0]]) \n",
    "        trackOHE = torch.tensor(j.trackOHE.iloc[0])\n",
    "\n",
    "        empty_dog_list = [null_dog_i]*8\n",
    "        boxes_list = [x for x in j['box']]      \n",
    "        dog_list = [raceDB.dogsDict[x].races[i] for x in j[\"dogid\"]]\n",
    "\n",
    "        for n,x in enumerate(boxes_list):\n",
    "            empty_dog_list[x-1] = dog_list[n]\n",
    "        \n",
    "        raceDB.add_race(i,trackOHE,dist)\n",
    "        \n",
    "        # List of Dog Input??\n",
    "        raceDB.racesDict[i].add_dogs(empty_dog_list)\n",
    "        raceDB.racesDict[i].nn_input()\n",
    "        raceDB.racesDict[i].add_track_name(j.track_name.iloc[0])\n",
    "        raceDB.racesDict[i].track_name = j.track_name.iloc[0]\n",
    "        raceDB.racesDict[i].grade = j.race_grade.iloc[0]\n",
    "\n",
    "    print(f\"number of races = {len(raceDB.racesDict)}, number of unique dogs = {len(raceDB.dogsDict)}\")\n",
    "    return raceDB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data, hidden_size):\n",
    "\n",
    "    #Load in pickeled dataframe\n",
    "    resultsdf = pickle.load(data)\n",
    "    dog_stats_df = pd.DataFrame(resultsdf)\n",
    "    dog_stats_df = dog_stats_df.fillna(-1).drop_duplicates(subset=['dogid', 'raceid'])\n",
    "    dog_stats_df['stats_cuda'] = dog_stats_df.apply(lambda x: torch.tensor(x['stats']), axis =1)\n",
    "    dog_stats_df['box'] = dog_stats_df['stats'].apply(lambda x: x[0])\n",
    "\n",
    "    #Created RaceDB\n",
    "    raceDB = Races(hidden_size, 1)\n",
    "\n",
    "    num_features_per_dog = len(dog_stats_df['stats'][0])\n",
    "    print(f\"{num_features_per_dog=}\")\n",
    "\n",
    "    #Fill in dog portion:\n",
    "\n",
    "    dog_stats_group = dog_stats_df.sort_values(['date']).groupby([\"dogid\"])\n",
    "\n",
    "    for i,j in tqdm(dog_stats_group):\n",
    "        j[\"next_race\"] = j[\"raceid\"].shift(-1).fillna(-1)\n",
    "        j[\"prev_race\"] = j[\"raceid\"].shift(1).fillna(-1)\n",
    "        raceDB.add_dog(i, j.dog_name.iloc[0])\n",
    "        j.apply(lambda x: raceDB.dogsDict[i].add_races(x['raceid'], x['date'], torch.Tensor(x['stats']),x['next_race'], x['prev_race'], x['box'], x['bfSP'], x['startprice']), axis=1)\n",
    "\n",
    "    #Fill in races portion\n",
    "    softmin = nn.Softmin(dim=0)\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "\n",
    "    null_dog = Dog(\"nullDog\", \"no_name\", raceDB.hidden_size, raceDB.layers)\n",
    "    null_dog_i = DogInput(\"nullDog\", \"-1\", torch.zeros(num_features_per_dog), null_dog,0, torch.zeros(raceDB.hidden_size),0,0)\n",
    "    null_dog_i.nextrace(-1)\n",
    "    null_dog_i.prevrace(-1)\n",
    "\n",
    "    null_dog_list = [null_dog] * 8\n",
    "    #TO FIX LATER PROPER BOX PLACEMENT #FIXED\n",
    "    dog_stats_df = dog_stats_df.sort_values('date')\n",
    "    races_group = dog_stats_df.groupby(['raceid'])\n",
    "    for i,j in tqdm(races_group):\n",
    "    #Track info tensors\n",
    "        dist = torch.tensor([j.dist.iloc[0]]) \n",
    "        trackOHE = torch.tensor(j.trackOHE.iloc[0])\n",
    "        #margins\n",
    "        empty_dog_list = [null_dog_i]*8\n",
    "        empty_margin_list = [20]*8\n",
    "        empty_place_list = [8]*8\n",
    "\n",
    "        places_list = [x for x in j[\"place\"]]\n",
    "        boxes_list = [x for x in j['box']]\n",
    "        margin_list = [x for x in j[\"margin\"]]\n",
    "        \n",
    "        dog_list = [raceDB.dogsDict[x].races[i] for x in j[\"dogid\"]]\n",
    "\n",
    "        #adjustedMargin = [margin_list[x-1] for x in boxes_list]\n",
    "        for n,x in enumerate(boxes_list):\n",
    "            empty_margin_list[x-1] = margin_list[n]\n",
    "            empty_dog_list[x-1] = dog_list[n]\n",
    "            empty_place_list[x-1] = places_list[n]\n",
    "        # adjustedMargin = softmin(torch.tensor(empty_margin_list)).to('cuda:0')\n",
    "        adjustedMargin = softmin(torch.tensor(empty_place_list)).to('cuda:0')\n",
    "        #adjusted_dog_list = [dog_list[x-1] for x in boxes_list]\n",
    "        \n",
    "        raceDB.add_race(i,trackOHE,dist, adjustedMargin)\n",
    "        \n",
    "        \n",
    "        # List of Dog Input??\n",
    "        raceDB.racesDict[i].add_dogs(empty_dog_list)\n",
    "        raceDB.racesDict[i].nn_input()\n",
    "        raceDB.racesDict[i].track_name = j.track_name.iloc[0]\n",
    "        raceDB.racesDict[i].grade = j.race_grade.iloc[0]\n",
    "\n",
    "    print(f\"number of races = {len(raceDB.racesDict)}, number of unique dogs = {len(raceDB.dogsDict)}\")\n",
    "    return raceDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_saver(model, optimizer, epoch, loss, hidden_state_dict):\n",
    "    \n",
    "    pathtofolder = \"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model\"\n",
    "    model_name = wandb.run.name\n",
    "    isExist = os.path.exists(\n",
    "        f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "    )\n",
    "    if isExist:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"db\":hidden_state_dict,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )\n",
    "    else:\n",
    "        print(\"created path\")\n",
    "        os.makedirs(\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "        )\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"db\":hidden_state_dict,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def validate_model(model,raceDB,criterion, batch_size, example_ct, epoch_loss, batch_ct):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    preds = []\n",
    "    grades = []\n",
    "    tracks = []\n",
    "    pred_confs = []\n",
    "    bfsps = []\n",
    "    start_prices = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(20_000,30_000,batch_size):   \n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "            race = raceDB.get_race_input(races_idx)\n",
    "            #tracks.extend([r.track for r in race])\n",
    "            X = race\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            output = model(X)\n",
    "            #print(y)\n",
    "\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            conf, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "            \n",
    "            total += batch_size\n",
    "            actuals.extend(actual.tolist())\n",
    "            preds.extend(predicted.tolist())\n",
    "            pred_confs.extend(conf.tolist())\n",
    "            tracks.extend([r.track_name for r in race])\n",
    "            grades.extend([r.grade for r in race])\n",
    "            for i,dog_idx in enumerate(actual.tolist()):\n",
    "                bfsps.append(race[i].dogs[dog_idx].bfsp)\n",
    "                #start_prices.append(race[i].dogs[dog_idx].sp)\n",
    "\n",
    "            \n",
    "            loss = criterion(output, y)\n",
    "            loss_val += loss\n",
    "\n",
    "    logdf = pd.DataFrame(data = {\"actuals\":actuals, \"preds\":preds,\"conf\":pred_confs, \"grade\":grades, \"track\":tracks, \"bfsps\":bfsps})#, \"sp\":start_prices })\n",
    "\n",
    "    table = wandb.Table(dataframe=logdf)\n",
    "    try:\n",
    "        wandb.log({\"table_key\": table})\n",
    "    except Exception as e:\n",
    "        print(\"e\")\n",
    "    print(f\"accuray: {correct/total}\")\n",
    "    wandb.log({\"accuracy\": correct/total, \"loss_val\": loss_val/(50_000/batch_size), \"correct\": correct,\"epoch_loss\": epoch_loss/batch_ct})\n",
    "\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, raceDB:Races, criterion, optimizer,scheduler, config=None):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    last = 0\n",
    "    batch_size = 100\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    m = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    # target_dog_id = '145856635'\n",
    "    # target_dog = raceDB.dogsDict[target_dog_id]\n",
    "    # race_ids = target_dog.races.keys()\n",
    "    losses = []\n",
    "    for epoch in trange(2_000):\n",
    "        model.train()\n",
    "        epoch_loss = torch.Tensor(0).to(device).requires_grad_(True)\n",
    "        batch_ct = 0\n",
    "\n",
    "        setup_loss = 1\n",
    "        \n",
    "        for i in range(0,70_000,batch_size):\n",
    "            if 20_000-1<i<30_000+1:\n",
    "                continue\n",
    "            batch_ct += 1\n",
    "            \n",
    "            races_idx = [i,i]\n",
    "            last = i\n",
    "\n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "            race = raceDB.get_race_input(races_idx)\n",
    "            #race = [raceDB.racesDict[r],raceDB.racesDict[r]]\n",
    "            X = race\n",
    "            # print(f\"race id = {X[0].raceid}\")\n",
    "\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            output = model(X)\n",
    "\n",
    "            \n",
    "            #print(output,y)\n",
    "            example_ct +=  batch_size\n",
    "\n",
    "            loss = criterion(output, y)# *weights\n",
    "            if setup_loss:\n",
    "                epoch_loss = loss\n",
    "                setup_loss=0\n",
    "            #oss = criterion(m(output), torch.flatten(actual))\n",
    "            \n",
    "            #loss.backward(retain_graph=True)  \n",
    "            #loss.backward()\n",
    "            #optimizer.step()\n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                    \n",
    "                    train_log(loss, example_ct, epoch)\n",
    "\n",
    "            epoch_loss = epoch_loss + loss\n",
    "            #output = model(X)\n",
    "\n",
    "            if ((batch_ct + 1) % 10) == 0:\n",
    "                optimizer.zero_grad()\n",
    "                epoch_loss.backward()\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "                print(epoch_loss)\n",
    "                losses.append(epoch_loss)\n",
    "                raceDB.detach_all_hidden_states()\n",
    "                setup_loss = 1\n",
    "                wandb.log({\"loss\": epoch_loss}, step = example_ct)\n",
    "\n",
    "\n",
    "\n",
    "            #[r.lstm_detach for r in race]\n",
    "        wandb.log({\"epoch_loss\": epoch_loss/batch_ct}, step = example_ct)\n",
    "        #print(f'{epoch_loss/batch_ct=}')\n",
    "        # optimizer.zero_grad()\n",
    "        # epoch_loss.backward()\n",
    "        # optimizer.step()\n",
    "        # model.zero_grad()\n",
    "        # print(epoch_loss)\n",
    "        # losses.append(epoch_loss)\n",
    "        # raceDB.detach_all_hidden_states()\n",
    "        # #print(loss)\n",
    "        acc = validate_model(model,raceDB,criterion, 8, example_ct, epoch_loss, batch_ct)\n",
    "        print(acc)\n",
    "        scheduler.step(acc)\n",
    "    print(losses)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38030/38030 [05:13<00:00, 121.45it/s]\n",
      "100%|██████████| 142750/142750 [02:19<00:00, 1025.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 142750, number of unique dogs = 38030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( 'dog_stats_df_FASTTRACK.npy', 'rb')\n",
    "hidden_size = 32\n",
    "raceDB = build_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:00<00:00, 1013.04it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 1712.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 48, number of unique dogs = 363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( r'C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\forms\\prediction_inputs_gru.npy', 'rb')\n",
    "hidden_size = 32\n",
    "predDB = build_pred_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raceDB.create_hidden_states_dict()\n",
    "# predDB.fill_hidden_states_from_dict(hidden_dict=dataset.hidden_states_dict)\n",
    "# len(raceDB.hidden_states_dict)\n",
    "# predDB.to_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def predict_model(model,predDB):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        races_idx = range(0,len(predDB.raceIDs)-1)\n",
    "        race = predDB.get_race_input(races_idx)\n",
    "        X = race\n",
    "        # for i,r in enumerate(race):\n",
    "        #     print(r.raceid, r.track_name)\n",
    "        #     #print(i,r.lstm_input())\n",
    "\n",
    "        output = model(X)\n",
    "        \n",
    "        print(output)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            print(r.raceid, r.track_name, r.dogs[predicted[i].item()])\n",
    "\n",
    "        print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Race at 0x2690f002520>,\n",
       " <__main__.Race at 0x2690f002730>,\n",
       " <__main__.Race at 0x2690f002220>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predDB.get_race_input([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_model(model,predDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dogid</th>\n",
       "      <th>dog_name</th>\n",
       "      <th>raceid</th>\n",
       "      <th>race_grade</th>\n",
       "      <th>date</th>\n",
       "      <th>trackOHE</th>\n",
       "      <th>track_name</th>\n",
       "      <th>dist</th>\n",
       "      <th>stats</th>\n",
       "      <th>place</th>\n",
       "      <th>startprice</th>\n",
       "      <th>margin</th>\n",
       "      <th>bfSP</th>\n",
       "      <th>box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59772</th>\n",
       "      <td>907000005</td>\n",
       "      <td>FIREBIRD TESS</td>\n",
       "      <td>1920680011</td>\n",
       "      <td>Grade 7</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Sandown (SAP)</td>\n",
       "      <td>515.0</td>\n",
       "      <td>[1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>8.59</td>\n",
       "      <td>37.280872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59741</th>\n",
       "      <td>647150064</td>\n",
       "      <td>EMPIRE LIGHTNING</td>\n",
       "      <td>1920680007</td>\n",
       "      <td>Grade 5</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Sale</td>\n",
       "      <td>440.0</td>\n",
       "      <td>[5, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59740</th>\n",
       "      <td>-745897</td>\n",
       "      <td>JET MIKADO</td>\n",
       "      <td>1920680007</td>\n",
       "      <td>Grade 5</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Sale</td>\n",
       "      <td>440.0</td>\n",
       "      <td>[2, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>2.98</td>\n",
       "      <td>18.606840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59739</th>\n",
       "      <td>169590076</td>\n",
       "      <td>SHOWTIME CHEVI</td>\n",
       "      <td>1920680007</td>\n",
       "      <td>Grade 5</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Sale</td>\n",
       "      <td>440.0</td>\n",
       "      <td>[4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5.75</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59738</th>\n",
       "      <td>189410060</td>\n",
       "      <td>RAIL RIDER</td>\n",
       "      <td>1920680007</td>\n",
       "      <td>Grade 5</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Sale</td>\n",
       "      <td>440.0</td>\n",
       "      <td>[1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>15.43</td>\n",
       "      <td>6.860929</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537905</th>\n",
       "      <td>564109467</td>\n",
       "      <td>TOWN ROCKER</td>\n",
       "      <td>839681512</td>\n",
       "      <td>S/E Heat</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Meadows (MEP)</td>\n",
       "      <td>600.0</td>\n",
       "      <td>[2, 0.05788423928302195, 0.0008314802120338439...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537904</th>\n",
       "      <td>550831471</td>\n",
       "      <td>EXTREME JEWEL</td>\n",
       "      <td>839681512</td>\n",
       "      <td>S/E Heat</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Meadows (MEP)</td>\n",
       "      <td>600.0</td>\n",
       "      <td>[3, 0.05769411756264639, 0.0005623408895558353...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537903</th>\n",
       "      <td>615174394</td>\n",
       "      <td>MIDNIGHT ROCKER</td>\n",
       "      <td>839681512</td>\n",
       "      <td>S/E Heat</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Meadows (MEP)</td>\n",
       "      <td>600.0</td>\n",
       "      <td>[6, 0.05725201518288475, 0.000877621256978406,...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>11.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537910</th>\n",
       "      <td>529306506</td>\n",
       "      <td>ASTON SAMBA</td>\n",
       "      <td>839681513</td>\n",
       "      <td>S/E Heat</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Meadows (MEP)</td>\n",
       "      <td>600.0</td>\n",
       "      <td>[6, 0.057729992084067, 0.0006725023356962765, ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538115</th>\n",
       "      <td>653134666</td>\n",
       "      <td>SCARLETT WINGS</td>\n",
       "      <td>839820812</td>\n",
       "      <td>Grade 7</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>460.0</td>\n",
       "      <td>[5, 0.05751395206243033, 0.000671305873384918,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538116 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dogid          dog_name      raceid race_grade       date  \\\n",
       "59772   907000005     FIREBIRD TESS  1920680011    Grade 7 2016-01-03   \n",
       "59741   647150064  EMPIRE LIGHTNING  1920680007    Grade 5 2016-01-03   \n",
       "59740     -745897        JET MIKADO  1920680007    Grade 5 2016-01-03   \n",
       "59739   169590076    SHOWTIME CHEVI  1920680007    Grade 5 2016-01-03   \n",
       "59738   189410060        RAIL RIDER  1920680007    Grade 5 2016-01-03   \n",
       "...           ...               ...         ...        ...        ...   \n",
       "537905  564109467       TOWN ROCKER   839681512   S/E Heat 2022-11-02   \n",
       "537904  550831471     EXTREME JEWEL   839681512   S/E Heat 2022-11-02   \n",
       "537903  615174394   MIDNIGHT ROCKER   839681512   S/E Heat 2022-11-02   \n",
       "537910  529306506       ASTON SAMBA   839681513   S/E Heat 2022-11-02   \n",
       "538115  653134666    SCARLETT WINGS   839820812    Grade 7 2022-11-02   \n",
       "\n",
       "                                             trackOHE     track_name   dist  \\\n",
       "59772   [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  Sandown (SAP)  515.0   \n",
       "59741   [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]           Sale  440.0   \n",
       "59740   [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]           Sale  440.0   \n",
       "59739   [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]           Sale  440.0   \n",
       "59738   [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]           Sale  440.0   \n",
       "...                                               ...            ...    ...   \n",
       "537905  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  Meadows (MEP)  600.0   \n",
       "537904  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  Meadows (MEP)  600.0   \n",
       "537903  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  Meadows (MEP)  600.0   \n",
       "537910  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  Meadows (MEP)  600.0   \n",
       "538115  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]        Geelong  460.0   \n",
       "\n",
       "                                                    stats  place  startprice  \\\n",
       "59772   [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...    6.0        22.4   \n",
       "59741   [5, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...    2.0         4.3   \n",
       "59740   [2, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...    4.0        17.1   \n",
       "59739   [4, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...    5.0        11.3   \n",
       "59738   [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, ...    7.0         5.1   \n",
       "...                                                   ...    ...         ...   \n",
       "537905  [2, 0.05788423928302195, 0.0008314802120338439...    2.0         5.9   \n",
       "537904  [3, 0.05769411756264639, 0.0005623408895558353...    1.0         1.7   \n",
       "537903  [6, 0.05725201518288475, 0.000877621256978406,...    5.0        10.5   \n",
       "537910  [6, 0.057729992084067, 0.0006725023356962765, ...    3.0         6.2   \n",
       "538115  [5, 0.05751395206243033, 0.000671305873384918,...    3.0         3.6   \n",
       "\n",
       "        margin       bfSP  box  \n",
       "59772     8.59  37.280872    1  \n",
       "59741     0.65   6.400000    5  \n",
       "59740     2.98  18.606840    2  \n",
       "59739     5.75  16.500000    4  \n",
       "59738    15.43   6.860929    1  \n",
       "...        ...        ...  ...  \n",
       "537905    6.09        NaN    2  \n",
       "537904    0.00        NaN    3  \n",
       "537903   11.56        NaN    6  \n",
       "537910    5.91        NaN    6  \n",
       "538115    3.89        NaN    5  \n",
       "\n",
       "[538116 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\dog_stats_df.npy\", 'rb')\n",
    "resultsdf = pickle.load(dog_stats_file)\n",
    "dog_stats_df = pd.DataFrame(resultsdf)\n",
    "dog_stats_df = dog_stats_df.sort_values('date')\n",
    "dog_stats_df['box'] = dog_stats_df['stats'].apply(lambda x: x[0])\n",
    "dog_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dog_stats_df[dog_stats_df['dogid']=='145856635'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8289, 0.8543, 0.8846, 0.8804, 0.9043, 0.8930, 0.8867, 0.8679],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = (1-(dog_stats_df[dog_stats_df['place']==1]['box'].value_counts(sort=False)/len(dog_stats_df[dog_stats_df['place']==1]))).tolist()\n",
    "weights = torch.tensor(weights).to(device)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1711407568744895,\n",
       " 0.14569833923223524,\n",
       " 0.11540974680098012,\n",
       " 0.11962973046555948,\n",
       " 0.09569833923223522,\n",
       " 0.107024230873945,\n",
       " 0.11332698066975225,\n",
       " 0.13207187585080316]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dog_stats_df[dog_stats_df['place']==1]['box'].value_counts(sort=False)/len(dog_stats_df[dog_stats_df['place']==1])).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(input, target, weight):\n",
    "        return (weight * (input - target) ** 2).sum() / weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"debug\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "\n",
    "      model = GRUNet(112,config['hidden_size'])\n",
    "      # criterion = nn.HuberLoss()\n",
    "      # criterion = nn.BCEWithLogitsLoss()\n",
    "      #optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "      #criterion = nn.NLLLoss()\n",
    "      # criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "      criterion = nn.SmoothL1Loss(reduction='mean', beta=0.1)\n",
    "\n",
    "      # optimizer = optim.RMSprop(model.parameters())\n",
    "      # optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "      optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',threshold=0.001, patience=100, verbose=True, factor=0.5)\n",
    "      # optimizer = optim.LBFGS(model.parameters(), lr=0.001)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      train(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      dataset.create_hidden_states_dict()\n",
    "      # if sweep:\n",
    "    #   raceDB.reset_all_lstm_states\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_race = raceDB.get_race_input([100,101])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142750"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raceDB.raceIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.0001, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'profit'},\n",
      " 'parameters': {'batch_size': {'values': [500, 1000, 5000]},\n",
      "                'dropout': {'values': [0.3]},\n",
      "                'epochs': {'values': [250]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'hidden_size': {'value': 16},\n",
      "                'l1_beta': {'value': 0.1},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.001,\n",
      "                                  'min': 0.00011},\n",
      "                'len_data': {'value': 70000},\n",
      "                'loss': {'values': ['L1']},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adamW'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'metric': {'name': 'profit', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adamW'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3]},\n",
       "  'len_data': {'value': 70000},\n",
       "  'hidden_size': {'value': 16},\n",
       "  'epochs': {'values': [250]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'values': ['L1']},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 0.00011, 'max': 0.001},\n",
       "  'l1_beta': {'value': 0.1},\n",
       "  'batch_size': {'values': [500, 1000, 5000]}}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"profit\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": 70000},\n",
    "    \"hidden_size\": {\"value\":16}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [250]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"L1\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00011,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [500,1000,5000]\n",
    "            # \"values\": [32, 64, 128, 360, 720]\n",
    "            # 'values':[4,8,16,32,64,128,360]\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raceDB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\GRU - WANDB - priced - simple - BPPT.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m raceDB\u001b[39m.\u001b[39mdetach_all_hidden_states()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raceDB' is not defined"
     ]
    }
   ],
   "source": [
    "raceDB.detach_all_hidden_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20221206_164342-1gw8y1jc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/debug/runs/1gw8y1jc\" target=\"_blank\">treasured-energy-169</a></strong> to <a href=\"https://wandb.ai/nickojelly/debug\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 32, 'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.0001, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "1000\n",
      "{'hidden_size': 32, 'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.0001, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "GRUNet(\n",
      "  (gru1): GRUCell(112, 32)\n",
      "  (gru2): GRUCell(112, 32)\n",
      "  (gru3): GRUCell(112, 32)\n",
      "  (gru4): GRUCell(112, 32)\n",
      "  (gru5): GRUCell(112, 32)\n",
      "  (gru6): GRUCell(112, 32)\n",
      "  (gru7): GRUCell(112, 32)\n",
      "  (gru8): GRUCell(112, 32)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (rl2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a2d8373e6d409a9a2207f740217750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">treasured-energy-169</strong>: <a href=\"https://wandb.ai/nickojelly/debug/runs/1gw8y1jc\" target=\"_blank\">https://wandb.ai/nickojelly/debug/runs/1gw8y1jc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221206_164342-1gw8y1jc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [203] at entry 0 and [195] at entry 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\GRU - WANDB - priced - simple - BPPT.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (model,dataset) \u001b[39m=\u001b[39m model_pipeline(raceDB,config\u001b[39m=\u001b[39;49mwandb_config_static)\n",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\GRU - WANDB - priced - simple - BPPT.ipynb Cell 34\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[1;34m(my_dataset, config, prev_model, sweep)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m   \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m   \u001b[39m# and use them to train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m   train(model, dataset, criterion, optimizer, scheduler, config)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m   dataset\u001b[39m.\u001b[39mcreate_hidden_states_dict()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m   \u001b[39m# if sweep:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m#   raceDB.reset_all_lstm_states\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# and test its final performance\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m#test(model, test_loader)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\GRU - WANDB - priced - simple - BPPT.ipynb Cell 34\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, raceDB, criterion, optimizer, scheduler, config)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([x\u001b[39m.\u001b[39mclasses \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m race])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m _, actual \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(y\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m output \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m#print(output,y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m example_ct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m  batch_size\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\GRU - WANDB - priced - simple - BPPT.ipynb Cell 34\u001b[0m in \u001b[0;36mGRUNet.forward\u001b[1;34m(self, race)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, race: Race):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack([r\u001b[39m.\u001b[39;49mfull_input\u001b[39m.\u001b[39;49mfloat() \u001b[39mfor\u001b[39;49;00m r \u001b[39min\u001b[39;49;00m race])\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# creates list of LSTM data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X45sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     hidden_state_in \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[r\u001b[39m.\u001b[39mlstm_input() \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m race])]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [203] at entry 0 and [195] at entry 5"
     ]
    }
   ],
   "source": [
    "(model,dataset) = model_pipeline(raceDB,config=wandb_config_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pause' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\GRU - WANDB - priced - simple - BPPT.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pause\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20simple%20-%20BPPT.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dataset\u001b[39m.\u001b[39mcreate_hidden_states_dict()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pause' is not defined"
     ]
    }
   ],
   "source": [
    "pause\n",
    "dataset.create_hidden_states_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDB.fill_hidden_states_from_dict(hidden_dict=dataset.hidden_states_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"LSTM_sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43115443075634c02a7c247a87b0dd9d74842892e56d473b9e19f544f3149aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
