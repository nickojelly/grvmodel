{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "from rnn_classes import Dog, DogInput, Race, Races, GRUNet\n",
    "from raceDB import build_dataset, build_pred_dataset\n",
    "import importlib\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_saver(model, optimizer, epoch, loss, hidden_state_dict, model_name = None):\n",
    "    \n",
    "    pathtofolder = \"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model\"\n",
    "    # model_name = wandb.run.name\n",
    "    if not model_name:\n",
    "        model_name = \"test NZ GRU saver\"\n",
    "    isExist = os.path.exists(\n",
    "        f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "    )\n",
    "    if isExist:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optim\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"db\":hidden_state_dict,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )\n",
    "    else:\n",
    "        print(\"created path\")\n",
    "        os.makedirs(\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "        )\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optim\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"db\":hidden_state_dict,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_to_bf(model:GRUNet,raceDB:Races,example_ct):\n",
    "    with torch.no_grad():\n",
    "        sft_max = nn.Softmax(dim=-1)\n",
    "        l_sftmax = nn.LogSoftmax(dim=-1)\n",
    "        nnl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        full_test_races = raceDB.get_test_input(range(0,len(raceDB.test_race_ids)))\n",
    "        full_test_races_w_prices = []\n",
    "        excluded, included = 0,0\n",
    "        for r in full_test_races:\n",
    "            if 0 in r.prices or -1 in r.prices:\n",
    "                excluded+=1\n",
    "            else:\n",
    "                full_test_races_w_prices.append(r)\n",
    "                included+=1\n",
    "        print(included,excluded)\n",
    "\n",
    "        output = l_sftmax(model(full_test_races_w_prices))\n",
    "        bf_prices = torch.log(torch.tensor([x.implied_prob for x in full_test_races_w_prices ]).to('cuda:0'))\n",
    "        full_classes = torch.stack([x.classes for x in full_test_races_w_prices ])\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(f\"our loss = {nnl_loss(output,full_classes)}\")\n",
    "        print(f\"their loss = {nnl_loss(bf_prices ,full_classes)}\")\n",
    "        wandb.log({\"our loss\":nnl_loss(output,full_classes), \"their loss\":nnl_loss(bf_prices ,full_classes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def validate_model(model:GRUNet,raceDB:Races,criterion, batch_size, example_ct, epoch_loss, batch_ct):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    sft_max = nn.Softmax(dim=-1)\n",
    "    l_sftmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    batch_size=10\n",
    "    len_test = len(raceDB.test_race_ids)-batch_size\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    preds = []\n",
    "    grades = []\n",
    "    tracks = []\n",
    "    pred_confs = []\n",
    "    bfsps = []\n",
    "    start_prices = []\n",
    "    loss_l = []\n",
    "    loss_t = []\n",
    "    margins_l = []\n",
    "    preds_l = []\n",
    "    pred_sftmax = []\n",
    "    raw_margins = []\n",
    "    raw_places = []\n",
    "    margins_prob = []\n",
    "\n",
    "    prices_list = []\n",
    "    raw_prices = []\n",
    "\n",
    "    price_dict = {}\n",
    "    price_dict['prices'] = []\n",
    "    price_dict['imp_prob'] = []\n",
    "    price_dict['pred_prob'] = []\n",
    "    price_dict['pred_price'] = []\n",
    "    price_dict['margin'] = []\n",
    "    price_dict['onehot_win'] = []\n",
    "    price_dict['raceID'] = []\n",
    "    price_dict['dogID'] = []\n",
    "    race_ids = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # loss_comparison\n",
    "        # full_test_races = raceDB.get_test_input(range(0,len(raceDB.test_race_ids)))\n",
    "        # output = l_sftmax(model(full_test_races))\n",
    "        # bf_prices = l_sftmax(torch.tensor([x.prices for x in full_test_races]).to('cuda:0'))\n",
    "        # full_classes = torch.stack([x.classes for x in full_test_races])\n",
    "        \n",
    "        # print(f\"our loss = {nnl_loss(output,full_classes)}\")\n",
    "        # print(f\"their loss = {nnl_loss(output,full_classes)}\")\n",
    "\n",
    "        for i in trange(0,len_test,batch_size, leave=False):\n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i+batch_size\n",
    "            race = raceDB.get_test_input(races_idx)\n",
    "            #tracks.extend([r.track for r in race])\n",
    "\n",
    "            X = race\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            output = model(X)\n",
    "            race_ids.extend([x.raceid for x in race])\n",
    "            #print(y)\n",
    "\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            onehot_win = F.one_hot(actual, num_classes=8)\n",
    "            conf, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "\n",
    "            softmax_preds = sft_max(output)\n",
    "\n",
    "            \n",
    "            total += batch_size\n",
    "            actuals.extend(actual.tolist())\n",
    "            preds.extend(predicted.tolist())\n",
    "            pred_confs.extend(conf.tolist())\n",
    "            tracks.extend([r.track_name for r in race])\n",
    "            grades.extend([r.grade for r in race])\n",
    "            for i,dog_idx in enumerate(actual.tolist()):\n",
    "                bfsps.append(race[i].dogs[dog_idx].bfsp)\n",
    "                #start_prices.append(race[i].dogs[dog_idx].sp)\n",
    "\n",
    "            \n",
    "            loss = criterion(output, y).detach()\n",
    "            loss_tensor = validation_CLE(output,y)\n",
    "            loss_t.append(loss_tensor.tolist())\n",
    "\n",
    "            loss_l.append(loss.tolist())\n",
    "            preds_l.append(output.tolist())\n",
    "            pred_sftmax.append(softmax_preds.tolist())\n",
    "            margins_l.append(y.tolist())\n",
    "            margins_prob.append(y.tolist())\n",
    "            raw_margins.append([x.raw_margins for x in race])\n",
    "            raw_places.append([x.raw_places for x in race])\n",
    "            loss_val += loss\n",
    "\n",
    "            price_dict['prices'].extend([x.prices for x in race])\n",
    "            price_dict['imp_prob'].extend([x.implied_prob for x in race])\n",
    "            price_dict['pred_prob'].extend(softmax_preds.tolist())\n",
    "            #print([(1/(x+(-7**10))).tolist() for x in torch.exp(output)])\n",
    "            price_dict['pred_price'].extend([(1/(x)).tolist() for x in softmax_preds])\n",
    "            price_dict['margin'].extend([x.raw_margins for x in race])\n",
    "            price_dict['onehot_win'].extend(onehot_win.tolist())\n",
    "            price_dict['raceID'].extend([[x.raceid]*8 for x in race])\n",
    "            price_dict['dogID'].extend([x.list_dog_ids() for x in race])\n",
    "\n",
    "            \n",
    "\n",
    "        loss_list = []\n",
    "\n",
    "        #print(\"start loss calc\")\n",
    "        for i,l in enumerate(loss_l):\n",
    "            for j in range(0,7):\n",
    "                loss_list.append([preds_l[i][j],margins_l[i][j],loss_t[i][j],l[j],pred_sftmax[i][j],margins_prob[i][j], raw_margins[i][j], raw_places[i][j]])\n",
    "\n",
    "    loss_df = pd.DataFrame(loss_list, columns=['Preds','Margins','Indiviual Losses','Losses','softmaxPreds','Softmax Margins','Raw margins', 'Raw places'])\n",
    "    loss_table = wandb.Table(dataframe=loss_df)\n",
    "\n",
    "\n",
    "    logdf = pd.DataFrame(data = {\"actuals\":actuals, \"preds\":preds,\"conf\":pred_confs, \"grade\":grades, \"track\":tracks, \"bfsps\":bfsps})#, \"sp\":start_prices })\n",
    "    \n",
    "    logdf['correct'] = logdf.apply(lambda x: 1 if x['actuals']==x['preds'] else 0, axis=1)\n",
    "    logdf['profit'] = logdf.apply(lambda x: 0 if x['bfsps']<1 else x['bfsps']-1  if x['correct'] else -1, axis=1)\n",
    "    logdf.to_csv('logDFtest.csv')\n",
    "\n",
    "    table = wandb.Table(dataframe=logdf)\n",
    "\n",
    "    logdf['count'] = 1\n",
    "    logdf['eligible_ct'] = logdf.apply(lambda x: 1 if x['bfsps'] > 1 else 0, axis = 1)\n",
    "\n",
    "    track_df = logdf.groupby('track', as_index=False).sum(numeric_only=True).reset_index()\n",
    "    track_table = wandb.Table(dataframe=track_df)\n",
    "    \n",
    "    prices_df = pd.DataFrame(price_dict)\n",
    "\n",
    "\n",
    "    prices_df['sum_price'] = prices_df.apply(lambda x: sum(x['prices']), axis = 1)\n",
    "    prices_df = prices_df[prices_df['sum_price']>0]\n",
    "\n",
    "    prices_flat = [item for sublist in prices_df['prices'].tolist() for item in sublist]\n",
    "    pred_prices = [item for sublist in prices_df['pred_price'].tolist() for item in sublist]\n",
    "    onehot_win  = [item for sublist in prices_df['onehot_win'].tolist() for item in sublist]\n",
    "    flat_margins = [item for sublist in prices_df['margin'].tolist() for item in sublist]\n",
    "    flat_dogs = [item for sublist in prices_df['dogID'].tolist() for item in sublist]\n",
    "    flat_races = [item for sublist in prices_df['raceID'].tolist() for item in sublist]\n",
    "    all_price_df = pd.DataFrame(data={'flat_dogs':flat_dogs,'flat_races':flat_races,'prices':prices_flat, 'pred_price':pred_prices, 'onehot_win':onehot_win,'split_margin':flat_margins})\n",
    "    all_price_df = all_price_df[all_price_df['prices']>1]\n",
    "    all_price_df['imp_prob'] =  all_price_df.apply(lambda x: 1/x['prices'], axis = 1)\n",
    "    all_price_df['pred_prob'] =  all_price_df.apply(lambda x: 1/x['pred_price'], axis = 1)\n",
    "    all_price_df['bet amount'] = all_price_df.apply(lambda x: (x['pred_prob']-x['imp_prob'])*100 if (x['pred_prob']>x['imp_prob'])&(1>x['imp_prob']>0) else 0, axis = 1)\n",
    "    all_price_df['profit'] = all_price_df.apply(lambda x: x['bet amount']*(x['prices']-1)*0.95 if x['onehot_win'] else -1*x['bet amount'], axis = 1)\n",
    "    all_price_df['flat_profit'] = all_price_df.apply(lambda x: 1*(x['prices']-1)*0.95 if (x['onehot_win'] and x['bet amount']) else -1, axis = 1)\n",
    "    all_price_df['colour'] = all_price_df.apply(lambda x: \"profitz\" if x['profit']>0 else (\"loss\" if x['profit']<0 else (\"no bet - win\" if x['onehot_win'] else \"no bet\")), axis=1)\n",
    "\n",
    "    all_price_table = wandb.Table(dataframe=all_price_df)\n",
    "\n",
    "    all_price_df.to_pickle('all_price_df_nz.npy')\n",
    "\n",
    "\n",
    "    price_table = wandb.Table(dataframe=prices_df)\n",
    "\n",
    "    try:\n",
    "        wandb.log({\"table_key\": table,\"loss_table\": loss_table,\"track_df\": track_table,\"price_table\":price_table, 'allprice_df':all_price_df })\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    #print(f\"accuray: {correct/total}\")\n",
    "    wandb.log({\"accuracy\": correct/total, \"loss_val\": torch.mean(loss_val)/len_test, \"correct\": correct, 'profit': logdf[logdf['actuals']==logdf['preds']]['profit'].sum(), 'multibet profit':all_price_df['profit'].sum(), 'multibet outlay':all_price_df['bet amount'].sum() })\n",
    "\n",
    "    return correct/total, torch.mean(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def validate_modelv2(model:GRUNet,raceDB:Races):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    sft_max = nn.Softmax(dim=-1)\n",
    "    batch_size=10\n",
    "    len_test = len(raceDB.raceIDs)-batch_size\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    preds = []\n",
    "    grades = []\n",
    "    tracks = []\n",
    "    pred_confs = []\n",
    "    bfsps = []\n",
    "    start_prices = []\n",
    "    loss_l = []\n",
    "    loss_t = []\n",
    "    margins_l = []\n",
    "    preds_l = []\n",
    "    pred_sftmax = []\n",
    "    raw_margins = []\n",
    "    raw_places = []\n",
    "    margins_prob = []\n",
    "\n",
    "    prices_list = []\n",
    "    raw_prices = []\n",
    "\n",
    "    price_dict = {}\n",
    "    price_dict['prices'] = []\n",
    "    price_dict['imp_prob'] = []\n",
    "    price_dict['pred_prob'] = []\n",
    "    price_dict['pred_price'] = []\n",
    "    price_dict['margin'] = []\n",
    "    price_dict['onehot_win'] = []\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0,len_test,batch_size, leave=False):\n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "            race = raceDB.get_race_input(races_idx)\n",
    "            #tracks.extend([r.track for r in race])\n",
    "            X = race\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            output = model(X)\n",
    "            #print(y)\n",
    "\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            onehot_win = F.one_hot(actual, num_classes=8)\n",
    "            conf, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "\n",
    "            softmax_preds = sft_max(output)\n",
    "\n",
    "            \n",
    "            total += batch_size\n",
    "            actuals.extend(actual.tolist())\n",
    "            preds.extend(predicted.tolist())\n",
    "            pred_confs.extend(conf.tolist())\n",
    "            tracks.extend([r.track_name for r in race])\n",
    "            grades.extend([r.grade for r in race])\n",
    "            for i,dog_idx in enumerate(actual.tolist()):\n",
    "                bfsps.append(race[i].dogs[dog_idx].bfsp)\n",
    "                #start_prices.append(race[i].dogs[dog_idx].sp)\n",
    "\n",
    "\n",
    "            price_dict['prices'].extend([x.prices for x in race])\n",
    "            price_dict['imp_prob'].extend([x.implied_prob for x in race])\n",
    "            price_dict['pred_prob'].extend(softmax_preds.tolist())\n",
    "            #print([(1/(x+(-7**10))).tolist() for x in torch.exp(output)])\n",
    "            price_dict['pred_price'].extend([(1/(x)).tolist() for x in softmax_preds])\n",
    "            price_dict['margin'].extend([x.raw_margins for x in race])\n",
    "            price_dict['onehot_win'].extend(onehot_win.tolist())\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    logdf = pd.DataFrame(data = {\"actuals\":actuals, \"preds\":preds,\"conf\":pred_confs, \"grade\":grades, \"track\":tracks, \"bfsps\":bfsps})#, \"sp\":start_prices })\n",
    "    \n",
    "    logdf['correct'] = logdf.apply(lambda x: 1 if x['actuals']==x['preds'] else 0, axis=1)\n",
    "    logdf['profit'] = logdf.apply(lambda x: 0 if x['bfsps']<1 else x['bfsps']-1  if x['correct'] else -1, axis=1)\n",
    "    logdf.to_csv('logDFtest.csv')\n",
    "\n",
    "    table = wandb.Table(dataframe=logdf)\n",
    "\n",
    "    logdf['count'] = 1\n",
    "    logdf['eligible_ct'] = logdf.apply(lambda x: 1 if x['bfsps'] > 1 else 0, axis = 1)\n",
    "\n",
    "    track_df = logdf.groupby('track', as_index=False).sum(numeric_only=True).reset_index()\n",
    "    \n",
    "    prices_df = pd.DataFrame(price_dict)\n",
    "\n",
    "\n",
    "    prices_df['sum_price'] = prices_df.apply(lambda x: sum(x['prices']), axis = 1)\n",
    "    prices_df = prices_df[prices_df['sum_price']>0]\n",
    "\n",
    "    prices_flat = [item for sublist in prices_df['prices'].tolist() for item in sublist]\n",
    "    pred_prices = [item for sublist in prices_df['pred_price'].tolist() for item in sublist]\n",
    "    onehot_win  = [item for sublist in prices_df['onehot_win'].tolist() for item in sublist]\n",
    "    flat_margins = [item for sublist in prices_df['margin'].tolist() for item in sublist]\n",
    "    all_price_df = pd.DataFrame(data={'prices':prices_flat, 'pred_price':pred_prices, 'onehot_win':onehot_win,'split_margin':flat_margins})\n",
    "    all_price_df = all_price_df[all_price_df['prices']>1]\n",
    "    all_price_df['imp_prob'] =  all_price_df.apply(lambda x: 1/x['prices'], axis = 1)\n",
    "    all_price_df['pred_prob'] =  all_price_df.apply(lambda x: 1/x['pred_price'], axis = 1)\n",
    "    all_price_df['bet amount'] = all_price_df.apply(lambda x: (x['pred_prob']-x['imp_prob'])*100 if (x['pred_prob']>x['imp_prob'])&(1>x['imp_prob']>0) else 0, axis = 1)\n",
    "    all_price_df['profit'] = all_price_df.apply(lambda x: x['bet amount']*(x['prices']-1)*0.95 if x['onehot_win'] else -1*x['bet amount'], axis = 1)\n",
    "    all_price_df['flat_profit'] = all_price_df.apply(lambda x: 1*(x['prices']-1)*0.95 if (x['onehot_win'] and x['bet amount']) else -1, axis = 1)\n",
    "    all_price_df['colour'] = all_price_df.apply(lambda x: \"profitz\" if x['profit']>0 else (\"loss\" if x['profit']<0 else (\"no bet - win\" if x['onehot_win'] else \"no bet\")), axis=1)\n",
    "\n",
    "\n",
    "    #print(f\"accuray: {correct/total}\")\n",
    "    stats = {\"accuracy\": correct/total,  \"correct\": correct, 'profit': logdf[logdf['actuals']==logdf['preds']]['profit'].sum(), 'multibet profit':all_price_df['profit'].sum(), 'multibet outlay':all_price_df['bet amount'].sum() }\n",
    "    print(stats)\n",
    "    return all_price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_indexer(batch_size,group_len, dataset_len):\n",
    "    num_batches = group_len\n",
    "    group_size = batch_size*group_len\n",
    "    all_batches = []\n",
    "    for n in range(num_batches):\n",
    "        batch = []\n",
    "        \n",
    "        for i in range(dataset_len):\n",
    "            if batch_size*(n)<i%group_size<batch_size*(n+1):\n",
    "                batch.append(i)\n",
    "        \n",
    "        all_batches.append(batch)\n",
    "    return all_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, raceDB:Races, criterion, optimizer,scheduler, config=None):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    last = 0\n",
    "    batch_size = 12\n",
    "    len_train = len(raceDB.train_race_ids)\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    m = nn.LogSoftmax(dim=1)\n",
    "    epoch_loss=0\n",
    "    batch_before_backwards = 10\n",
    "    saved_batches = []\n",
    "\n",
    "    \n",
    "    #losses = torch.tesnor()\n",
    "    for epoch in trange(2000):\n",
    "        model.train()\n",
    "        batch_ct = 0\n",
    "        setup_loss = 1\n",
    "        # if epoch<100:\n",
    "        #     batch_size=100\n",
    "        # else:\n",
    "        #     batch_size=25\n",
    "        #batch_before_backwards = randint(5,20)\n",
    "        len_train_batch = len_train-(len_train%(batch_size*batch_before_backwards))\n",
    "        batch_indexes = batch_indexer(batch_size, batch_before_backwards, len_train_batch)\n",
    "        for i,batch in enumerate(batch_indexes):\n",
    "            last = i\n",
    "            #print(f\"{i=}\\n{batch_ct=}, {setup_loss=}, {batch_ct+1%10==0=}\")\n",
    "            if ((batch_ct+1)%batch_before_backwards==0):\n",
    "                if setup_loss:\n",
    "                    print(\"hit here\")\n",
    "                    continue\n",
    "                else:\n",
    "                    epoch_loss = torch.mean(epoch_loss)\n",
    "                    optimizer.zero_grad()\n",
    "                    epoch_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    model.zero_grad()\n",
    "                    raceDB.detach_all_hidden_states()\n",
    "                    setup_loss = 1\n",
    "                    wandb.log({\"batch_loss\": epoch_loss.item(), \"batch_before_backwards\": batch_before_backwards}, step = example_ct)\n",
    "                    \n",
    "                    model(saved_batches)\n",
    "                    saved_batches = []\n",
    "\n",
    "            batch_ct += 1\n",
    "\n",
    "            #races_idx = range(last,last+batch_size)\n",
    "            race = raceDB.get_train_input(batch)\n",
    "            X = race\n",
    "            saved_batches.extend(X)\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            w = torch.stack([x.win_weight for x in race])\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            output = model(X)\n",
    "\n",
    "            \n",
    "            example_ct +=  batch_size\n",
    "\n",
    "            loss = criterion(output, y)*w\n",
    "            if setup_loss:\n",
    "                epoch_loss = loss\n",
    "                setup_loss=0\n",
    "\n",
    "\n",
    "\n",
    "            #epoch_loss = torch.stack([epoch_loss, loss])\n",
    "            epoch_loss = epoch_loss + loss\n",
    "            \n",
    "\n",
    "        #print(\"finished epoch\")\n",
    "        setup_loss = 1\n",
    "\n",
    "        wandb.log({\"epoch_loss\": torch.mean(epoch_loss)}, step = example_ct)\n",
    "        if epoch%3==0:\n",
    "            acc, loss_val = validate_model(model,raceDB,criterion, 8, example_ct, epoch_loss, batch_ct)\n",
    "        # compare_model_to_bf(model, raceDB, example_ct)\n",
    "        train_log(torch.mean(loss), example_ct, epoch)\n",
    "        epoch_loss = 0  \n",
    "        #print(acc)\n",
    "        scheduler.step(loss_val)\n",
    "        raceDB.detach_all_hidden_states()\n",
    "    #print(losses)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115439, 18)\n",
      "(1115439, 18)\n",
      "num_features_per_dog=16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1308bb7c01a427b824ea312ef100b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ae34cff8094258bcd4c3400c6f013b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\tqdm\\std.py:1195: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 15765, number of unique dogs = 3413\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "#dog_stats_file = open( 'new gru input 2023-01.npy', 'rb')\n",
    "hidden_size = 64\n",
    "raceDB = build_dataset('gru_input.npy', hidden_size ,track_filer=\"NZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples 15100, Test examples 665\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.strptime(\"2022-12-01\", \"%Y-%m-%d\")\n",
    "raceDB.create_test_split_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nz_races = raceDB.get_test_input(range(0,len(raceDB.test_race_ids)-1))\n",
    "# dates = [r.race_date for r in nz_races]\n",
    "# all_nz_dates = NZ.groupby('date').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog_stats_file = open( r'C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\prediction validation 2023-01.npy', 'rb')\n",
    "# hidden_size = 64\n",
    "# predDB = build_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "# dog_stats_file = open( r'C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\forms\\prediction_inputs_gru.npy', 'rb')\n",
    "# hidden_size = 64\n",
    "# predDB = build_pred_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raceDB.create_hidden_states_dict()\n",
    "# predDB.fill_hidden_states_from_dict(hidden_dict=raceDB.hidden_states_dict)\n",
    "# # len(raceDB.hidden_states_dict)\n",
    "# # predDB.to_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def predict_model(model,predDB):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        races_idx = range(0,len(predDB.raceIDs)-1)\n",
    "        race = predDB.get_race_input(races_idx)\n",
    "        X = race\n",
    "        # for i,r in enumerate(race):\n",
    "        #     print(r.raceid, r.track_name)\n",
    "        #     #print(i,r.lstm_input())\n",
    "\n",
    "        output = model(X)\n",
    "        \n",
    "        print(output)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            print(r.raceid, r.track_name, r.dogs[predicted[i].item()])\n",
    "\n",
    "        print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"GRU - FastTrack - NZ Testing\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "\n",
    "      model = GRUNet(203,config['hidden_size'])\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      #criterion = nn.KLDivLoss(reduction='none', log_target=True)\n",
    "      criterion = nn.CrossEntropyLoss(reduction='none', label_smoothing=0.1 )\n",
    "      optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',threshold=0.0001, patience=50, verbose=True, factor=0.5)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        train(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      except KeyboardInterrupt:\n",
    "        print(\"finished Early\")\n",
    "      dataset.create_hidden_states_dict()\n",
    "      # if sweep:\n",
    "    #   raceDB.reset_all_lstm_states\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.001, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raceDB.detach_all_hidden_states()\n",
    "# raceDB.create_test_split()\n",
    "# raceDB.reset_all_lstm_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_dict = torch.load(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\savedmodel\\long run profit NZ\\long run profit NZ_450.pt\")\n",
    "# model_state_dict = saved_dict['model_state_dict']\n",
    "# raceDB.fill_hidden_states_from_dict(saved_dict['db'])\n",
    "# raceDB.to_cuda()\n",
    "# # predDB.fill_hidden_states_from_dict(hidden_dict=raceDB.hidden_states_dict)\n",
    "# # predDB.to_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([203])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = raceDB.get_race_input([0,1])\n",
    "x[0].full_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.detach_all_hidden_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\wandb\\run-20230124_091803-5izvdfyn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20NZ%20Testing/runs/5izvdfyn\" target=\"_blank\">floating-festival-102</a></strong> to <a href=\"https://wandb.ai/nickojelly/GRU%20-%20FastTrack%20-%20NZ%20Testing\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.001, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "1000\n",
      "{'hidden_size': 64, 'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64, 'learning_rate': 0.001, 'loss': 'L1', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}\n",
      "GRUNet(\n",
      "  (gru1): GRUCell(203, 64)\n",
      "  (gru2): GRUCell(203, 64)\n",
      "  (gru3): GRUCell(203, 64)\n",
      "  (gru4): GRUCell(203, 64)\n",
      "  (gru5): GRUCell(203, 64)\n",
      "  (gru6): GRUCell(203, 64)\n",
      "  (gru7): GRUCell(203, 64)\n",
      "  (gru8): GRUCell(203, 64)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (rl2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
      "  (output_fn): Identity()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6f89b0e37a4267bf96a182b56c4620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d247bbc532a04b04b2647c555bfe4cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa478af4e734f0aafea0d97d56694cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcbdc47e70a43d594944bacfabd591e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b02eab2ff544b7ea7b890a6293c76ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca71d748fd64529afeca748227ac22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0af23ab00f4dc8a266a0c1127c4ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bd3d9d3d9e49959b43179c6dc2b2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85357245cf894cb5b4b0e3cfe89a2de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0681f6740924123b9d328f045dcadcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da61d749610447ab394566d75fb0337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eba1dd37c234b389639bc0fc2c30713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143ef26f5167480d8d3240fa8ee19c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9ce9f823704c949c8ff365e762b19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e542482644644bf9809a21ae18921cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cab5d46897d49ebac874359e62aea58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdf13af6f554796bf2299fe746e185d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4a927b6dbe44d3ad78f4149aa2ef28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5a8356233a4e57a66cdacdaef1d5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cef499690a441abb917cd197408b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d06184a5d7a470ca89b8f8b2b7c2084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d8768524db414599ace0bb75d9fdb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236e15c619c74a6fa7fa04cd08d67a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4013e5e1a0a04aa9aeb48e57a7d61d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47048439359845858d0cd011ed05b1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead9d1ab36694feaa592ba6c1564fd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff8d59281e34ef5af7d73046611d4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331dcaadc4dd4915bea4aa5335eca9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e635dfcc83644170b62c7e959b2d7a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2241809969d4229a94f2eb94e5f6305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_state_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#stop\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[39m=\u001b[39m GRUNet(\u001b[39m203\u001b[39m,\u001b[39m64\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(model_state_dict)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_state_dict' is not defined"
     ]
    }
   ],
   "source": [
    "stop\n",
    "model = GRUNet(203,64).to(device)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6886b981d21406fb3cd633198e9408b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.22962962962962963, 'correct': 62, 'profit': 155.8730624273856, 'multibet profit': 610.4800603151755, 'multibet outlay': 5630.432833115364}\n"
     ]
    }
   ],
   "source": [
    "all_price_df = validate_modelv2(model, predDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss            810\n",
       "no bet          380\n",
       "no bet - win    135\n",
       "profitz          58\n",
       "Name: colour, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_price_df.colour.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static, prev_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# \n",
    "# all_price_df[all_price_df['onehot_win']==1].sort_values('prices', ascending=False).shape\n",
    "all_price_df.sort_values('prices', ascending=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset.create_hidden_states_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    }
   ],
   "source": [
    "model_saver(model, optimizer, 450, 0.1, dataset.hidden_states_dict, model_name=\"NEW 650 RUN NZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"profit\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": 70000},\n",
    "    \"hidden_size\": {\"value\":16}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [250]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"L1\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00011,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [500,1000,5000]\n",
    "            # \"values\": [32, 64, 128, 360, 720]\n",
    "            # 'values':[4,8,16,32,64,128,360]\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"LSTM_sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43115443075634c02a7c247a87b0dd9d74842892e56d473b9e19f544f3149aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
