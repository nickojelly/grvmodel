{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from operator import itemgetter\n",
    "import operator\n",
    "from random import randint\n",
    "from rnn_classes import Dog, DogInput, Race, Races, GRUNet\n",
    "from raceDB import build_dataset, build_pred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_saver(model, optimizer, epoch, loss, hidden_state_dict, model_name = None):\n",
    "    \n",
    "    pathtofolder = \"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model\"\n",
    "    # model_name = wandb.run.name\n",
    "    if not model_name:\n",
    "        model_name = \"test NZ GRU saver\"\n",
    "    isExist = os.path.exists(\n",
    "        f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "    )\n",
    "    if isExist:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optim\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"db\":hidden_state_dict,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )\n",
    "    else:\n",
    "        print(\"created path\")\n",
    "        os.makedirs(\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "        )\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optim\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "                \"db\":hidden_state_dict,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_CLE(x,y):\n",
    "    loss_t = -torch.log(torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True))*y\n",
    "    return loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def validate_model(model:GRUNet,raceDB,criterion, batch_size, example_ct, epoch_loss, batch_ct):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    sft_max = nn.Softmax(dim=-1)\n",
    "    batch_size=100\n",
    "    len_test = len(raceDB.test_race_ids)-batch_size\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    preds = []\n",
    "    grades = []\n",
    "    tracks = []\n",
    "    pred_confs = []\n",
    "    bfsps = []\n",
    "    start_prices = []\n",
    "    loss_l = []\n",
    "    loss_t = []\n",
    "    margins_l = []\n",
    "    preds_l = []\n",
    "    pred_sftmax = []\n",
    "    raw_margins = []\n",
    "    raw_places = []\n",
    "    margins_prob = []\n",
    "\n",
    "    prices_list = []\n",
    "    raw_prices = []\n",
    "\n",
    "    price_dict = {}\n",
    "    price_dict['prices'] = []\n",
    "    price_dict['imp_prob'] = []\n",
    "    price_dict['pred_prob'] = []\n",
    "    price_dict['pred_price'] = []\n",
    "    price_dict['margin'] = []\n",
    "    price_dict['onehot_win'] = []\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0,len_test,batch_size, leave=False):\n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "            race = raceDB.get_test_input(races_idx)\n",
    "            #tracks.extend([r.track for r in race])\n",
    "            X = race\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            output = model(X)\n",
    "            #print(y)\n",
    "\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            onehot_win = F.one_hot(actual, num_classes=8)\n",
    "            conf, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "\n",
    "            softmax_preds = sft_max(output)\n",
    "\n",
    "            \n",
    "            total += batch_size\n",
    "            actuals.extend(actual.tolist())\n",
    "            preds.extend(predicted.tolist())\n",
    "            pred_confs.extend(conf.tolist())\n",
    "            tracks.extend([r.track_name for r in race])\n",
    "            grades.extend([r.grade for r in race])\n",
    "            for i,dog_idx in enumerate(actual.tolist()):\n",
    "                bfsps.append(race[i].dogs[dog_idx].bfsp)\n",
    "                #start_prices.append(race[i].dogs[dog_idx].sp)\n",
    "\n",
    "            \n",
    "            loss = criterion(output, y).detach()\n",
    "            loss_tensor = validation_CLE(output,y)\n",
    "            loss_t.append(loss_tensor.tolist())\n",
    "\n",
    "            loss_l.append(loss.tolist())\n",
    "            preds_l.append(output.tolist())\n",
    "            pred_sftmax.append(softmax_preds.tolist())\n",
    "            margins_l.append(y.tolist())\n",
    "            margins_prob.append(y.tolist())\n",
    "            raw_margins.append([x.raw_margins for x in race])\n",
    "            raw_places.append([x.raw_places for x in race])\n",
    "            loss_val += loss\n",
    "\n",
    "            price_dict['prices'].extend([x.prices for x in race])\n",
    "            price_dict['imp_prob'].extend([x.implied_prob for x in race])\n",
    "            price_dict['pred_prob'].extend(softmax_preds.tolist())\n",
    "            #print([(1/(x+(-7**10))).tolist() for x in torch.exp(output)])\n",
    "            price_dict['pred_price'].extend([(1/(x)).tolist() for x in softmax_preds])\n",
    "            price_dict['margin'].extend([x.raw_margins for x in race])\n",
    "            price_dict['onehot_win'].extend(onehot_win.tolist())\n",
    "\n",
    "            \n",
    "\n",
    "        loss_list = []\n",
    "\n",
    "        #print(\"start loss calc\")\n",
    "        for i,l in enumerate(loss_l):\n",
    "            for j in range(0,7):\n",
    "                loss_list.append([preds_l[i][j],margins_l[i][j],loss_t[i][j],l[j],pred_sftmax[i][j],margins_prob[i][j], raw_margins[i][j], raw_places[i][j]])\n",
    "\n",
    "    loss_df = pd.DataFrame(loss_list, columns=['Preds','Margins','Indiviual Losses','Losses','softmaxPreds','Softmax Margins','Raw margins', 'Raw places'])\n",
    "    loss_table = wandb.Table(dataframe=loss_df)\n",
    "\n",
    "\n",
    "    logdf = pd.DataFrame(data = {\"actuals\":actuals, \"preds\":preds,\"conf\":pred_confs, \"grade\":grades, \"track\":tracks, \"bfsps\":bfsps})#, \"sp\":start_prices })\n",
    "    \n",
    "    logdf['correct'] = logdf.apply(lambda x: 1 if x['actuals']==x['preds'] else 0, axis=1)\n",
    "    logdf['profit'] = logdf.apply(lambda x: 0 if x['bfsps']<1 else x['bfsps']-1  if x['correct'] else -1, axis=1)\n",
    "    logdf.to_csv('logDFtest.csv')\n",
    "\n",
    "    table = wandb.Table(dataframe=logdf)\n",
    "\n",
    "    logdf['count'] = 1\n",
    "    logdf['eligible_ct'] = logdf.apply(lambda x: 1 if x['bfsps'] > 1 else 0, axis = 1)\n",
    "\n",
    "    track_df = logdf.groupby('track', as_index=False).sum().reset_index()\n",
    "    track_table = wandb.Table(dataframe=track_df)\n",
    "    \n",
    "    prices_df = pd.DataFrame(price_dict)\n",
    "\n",
    "\n",
    "    prices_df['sum_price'] = prices_df.apply(lambda x: sum(x['prices']), axis = 1)\n",
    "    prices_df = prices_df[prices_df['sum_price']>0]\n",
    "\n",
    "    prices_flat = [item for sublist in prices_df['prices'].tolist() for item in sublist]\n",
    "    pred_prices = [item for sublist in prices_df['pred_price'].tolist() for item in sublist]\n",
    "    onehot_win  = [item for sublist in prices_df['onehot_win'].tolist() for item in sublist]\n",
    "    flat_margins = [item for sublist in prices_df['margin'].tolist() for item in sublist]\n",
    "    all_price_df = pd.DataFrame(data={'prices':prices_flat, 'pred_price':pred_prices, 'onehot_win':onehot_win,'split_margin':flat_margins})\n",
    "    all_price_df = all_price_df[all_price_df['prices']>1]\n",
    "    all_price_df['imp_prob'] =  all_price_df.apply(lambda x: 1/x['prices'], axis = 1)\n",
    "    all_price_df['pred_prob'] =  all_price_df.apply(lambda x: 1/x['pred_price'], axis = 1)\n",
    "    all_price_df['bet amount'] = all_price_df.apply(lambda x: (x['pred_prob']-x['imp_prob'])*100 if (x['pred_prob']>x['imp_prob'])&(1>x['imp_prob']>0) else 0, axis = 1)\n",
    "    all_price_df['profit'] = all_price_df.apply(lambda x: x['bet amount']*(x['prices']-1)*0.95 if x['onehot_win'] else -1*x['bet amount'], axis = 1)\n",
    "    all_price_df['flat_profit'] = all_price_df.apply(lambda x: 1*(x['prices']-1)*0.95 if (x['onehot_win'] and x['bet amount']) else -1, axis = 1)\n",
    "    all_price_df['colour'] = all_price_df.apply(lambda x: \"profitz\" if x['profit']>0 else (\"loss\" if x['profit']<0 else (\"no bet - win\" if x['onehot_win'] else \"no bet\")), axis=1)\n",
    "\n",
    "    all_price_table = wandb.Table(dataframe=all_price_df)\n",
    "\n",
    "\n",
    "    price_table = wandb.Table(dataframe=prices_df)\n",
    "\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        wandb.log({\"table_key\": table,\"loss_table\": loss_table,\"track_df\": track_table,\"price_table\":price_table, 'allprice_df':all_price_df })\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    #print(f\"accuray: {correct/total}\")\n",
    "    wandb.log({\"accuracy\": correct/total, \"loss_val\": torch.mean(loss_val)/len_test, \"correct\": correct, 'profit': logdf[logdf['actuals']==logdf['preds']]['profit'].sum(), 'multibet profit':all_price_df['profit'].sum(), 'multibet outlay':all_price_df['bet amount'].sum() })\n",
    "\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def validate_modelv2(model:GRUNet,raceDB:Races):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    sft_max = nn.Softmax(dim=-1)\n",
    "    batch_size=10\n",
    "    len_test = len(raceDB.raceIDs)-batch_size\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    preds = []\n",
    "    grades = []\n",
    "    tracks = []\n",
    "    pred_confs = []\n",
    "    bfsps = []\n",
    "    start_prices = []\n",
    "    loss_l = []\n",
    "    loss_t = []\n",
    "    margins_l = []\n",
    "    preds_l = []\n",
    "    pred_sftmax = []\n",
    "    raw_margins = []\n",
    "    raw_places = []\n",
    "    margins_prob = []\n",
    "\n",
    "    prices_list = []\n",
    "    raw_prices = []\n",
    "\n",
    "    price_dict = {}\n",
    "    price_dict['prices'] = []\n",
    "    price_dict['imp_prob'] = []\n",
    "    price_dict['pred_prob'] = []\n",
    "    price_dict['pred_price'] = []\n",
    "    price_dict['margin'] = []\n",
    "    price_dict['onehot_win'] = []\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0,len_test,batch_size, leave=False):\n",
    "            races_idx = range(last,last+batch_size)\n",
    "            last = i\n",
    "            race = raceDB.get_race_input(races_idx)\n",
    "            #tracks.extend([r.track for r in race])\n",
    "            X = race\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            output = model(X)\n",
    "            #print(y)\n",
    "\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            onehot_win = F.one_hot(actual, num_classes=8)\n",
    "            conf, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "\n",
    "            softmax_preds = sft_max(output)\n",
    "\n",
    "            \n",
    "            total += batch_size\n",
    "            actuals.extend(actual.tolist())\n",
    "            preds.extend(predicted.tolist())\n",
    "            pred_confs.extend(conf.tolist())\n",
    "            tracks.extend([r.track_name for r in race])\n",
    "            grades.extend([r.grade for r in race])\n",
    "            for i,dog_idx in enumerate(actual.tolist()):\n",
    "                bfsps.append(race[i].dogs[dog_idx].bfsp)\n",
    "                #start_prices.append(race[i].dogs[dog_idx].sp)\n",
    "\n",
    "\n",
    "            price_dict['prices'].extend([x.prices for x in race])\n",
    "            price_dict['imp_prob'].extend([x.implied_prob for x in race])\n",
    "            price_dict['pred_prob'].extend(softmax_preds.tolist())\n",
    "            #print([(1/(x+(-7**10))).tolist() for x in torch.exp(output)])\n",
    "            price_dict['pred_price'].extend([(1/(x)).tolist() for x in softmax_preds])\n",
    "            price_dict['margin'].extend([x.raw_margins for x in race])\n",
    "            price_dict['onehot_win'].extend(onehot_win.tolist())\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    logdf = pd.DataFrame(data = {\"actuals\":actuals, \"preds\":preds,\"conf\":pred_confs, \"grade\":grades, \"track\":tracks, \"bfsps\":bfsps})#, \"sp\":start_prices })\n",
    "    \n",
    "    logdf['correct'] = logdf.apply(lambda x: 1 if x['actuals']==x['preds'] else 0, axis=1)\n",
    "    logdf['profit'] = logdf.apply(lambda x: 0 if x['bfsps']<1 else x['bfsps']-1  if x['correct'] else -1, axis=1)\n",
    "    logdf.to_csv('logDFtest.csv')\n",
    "\n",
    "    table = wandb.Table(dataframe=logdf)\n",
    "\n",
    "    logdf['count'] = 1\n",
    "    logdf['eligible_ct'] = logdf.apply(lambda x: 1 if x['bfsps'] > 1 else 0, axis = 1)\n",
    "\n",
    "    track_df = logdf.groupby('track', as_index=False).sum().reset_index()\n",
    "    \n",
    "    prices_df = pd.DataFrame(price_dict)\n",
    "\n",
    "\n",
    "    prices_df['sum_price'] = prices_df.apply(lambda x: sum(x['prices']), axis = 1)\n",
    "    prices_df = prices_df[prices_df['sum_price']>0]\n",
    "\n",
    "    prices_flat = [item for sublist in prices_df['prices'].tolist() for item in sublist]\n",
    "    pred_prices = [item for sublist in prices_df['pred_price'].tolist() for item in sublist]\n",
    "    onehot_win  = [item for sublist in prices_df['onehot_win'].tolist() for item in sublist]\n",
    "    flat_margins = [item for sublist in prices_df['margin'].tolist() for item in sublist]\n",
    "    all_price_df = pd.DataFrame(data={'prices':prices_flat, 'pred_price':pred_prices, 'onehot_win':onehot_win,'split_margin':flat_margins})\n",
    "    all_price_df = all_price_df[all_price_df['prices']>1]\n",
    "    all_price_df['imp_prob'] =  all_price_df.apply(lambda x: 1/x['prices'], axis = 1)\n",
    "    all_price_df['pred_prob'] =  all_price_df.apply(lambda x: 1/x['pred_price'], axis = 1)\n",
    "    all_price_df['bet amount'] = all_price_df.apply(lambda x: (x['pred_prob']-x['imp_prob'])*100 if (x['pred_prob']>x['imp_prob'])&(1>x['imp_prob']>0) else 0, axis = 1)\n",
    "    all_price_df['profit'] = all_price_df.apply(lambda x: x['bet amount']*(x['prices']-1)*0.95 if x['onehot_win'] else -1*x['bet amount'], axis = 1)\n",
    "    all_price_df['flat_profit'] = all_price_df.apply(lambda x: 1*(x['prices']-1)*0.95 if (x['onehot_win'] and x['bet amount']) else -1, axis = 1)\n",
    "    all_price_df['colour'] = all_price_df.apply(lambda x: \"profitz\" if x['profit']>0 else (\"loss\" if x['profit']<0 else (\"no bet - win\" if x['onehot_win'] else \"no bet\")), axis=1)\n",
    "\n",
    "\n",
    "    #print(f\"accuray: {correct/total}\")\n",
    "    stats = {\"accuracy\": correct/total,  \"correct\": correct, 'profit': logdf[logdf['actuals']==logdf['preds']]['profit'].sum(), 'multibet profit':all_price_df['profit'].sum(), 'multibet outlay':all_price_df['bet amount'].sum() }\n",
    "    print(stats)\n",
    "    return all_price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, raceDB:Races, criterion, optimizer,scheduler, config=None):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    last = 0\n",
    "    batch_size = 25\n",
    "    len_train = len(raceDB.train_race_ids)-batch_size\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    m = nn.LogSoftmax(dim=1)\n",
    "    epoch_loss=0\n",
    "    batch_before_backwards = 10\n",
    "    #losses = torch.tesnor()\n",
    "    for epoch in trange(2000):\n",
    "        model.train()\n",
    "        batch_ct = 0\n",
    "        setup_loss = 1\n",
    "\n",
    "        \n",
    "        for i in trange(0,len_train,batch_size, leave=False):\n",
    "            last = i\n",
    "            #print(f\"{i=}\\n{batch_ct=}, {setup_loss=}, {batch_ct+1%10==0=}\")\n",
    "            if ((batch_ct+1)%batch_before_backwards==0):\n",
    "                if setup_loss:\n",
    "                    print(\"hit here\")\n",
    "                    continue\n",
    "                else:\n",
    "                    epoch_loss = torch.mean(epoch_loss)\n",
    "                    optimizer.zero_grad()\n",
    "                    epoch_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    model.zero_grad()\n",
    "                    raceDB.detach_all_hidden_states()\n",
    "                    setup_loss = 1\n",
    "                    wandb.log({\"batch_loss\": epoch_loss.item(), \"batch_before_backwards\": batch_before_backwards}, step = example_ct)\n",
    "                    batch_before_backwards = randint(5,20)\n",
    "\n",
    "            batch_ct += 1\n",
    "\n",
    "            races_idx = range(last,last+batch_size)\n",
    "            race = raceDB.get_train_input(races_idx)\n",
    "            X = race\n",
    "            y = torch.stack([x.classes for x in race])\n",
    "            w = torch.stack([x.win_weight for x in race])\n",
    "            _, actual = torch.max(y.data, 1)\n",
    "            output = model(X)\n",
    "\n",
    "            \n",
    "            example_ct +=  batch_size\n",
    "\n",
    "            loss = criterion(output, y)*w\n",
    "            if setup_loss:\n",
    "                epoch_loss = loss\n",
    "                setup_loss=0\n",
    "\n",
    "            if ((batch_ct + 1) % 25) == 0:                    \n",
    "                    train_log(torch.mean(loss), example_ct, epoch)\n",
    "\n",
    "            #epoch_loss = torch.stack([epoch_loss, loss])\n",
    "            epoch_loss = epoch_loss + loss\n",
    "            \n",
    "\n",
    "        #print(\"finished epoch\")\n",
    "        setup_loss = 1\n",
    "\n",
    "        wandb.log({\"epoch_loss\": torch.mean(epoch_loss)}, step = example_ct)\n",
    "        acc = validate_model(model,raceDB,criterion, 8, example_ct, epoch_loss, batch_ct)\n",
    "        epoch_loss = 0  \n",
    "        #print(acc)\n",
    "        scheduler.step(acc)\n",
    "    #print(losses)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features_per_dog=16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7b9e53d0bb4ca8a83625ef5fc51846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'prev_race'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3080\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3081\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index.pyx:101\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:4554\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:4562\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prev_race'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\GRU - WANDB - priced - Fasttrack v5.4 NZ.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20Fasttrack%20v5.4%20NZ.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dog_stats_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m( \u001b[39m'\u001b[39m\u001b[39mdog_stats_df_FASTTRACK new margins.npy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20Fasttrack%20v5.4%20NZ.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m hidden_size \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20Fasttrack%20v5.4%20NZ.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m raceDB \u001b[39m=\u001b[39m build_dataset(dog_stats_file, hidden_size)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\raceDB.py:102\u001b[0m, in \u001b[0;36mbuild_dataset\u001b[1;34m(data, hidden_size)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[39m#j[\"prev_race\"] = j[\"raceid\"].shift(1).fillna(-1)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     raceDB\u001b[39m.\u001b[39madd_dog(i, j\u001b[39m.\u001b[39mdog_name\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> 102\u001b[0m     j\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: raceDB\u001b[39m.\u001b[39;49mdogsDict[i]\u001b[39m.\u001b[39;49madd_races(x[\u001b[39m'\u001b[39;49m\u001b[39mraceid\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m], torch\u001b[39m.\u001b[39;49mTensor(x[\u001b[39m'\u001b[39;49m\u001b[39mstats\u001b[39;49m\u001b[39m'\u001b[39;49m]),x[\u001b[39m'\u001b[39;49m\u001b[39mnext_race\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mprev_race\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mbox\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mbfSP\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mstartprice\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    104\u001b[0m \u001b[39m#Fill in races portion\u001b[39;00m\n\u001b[0;32m    105\u001b[0m softmin \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSoftmin(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py:7768\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7757\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   7759\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   7760\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   7761\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   7766\u001b[0m     kwds\u001b[39m=\u001b[39mkwds,\n\u001b[0;32m   7767\u001b[0m )\n\u001b[1;32m-> 7768\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\apply.py:185\u001b[0m, in \u001b[0;36mFrameApply.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 185\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\apply.py:276\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 276\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    278\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\apply.py:290\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    288\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    289\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    291\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    292\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    293\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    294\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\raceDB.py:102\u001b[0m, in \u001b[0;36mbuild_dataset.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[39m#j[\"prev_race\"] = j[\"raceid\"].shift(1).fillna(-1)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     raceDB\u001b[39m.\u001b[39madd_dog(i, j\u001b[39m.\u001b[39mdog_name\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> 102\u001b[0m     j\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: raceDB\u001b[39m.\u001b[39mdogsDict[i]\u001b[39m.\u001b[39madd_races(x[\u001b[39m'\u001b[39m\u001b[39mraceid\u001b[39m\u001b[39m'\u001b[39m], x[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m], torch\u001b[39m.\u001b[39mTensor(x[\u001b[39m'\u001b[39m\u001b[39mstats\u001b[39m\u001b[39m'\u001b[39m]),x[\u001b[39m'\u001b[39m\u001b[39mnext_race\u001b[39m\u001b[39m'\u001b[39m], x[\u001b[39m'\u001b[39;49m\u001b[39mprev_race\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39m\u001b[39mbox\u001b[39m\u001b[39m'\u001b[39m], x[\u001b[39m'\u001b[39m\u001b[39mbfSP\u001b[39m\u001b[39m'\u001b[39m], x[\u001b[39m'\u001b[39m\u001b[39mstartprice\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[39m#Fill in races portion\u001b[39;00m\n\u001b[0;32m    105\u001b[0m softmin \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSoftmin(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\series.py:853\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    850\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    852\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\series.py:961\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m    960\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m--> 961\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m    962\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3082\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3081\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3082\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[39mif\u001b[39;00m tolerance \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     tolerance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_tolerance(tolerance, np\u001b[39m.\u001b[39masarray(key))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prev_race'"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( 'dog_stats_df_FASTTRACK new margins.npy', 'rb')\n",
    "hidden_size = 64\n",
    "raceDB = build_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features_per_dog=16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284e8396fcc3465db37e920f065d7e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/811 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada52b47e40648728474b13bd0112c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 280, number of unique dogs = 811\n"
     ]
    }
   ],
   "source": [
    "dog_stats_file = open( r'C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\prediction validation 2023-01.npy', 'rb')\n",
    "hidden_size = 64\n",
    "predDB = build_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973c68e563904e6db09ec787b25c34bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/363 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320e08a7fb284ae4bfb2077e02aa2b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of races = 48, number of unique dogs = 363\n"
     ]
    }
   ],
   "source": [
    "# #os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "# dog_stats_file = open( r'C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\forms\\prediction_inputs_gru.npy', 'rb')\n",
    "# hidden_size = 64\n",
    "# predDB = build_pred_dataset(dog_stats_file, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.create_hidden_states_dict()\n",
    "predDB.fill_hidden_states_from_dict(hidden_dict=raceDB.hidden_states_dict)\n",
    "# len(raceDB.hidden_states_dict)\n",
    "# predDB.to_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def predict_model(model,predDB):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    list_t = [] \n",
    "    last = 0\n",
    "    loss_val = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        races_idx = range(0,len(predDB.raceIDs)-1)\n",
    "        race = predDB.get_race_input(races_idx)\n",
    "        X = race\n",
    "        # for i,r in enumerate(race):\n",
    "        #     print(r.raceid, r.track_name)\n",
    "        #     #print(i,r.lstm_input())\n",
    "\n",
    "        output = model(X)\n",
    "        \n",
    "        print(output)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        for i,r in enumerate(race):\n",
    "            print(r.raceid, r.track_name, r.dogs[predicted[i].item()])\n",
    "\n",
    "        print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8130, 0.8508, 0.8918, 0.8742, 0.9023, 0.9040, 0.8893, 0.8746],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "#os.chdir(r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\")\n",
    "dog_stats_file = open( r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\DATA\\dog_stats_df_FASTTRACK new margins.npy\", 'rb')\n",
    "resultsdf = pickle.load(dog_stats_file)\n",
    "dog_stats_df = pd.DataFrame(resultsdf)\n",
    "dog_stats_df = dog_stats_df.sort_values('date')\n",
    "dog_stats_df['box'] = dog_stats_df['stats'].apply(lambda x: x[0])\n",
    "dog_stats_df\n",
    "weights = (1-(dog_stats_df[dog_stats_df['place']==1]['box'].value_counts(sort=False)/len(dog_stats_df[dog_stats_df['place']==1]))).tolist()\n",
    "weights = torch.tensor(weights).to(device)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure(optimizer, criterion, outs, classes):\n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.functional.mse_loss(outs, classes)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def model_pipeline(my_dataset=raceDB,config=None,prev_model=None, sweep=True, model_state_dict=None):\n",
    "    if my_dataset:\n",
    "      dataset = my_dataset    \n",
    "    else:\n",
    "      dataset = raceDB\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"GRU - FastTrack - NZ Testing\", config=config):\n",
    "      #  access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "\n",
    "      model = GRUNet(203,config['hidden_size'])\n",
    "      if model_state_dict:\n",
    "        model.load_state_dict(model_state_dict)\n",
    "      #criterion = nn.KLDivLoss(reduction='none', log_target=True)\n",
    "      criterion = nn.CrossEntropyLoss(reduction='none', label_smoothing=0.01 )\n",
    "      optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "      scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',threshold=0.001, patience=50, verbose=True, factor=0.5)\n",
    "      model = model.to(device)\n",
    "      # optimizer = optimizer.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      try:\n",
    "        train(model, dataset, criterion, optimizer, scheduler, config)\n",
    "      except KeyboardInterrupt:\n",
    "        print(\"finished Early\")\n",
    "      dataset.create_hidden_states_dict()\n",
    "      # if sweep:\n",
    "    #   raceDB.reset_all_lstm_states\n",
    "    \n",
    "\n",
    "\n",
    "    # and test its final performance\n",
    "    #test(model, test_loader)\n",
    "\n",
    "    return (model,dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raceDB.raceIDs)\n",
    "wandb_config_static = {'hidden_size':hidden_size,'batch_size': 500, 'dropout': 0.3, 'epochs': 1000, 'f1_layer_size': 256, 'f2_layer_size': 64 , 'learning_rate': 0.0001, 'loss': 'L1', 'l1_beta':0.1,  'num_layers': 2, 'optimizer': 'adamW', 'validation_split': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceDB.detach_all_hidden_states()\n",
    "raceDB.create_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"profit\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adamW\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3]},\n",
    "    \"len_data\": {\"value\": 70000},\n",
    "    \"hidden_size\": {\"value\":16}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [250]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            \"values\": [ \"L1\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            # 'value': 'l1_custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00011,\n",
    "            \"max\": 0.001,\n",
    "        },\n",
    "        \"l1_beta\": {\"value\": 0.1\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'values': [500,1000,5000]\n",
    "            # \"values\": [32, 64, 128, 360, 720]\n",
    "            # 'values':[4,8,16,32,64,128,360]\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDB.to_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\savedmodel\\test NZ GRU saver\\test NZ GRU saver_450.pt\"\n",
    "saved_dict = torch.load(save_path)\n",
    "model_state_dict = saved_dict['model_state_dict']\n",
    "raceDB.fill_hidden_states_from_dict(saved_dict['db'])\n",
    "raceDB.to_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ae1c7387c749a4a96bfd661d32789d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.24444444444444444, 'correct': 66, 'profit': 149.28543054356447, 'multibet profit': 520.4581391270249, 'multibet outlay': 5837.803125666966}\n"
     ]
    }
   ],
   "source": [
    "all_price_df = validate_modelv2(model, predDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'raw_prices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\LSTM\\GRU - WANDB - priced - Fasttrack v5.4 NZ.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/LSTM/GRU%20-%20WANDB%20-%20priced%20-%20Fasttrack%20v5.4%20NZ.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_race \u001b[39m=\u001b[39m raceDB\u001b[39m.\u001b[39;49mget_race_input([\u001b[39m100\u001b[39;49m,\u001b[39m200\u001b[39;49m])\u001b[39m.\u001b[39;49mraw_prices\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'raw_prices'"
     ]
    }
   ],
   "source": [
    "(model,dataset, optimizer) = model_pipeline(raceDB,config=wandb_config_static, prev_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1383, 10)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# \n",
    "# \n",
    "# all_price_df[all_price_df['onehot_win']==1].sort_values('prices', ascending=False).shape\n",
    "all_price_df.sort_values('prices', ascending=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset.create_hidden_states_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    }
   ],
   "source": [
    "model_saver(model, optimizer, 450, 0.1, dataset.hidden_states_dict, model_name=\"Good profit NZ after test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDB.fill_hidden_states_from_dict(hidden_dict=dataset.hidden_states_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"LSTM_sweeps\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43115443075634c02a7c247a87b0dd9d74842892e56d473b9e19f544f3149aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
