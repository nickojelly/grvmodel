{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "with torch.profiler.profile() as profiler:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluded =  0\n"
     ]
    }
   ],
   "source": [
    "REBUILD_DATA = True\n",
    "\n",
    "\n",
    "class GRV:\n",
    "    # class to store training data\n",
    "\n",
    "    # reading data from pickle\n",
    "    file = open(r\"DATA/total_list_w_price_bf.npy\", \"rb\")\n",
    "    data = pickle.load(file)\n",
    "    # seperate out classes from inputs\n",
    "    raceIDs, inputs, classes, prices, win_price, margins, betfairSP = zip(*data)\n",
    "    # removing nan from inputs and convert to float\n",
    "    inputs_df = pd.DataFrame(inputs)\n",
    "    inputs_df.fillna(value=-1, inplace=True)\n",
    "    inputs = inputs_df.values.tolist()\n",
    "    inputs = [[float(i) for i in j] for j in inputs]\n",
    "\n",
    "    # data\n",
    "    training_data = []\n",
    "\n",
    "    def make_training_data(self):\n",
    "        excluded = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            if len(self.classes[i]) == 8:\n",
    "                self.training_data.append(\n",
    "                    [\n",
    "                        np.array(self.inputs[i]),\n",
    "                        np.array(self.classes[i]),\n",
    "                        np.array(self.prices[i]),\n",
    "                        np.array(self.margins[i]),\n",
    "                        np.array(self.betfairSP[i]),\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                adjustedList = self.classes[i] + ([8] * (8 - len(self.classes[i])))\n",
    "                adjustedListP = self.prices[i] + ([0] * (8 - len(self.prices[i])))\n",
    "                adjustedListM = self.margins[i] + ([100] * (8 - len(self.margins[i])))\n",
    "                adjustedListSP = self.margins[i] + ([0] * (8 - len(self.betfairSP[i])))\n",
    "                self.training_data.append(\n",
    "                    [\n",
    "                        np.array(self.inputs[i]),\n",
    "                        np.array(adjustedList),\n",
    "                        np.array(adjustedListP),\n",
    "                        np.array(adjustedListM),\n",
    "                        np.array(adjustedListSP)\n",
    "                    ]\n",
    "                )\n",
    "                if len(adjustedList) != 8:\n",
    "                    print(adjustedList)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"excluded = \", excluded)\n",
    "\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    grv = GRV()\n",
    "    grv.make_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_6712\\2102313497.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  Y_w = torch.tensor([i for i in Y_w])\n"
     ]
    }
   ],
   "source": [
    "softmin = nn.Softmin(dim=1)\n",
    "\n",
    "# dataset setup\n",
    "training_data = grv.training_data\n",
    "\n",
    "X = torch.Tensor(np.array([i[0] for i in training_data]))\n",
    "Y = torch.Tensor(np.array([i[1] for i in training_data]))\n",
    "P = torch.Tensor(np.array([i[2] for i in training_data]))\n",
    "Y_m = softmin(torch.Tensor(np.array([i[3] for i in training_data])))\n",
    "bfSP = torch.Tensor(np.array([i[4] for i in training_data]))\n",
    "\n",
    "# Generate winner only class\n",
    "Y_w = []\n",
    "for i in Y:\n",
    "    n = np.zeros(8)\n",
    "    index = torch.argmin(i)\n",
    "    n[index] = float(1)\n",
    "    Y_w.append(n)\n",
    "\n",
    "Y_w = torch.tensor([i for i in Y_w])\n",
    "X = X.to(device)\n",
    "Y_w = Y_w.to(device)\n",
    "\n",
    "\n",
    "Y_m = Y_m.to(device)\n",
    "P = P.to(device)\n",
    "bfSP = bfSP.to('cuda')\n",
    "bfSP = torch.nan_to_num(bfSP, nan=0)\n",
    "my_dataset = TensorDataset(X, Y_m, P, bfSP)\n",
    "my_dataloader = DataLoader(my_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to pass in dataset to get_data (created above)\n",
    "def make_loader(dataset, config, train=True):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(config[\"validation_split\"] * dataset_size))\n",
    "    random_seed = 42\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    if train:\n",
    "        dataset_sampler = SubsetRandomSampler(train_indices)\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "            num_workers=0,\n",
    "            sampler=dataset_sampler\n",
    "        )\n",
    "    else:\n",
    "        dataset_sampler = SubsetRandomSampler(val_indices)\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "            num_workers=0,\n",
    "            sampler=dataset_sampler,\n",
    "        )\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(f1_layer_size, f2_layer_size, dropout, num_layers=2):\n",
    "\n",
    "    if num_layers == 2:\n",
    "        network = nn.Sequential(  # fully-connected, dual hidden layer\n",
    "            nn.Linear(120, f1_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f1_layer_size, f2_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f2_layer_size, 8),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        network = nn.Sequential(  # fully-connected, dual hidden layer\n",
    "            nn.Linear(120, f1_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f1_layer_size, f2_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f2_layer_size, f2_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(f2_layer_size, 8),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_MSE(output, target):\n",
    "    sorts = torch.argsort(target)\n",
    "    out = sorts.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    out_first3 = ohe*output\n",
    "    target_ohe = ohe*target\n",
    "    loss = torch.sum((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "    # loss = torch.sum(((out_first3-target_ohe))**2)\n",
    "    return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_order_MSE(output, target):\n",
    "    sorts = torch.argsort(target)\n",
    "    out = sorts.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    out_first3 = ohe*output\n",
    "    target_ohe = ohe*target\n",
    "    loss = torch.mean(((abs(out_first3-target_ohe)*10)**2))\n",
    "    # loss = torch.sum(((out_first3-target_ohe))**2)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_customiser(x,y,loss_func=nn.HuberLoss(reduction='none',delta=0.1)):\n",
    "    sorts_t = torch.argsort(y)\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    loss = loss_func(x,y)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config, dataset):\n",
    "    # Make the data\n",
    "\n",
    "    train_loader = make_loader(dataset, config, train=True)\n",
    "    test_loader = make_loader(dataset, config, train=False)\n",
    "    # Make the model\n",
    "    # model = Net().to(device)\n",
    "    model = build_network(\n",
    "        config[\"f1_layer_size\"], config[\"f2_layer_size\"], config[\"dropout\"], config[\"num_layers\"]\n",
    "    )\n",
    "\n",
    "    loss_functions = {\n",
    "        \"Huber\":nn.HuberLoss(),\n",
    "        \"Huber_custom\":loss_customiser,\n",
    "        \"MSE\":nn.MSELoss(),\n",
    "        \"L1\":nn.SmoothL1Loss(reduction='sum', beta=config[\"l1_beta\"]),\n",
    "        \"BCE\":nn.CrossEntropyLoss(),\n",
    "        \"Custom\":custom_MSE,\n",
    "        \"KL\":nn.KLDivLoss(reduction='batchmean'),\n",
    "        \"NLL\":nn.NLLLoss()\n",
    "    }\n",
    "    # Make the loss and optimizer\n",
    "    #  criterion = nn.NLLLoss()\n",
    "    loss_f = loss_functions[config['loss']]\n",
    "    criterion = loss_f\n",
    "    optimizer = config[\"optimizer\"]\n",
    "\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(), lr=config[\"learning_rate\"], momentum=0.9\n",
    "        )\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "    return model, train_loader, test_loader, criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, batch_ct):\n",
    "    model.eval()\n",
    "    classL, predL, maxL, correctL, priceP, priceR, bfPriceR, pred_odds, model_outputs = [], [], [], [], [], [], [], [], []\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total, max_sum, max_w_sum, profit, bfprofit, bfnotavail = 0, 0, 0, 0, 0,0,0\n",
    "        value_pick_correct, value_pick_profit = 0, 0\n",
    "        num_bets = 0\n",
    "        for images, labels, prices, bfspPrices in test_loader:\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            #converts prices from tensor to list\n",
    "            prices = prices[0,].tolist()\n",
    "            bfspPrices = bfspPrices[0,].tolist()\n",
    "\n",
    "            #gets the prediction and its confidence and the real class\n",
    "            max, predicted = torch.max(outputs.data, 1)\n",
    "            _, real = torch.max(labels.data, 1)\n",
    "\n",
    "            #converts prediction from tensor to item\n",
    "            prediction = predicted.item()\n",
    "            real_item = real.item()\n",
    "\n",
    "            #appends prediction and likelyhood to lists\n",
    "            predL.append(prediction)\n",
    "            maxL.append(max.item())\n",
    "\n",
    "        \n",
    "            total += labels.size(0)\n",
    "            correct += prediction == real_item\n",
    "\n",
    "            correctL.append(int(prediction == real_item))\n",
    "            classL.append(real_item)\n",
    "\n",
    "            priceR.append(prices[real_item])\n",
    "            priceP.append(prices[prediction])\n",
    "            bfPriceR.append(bfspPrices[real_item])\n",
    "            # print(outputs.data.flatten().tolist())\n",
    "\n",
    "            predicted_odds = [\n",
    "                1 / ((x + 10**-7)) for x in outputs.data.flatten().tolist()\n",
    "            ]\n",
    "\n",
    "            pred_odds.append(predicted_odds)\n",
    "            model_outputs.append(outputs.data.flatten().tolist())\n",
    "\n",
    "            if prices[real_item] > (predicted_odds[real_item] ):\n",
    "                value_pick_correct += 1\n",
    "                value_pick_profit += prices[real_item]\n",
    "\n",
    "            bets = [x > (y) for x, y in zip(prices, predicted_odds)]\n",
    "            num_bets += sum(bets)\n",
    "\n",
    "            value_pick_profit += -sum(bets)\n",
    "\n",
    "            if prediction == real_item:\n",
    "                max_sum += max\n",
    "                profit += prices[real_item]\n",
    "                if bfspPrices[real_item]:\n",
    "                    bfprofit += bfspPrices[real_item]\n",
    "                else:\n",
    "                    bfprofit += prices[real_item]\n",
    "                    bfnotavail += 1\n",
    "            else:\n",
    "                max_w_sum += max\n",
    "\n",
    "            profit += -1\n",
    "            bfprofit += -1\n",
    "\n",
    "            # print(f\"{correct=}\")\n",
    "\n",
    "        # print(f\"Accuracy of the model on the {total} \" +\n",
    "        #       f\"test images: {100 * correct / total}%\" +\n",
    "        #       f\"profit: {profit}\"+\n",
    "        #       f\"profit: {value_pick_profit}\")\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"test_accuracy\": correct / total,\n",
    "                \"correct_conf\": max_sum / correct,\n",
    "                \"incorrect_conf\": (max_w_sum) / (total - correct),\n",
    "                \"profit\": profit,\n",
    "                \"bfprofit\": bfprofit,\n",
    "                \"bfnotavail\": bfnotavail,\n",
    "                \"value_pick_roi\": value_pick_profit / num_bets,\n",
    "                \"num_bets_per\": num_bets / total,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # logdf = pd.DataFrame(\n",
    "        #     data={\n",
    "        #         \"class\": classL,\n",
    "        #         \"pred\": predL,\n",
    "        #         \"max\": maxL,\n",
    "        #         \"correct\": correctL,\n",
    "        #         \"priceR\": priceR,\n",
    "        #         \"priceP\": priceP,\n",
    "        #         \"bets\": sum(bets),\n",
    "        #         \"pred_odds\": pred_odds,\n",
    "        #         \"model_outputs\": model_outputs,\n",
    "        #         \"bfodds\" : bfPriceR\n",
    "        #     }\n",
    "        # )\n",
    "        # table = wandb.Table(dataframe=logdf)\n",
    "        # wandb.log({\"table_key\": table})\n",
    "        # classCounts = logdf[\"class\"].value_counts()\n",
    "        # predCounts = logdf[\"pred\"].value_counts()\n",
    "        # boxplot = logdf.boxplot(column=['priceR'],by='correct')\n",
    "        # print(classCounts, predCounts)\n",
    "        # boxplot\n",
    "        # plt.savefig(\"boxplot.png\")\n",
    "        # wandb.log({\"boxplot\":boxplot})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
    "    #print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_saver(model, optimizer, epoch, loss):\n",
    "    \n",
    "    pathtofolder = \"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model\"\n",
    "    model_name = wandb.run.name\n",
    "    isExist = os.path.exists(\n",
    "        f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "    )\n",
    "    if isExist:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )\n",
    "    else:\n",
    "        print(\"created path\")\n",
    "        os.makedirs(\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/\"\n",
    "        )\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"loss\": loss,\n",
    "            },\n",
    "            f\"C:/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New Model/savedmodel/{model_name}/{model_name}_{epoch}.pt\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader,test_loader, criterion, optimizer, config):\n",
    "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Run training and track with wandb\n",
    "    total_batches = len(loader) * config.epochs\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "\n",
    "    raw_inputs = True\n",
    "    if config['loss'] == \"KL\":\n",
    "\n",
    "        for epoch in tqdm(range(config.epochs)):\n",
    "            for _, (images, labels, _ , _) in enumerate(loader):\n",
    "\n",
    "                loss = train_batch_lsftmax(images, labels, model, optimizer, criterion, btch_count=batch_ct, raw_inputs=True)\n",
    "                example_ct +=  len(images)\n",
    "                batch_ct += 1\n",
    "\n",
    "                # Report metrics every 25th batch\n",
    "                if ((batch_ct + 1) % 250) == 0:\n",
    "                    train_log(loss, example_ct, epoch)\n",
    "                    \n",
    "\n",
    "            if epoch %10 ==0:\n",
    "                test(model,test_loader, epoch)\n",
    "                model_saver(model,optimizer,epoch,loss)\n",
    "\n",
    "    else:\n",
    "        for epoch in tqdm(range(config.epochs)):\n",
    "            for _, (images, labels, _ , _) in enumerate(loader):\n",
    "\n",
    "                loss = train_batch(images, labels, model, optimizer, criterion, btch_count=batch_ct, raw_inputs=True)\n",
    "                example_ct +=  len(images)\n",
    "                batch_ct += 1\n",
    "\n",
    "                # Report metrics every 25th batch\n",
    "                if ((batch_ct + 1) % 250) == 0:\n",
    "                    train_log(loss, example_ct, epoch)\n",
    "\n",
    "            if epoch %10 ==0:\n",
    "                test(model,test_loader, epoch)\n",
    "                model_saver(model, optimizer, epoch, loss)\n",
    "\n",
    "def train_batch(images, labels, model, optimizer, criterion, btch_count=0, raw_inputs=True):\n",
    "    images, labels = images, labels\n",
    "    \n",
    "\n",
    "    # Forward pass ➡\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels.float())\n",
    "    \n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_batch_lsftmax(images, labels, model, optimizer, criterion, btch_count=0, raw_inputs=True):\n",
    "    images, labels = images, labels\n",
    "    \n",
    "\n",
    "    # Forward pass ➡\n",
    "    outputs = model(images)\n",
    "    loss = criterion(F.log_softmax(outputs), labels.float())\n",
    "    \n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(config=None,prev_model=None):\n",
    "    dataset = my_dataset\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"new customs\", config=config):\n",
    "      # access all HPs through wandb.config, so logging matches execution!\n",
    "      wandb.define_metric(\"loss\", summary=\"min\")\n",
    "      wandb.define_metric(\"test_accuracy\", summary=\"max\")\n",
    "      wandb.define_metric(\"bfprofit\", summary=\"max\")\n",
    "      config = wandb.config\n",
    "      pprint.pprint(config)\n",
    "      pprint.pprint(config.epochs)\n",
    "      print(config)\n",
    "\n",
    "      # make the model, data, and optimization problem\n",
    "      model, train_loader, test_loader, criterion, optimizer = make(config, dataset)\n",
    "      if prev_model:\n",
    "        print(\"here\")\n",
    "        model.load_state_dict(torch.load(prev_model), strict = False)\n",
    "      model = model.to(device)\n",
    "      print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      train(model, train_loader,test_loader, criterion, optimizer, config)\n",
    "\n",
    "      # and test its final performance\n",
    "      #test(model, test_loader)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'profit'},\n",
      " 'parameters': {'batch_size': {'value': 32},\n",
      "                'dropout': {'values': [0.3, 0.4, 0.5]},\n",
      "                'epochs': {'values': [500]},\n",
      "                'f1_layer_size': {'values': [64]},\n",
      "                'f2_layer_size': {'values': [64]},\n",
      "                'l1_beta': {'distribution': 'uniform', 'max': 1, 'min': 0},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.0005,\n",
      "                                  'min': 5e-05},\n",
      "                'loss': {'value': 'L1'},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adam'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'metric': {'name': 'profit', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adam'},\n",
       "  'f1_layer_size': {'values': [64]},\n",
       "  'f2_layer_size': {'values': [64]},\n",
       "  'dropout': {'values': [0.3, 0.4, 0.5]},\n",
       "  'epochs': {'values': [500]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'value': 'L1'},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 5e-05, 'max': 0.0005},\n",
       "  'l1_beta': {'distribution': 'uniform', 'min': 0, 'max': 1},\n",
       "  'batch_size': {'value': 32}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"profit\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adam\"},\n",
    "    \"f1_layer_size\": {\"values\": [64]},\n",
    "    \"f2_layer_size\": {\"values\": [64]},\n",
    "    \"dropout\": {\"values\": [0.3, 0.4, 0.5]},\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [500]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            'value': 'L1'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00005,\n",
    "            \"max\": 0.0005,\n",
    "        },\n",
    "        \"l1_beta\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0,\n",
    "            \"max\": 1,\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            'value': 32\n",
    "            # \"values\": [32, 64, 128, 360,720]\n",
    "            # 'values':[4,8,16,32,64,128,360]\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'profit'},\n",
      " 'parameters': {'batch_size': {'values': [32, 64, 128, 360, 720]},\n",
      "                'dropout': {'values': [0.3, 0.4, 0.5]},\n",
      "                'epochs': {'values': [500]},\n",
      "                'f1_layer_size': {'values': [256]},\n",
      "                'f2_layer_size': {'values': [256]},\n",
      "                'l1_beta': {'distribution': 'uniform', 'max': 1, 'min': 0},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.0005,\n",
      "                                  'min': 5e-05},\n",
      "                'loss': {'value': 'Custom'},\n",
      "                'num_layers': {'values': [2]},\n",
      "                'optimizer': {'value': 'adam'},\n",
      "                'validation_split': {'value': 0.1}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'method': 'random',\n",
       " 'metric': {'name': 'profit', 'goal': 'maximize'},\n",
       " 'parameters': {'optimizer': {'value': 'adam'},\n",
       "  'f1_layer_size': {'values': [256]},\n",
       "  'f2_layer_size': {'values': [256]},\n",
       "  'dropout': {'values': [0.3, 0.4, 0.5]},\n",
       "  'epochs': {'values': [500]},\n",
       "  'validation_split': {'value': 0.1},\n",
       "  'loss': {'value': 'Custom'},\n",
       "  'num_layers': {'values': [2]},\n",
       "  'learning_rate': {'distribution': 'uniform', 'min': 5e-05, 'max': 0.0005},\n",
       "  'l1_beta': {'distribution': 'uniform', 'min': 0, 'max': 1},\n",
       "  'batch_size': {'values': [32, 64, 128, 360, 720]}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"profit\", \"goal\": \"maximize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"value\": \"adam\"},\n",
    "    \"f1_layer_size\": {\"values\": [256]},\n",
    "    \"f2_layer_size\": {\"values\": [256]},\n",
    "    \"dropout\": {\"values\": [0.3, 0.4, 0.5]},\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"epochs\": {\"values\": [500]},\n",
    "        \"validation_split\": {\"value\": 0.1},\n",
    "        \"loss\": {\n",
    "            # \"values\": [ \"L1\",  \"Custom\", \"KL\"],\n",
    "            # \"values\": [\"Huber\", \"MSE\", \"L1\", \"BCE\", \"Custom\", \"KL\"]\n",
    "            'value': 'Custom'\n",
    "        },\n",
    "        \"num_layers\": {\"values\": [2]},\n",
    "    }\n",
    ")\n",
    "\n",
    "parameters_dict.update(\n",
    "    {\n",
    "        \"learning_rate\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0.00005,\n",
    "            \"max\": 0.0005,\n",
    "        },\n",
    "        \"l1_beta\": {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            \"distribution\": \"uniform\",\n",
    "            \"min\": 0,\n",
    "            \"max\": 1,\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            # 'value': 1000\n",
    "            \"values\": [32, 64, 128, 360,720]\n",
    "            # 'values':[4,8,16,32,64,128,360]\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)\n",
    "\n",
    "\n",
    "sweep_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_124939-9ncsg0qd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/new%20customs/runs/9ncsg0qd\" target=\"_blank\">unique-hill-3</a></strong> to <a href=\"https://wandb.ai/nickojelly/new%20customs\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 250, 'f1_layer_size': 128, 'f2_layer_size': 128, 'learning_rate': 0.0001, 'loss': 'Huber_custom', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "250\n",
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 250, 'f1_layer_size': 128, 'f2_layer_size': 128, 'learning_rate': 0.0001, 'loss': 'Huber_custom', 'l1_beta': 0.1, 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=128, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/250 [00:16<1:09:10, 16.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [31:21<00:00,  7.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c26b0ba1354d40a77addc72b4c27fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▇█████▇▇▇▇▇▇▇▇▇▇▆▆▇▆▆▆▆▆</td></tr><tr><td>bfprofit</td><td>▁▄▄▄▇▇▇▄█▆█▆▆▇▅▆▆▅▇█▄▇▇▄▄</td></tr><tr><td>correct_conf</td><td>▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇████</td></tr><tr><td>loss</td><td>▇▆█▇▇▇▄▇▆▅▇▄▄▅▆▅▅▅▅▄▇▆▆▆▅▄▃▄▅█▃▂▃▄▆▁▅▃▇▆</td></tr><tr><td>num_bets_per</td><td>█▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>profit</td><td>▁▄▅▃▇▇▆▃▇▆█▆▆▆▅▆▆▅▆▇▃▆▆▄▄</td></tr><tr><td>test_accuracy</td><td>▁▇█████▇▇▇█▇▇▇▇▇▇▇▇▇▆▇▇▇▆</td></tr><tr><td>value_pick_roi</td><td>▁▆▅▄▄▃▄▆▅▃▆▄▆▅▆▅▆▆▇▅▅█▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>866</td></tr><tr><td>correct_conf</td><td>0.47598</td></tr><tr><td>epoch</td><td>249</td></tr><tr><td>incorrect_conf</td><td>0.41788</td></tr><tr><td>num_bets_per</td><td>3.16853</td></tr><tr><td>profit</td><td>-867.94</td></tr><tr><td>value_pick_roi</td><td>-0.23286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">unique-hill-3</strong>: <a href=\"https://wandb.ai/nickojelly/new%20customs/runs/9ncsg0qd\" target=\"_blank\">https://wandb.ai/nickojelly/new%20customs/runs/9ncsg0qd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_124939-9ncsg0qd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_config = {'batch_size': 32, 'dropout': 0.5, 'epochs': 250, 'f1_layer_size': 128, 'f2_layer_size': 128, 'learning_rate': 0.0001, 'loss': 'Huber_custom', 'l1_beta':0.1, 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
    "model = model_pipeline(config=wandb_config)\n",
    "# model = model_pipeline(config=wandb_config, prev_model=r'C:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\good models\\bumbling-sweep-6_430.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: icv88iyd\n",
      "Sweep URL: https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wisqv66j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 360\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.5810159406207785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00040775332522671894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_024029-wisqv66j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/wisqv66j\" target=\"_blank\">devout-sweep-1</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 360, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.5810159406207785, 'learning_rate': 0.00040775332522671894, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 360, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.5810159406207785, 'learning_rate': 0.00040775332522671894, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.4, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.4, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [24:04<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9665171fa7af4f24aa66f7166469847a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁███████████████████████████████████████</td></tr><tr><td>bfprofit</td><td>▁███████████████████████████████████████</td></tr><tr><td>correct_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>loss</td><td>▃▃▄▆▄▂▄▃▅▄▃▅▄▄▆▃▃█▅▆▄▄▃▅▄▃▅█▄▄▁▄▄▃▃▅▆▄▅▄</td></tr><tr><td>num_bets_per</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▁███████████████████████████████████████</td></tr><tr><td>test_accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>value_pick_roi</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>558</td></tr><tr><td>correct_conf</td><td>1.0</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>1.0</td></tr><tr><td>num_bets_per</td><td>0.98984</td></tr><tr><td>profit</td><td>-1290.75999</td></tr><tr><td>value_pick_roi</td><td>-0.18457</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devout-sweep-1</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/wisqv66j\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/wisqv66j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_024029-wisqv66j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 58vdc6r2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 360\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.23035562014566724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003995840263268522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_030444-58vdc6r2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/58vdc6r2\" target=\"_blank\">misunderstood-sweep-2</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 360, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.23035562014566724, 'learning_rate': 0.0003995840263268522, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 360, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.23035562014566724, 'learning_rate': 0.0003995840263268522, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.3, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:13<1:48:56, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [24:04<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697363a131f5458c9c07d6170cca73e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▇█████████▇▇▇▇██▇▇▇▇█▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>bfprofit</td><td>▁▆▄▆▅▄▆▇▇█▇▆▆▆▆▇▆▆▇▆▇█▆▇▇▇▇▇▆▆▆▆▇▆▅▆▆▇▇▇</td></tr><tr><td>correct_conf</td><td>▂▁▂▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▃▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>loss</td><td>█▇▇▇▆▅▄▄▄▄▃▃▃▂▂▂▁▁▂▂▂▁▁▂▁▂▁▂▂▁▂▂▁▁▂▁▁▂▂▁</td></tr><tr><td>num_bets_per</td><td>██▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▁▆▅▆▆▅▆▇▇█▇▇▆▆▆▇▆▇▇▆██▇▇▇▇▇▇▆▆▆▇▇▆▆▇▇▇▇▇</td></tr><tr><td>test_accuracy</td><td>▁▇██████▇█▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>value_pick_roi</td><td>▁▄▅▄▆▅▆▆▇▅▆▆▆▆▆▇▆▇▇▇██▇▇▇▇▇▇▆▇▆▇▇▆▆▇█▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>788</td></tr><tr><td>correct_conf</td><td>0.96657</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>0.95483</td></tr><tr><td>num_bets_per</td><td>1.09667</td></tr><tr><td>profit</td><td>-757.96</td></tr><tr><td>value_pick_roi</td><td>-0.11975</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misunderstood-sweep-2</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/58vdc6r2\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/58vdc6r2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_030444-58vdc6r2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 897nrzz9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.3410539694708842\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00031884557501169673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_032857-897nrzz9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/897nrzz9\" target=\"_blank\">radiant-sweep-3</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.3410539694708842, 'learning_rate': 0.00031884557501169673, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 128, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.3410539694708842, 'learning_rate': 0.00031884557501169673, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.3, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:13<1:50:13, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [30:32<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c88c537a0b494c876e18b814b27ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▁▁▁▁▇██▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▇▆▆▆▆▇▆</td></tr><tr><td>bfprofit</td><td>▁▁▁▁▁▄▃▆▃▅▂▂█▄▄▄▃▃▅▄▂▆▄▂█▅▂▄▄▂▂▃▃▆▃▂▁▃▅▂</td></tr><tr><td>correct_conf</td><td>█████▁▂▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>█████▁▂▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>loss</td><td>█▇▇▇▇▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▂▂▂▁▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>num_bets_per</td><td>▁▁▁▁▁█▇▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>profit</td><td>▁▁▁▁▁▅▅█▅▆▄▄█▅▅▅▄▅▆▅▄▆▄▄█▅▃▄▅▃▃▄▅▆▅▃▃▄▆▃</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▇██▇▇▇▇█▇▇▇▆▇▇▇▆▇▇▆▇▇▇▇▆▆▆▆▆▇▆▆▆▆▇▆</td></tr><tr><td>value_pick_roi</td><td>▃▃▃▃▃▁▄▄▆▅▆▅█▅▄▅▅▄▇▄▅▅▅▃▇▆▃▅▄▄▄▆▄▆▅▅▄▄▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>791</td></tr><tr><td>correct_conf</td><td>0.96814</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>0.95919</td></tr><tr><td>num_bets_per</td><td>1.08621</td></tr><tr><td>profit</td><td>-1095.52</td></tr><tr><td>value_pick_roi</td><td>-0.17135</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">radiant-sweep-3</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/897nrzz9\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/897nrzz9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_032857-897nrzz9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8wpe4i02 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.4396007728458785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001479281395136201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_035942-8wpe4i02</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/8wpe4i02\" target=\"_blank\">peach-sweep-4</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.4396007728458785, 'learning_rate': 0.0001479281395136201, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 64, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.4396007728458785, 'learning_rate': 0.0001479281395136201, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.3, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:14<2:01:30, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [41:01<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6eaf70e77841e3954551eeb23388cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁███▇▇▇▇▇▇▇▇▇▆▇▇▇▆▇▇▇▇▆▆▇▇▇▆▆▆▆▆▇▆▇▇▆▆▇▆</td></tr><tr><td>bfprofit</td><td>▇▂▄▄▄▄▅▇▅▇█▅▄▄▃▃▁▄▄▁▄▂▆▄▆▄▇▃▂▃▅▃▅▅▇▃▅▃▂▅</td></tr><tr><td>correct_conf</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>loss</td><td>█▇▇▆▅▆▅▃▄▄▅▃▂▃▂▂▃▁▂▃▂▂▂▂▃▂▁▂▁▃▁▁▁▂▃▁▁▁▂▁</td></tr><tr><td>num_bets_per</td><td>█▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▂▂▄▄▅▃▅▇▄▆█▅▃▃▃▂▁▃▃▁▄▂▅▃▄▃▇▃▂▂▄▂▅▄▆▃▄▂▁▄</td></tr><tr><td>test_accuracy</td><td>▁████▇▇▇▇▇▇▇▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇▇▆▇▇▆▇▆▇▇▇▆▇▇</td></tr><tr><td>value_pick_roi</td><td>▁▅▄▅▆▆▆█▇▆▆█▆▅▆▆▆▅▇▆▆▆▇▅▆▆▆▇▅▅▆▆▇▆▇▆▇▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>802</td></tr><tr><td>correct_conf</td><td>0.96296</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>0.95688</td></tr><tr><td>num_bets_per</td><td>1.09204</td></tr><tr><td>profit</td><td>-903.22001</td></tr><tr><td>value_pick_roi</td><td>-0.14375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">peach-sweep-4</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/8wpe4i02\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/8wpe4i02</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_035942-8wpe4i02\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3hwfzp4j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.6651938193723773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004561401793457596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_044054-3hwfzp4j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/3hwfzp4j\" target=\"_blank\">devoted-sweep-5</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.6651938193723773, 'learning_rate': 0.0004561401793457596, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 64, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.6651938193723773, 'learning_rate': 0.0004561401793457596, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.3, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:14<2:02:46, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [41:18<00:00,  4.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915e9ebb47bc4085966437d48a53cdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bfprofit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>correct_conf</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▄▃▆▅▆▅▄▆▂▁▄▂▄█▃▂▂▄▅▃▃▇▄▄▅▅▃▃▃▅▁▅▃▄▅▄▄▂▅▇</td></tr><tr><td>num_bets_per</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_pick_roi</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>478</td></tr><tr><td>correct_conf</td><td>1.0</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>1.0</td></tr><tr><td>num_bets_per</td><td>0.9997</td></tr><tr><td>profit</td><td>-1629.18</td></tr><tr><td>value_pick_roi</td><td>-0.24319</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devoted-sweep-5</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/3hwfzp4j\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/3hwfzp4j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_044054-3hwfzp4j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4ydfcj9r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 720\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.5175155642910485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 9.196069190540892e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_052222-4ydfcj9r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/4ydfcj9r\" target=\"_blank\">wobbly-sweep-6</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 720, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.5175155642910485, 'learning_rate': 9.196069190540892e-05, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 720, 'dropout': 0.3, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.5175155642910485, 'learning_rate': 9.196069190540892e-05, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.3, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:11<1:35:47, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [22:43<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fd9fedf03e484d8415c999b2fc59d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▆▇▆▇████▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>bfprofit</td><td>▁▇▅▇▂▇██▅▆▄▆▆▄▄▄▃▅▆▅▆▅▅▆▆▅▅▆▆▅▄▅▄▃▄▄▄▄▃▅</td></tr><tr><td>correct_conf</td><td>▆▁▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▇▁▂▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>loss</td><td>█▆▆▅▅▅▄▄▄▄▄▅▃▄▃▄▃▃▃▄▃▂▃▃▃▃▂▃▂▃▂▁▂▂▂▂▃▁▂▁</td></tr><tr><td>num_bets_per</td><td>▂█▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▁▇▅▅▃▇██▆▅▄▆▆▅▄▄▄▆▆▆▆▅▅▆▆▆▅▆▆▅▄▅▅▄▄▄▅▄▄▅</td></tr><tr><td>test_accuracy</td><td>▁▆▆▇▇█████▇███▇▇▇████▇█▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>value_pick_roi</td><td>▁▂▃▅█▆▆▇▆▇█▆▆▇▆█▆▇▆▇▆█▆▆▆█▆▇▇▆▇▆▆▇▅▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>859</td></tr><tr><td>correct_conf</td><td>0.84434</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>0.81142</td></tr><tr><td>num_bets_per</td><td>1.40804</td></tr><tr><td>profit</td><td>-934.78</td></tr><tr><td>value_pick_roi</td><td>-0.18377</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wobbly-sweep-6</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/4ydfcj9r\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/4ydfcj9r</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_052222-4ydfcj9r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w40d984z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.869223566568005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002711540389351009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_054518-w40d984z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/w40d984z\" target=\"_blank\">graceful-sweep-7</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.869223566568005, 'learning_rate': 0.0002711540389351009, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 64, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.869223566568005, 'learning_rate': 0.0002711540389351009, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.4, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.4, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:14<2:00:38, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [41:14<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c598d6cef94a93b2db2bf3f92c685a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bfprofit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>correct_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>loss</td><td>▅▄▅▄▄▆▇▄▄▄▇▆▃█▃█▃▄▄▆▃▆▅▁▄▄▇▄▁▆▅▆▄▃▅▄▅▃█▃</td></tr><tr><td>num_bets_per</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_pick_roi</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>558</td></tr><tr><td>correct_conf</td><td>1.0</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>1.0</td></tr><tr><td>num_bets_per</td><td>0.98984</td></tr><tr><td>profit</td><td>-1290.75999</td></tr><tr><td>value_pick_roi</td><td>-0.18457</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">graceful-sweep-7</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/w40d984z\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/w40d984z</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_054518-w40d984z\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0s3dsl2y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.9992367509357972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000480024117927099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_062650-0s3dsl2y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/0s3dsl2y\" target=\"_blank\">true-sweep-8</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.9992367509357972, 'learning_rate': 0.000480024117927099, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 128, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.9992367509357972, 'learning_rate': 0.000480024117927099, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.4, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.4, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:12<1:46:09, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [30:32<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd04344eb2e34bc187dde8f1bcb3741d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▅████▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bfprofit</td><td>▅▆▆▆▆▁▁▁▁███████████████████████████████</td></tr><tr><td>correct_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>loss</td><td>▃▄▃▄▄▆▂▅▃▄▄▃▄▆▂▅▃▃▃▅▅▆▄▁▂▄▃▆▄█▄▆▅▆▅▆▆▆▃▃</td></tr><tr><td>num_bets_per</td><td>█▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>profit</td><td>█████▁▁▁▁███████████████████████████████</td></tr><tr><td>test_accuracy</td><td>▆████▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_pick_roi</td><td>▇████▁▁▁▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>445</td></tr><tr><td>correct_conf</td><td>1.0</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>1.0</td></tr><tr><td>num_bets_per</td><td>1.0</td></tr><tr><td>profit</td><td>-1296.93999</td></tr><tr><td>value_pick_roi</td><td>-0.19378</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-8</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/0s3dsl2y\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/0s3dsl2y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_062650-0s3dsl2y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yw8idtms with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.7191655263684742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00045616489444464607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_065736-yw8idtms</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/yw8idtms\" target=\"_blank\">scarlet-sweep-9</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'dropout': 0.5, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.7191655263684742, 'learning_rate': 0.00045616489444464607, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 128, 'dropout': 0.5, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.7191655263684742, 'learning_rate': 0.00045616489444464607, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:12<1:47:44, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [30:39<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5441d944d91345438b85e37e0963bb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁███████████████████████████████████████</td></tr><tr><td>bfprofit</td><td>▁███████████████████████████████████████</td></tr><tr><td>correct_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>loss</td><td>▄▇▃▄█▁▆▆█▇▇▆▅▃▆▆▃█▅▅▄▄▃▅▅▅▄▅▆▄▅▆▆▇▅▇▇▆▆▇</td></tr><tr><td>num_bets_per</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>value_pick_roi</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>558</td></tr><tr><td>correct_conf</td><td>1.0</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>1.0</td></tr><tr><td>num_bets_per</td><td>0.98984</td></tr><tr><td>profit</td><td>-1290.75999</td></tr><tr><td>value_pick_roi</td><td>-0.18457</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">scarlet-sweep-9</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/yw8idtms\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/yw8idtms</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_065736-yw8idtms\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ltrd0vkr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 360\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.5489830041209195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004008324468715094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_072834-ltrd0vkr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/ltrd0vkr\" target=\"_blank\">fast-sweep-10</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 360, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.5489830041209195, 'learning_rate': 0.0004008324468715094, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 360, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.5489830041209195, 'learning_rate': 0.0004008324468715094, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.4, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.4, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:12<1:43:44, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [24:04<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d9c6ea3eb84d87a8d5755ecc48f0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▇▇██████▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▆▇▇▆▆▇▆</td></tr><tr><td>bfprofit</td><td>▁▂▃▆▅▅▇▆▆▇▆▇▇▇▆█▆▇▇▇▅▆█▆▇▆▇█▅▇▆▅▆▆▆▅▅▅▄▄</td></tr><tr><td>correct_conf</td><td>█▁▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>█▁▂▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>loss</td><td>█▆▆▆▆▆▅▃▃▂▃▂▂▂▂▂▁▁▁▂▂▂▁▂▁▁▂▁▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>num_bets_per</td><td>▁█▇▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>profit</td><td>▁▃▄▇▆▅▇▆▆▇▆▇▇▇▆▇▆▇▇▇▅▆█▆█▆▇▇▆▇▇▆▆▆▆▆▆▅▆▅</td></tr><tr><td>test_accuracy</td><td>▁▇▇██████▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>value_pick_roi</td><td>▂▂▁▂▄▄▅▅▅▇▆▇▆▇▆▇▆▇██▇▇█▇█▇▆▇▆▇▇▆▆▆▅▇▆▇▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>796</td></tr><tr><td>correct_conf</td><td>0.96427</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>0.95482</td></tr><tr><td>num_bets_per</td><td>1.09921</td></tr><tr><td>profit</td><td>-886.5</td></tr><tr><td>value_pick_roi</td><td>-0.15168</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fast-sweep-10</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/ltrd0vkr\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/ltrd0vkr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_072834-ltrd0vkr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ym9h9d7w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 360\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.33961540547196845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004179255880612379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_075250-ym9h9d7w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/ym9h9d7w\" target=\"_blank\">silver-sweep-11</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 360, 'dropout': 0.5, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.33961540547196845, 'learning_rate': 0.0004179255880612379, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 360, 'dropout': 0.5, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.33961540547196845, 'learning_rate': 0.0004179255880612379, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:12<1:43:12, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [24:08<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8277eef790438b9b156c078e4090a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bfprofit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>correct_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▁███████████████████████████████████████</td></tr><tr><td>loss</td><td>▆▇▄▆▄▅█▄▅▄▅▃▆▅▇▄▄▄▃▅▇▅▆█▅▁▄▅▆▆▇▄▄▆▃▄▄▅▄▆</td></tr><tr><td>num_bets_per</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_pick_roi</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>558</td></tr><tr><td>correct_conf</td><td>1.0</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>1.0</td></tr><tr><td>num_bets_per</td><td>0.98984</td></tr><tr><td>profit</td><td>-1290.75999</td></tr><tr><td>value_pick_roi</td><td>-0.18457</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">silver-sweep-11</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/ym9h9d7w\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/ym9h9d7w</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_075250-ym9h9d7w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yc25tvxt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.36961056619203314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004901785761575497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_081738-yc25tvxt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/yc25tvxt\" target=\"_blank\">fiery-sweep-12</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.36961056619203314, 'learning_rate': 0.0004901785761575497, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.36961056619203314, 'learning_rate': 0.0004901785761575497, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:14<2:00:36, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [41:26<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36deb7ac9bd746d682eea3bd1222409f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bfprofit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>correct_conf</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▅▆▄▄▃▂█▃▃▁▅▄▇█▁▄▃▃▃▂▅▇▆▅▆▅▄▂▃▄▂▆▄▃▆█▆▄▁▆</td></tr><tr><td>num_bets_per</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>value_pick_roi</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>478</td></tr><tr><td>correct_conf</td><td>1.0</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>1.0</td></tr><tr><td>num_bets_per</td><td>0.9997</td></tr><tr><td>profit</td><td>-1629.18</td></tr><tr><td>value_pick_roi</td><td>-0.24319</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fiery-sweep-12</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/yc25tvxt\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/yc25tvxt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_081738-yc25tvxt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zt1jaw3q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.9514586822415588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002476464510461381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_085915-zt1jaw3q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/zt1jaw3q\" target=\"_blank\">feasible-sweep-13</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.9514586822415588, 'learning_rate': 0.0002476464510461381, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.9514586822415588, 'learning_rate': 0.0002476464510461381, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:14<2:01:34, 14.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [41:24<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b4e31afc3647b0829fe3061e1efb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>▁▇█████▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇</td></tr><tr><td>bfprofit</td><td>▁▄▆▆█▄▇▆▇▇█▅▅▇▅▆▇▅█▄▇▆▄▄▅▆▆▆▄▄▆▄▄▄▄▅▃▃▃▅</td></tr><tr><td>correct_conf</td><td>█▁▂▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>incorrect_conf</td><td>█▁▂▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>loss</td><td>█▄▆▃▅▄▄▂▃▂▂▂▂▂▃▁▂▃▃▂▂▂▂▂▂▂▁▂▁▁▁▂▂▁▁▂▁▃▁▁</td></tr><tr><td>num_bets_per</td><td>▁█▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>profit</td><td>▁▅▇▆█▅▇▆▇▆▇▅▅▇▅▆▇▅▇▄▇▅▄▄▅▆▆▇▄▅▅▄▄▄▄▅▃▄▃▅</td></tr><tr><td>test_accuracy</td><td>▁▇██████▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>value_pick_roi</td><td>▁▃▃▃▅▄█▇▇▆▆█▅▇▆▇█▅█▅▆▇▅▅▅▆▆▅▃▅▅▆▅▅▆▆▄▅▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bfnotavail</td><td>826</td></tr><tr><td>correct_conf</td><td>0.97456</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>incorrect_conf</td><td>0.96945</td></tr><tr><td>num_bets_per</td><td>1.06455</td></tr><tr><td>profit</td><td>-936.38</td></tr><tr><td>value_pick_roi</td><td>-0.14581</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">feasible-sweep-13</strong>: <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/zt1jaw3q\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/zt1jaw3q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220821_085915-zt1jaw3q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4o59r2mq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf2_layer_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl1_beta: 0.6804381740174369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.813183771033159e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: Custom\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvalidation_split: 0.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\wandb\\run-20220821_094049-4o59r2mq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/runs/4o59r2mq\" target=\"_blank\">hopeful-sweep-14</a></strong> to <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd\" target=\"_blank\">https://wandb.ai/nickojelly/grv_priced_sweep_l1_test_new/sweeps/icv88iyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.6804381740174369, 'learning_rate': 7.813183771033159e-05, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "500\n",
      "{'batch_size': 64, 'dropout': 0.4, 'epochs': 500, 'f1_layer_size': 256, 'f2_layer_size': 256, 'l1_beta': 0.6804381740174369, 'learning_rate': 7.813183771033159e-05, 'loss': 'Custom', 'num_layers': 2, 'optimizer': 'adam', 'validation_split': 0.1}\n",
      "Sequential(\n",
      "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.4, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.4, inplace=False)\n",
      "  (6): Linear(in_features=256, out_features=8, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:14<2:01:16, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 226/500 [19:19<21:15,  4.66s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "#model_pipeline(config)\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"grv_priced_sweep_l1_test_new\")\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=120, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (7): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43115443075634c02a7c247a87b0dd9d74842892e56d473b9e19f544f3149aff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
