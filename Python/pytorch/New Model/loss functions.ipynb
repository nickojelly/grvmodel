{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "with torch.profiler.profile() as profiler:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_MSE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\loss functions.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m loss_functions \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mHuber\u001b[39m\u001b[39m\"\u001b[39m:nn\u001b[39m.\u001b[39mHuberLoss(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mMSE\u001b[39m\u001b[39m\"\u001b[39m:nn\u001b[39m.\u001b[39mMSELoss(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mL1\u001b[39m\u001b[39m\"\u001b[39m:nn\u001b[39m.\u001b[39mSmoothL1Loss(reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m, beta\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBCE\u001b[39m\u001b[39m\"\u001b[39m:nn\u001b[39m.\u001b[39mCrossEntropyLoss(),\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCustom\u001b[39m\u001b[39m\"\u001b[39m:custom_MSE,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mKL\u001b[39m\u001b[39m\"\u001b[39m:nn\u001b[39m.\u001b[39mKLDivLoss(reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbatchmean\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'custom_MSE' is not defined"
     ]
    }
   ],
   "source": [
    "loss_functions = {\n",
    "    \"Huber\":nn.HuberLoss(),\n",
    "    \"MSE\":nn.MSELoss(),\n",
    "    \"L1\":nn.SmoothL1Loss(reduction='sum', beta=0.5),\n",
    "    \"BCE\":nn.CrossEntropyLoss(),\n",
    "    \"Custom\":custom_MSE,\n",
    "    \"KL\":nn.KLDivLoss(reduction='batchmean')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber = loss_functions[\"Huber\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tests(output,target):\n",
    "    huber = nn.HuberLoss(),\n",
    "    mse = nn.MSELoss(),\n",
    "    l1 = nn.SmoothL1Loss(reduction='sum', beta=0.5),\n",
    "    bce = nn.CrossEntropyLoss(),\n",
    "    Custom = custom_MSE,\n",
    "    kl = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "    print(f\"huber = {huber(output,target)}\")\n",
    "    print(f\"l1 = {l1(output,target)}\")\n",
    "    print(f\"MSE = {mse(output,target)}\")\n",
    "    print(f\"bce = {bce(output,target)}\")\n",
    "    print(f\"KL = {kl(output,target)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\loss functions.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sftmax \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSoftmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m loss_tests(sftmax(x), sftmax(y))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "sftmax = torch.nn.Softmax(dim=1)\n",
    "loss_tests(sftmax(x), sftmax(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_MSE(output, target):\n",
    "    print(target.float())\n",
    "    sorts_t = torch.argsort(target)\n",
    "    sorts_o = torch.argsort(output)\n",
    "    print(sorts_t)\n",
    "    print(sorts_o)\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    print(out)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    print(ohe)\n",
    "    out_first3 = ohe*output\n",
    "    target_ohe = ohe*target\n",
    "    print(f\"{out_first3=},\\n{target_ohe=}\")\n",
    "    print(f\"delta = {abs(out_first3-target_ohe)+1}\")\n",
    "    print(f\"delta 2 = {abs(out_first3-target_ohe)**2+1}\")\n",
    "    loss = torch.mean((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "    print((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "    print(\"h\",((abs(out_first3-target_ohe)*10)**2))\n",
    "    # loss = torch.sum(((out_first3-target_ohe))**2)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_huber(output, target):\n",
    "    print(target.float())\n",
    "    sorts_t = torch.argsort(target)\n",
    "    sorts_o = torch.argsort(output)\n",
    "    print(sorts_t)\n",
    "    print(sorts_o)\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    print(out)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    print(ohe)\n",
    "    out_first3 = ohe*output\n",
    "    target_ohe = ohe*target\n",
    "    print(f\"{out_first3=},\\n{target_ohe=}\")\n",
    "    print(f\"delta = {0.5*(out_first3-target_ohe)**2/0.2}\")\n",
    "    print(f\"delta 2 = {abs(out_first3-target_ohe)**2+1}\")\n",
    "    loss = torch.mean((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "    print((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "    print(\"h\",((abs(out_first3-target_ohe)*10)**2))\n",
    "    # loss = torch.sum(((out_first3-target_ohe))**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_KL(output, target):\n",
    "    print(target.float())\n",
    "    sorts_t = torch.argsort(target)\n",
    "    sorts_o = torch.argsort(output)\n",
    "    target100 = target*100\n",
    "    output100 = output*100\n",
    "    print(sorts_t)\n",
    "    print(sorts_o)\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    print(out)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    print(ohe)\n",
    "    out_first3 = ohe*output\n",
    "    target_ohe = ohe*target\n",
    "    print(f\"{out_first3=},\\n{target_ohe=}\")\n",
    "\n",
    "    print(f\"delta = {abs(out_first3-target_ohe)+1}\")\n",
    "\n",
    "    print(f\"reg log deltas = {target100*(target100.log()-output100.log())}\")\n",
    "\n",
    "    print(f\"log deltas = {(target_ohe+1)*((target_ohe+1).log()-(out_first3+1).log())}\")\n",
    "\n",
    "    loss = torch.mean((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "\n",
    "    print((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "\n",
    "    print(\"h\",((abs(out_first3-target_ohe)*10)**2))\n",
    "\n",
    "    # loss = torch.sum(((out_first3-target_ohe))**2)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_order(output, target):\n",
    "    print(f\"{target}\\n{output}\")\n",
    "    sorts_t = torch.argsort(target)\n",
    "    sorts_o = torch.argsort(output)\n",
    "    print(sorts_t)\n",
    "    print(sorts_o)\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    print(out)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    print(ohe)\n",
    "    out_first3 = ohe*output\n",
    "    target_ohe = ohe*target\n",
    "    print(f\"{out_first3=},\\n{target_ohe=}\")\n",
    "    print(f\"delta = {abs(out_first3-target_ohe)+1}\")\n",
    "    print(f\"delta 2 = {abs(out_first3-target_ohe)**2+1}\")\n",
    "    loss = torch.mean((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "    print((((target_ohe+1)*abs(out_first3-target_ohe)+1)**2))\n",
    "    print(\"h\",((abs(out_first3-target_ohe)*10)**2))\n",
    "    # loss = torch.sum(((out_first3-target_ohe))**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3233e-01, 1.5674e-03, 1.1582e-02, 8.5577e-02, 3.1482e-02, 4.2606e-03,\n",
      "         5.7661e-04, 2.3262e-01],\n",
      "        [2.3262e-01, 1.5674e-03, 8.5577e-02, 6.3233e-01, 5.7661e-04, 4.2606e-03,\n",
      "         1.1582e-02, 3.1482e-02]])\n",
      "tensor([[6, 1, 5, 2, 4, 3, 7, 0],\n",
      "        [4, 1, 5, 6, 7, 2, 0, 3]])\n",
      "tensor([[4, 1, 5, 6, 7, 2, 0, 3],\n",
      "        [6, 1, 5, 2, 4, 3, 7, 0]])\n",
      "tensor([[6, 1, 5],\n",
      "        [4, 1, 5]])\n",
      "tensor([[0, 1, 0, 0, 0, 1, 1, 0],\n",
      "        [0, 1, 0, 0, 1, 1, 0, 0]])\n",
      "out_first3=tensor([[0.0000, 0.0016, 0.0000, 0.0000, 0.0000, 0.0043, 0.0116, 0.0000],\n",
      "        [0.0000, 0.0016, 0.0000, 0.0000, 0.0315, 0.0043, 0.0000, 0.0000]]),\n",
      "target_ohe=tensor([[0.0000, 0.0016, 0.0000, 0.0000, 0.0000, 0.0043, 0.0006, 0.0000],\n",
      "        [0.0000, 0.0016, 0.0000, 0.0000, 0.0006, 0.0043, 0.0000, 0.0000]])\n",
      "delta = tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0110, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0309, 1.0000, 1.0000, 1.0000]])\n",
      "reg log deltas = tensor([[ 63.2333,   0.0000,  -2.3163, -17.1154,  12.5928,   0.0000,  -0.1730,\n",
      "          46.5244],\n",
      "        [-23.2622,   0.0000,  17.1154, 126.4665,  -0.2306,   0.0000,   3.4745,\n",
      "          -6.2964]])\n",
      "log deltas = tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0109,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0304,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0221, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0628, 1.0000, 1.0000, 1.0000]])\n",
      "h tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0121, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0955, 0.0000, 0.0000, 0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0053)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[7.0,2.0,6.0,8.0,1.0,3.0,4.0,5.0],[8.0,2.0,4.0,6.0,5.0,3.0,1.0,7.0]])\n",
    "y = torch.tensor([[8.0,2.0,4.0,6.0,5.0,3.0,1.0,7.0],[7.0,2.0,6.0,8.0,1.0,3.0,4.0,5.0]])\n",
    "x_idx = custom_KL(sftmax(x),sftmax(y))\n",
    "x_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_customiser(loss_func,x,y):\n",
    "    sorts_t = torch.argsort(sftmax(y))+1\n",
    "    sorts_factor = 1/sorts_t\n",
    "    print(sorts_factor)\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    loss = loss_func(x,y)\n",
    "    loss_ohe = loss*ohe\n",
    "    print(f\"{sorts_t}\\n{out}\\n{ohe}\\n{loss}\\n{loss_ohe}\")\n",
    "    return (torch.mean(loss),torch.mean(loss_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_customiser(loss_func,x,y):\n",
    "    sorts_t = torch.argsort(sftmax(y))+1\n",
    "    sorts_o = torch.argsort(sftmax(x))+1\n",
    "    sorts_factor = 1/sorts_t\n",
    "    print(sorts_t)\n",
    "    print(sorts_o)\n",
    "    print(abs(sorts_t-sorts_o))\n",
    "    out = sorts_t.narrow(1,0,3)\n",
    "    ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "    loss = loss_func(x,y)\n",
    "    loss_ohe = loss*ohe\n",
    "    loss_place = loss*abs(sorts_t-sorts_o)\n",
    "    print(f\"{sorts_t}\\n{out}\\n{ohe}\\n{loss}\\n{loss_ohe}\")\n",
    "    return (torch.mean(loss),torch.mean(loss_ohe), torch.mean(loss_place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 2, 6, 3, 5, 4, 8, 1],\n",
      "        [5, 2, 6, 7, 8, 3, 1, 4]])\n",
      "tensor([[5, 2, 6, 7, 8, 3, 1, 4],\n",
      "        [7, 2, 6, 3, 5, 4, 8, 1]])\n",
      "tensor([[2, 0, 0, 4, 3, 1, 7, 3],\n",
      "        [2, 0, 0, 4, 3, 1, 7, 3]])\n",
      "tensor([[7, 2, 6, 3, 5, 4, 8, 1],\n",
      "        [5, 2, 6, 7, 8, 3, 1, 4]])\n",
      "tensor([[7, 2, 6],\n",
      "        [5, 2, 6]])\n",
      "tensor([[0, 0, 1, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 1, 0, 0, 1, 1, 0]])\n",
      "tensor([[7.9884e-02, 0.0000e+00, 2.7377e-03, 1.4947e-01, 4.7757e-04, 0.0000e+00,\n",
      "         6.0555e-05, 2.0229e-02],\n",
      "        [7.9884e-02, 0.0000e+00, 2.7377e-03, 1.4947e-01, 4.7757e-04, 0.0000e+00,\n",
      "         6.0555e-05, 2.0229e-02]])\n",
      "tensor([[0.0000e+00, 0.0000e+00, 2.7377e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.0555e-05, 2.0229e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 2.7377e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         6.0555e-05, 0.0000e+00]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0316), tensor(0.0016), tensor(0.1025))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber = nn.HuberLoss(reduction='none')\n",
    "\n",
    "sorts_t = torch.argsort(sftmax(y))\n",
    "out = sorts_t.narrow(1,0,3)\n",
    "ohe = torch.nn.functional.one_hot(out, num_classes=8).sum(1)\n",
    "\n",
    "huber(sftmax(x),sftmax(y))*ohe\n",
    "\n",
    "loss_customiser(huber, sftmax(x),sftmax(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"softmax_lastdim_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\grvmodel\\Python\\pytorch\\New Model\\loss functions.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sftmax \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSoftmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/grvmodel/Python/pytorch/New%20Model/loss%20functions.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sftmax(y)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1376\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1376\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49msoftmax(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim, _stacklevel\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1834\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1832\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1833\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1834\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   1835\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1836\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"softmax_lastdim_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "sftmax = torch.nn.Softmax(dim=1)\n",
    "sftmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43115443075634c02a7c247a87b0dd9d74842892e56d473b9e19f544f3149aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
